{"id": "8158bb9a-3f90-4f3e-b53a-db285aadf174", "solution": "import numpy as np\n\nclass ADELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 10 * dim  # Population size, adjustable\n        self.mutation_factor = 0.8  # DE mutation factor, can be adaptive\n        self.crossover_rate = 0.9  # DE crossover rate, can be adaptive\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.1\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Perform local search on the best found individual\n            local_candidate = self._local_search(best_individual, best_individual)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n        return best_individual, best_fitness", "name": "ADELS", "description": "Adaptive Differential Evolution with Local Search (ADELS) combines differential evolution and local search strategies to balance global exploration and local exploitation, optimizing functions efficiently within a given evaluation budget.", "configspace": "", "generation": 0, "fitness": 0.25932572156286077, "feedback": "The algorithm ADELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.21.", "error": "", "parent_id": null, "metadata": {"aucs": [0.630910768422311, 0.6228440785586251, 0.6368137546274093, 0.6433491067634066, 0.6307880254592593, 0.6369415448622462, 0.6116005503586031, 0.6303615239780753, 0.6496024518393061, 0.37244403461717346, 0.4134850327906554, 0.3576797559243914, 0.3773074945398024, 0.3932026054052037, 0.3905718642236051, 0.3810442226849272, 0.39568061659782616, 0.37936489889306235, 0.08016041582790445, 0.09381464177706056, 0.10278919040333678, 0.1191987476635008, 0.09592849955094374, 0.0937077412369095, 0.08991358470904764, 0.0983941392557297, 0.10797650730278074, 0.09740971284971256, 0.09853438768453471, 0.09066055633996584, 0.08756355774900382, 0.09446615720405993, 0.09490851469219141, 0.08186325772983039, 0.08734853279476351, 0.0866317250073767, 0.9257932563172493, 0.9402464215905781, 0.9244295713636397, 0.9602083053870073, 0.9420404066823631, 0.9430614426719448, 0.9580014884761265, 0.9632243878310324, 0.9572389674383627, 0.295824637287318, 0.2715857679629353, 0.3019603767777831, 0.3130686611670086, 0.2846350960240692, 0.2708174845437399, 0.28231744416732096, 0.31176545655457877, 0.3022707414681173, 0.46981570857480315, 0.5667165294165957, 0.5465032429213206, 0.5489456543995614, 0.5077414493183774, 0.5878239420591593, 0.5089625720416169, 0.5709014559675907, 0.4693703988789787, 0.2013794363967919, 0.18971350166860834, 0.208622285025567, 0.1478751406995118, 0.2013279925956627, 0.1995563671126377, 0.2226667954180701, 0.2096848187186754, 0.1878943128684436, 0.015996673817001317, 0.021061321437804148, 0.2137615813162982, 0.22532807581887881, 0.1957440641809951, 0.179190196289423, 0.20158696790963282, 0.20046572057290368, 0.21189124749017063, 0.12171444826644728, 0.1550328393529904, 0.1156086428099774, 0.11839401673579864, 0.14323490526425908, 0.1250302808838707, 0.13506274013165254, 0.12764797908030234, 0.13114145479681394, 0.24794648280086007, 0.2555154805695543, 0.24379138792336674, 0.25404083409836353, 0.2218806077446046, 0.2813917511726727, 0.247243115400957, 0.27347437000062236, 0.27126292727957535, 0.03055858421986757, 0.03996331227490668, 0.03828391890619498, 0.027784774073799645, 0.034738682326604375, 0.05134409365241521, 0.019483894217274256, 0.01569940721296681, 0.03582787682631405, 0.15023265238293482, 0.14648230587861066, 0.16376072335608605, 0.15313283504602038, 0.17167286504045964, 0.1690241745303156, 0.16103178244888894, 0.16352652119791933, 0.16607512573940708, 0.47115273409020064, 0.484611889539977, 0.4818212818623442, 0.4821672943260139, 0.4841543297946266, 0.4874987148801396, 0.47212911683809955, 0.47768712153765713, 0.4876777670076289, 0.08027471468964176, 0.08919474295218699, 0.08861705005130793, 0.09024499927606033, 0.08006252782830903, 0.08634035799881334, 0.0791875040996467, 0.08576322537947001, 0.080182476156616, 0.14467194397565541, 0.13499315892565333, 0.12886093622941552, 0.12974500552433654, 0.13731315163403124, 0.20560571025954155, 0.13723435212975033, 0.12562819965953897, 0.13708858308043215, 0.28776925745713355, 0.2548771488091336, 0.27701670180617366, 0.2540672327499097, 0.2709818632554669, 0.263797481213364, 0.2851246500548904, 0.2915882349898946, 0.28138192269079076, 0.19682454310509634, 0.21844725855421177, 0.218058101301564, 0.19613360915652778, 0.19061778340376023, 0.18476519165471872, 0.20385080802686084, 0.22507500476252185, 0.22020281045128387, 0.1992664508760672, 0.18707136867366958, 0.17768715871067486, 0.20452181530206082, 0.17707790091039455, 0.1819267561258655, 0.1783790484549338, 0.17462381431233098, 0.1784462569442481, 0.1771663847502426, 0.16888053981640572, 0.17736629503624024, 0.17735564044012353, 0.17047516857210032, 0.18796226454652465, 0.17951891859271563, 0.16744435144956316, 0.18203637657022143, 0.5605145422382731, 0.1904077205645477, 0.17989701707319838, 0.5720550490954972, 0.176281786785777, 0.19819746421783746, 0.2622197587089692, 0.27464187991295896, 0.25496140139599244, 0.196090430958203, 0.19944805946096877, 0.187068995639616, 0.18804678151649423, 0.18983785236952122, 0.3536388173677081, 0.2077571360425694, 0.14845001083018872, 0.208780516961537, 0.18715294249579384, 0.17635514087395732, 0.18456783039416658, 0.181067527435269, 0.16298585139925836, 0.17991334108025525, 0.19820853179556674, 0.18923726623201764, 0.19676431057872956, 0.06708628542175643, 0.07132326452243165, 0.06666674050854249, 0.06695901941634153, 0.07208554397161604, 0.07586999806601458, 0.07713995583314881, 0.08551246494595321, 0.06715225761799848]}, "mutation_prompt": null}
{"id": "f792bcf6-385e-41cc-b814-f7469b81f38b", "solution": "import numpy as np\n\nclass ADELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 10 * dim  # Population size, adjustable\n        self.mutation_factor = 0.8  # DE mutation factor, can be adaptive\n        self.crossover_rate = 0.9  # DE crossover rate, can be adaptive\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.1\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Perform local search on the best found individual\n            local_candidate = self._local_search(best_individual, best_individual)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n        return best_individual, best_fitness", "name": "ADELS", "description": "Adaptive Differential Evolution with Local Search (ADELS) combines differential evolution and local search strategies to balance global exploration and local exploitation, optimizing functions efficiently within a given evaluation budget.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8158bb9a-3f90-4f3e-b53a-db285aadf174", "metadata": {"aucs": [0.630910768422311, 0.6228440785586251, 0.6368137546274093, 0.6433491067634066, 0.6307880254592593, 0.6369415448622462, 0.6116005503586031, 0.6303615239780753, 0.6496024518393061, 0.37244403461717346, 0.4134850327906554, 0.3576797559243914, 0.3773074945398024, 0.3932026054052037, 0.3905718642236051, 0.3810442226849272, 0.39568061659782616, 0.37936489889306235, 0.08016041582790445, 0.09381464177706056, 0.10278919040333678, 0.1191987476635008, 0.09592849955094374, 0.0937077412369095, 0.08991358470904764, 0.0983941392557297, 0.10797650730278074, 0.09740971284971256, 0.09853438768453471, 0.09066055633996584, 0.08756355774900382, 0.09446615720405993, 0.09490851469219141, 0.08186325772983039, 0.08734853279476351, 0.0866317250073767, 0.9257932563172493, 0.9402464215905781, 0.9244295713636397, 0.9602083053870073, 0.9420404066823631, 0.9430614426719448, 0.9580014884761265, 0.9632243878310324, 0.9572389674383627, 0.295824637287318, 0.2715857679629353, 0.3019603767777831, 0.3130686611670086, 0.2846350960240692, 0.2708174845437399, 0.28231744416732096, 0.31176545655457877, 0.3022707414681173, 0.46981570857480315, 0.5667165294165957, 0.5465032429213206, 0.5489456543995614, 0.5077414493183774, 0.5878239420591593, 0.5089625720416169, 0.5709014559675907, 0.4693703988789787, 0.2013794363967919, 0.18971350166860834, 0.208622285025567, 0.1478751406995118, 0.2013279925956627, 0.1995563671126377, 0.2226667954180701, 0.2096848187186754, 0.1878943128684436, 0.015996673817001317, 0.021061321437804148, 0.2137615813162982, 0.22532807581887881, 0.1957440641809951, 0.179190196289423, 0.20158696790963282, 0.20046572057290368, 0.21189124749017063, 0.12171444826644728, 0.1550328393529904, 0.1156086428099774, 0.11839401673579864, 0.14323490526425908, 0.1250302808838707, 0.13506274013165254, 0.12764797908030234, 0.13114145479681394, 0.24794648280086007, 0.2555154805695543, 0.24379138792336674, 0.25404083409836353, 0.2218806077446046, 0.2813917511726727, 0.247243115400957, 0.27347437000062236, 0.27126292727957535, 0.03055858421986757, 0.03996331227490668, 0.03828391890619498, 0.027784774073799645, 0.034738682326604375, 0.05134409365241521, 0.019483894217274256, 0.01569940721296681, 0.03582787682631405, 0.15023265238293482, 0.14648230587861066, 0.16376072335608605, 0.15313283504602038, 0.17167286504045964, 0.1690241745303156, 0.16103178244888894, 0.16352652119791933, 0.16607512573940708, 0.47115273409020064, 0.484611889539977, 0.4818212818623442, 0.4821672943260139, 0.4841543297946266, 0.4874987148801396, 0.47212911683809955, 0.47768712153765713, 0.4876777670076289, 0.08027471468964176, 0.08919474295218699, 0.08861705005130793, 0.09024499927606033, 0.08006252782830903, 0.08634035799881334, 0.0791875040996467, 0.08576322537947001, 0.080182476156616, 0.14467194397565541, 0.13499315892565333, 0.12886093622941552, 0.12974500552433654, 0.13731315163403124, 0.20560571025954155, 0.13723435212975033, 0.12562819965953897, 0.13708858308043215, 0.28776925745713355, 0.2548771488091336, 0.27701670180617366, 0.2540672327499097, 0.2709818632554669, 0.263797481213364, 0.2851246500548904, 0.2915882349898946, 0.28138192269079076, 0.19682454310509634, 0.21844725855421177, 0.218058101301564, 0.19613360915652778, 0.19061778340376023, 0.18476519165471872, 0.20385080802686084, 0.22507500476252185, 0.22020281045128387, 0.1992664508760672, 0.18707136867366958, 0.17768715871067486, 0.20452181530206082, 0.17707790091039455, 0.1819267561258655, 0.1783790484549338, 0.17462381431233098, 0.1784462569442481, 0.1771663847502426, 0.16888053981640572, 0.17736629503624024, 0.17735564044012353, 0.17047516857210032, 0.18796226454652465, 0.17951891859271563, 0.16744435144956316, 0.18203637657022143, 0.5605145422382731, 0.1904077205645477, 0.17989701707319838, 0.5720550490954972, 0.176281786785777, 0.19819746421783746, 0.2622197587089692, 0.27464187991295896, 0.25496140139599244, 0.196090430958203, 0.19944805946096877, 0.187068995639616, 0.18804678151649423, 0.18983785236952122, 0.3536388173677081, 0.2077571360425694, 0.14845001083018872, 0.208780516961537, 0.18715294249579384, 0.17635514087395732, 0.18456783039416658, 0.181067527435269, 0.16298585139925836, 0.17991334108025525, 0.19820853179556674, 0.18923726623201764, 0.19676431057872956, 0.06708628542175643, 0.07132326452243165, 0.06666674050854249, 0.06695901941634153, 0.07208554397161604, 0.07586999806601458, 0.07713995583314881, 0.08551246494595321, 0.06715225761799848]}, "mutation_prompt": null}
{"id": "1432277b-a81e-4e7f-8f2c-0839fe7a6cd6", "solution": "import numpy as np\n\nclass ADELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 10 * dim  # Population size, adjustable\n        self.mutation_factor = 0.8  # DE mutation factor, can be adaptive\n        self.crossover_rate = 0.9  # DE crossover rate, can be adaptive\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.1\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Perform local search on the best found individual\n            local_candidate = self._local_search(best_individual, best_individual)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n        return best_individual, best_fitness", "name": "ADELS", "description": "Adaptive Differential Evolution with Local Search (ADELS) combines differential evolution and local search strategies to balance global exploration and local exploitation, optimizing functions efficiently within a given evaluation budget.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8158bb9a-3f90-4f3e-b53a-db285aadf174", "metadata": {"aucs": [0.630910768422311, 0.6228440785586251, 0.6368137546274093, 0.6433491067634066, 0.6307880254592593, 0.6369415448622462, 0.6116005503586031, 0.6303615239780753, 0.6496024518393061, 0.37244403461717346, 0.4134850327906554, 0.3576797559243914, 0.3773074945398024, 0.3932026054052037, 0.3905718642236051, 0.3810442226849272, 0.39568061659782616, 0.37936489889306235, 0.08016041582790445, 0.09381464177706056, 0.10278919040333678, 0.1191987476635008, 0.09592849955094374, 0.0937077412369095, 0.08991358470904764, 0.0983941392557297, 0.10797650730278074, 0.09740971284971256, 0.09853438768453471, 0.09066055633996584, 0.08756355774900382, 0.09446615720405993, 0.09490851469219141, 0.08186325772983039, 0.08734853279476351, 0.0866317250073767, 0.9257932563172493, 0.9402464215905781, 0.9244295713636397, 0.9602083053870073, 0.9420404066823631, 0.9430614426719448, 0.9580014884761265, 0.9632243878310324, 0.9572389674383627, 0.295824637287318, 0.2715857679629353, 0.3019603767777831, 0.3130686611670086, 0.2846350960240692, 0.2708174845437399, 0.28231744416732096, 0.31176545655457877, 0.3022707414681173, 0.46981570857480315, 0.5667165294165957, 0.5465032429213206, 0.5489456543995614, 0.5077414493183774, 0.5878239420591593, 0.5089625720416169, 0.5709014559675907, 0.4693703988789787, 0.2013794363967919, 0.18971350166860834, 0.208622285025567, 0.1478751406995118, 0.2013279925956627, 0.1995563671126377, 0.2226667954180701, 0.2096848187186754, 0.1878943128684436, 0.015996673817001317, 0.021061321437804148, 0.2137615813162982, 0.22532807581887881, 0.1957440641809951, 0.179190196289423, 0.20158696790963282, 0.20046572057290368, 0.21189124749017063, 0.12171444826644728, 0.1550328393529904, 0.1156086428099774, 0.11839401673579864, 0.14323490526425908, 0.1250302808838707, 0.13506274013165254, 0.12764797908030234, 0.13114145479681394, 0.24794648280086007, 0.2555154805695543, 0.24379138792336674, 0.25404083409836353, 0.2218806077446046, 0.2813917511726727, 0.247243115400957, 0.27347437000062236, 0.27126292727957535, 0.03055858421986757, 0.03996331227490668, 0.03828391890619498, 0.027784774073799645, 0.034738682326604375, 0.05134409365241521, 0.019483894217274256, 0.01569940721296681, 0.03582787682631405, 0.15023265238293482, 0.14648230587861066, 0.16376072335608605, 0.15313283504602038, 0.17167286504045964, 0.1690241745303156, 0.16103178244888894, 0.16352652119791933, 0.16607512573940708, 0.47115273409020064, 0.484611889539977, 0.4818212818623442, 0.4821672943260139, 0.4841543297946266, 0.4874987148801396, 0.47212911683809955, 0.47768712153765713, 0.4876777670076289, 0.08027471468964176, 0.08919474295218699, 0.08861705005130793, 0.09024499927606033, 0.08006252782830903, 0.08634035799881334, 0.0791875040996467, 0.08576322537947001, 0.080182476156616, 0.14467194397565541, 0.13499315892565333, 0.12886093622941552, 0.12974500552433654, 0.13731315163403124, 0.20560571025954155, 0.13723435212975033, 0.12562819965953897, 0.13708858308043215, 0.28776925745713355, 0.2548771488091336, 0.27701670180617366, 0.2540672327499097, 0.2709818632554669, 0.263797481213364, 0.2851246500548904, 0.2915882349898946, 0.28138192269079076, 0.19682454310509634, 0.21844725855421177, 0.218058101301564, 0.19613360915652778, 0.19061778340376023, 0.18476519165471872, 0.20385080802686084, 0.22507500476252185, 0.22020281045128387, 0.1992664508760672, 0.18707136867366958, 0.17768715871067486, 0.20452181530206082, 0.17707790091039455, 0.1819267561258655, 0.1783790484549338, 0.17462381431233098, 0.1784462569442481, 0.1771663847502426, 0.16888053981640572, 0.17736629503624024, 0.17735564044012353, 0.17047516857210032, 0.18796226454652465, 0.17951891859271563, 0.16744435144956316, 0.18203637657022143, 0.5605145422382731, 0.1904077205645477, 0.17989701707319838, 0.5720550490954972, 0.176281786785777, 0.19819746421783746, 0.2622197587089692, 0.27464187991295896, 0.25496140139599244, 0.196090430958203, 0.19944805946096877, 0.187068995639616, 0.18804678151649423, 0.18983785236952122, 0.3536388173677081, 0.2077571360425694, 0.14845001083018872, 0.208780516961537, 0.18715294249579384, 0.17635514087395732, 0.18456783039416658, 0.181067527435269, 0.16298585139925836, 0.17991334108025525, 0.19820853179556674, 0.18923726623201764, 0.19676431057872956, 0.06708628542175643, 0.07132326452243165, 0.06666674050854249, 0.06695901941634153, 0.07208554397161604, 0.07586999806601458, 0.07713995583314881, 0.08551246494595321, 0.06715225761799848]}, "mutation_prompt": null}
{"id": "5c693442-cc67-4ef0-b243-c9eab190ed1e", "solution": "import numpy as np\n\nclass EnhancedADELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.population_size = 10 * dim  # Initial population size\n        self.mutation_factor = 0.8  # Initial DE mutation factor\n        self.crossover_rate = 0.9  # Initial DE crossover rate\n        self.adaptive_rate = 0.1  # Rate of adaptation for parameters\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.05 + np.random.rand() * 0.1  # Dynamic step size\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self):\n        self.mutation_factor = np.clip(self.mutation_factor + np.random.uniform(-self.adaptive_rate, self.adaptive_rate), 0.5, 1.0)\n        self.crossover_rate = np.clip(self.crossover_rate + np.random.uniform(-self.adaptive_rate, self.adaptive_rate), 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(4 * self.dim, self.population_size // 2)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                self._adapt_parameters()\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n                \n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            # Perform local search on the best found individual\n            local_candidate = self._local_search(best_individual, best_individual)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedADELS", "description": "Enhanced ADELS with adaptive parameter control and dynamic population resizing balances exploration and exploitation better, improving convergence efficiency.", "configspace": "", "generation": 3, "fitness": 0.2974297493965264, "feedback": "The algorithm EnhancedADELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.22.", "error": "", "parent_id": "8158bb9a-3f90-4f3e-b53a-db285aadf174", "metadata": {"aucs": [0.6775036799711442, 0.6978175357784137, 0.7017961281541739, 0.6851156389298687, 0.704349668302103, 0.7046212197613035, 0.6837758951443828, 0.6883098176336772, 0.7163463730444501, 0.49883177710655313, 0.48515710398489886, 0.4895463866351061, 0.49117562893614664, 0.46448623333330696, 0.4760497252092529, 0.5174058465784444, 0.47654770043533135, 0.5029680369487499, 0.09928893193689636, 0.12600382893170903, 0.10900525801326488, 0.12041610006830783, 0.14435946233442098, 0.11465112580806924, 0.11370529923933104, 0.11528301707191968, 0.11246135269649016, 0.09555507673138286, 0.10995612743694805, 0.11041535908281386, 0.10709215291331531, 0.11647931168443959, 0.08411568274347414, 0.0920277167801754, 0.09433624494829851, 0.1003438355618328, 0.9549830731458672, 0.9544976938566423, 0.8906595138659651, 0.9411821284718616, 0.92191491295311, 0.9403356679128587, 0.9223248582183721, 0.9389949718056968, 0.9191104196196613, 0.3511609205201338, 0.3295940831140307, 0.3465395625445272, 0.3602047267550589, 0.3384755280969072, 0.3446739900384167, 0.38035980833091587, 0.36041554397492215, 0.3435994681922111, 0.5481456472541422, 0.570633295125852, 0.5718534265503914, 0.6586364692086432, 0.597053169887412, 0.6016546228031852, 0.6184301962545098, 0.5737930057035312, 0.603988681567468, 0.2382655244972406, 0.2256811387114237, 0.23640010520553123, 0.2886643274451245, 0.2273950219530334, 0.27614245122879133, 0.2899487713394635, 0.2342439762750751, 0.2595514655302611, 0.1703275742442515, 0.2679042011724916, 0.20375539021966538, 0.2564036687758354, 0.27906112151225326, 0.25270914053989313, 0.22636422289664204, 0.21274711061511742, 0.269803266622486, 0.1480060859248724, 0.13801199595309577, 0.22295740958481658, 0.15203289235661954, 0.18768788032745964, 0.15778670189725785, 0.18067784750258997, 0.17411587002677353, 0.15310721955894147, 0.2943254482267952, 0.25541956653701714, 0.30368454700039227, 0.31920511802609874, 0.29416348631433553, 0.3007113864549549, 0.29488692906612846, 0.31449227209759123, 0.3746451503172866, 0.04851269829168281, 0.07461067644222708, 0.02960647296421426, 0.04609307127739792, 0.08731499460730008, 0.06970096574232776, 0.03954386995553105, 0.031031881270792816, 0.048794374341569524, 0.18612905278777347, 0.16669384281045263, 0.19707768044816842, 0.17839026456332996, 0.18162099726363035, 0.19589013782270048, 0.18550662334864743, 0.1901777984472537, 0.1898794227532441, 0.5428899813462913, 0.5482221771913969, 0.549537836601278, 0.52879455976126, 0.5355648118360892, 0.5407666851007149, 0.5422989037424809, 0.5412359806598559, 0.5545704224465426, 0.11045583636729084, 0.08540155480707012, 0.09050161378395571, 0.09214171262750803, 0.09576516052036532, 0.08094305635695476, 0.08363111195169026, 0.08261608043290347, 0.08760514847398226, 0.14104411818866625, 0.13572421113720612, 0.15901054790598812, 0.20319081537466344, 0.1398158392601394, 0.17916561489925986, 0.15866952969578285, 0.14637178403550788, 0.19874667305863014, 0.289759626574173, 0.31116321082225173, 0.31329356092365246, 0.29206991119496983, 0.2853773895808339, 0.29773230754270585, 0.30063084482959723, 0.34988405064324557, 0.30927199737325717, 0.21813044612642385, 0.2425885377051018, 0.22250530647743028, 0.2209933664706698, 0.22414219767571208, 0.20727148142323726, 0.22681621375497507, 0.24234864079963003, 0.2425973054742495, 0.19046248586170478, 0.16919376794384267, 0.18186694673581705, 0.1723849602731501, 0.1762401008684814, 0.18264787374235625, 0.19039061829834047, 0.18551148780054705, 0.16693715550307586, 0.17758954260456472, 0.18100959521627102, 0.18203253985266554, 0.1762361002892343, 0.22578914954620155, 0.18397760880219682, 0.20952314227141144, 0.22529335100190373, 0.20246298653501515, 0.5317870749614246, 0.17075479622027256, 0.19162675526675732, 0.17775551180807148, 0.6253888302560568, 0.35734343369070065, 0.4214016752205395, 0.31277200706954655, 0.17758918277083846, 0.19050779937785312, 0.19912113951212418, 0.5042476300769425, 0.48311390991563996, 0.3189826228065321, 0.18008426301826075, 0.6354712731773942, 0.5914659091438182, 0.20164258244585587, 0.18630111330031274, 0.17820328864921287, 0.18593341815588538, 0.1703080464976685, 0.1803166563414954, 0.18335341846025444, 0.18733056532210535, 0.1741000196361816, 0.18259759796047303, 0.07024736104819818, 0.0666610806536817, 0.08199622758146619, 0.07211292843811934, 0.07397621026123147, 0.07509372005055959, 0.07124250865164483, 0.07700986904507723, 0.08780109001659164]}, "mutation_prompt": null}
{"id": "0a1b95cd-d9a7-4e3c-b656-89239c59e0c5", "solution": "import numpy as np\n\nclass AdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, fitness):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.05 + np.random.rand() * 0.1\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness, population):\n        best_idx = np.argmin(fitness)\n        worst_idx = np.argmax(fitness)\n        for idx in range(self.population_size):\n            if fitness[idx] > fitness[best_idx]:\n                self.mutation_factor = np.clip(self.mutation_factor + np.random.uniform(-self.adaptive_factor, self.adaptive_factor), 0.5, 1.0)\n                self.crossover_rate = np.clip(self.crossover_rate + np.random.uniform(-self.adaptive_factor, self.adaptive_factor), 0.7, 1.0)\n            else:\n                self.mutation_factor = np.clip(self.mutation_factor + np.random.uniform(-self.adaptive_factor/2, self.adaptive_factor/2), 0.5, 1.0)\n                self.crossover_rate = np.clip(self.crossover_rate + np.random.uniform(-self.adaptive_factor/2, self.adaptive_factor/2), 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(4 * self.dim, self.population_size // 2)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            for i in range(self.population_size):\n                self._adapt_parameters(fitness, population)\n                mutant = self._mutate(i, population, fitness)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            local_candidate = self._local_search(best_individual, best_individual)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "AdaptiveDELS", "description": "AdaptiveDELS with self-tuning mutation crossover strategies and individual-based learning enhances convergence by dynamically adjusting strategies per individual.", "configspace": "", "generation": 4, "fitness": 0.2980052460973809, "feedback": "The algorithm AdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.22.", "error": "", "parent_id": "5c693442-cc67-4ef0-b243-c9eab190ed1e", "metadata": {"aucs": [0.6951751020826733, 0.6641638879919581, 0.6940655086934617, 0.6973210426961886, 0.7053900842806776, 0.6966221310711311, 0.7145057343094432, 0.6922772146570665, 0.6706735141752656, 0.4889503779299238, 0.5134377358971445, 0.4687903043687017, 0.44414897275952336, 0.46163726242521375, 0.4816750451763886, 0.5089963713757681, 0.49162752579094326, 0.5005157062551031, 0.11353605893532315, 0.11732358418919953, 0.10723864116562543, 0.15984682861165678, 0.11592863923935182, 0.11851423962511476, 0.11419296382665356, 0.109752911540971, 0.12008858009769463, 0.10593399953631122, 0.10186224495602514, 0.09234323047662496, 0.09997804012091183, 0.09445472568470559, 0.09329704877013245, 0.0975948764757879, 0.10101802322437214, 0.10943048076397177, 0.9171219978469578, 0.9575244798182927, 0.9491228441044973, 0.9486482249923875, 0.9600015973855057, 0.9252211115724237, 0.8971662738532548, 0.9204922294524658, 0.9362678815296972, 0.30759182110743555, 0.3371448558167869, 0.34184335735792415, 0.33442845723545234, 0.3472622978036948, 0.33502479234859717, 0.35400898530928593, 0.3886656992272256, 0.35534719473720966, 0.5966562671183622, 0.5325763689620077, 0.5106585082920206, 0.6716375737879934, 0.6367623750002407, 0.5693756312294225, 0.6112753469864367, 0.5857220149863588, 0.5496981706824209, 0.251795928526485, 0.26340161245754323, 0.23198284085159926, 0.22776734433655288, 0.26962714240407526, 0.2231721900024083, 0.26086747060139026, 0.21006407190217635, 0.23277994262073964, 0.28385442861628096, 0.12183555433229665, 0.1695911745351537, 0.25567316277850505, 0.2422787228809008, 0.29772144853173454, 0.2280635006166969, 0.20849656808650607, 0.27324334414137985, 0.14638753928808068, 0.18800017399431912, 0.18417274594359412, 0.16912112135668433, 0.14665336093717085, 0.1639777037247513, 0.16980375651724522, 0.16489698349682114, 0.18852671515583308, 0.3136319868030556, 0.28437997583953833, 0.3033183843776929, 0.2697039456626297, 0.29824479304355145, 0.2932178528074161, 0.31303478287593645, 0.3335290441427944, 0.3388956311335053, 0.06817400644236482, 0.0377311957018166, 0.03766770055582691, 0.09094931978114984, 0.08531901413859777, 0.07211902852899899, 0.08729132762648373, 0.058026667290156375, 0.06073370832878644, 0.18616429389184963, 0.18248555010478462, 0.1879781060153567, 0.19408621719536556, 0.20138567866506818, 0.18525925991250858, 0.20882917612986351, 0.20668637186490402, 0.19667780095025533, 0.5396684698664167, 0.5460801835343391, 0.5517169194792819, 0.5528607830013923, 0.559540501171685, 0.5557441727869699, 0.5387530522816623, 0.5296752289872575, 0.5488140246125184, 0.09308534919866107, 0.09200395448536669, 0.08470010660200245, 0.09683807386735022, 0.08239427713896452, 0.10959658897330171, 0.1004746440089328, 0.08665753378967078, 0.08104216253399521, 0.31387863755896683, 0.26916866899338654, 0.14176388255102645, 0.14031139425509132, 0.17046667855303055, 0.13728414680198597, 0.17140587892416914, 0.14534736792720737, 0.16604908123578366, 0.30062136370981685, 0.2971523990585797, 0.2883513964014166, 0.2916156572230192, 0.3133129416018111, 0.28533151708972093, 0.3289135043975552, 0.3348601507667375, 0.3165528426819395, 0.219377290778217, 0.21659443401769596, 0.22556262528903426, 0.2172800054095968, 0.21597973578372376, 0.2304358327126671, 0.2462013084760588, 0.2372824131976784, 0.23221405187064215, 0.18507130786745418, 0.1696989394152152, 0.18736488948633, 0.19096655287340358, 0.194800959274534, 0.20900691695505258, 0.1811084939085783, 0.17363065840576086, 0.1852197015313659, 0.17480976057814135, 0.1764830307406553, 0.18630307012823022, 0.183557868848244, 0.17881306816046194, 0.18606439940757702, 0.1725763857597853, 0.17730929814650154, 0.19810436231865947, 0.6082286879701182, 0.4449212312871784, 0.5330056329929698, 0.17484197704253635, 0.17754745557234108, 0.1820206253874388, 0.17705826317875795, 0.5997557094531606, 0.1831523240184474, 0.5396102100102449, 0.4658528109915363, 0.3998411200369538, 0.5288058129500961, 0.3749805439137306, 0.312009627377845, 0.20380345078581552, 0.19631031065076876, 0.20383713615290378, 0.204897207486196, 0.1877364751800752, 0.19287303663087696, 0.18375964683041401, 0.18458783937581713, 0.18900149016442325, 0.20187558783860782, 0.17464215713669018, 0.16933018395511568, 0.0714518321649793, 0.07772684877581904, 0.0722720693796387, 0.06862600284507647, 0.07503543918975042, 0.06692552834228194, 0.07493776769879967, 0.07114056548836345, 0.0740472852176739]}, "mutation_prompt": null}
{"id": "68122ad2-e998-42a0-bad4-6deb13e9cc29", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.05 + np.random.rand() * 0.1\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > np.median(fitness)))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            local_candidate = np.random.multivariate_normal(best_individual, self.covariance_matrix)\n            local_candidate = np.clip(local_candidate, self.lb, self.ub)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with dynamic population resizing, elitism, and covariance matrix adaptation for efficient exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.30765316871413734, "feedback": "The algorithm EnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.22.", "error": "", "parent_id": "0a1b95cd-d9a7-4e3c-b656-89239c59e0c5", "metadata": {"aucs": [0.6796868286395616, 0.6755147985423688, 0.6502027390442343, 0.69362686174656, 0.711420167799202, 0.6913613343352187, 0.6736866010897197, 0.6548807128027874, 0.6454763035677593, 0.5348474559914682, 0.5081706935844605, 0.4844953224853722, 0.5133073865145141, 0.5080232238987659, 0.5206902376778806, 0.5065230133094644, 0.523750377122102, 0.5564563945149372, 0.12709230128164417, 0.11185703866244912, 0.2829803276348478, 0.30744390002608846, 0.1386008124778476, 0.10990034773488411, 0.2697148101489544, 0.13339176857292967, 0.23073868009041343, 0.1261353986864827, 0.10087984831696362, 0.3262628180645556, 0.24058926341893472, 0.10384266253923469, 0.09243336278791758, 0.21374581712005958, 0.12537673767290902, 0.17178896689833, 0.9304485069516456, 0.9113012657246453, 0.899641278293201, 0.9320392177541923, 0.9770186266527948, 0.9526382425353037, 0.964991440956482, 0.9498271370466436, 0.9422205666854931, 0.4022944227586257, 0.4021348815128635, 0.41004003671087497, 0.4014773685268882, 0.4238267175633078, 0.4216474355239309, 0.32534814638287834, 0.4312002405068931, 0.43145052814569973, 0.5783420215186745, 0.5528268643236984, 0.572965935223662, 0.5198638129985211, 0.5413320072581541, 0.5930432512109346, 0.56601028159427, 0.5734588286594591, 0.5481458849023764, 0.14388414850260356, 0.17495045287117506, 0.1983813700139463, 0.21178791786211182, 0.16643878351203367, 0.1654728521048039, 0.17895527605704442, 0.18822655588541626, 0.15385741728051894, 0.19034207828718452, 0.10969508564969199, 0.11462399441917204, 0.16327529642404548, 0.22071475406118568, 0.16030369408694312, 0.16547450679628584, 0.15938916346532261, 0.15359725984569284, 0.10954492550040795, 0.13785965372559528, 0.24305892481876945, 0.15115362306362568, 0.29838735482544654, 0.25839594350109873, 0.10779894715937155, 0.1411730042475423, 0.1560135793500096, 0.22811560852278534, 0.4441489969860518, 0.18982034020434235, 0.34580410283776397, 0.33074920303781774, 0.2308740191091856, 0.3303818855014533, 0.21882468514285658, 0.2471082032794797, 0.03686549631347458, 0.039739689728001015, 0.03655670071938222, 0.10812566701538184, 0.06769487073664282, 0.0330691015784188, 0.10920794924269217, 0.1034359695746574, 0.0740042853435674, 0.18041953374261666, 0.2017572998555135, 0.16088043829743237, 0.2139707759499142, 0.20885275841815232, 0.19165449660608425, 0.2010003615305379, 0.15789731401361984, 0.18408219750516497, 0.5339189399821194, 0.5026175337159007, 0.5436120928480516, 0.5158913256628022, 0.49946612533139656, 0.558193448483682, 0.5281211502862309, 0.5400082214223794, 0.45701764407495715, 0.0931390957609094, 0.09750472819071454, 0.08855515349688226, 0.07922233189385042, 0.08380390399707371, 0.08435645752348442, 0.08253855945855981, 0.09366958739263331, 0.09690373977883826, 0.17601288603441623, 0.1469372658166942, 0.166838921527929, 0.15127828503681173, 0.1364325482881077, 0.14886545109507954, 0.1558214925419803, 0.12684464194835787, 0.1584028877261473, 0.3281540642760866, 0.36027342556845154, 0.3311072488437601, 0.3528579349748795, 0.3059055619450535, 0.31690880750900774, 0.4128111604206661, 0.36561782672573184, 0.3923753763472013, 0.2461585985964585, 0.22898144919944396, 0.22957764373393508, 0.239013386600062, 0.21032151049802328, 0.2228958284513719, 0.2711001855649118, 0.2727073416359348, 0.2519494745452797, 0.1650051978218927, 0.17826173393682332, 0.18903541801667223, 0.2021491856660026, 0.17644669739194652, 0.1871456406272194, 0.20657396293855323, 0.1797307546143294, 0.2070029308765241, 0.23424967304589506, 0.2046998847404603, 0.26530069304414694, 0.32342092178620674, 0.2423010729617694, 0.1880655826833073, 0.1860941971944129, 0.17685838270291765, 0.1911475293150403, 0.6445031724438453, 0.4219990082821582, 0.18553786014123486, 0.5265458904897101, 0.48317705237243913, 0.47529700706969413, 0.3726302631127155, 0.5251681921186762, 0.5346418100740367, 0.5506498877562156, 0.18867649490878535, 0.6246695598109935, 0.21641282718763666, 0.2068091188717891, 0.4812080706733365, 0.7231026199318364, 0.20237308746696558, 0.20674466030682315, 0.17995467881511917, 0.18847595782356752, 0.19811739883997803, 0.20178687081301416, 0.18663921880122236, 0.19222982212582362, 0.19874805814316276, 0.1860534786141762, 0.19626136440603137, 0.06892331142672481, 0.07701595277486672, 0.07586906352249667, 0.07159088529783164, 0.07153710511442002, 0.06721199653019505, 0.08359403174043545, 0.08315506711305298, 0.06936411638231932]}, "mutation_prompt": null}
{"id": "ad90e02d-dc84-493f-aa4a-fd25aee0d8cf", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.tournament_size = 3  # New parameter for tournament selection\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.05 + np.random.rand() * 0.1\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        mean_fitness = np.mean(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment_dir = -1 if fit > mean_fitness else 1\n            adjustment = self.adaptive_factor * adjustment_dir\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _tournament_selection(self, population, fitness):\n        selected_idx = np.random.choice(range(self.population_size), self.tournament_size, replace=False)\n        best_idx = selected_idx[np.argmin(fitness[selected_idx])]\n        return population[best_idx]\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                selected = self._tournament_selection(population, fitness)\n                mutant = self._mutate(i, population)\n                trial = self._crossover(selected, mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            local_candidate = np.random.multivariate_normal(best_individual, self.covariance_matrix)\n            local_candidate = np.clip(local_candidate, self.lb, self.ub)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "EnhancedAdaptiveDELS with adaptive hyperparameter tuning and tournament selection for improved convergence.", "configspace": "", "generation": 6, "fitness": 0.29699893926184057, "feedback": "The algorithm EnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.22.", "error": "", "parent_id": "68122ad2-e998-42a0-bad4-6deb13e9cc29", "metadata": {"aucs": [0.6880712088791725, 0.6400246576310011, 0.6442930743152762, 0.7079007234861671, 0.7127484088645011, 0.6831425463251646, 0.6616112730442112, 0.6422488094580435, 0.6770750229460587, 0.49636463515040297, 0.5471884482779369, 0.5413711585456122, 0.519046237588473, 0.5174529515778729, 0.5082924514026782, 0.5365317159044615, 0.5375931083192532, 0.3682992575556361, 0.14425656900433892, 0.1377202450271594, 0.11366357076937872, 0.4327162468503031, 0.1716382370290701, 0.14621259057058866, 0.27239112695097534, 0.09468942814732906, 0.11476629926082837, 0.11329616154441724, 0.11490279075817889, 0.09908102010262354, 0.1255148868485496, 0.11430347321055634, 0.2935698478535239, 0.13774049576251668, 0.11072427432407517, 0.1087004421335157, 0.969196948418124, 0.9757290598756027, 0.9301572791546786, 0.9723170807952163, 0.9735250314484646, 0.9589978506202281, 0.9424926322383532, 0.9800573624794381, 0.9904010757024021, 0.2637538259490734, 0.2792376630602642, 0.4159733516515258, 0.39156096447151045, 0.34700395390552063, 0.47913799682171543, 0.2845187799849779, 0.29456731952167015, 0.2581790604088605, 0.5763560785700967, 0.5621957020935957, 0.3222008030473624, 0.6120029339726881, 0.5761942475144886, 0.5960236458220198, 0.5997974549330133, 0.5750072406775959, 0.30670042191071767, 0.14519187283530932, 0.14014146313318032, 0.13977348594677064, 0.13849319972889318, 0.14250666518047472, 0.1633694056311482, 0.1421161076052171, 0.13768875418577298, 0.13141976226387397, 0.33827822627519133, 0.06424619499820361, 0.02873838116178562, 0.15994904345857508, 0.16310593827067477, 0.11349312292930713, 0.15321882486846206, 0.15213169650120706, 0.24350937650692617, 0.13720569019153883, 0.15576686299621811, 0.24967570372015768, 0.11329728801470251, 0.07827735670667735, 0.10721374309716902, 0.15599360900129577, 0.1180510776931245, 0.08733669238502062, 0.2116014213926103, 0.26897885795771903, 0.2649160295076567, 0.22730112034583883, 0.25218208571392675, 0.24402265510340082, 0.30986131698686814, 0.36156709067978543, 0.29201738443618686, 0.040767992903899763, 0.04059639574364904, 0.120766794280326, 0.09074226924190165, 0.08346619194219274, 0.06706063503344939, 0.09865706350190939, 0.09887892653556862, 0.1351050298712646, 0.18588121868339846, 0.17963887317625626, 0.24599586550272923, 0.1704262960935412, 0.22423816036366218, 0.2500442699699984, 0.18474771793190026, 0.1942027004557716, 0.22308470355122367, 0.49454100283912694, 0.48555087099698035, 0.4337766023793973, 0.4792899487929414, 0.5400888057785203, 0.5215065344046617, 0.460650151951703, 0.5494569711574968, 0.5128164081410653, 0.10055559004796322, 0.09840571952692301, 0.08996544908732262, 0.11895777716121103, 0.09726179733889107, 0.09867284364446838, 0.08723693841873081, 0.07924936096999824, 0.09846252567216796, 0.183244842967913, 0.21154473080388225, 0.14155986077663563, 0.1834607483755364, 0.17422521902943156, 0.20930317130521858, 0.18842510964103865, 0.1627573126946349, 0.1711835875759864, 0.31428424815501377, 0.3308559242311454, 0.4251678274874412, 0.40221387426432076, 0.3453662790047486, 0.44538028017764075, 0.4096099321787182, 0.35405713159994445, 0.3609544560893403, 0.31440119227198016, 0.2713781346541527, 0.28015202679153683, 0.3076625376849914, 0.300757515134217, 0.2423110904861362, 0.2919644367675793, 0.2628626368832131, 0.3399756087204354, 0.18394927536963657, 0.19004219685585444, 0.1911091096868266, 0.18754987197889816, 0.18388834756304873, 0.16913642000064633, 0.1762824618273111, 0.18663915928689634, 0.18956339908937891, 0.19019412307317796, 0.17676808974038372, 0.21031593740598775, 0.5272312319407846, 0.34597891367745737, 0.1926185545254352, 0.2613919081650856, 0.19261297132565958, 0.18884531702086005, 0.6754168614011425, 0.1491455637412259, 0.6321360111761716, 0.6226665589697665, 0.19076457631963772, 0.18052503957738353, 0.16896188145953894, 0.18603893121376658, 0.1785867443332949, 0.164927146742203, 0.2005213366687163, 0.45958567118792815, 0.6078940445326011, 0.5021252958120002, 0.5205133648822833, 0.15178177801260084, 0.1969294126122786, 0.2067906929158685, 0.18280157709400213, 0.1683750729523641, 0.1875644217620095, 0.19983726656287004, 0.21008217571898535, 0.20522147988708261, 0.17163659212585625, 0.1821277657521141, 0.17789878600675713, 0.0705470963299778, 0.07336373103544569, 0.07597301759591046, 0.07870453049108905, 0.08224867625305465, 0.07566585109884783, 0.07507357684302585, 0.06940186898630274, 0.07894640724515178]}, "mutation_prompt": null}
{"id": "3e7f22b9-8407-464a-9ba2-23031955ea60", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.05 + np.random.rand() * 0.1\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > np.median(fitness)))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            local_candidate = np.random.multivariate_normal(best_individual, self.covariance_matrix)\n            local_candidate = np.clip(local_candidate, self.lb, self.ub)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with dynamic population resizing, elitism, and covariance matrix adaptation for efficient exploration and exploitation.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "68122ad2-e998-42a0-bad4-6deb13e9cc29", "metadata": {"aucs": [0.6796868286395616, 0.6755147985423688, 0.6502027390442343, 0.69362686174656, 0.711420167799202, 0.6913613343352187, 0.6736866010897197, 0.6548807128027874, 0.6454763035677593, 0.5348474559914682, 0.5081706935844605, 0.4844953224853722, 0.5133073865145141, 0.5080232238987659, 0.5206902376778806, 0.5065230133094644, 0.523750377122102, 0.5564563945149372, 0.12709230128164417, 0.11185703866244912, 0.2829803276348478, 0.30744390002608846, 0.1386008124778476, 0.10990034773488411, 0.2697148101489544, 0.13339176857292967, 0.23073868009041343, 0.1261353986864827, 0.10087984831696362, 0.3262628180645556, 0.24058926341893472, 0.10384266253923469, 0.09243336278791758, 0.21374581712005958, 0.12537673767290902, 0.17178896689833, 0.9304485069516456, 0.9113012657246453, 0.899641278293201, 0.9320392177541923, 0.9770186266527948, 0.9526382425353037, 0.964991440956482, 0.9498271370466436, 0.9422205666854931, 0.4022944227586257, 0.4021348815128635, 0.41004003671087497, 0.4014773685268882, 0.4238267175633078, 0.4216474355239309, 0.32534814638287834, 0.4312002405068931, 0.43145052814569973, 0.5783420215186745, 0.5528268643236984, 0.572965935223662, 0.5198638129985211, 0.5413320072581541, 0.5930432512109346, 0.56601028159427, 0.5734588286594591, 0.5481458849023764, 0.14388414850260356, 0.17495045287117506, 0.1983813700139463, 0.21178791786211182, 0.16643878351203367, 0.1654728521048039, 0.17895527605704442, 0.18822655588541626, 0.15385741728051894, 0.19034207828718452, 0.10969508564969199, 0.11462399441917204, 0.16327529642404548, 0.22071475406118568, 0.16030369408694312, 0.16547450679628584, 0.15938916346532261, 0.15359725984569284, 0.10954492550040795, 0.13785965372559528, 0.24305892481876945, 0.15115362306362568, 0.29838735482544654, 0.25839594350109873, 0.10779894715937155, 0.1411730042475423, 0.1560135793500096, 0.22811560852278534, 0.4441489969860518, 0.18982034020434235, 0.34580410283776397, 0.33074920303781774, 0.2308740191091856, 0.3303818855014533, 0.21882468514285658, 0.2471082032794797, 0.03686549631347458, 0.039739689728001015, 0.03655670071938222, 0.10812566701538184, 0.06769487073664282, 0.0330691015784188, 0.10920794924269217, 0.1034359695746574, 0.0740042853435674, 0.18041953374261666, 0.2017572998555135, 0.16088043829743237, 0.2139707759499142, 0.20885275841815232, 0.19165449660608425, 0.2010003615305379, 0.15789731401361984, 0.18408219750516497, 0.5339189399821194, 0.5026175337159007, 0.5436120928480516, 0.5158913256628022, 0.49946612533139656, 0.558193448483682, 0.5281211502862309, 0.5400082214223794, 0.45701764407495715, 0.0931390957609094, 0.09750472819071454, 0.08855515349688226, 0.07922233189385042, 0.08380390399707371, 0.08435645752348442, 0.08253855945855981, 0.09366958739263331, 0.09690373977883826, 0.17601288603441623, 0.1469372658166942, 0.166838921527929, 0.15127828503681173, 0.1364325482881077, 0.14886545109507954, 0.1558214925419803, 0.12684464194835787, 0.1584028877261473, 0.3281540642760866, 0.36027342556845154, 0.3311072488437601, 0.3528579349748795, 0.3059055619450535, 0.31690880750900774, 0.4128111604206661, 0.36561782672573184, 0.3923753763472013, 0.2461585985964585, 0.22898144919944396, 0.22957764373393508, 0.239013386600062, 0.21032151049802328, 0.2228958284513719, 0.2711001855649118, 0.2727073416359348, 0.2519494745452797, 0.1650051978218927, 0.17826173393682332, 0.18903541801667223, 0.2021491856660026, 0.17644669739194652, 0.1871456406272194, 0.20657396293855323, 0.1797307546143294, 0.2070029308765241, 0.23424967304589506, 0.2046998847404603, 0.26530069304414694, 0.32342092178620674, 0.2423010729617694, 0.1880655826833073, 0.1860941971944129, 0.17685838270291765, 0.1911475293150403, 0.6445031724438453, 0.4219990082821582, 0.18553786014123486, 0.5265458904897101, 0.48317705237243913, 0.47529700706969413, 0.3726302631127155, 0.5251681921186762, 0.5346418100740367, 0.5506498877562156, 0.18867649490878535, 0.6246695598109935, 0.21641282718763666, 0.2068091188717891, 0.4812080706733365, 0.7231026199318364, 0.20237308746696558, 0.20674466030682315, 0.17995467881511917, 0.18847595782356752, 0.19811739883997803, 0.20178687081301416, 0.18663921880122236, 0.19222982212582362, 0.19874805814316276, 0.1860534786141762, 0.19626136440603137, 0.06892331142672481, 0.07701595277486672, 0.07586906352249667, 0.07159088529783164, 0.07153710511442002, 0.06721199653019505, 0.08359403174043545, 0.08315506711305298, 0.06936411638231932]}, "mutation_prompt": null}
{"id": "f6228197-1b2d-4f5b-8983-c18ba061e4ba", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.05 + np.random.rand() * 0.1\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > np.median(fitness)))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            local_candidate = np.random.multivariate_normal(best_individual, self.covariance_matrix)\n            local_candidate = np.clip(local_candidate, self.lb, self.ub)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with dynamic population resizing, elitism, and covariance matrix adaptation for efficient exploration and exploitation.", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "68122ad2-e998-42a0-bad4-6deb13e9cc29", "metadata": {"aucs": [0.6796868286395616, 0.6755147985423688, 0.6502027390442343, 0.69362686174656, 0.711420167799202, 0.6913613343352187, 0.6736866010897197, 0.6548807128027874, 0.6454763035677593, 0.5348474559914682, 0.5081706935844605, 0.4844953224853722, 0.5133073865145141, 0.5080232238987659, 0.5206902376778806, 0.5065230133094644, 0.523750377122102, 0.5564563945149372, 0.12709230128164417, 0.11185703866244912, 0.2829803276348478, 0.30744390002608846, 0.1386008124778476, 0.10990034773488411, 0.2697148101489544, 0.13339176857292967, 0.23073868009041343, 0.1261353986864827, 0.10087984831696362, 0.3262628180645556, 0.24058926341893472, 0.10384266253923469, 0.09243336278791758, 0.21374581712005958, 0.12537673767290902, 0.17178896689833, 0.9304485069516456, 0.9113012657246453, 0.899641278293201, 0.9320392177541923, 0.9770186266527948, 0.9526382425353037, 0.964991440956482, 0.9498271370466436, 0.9422205666854931, 0.4022944227586257, 0.4021348815128635, 0.41004003671087497, 0.4014773685268882, 0.4238267175633078, 0.4216474355239309, 0.32534814638287834, 0.4312002405068931, 0.43145052814569973, 0.5783420215186745, 0.5528268643236984, 0.572965935223662, 0.5198638129985211, 0.5413320072581541, 0.5930432512109346, 0.56601028159427, 0.5734588286594591, 0.5481458849023764, 0.14388414850260356, 0.17495045287117506, 0.1983813700139463, 0.21178791786211182, 0.16643878351203367, 0.1654728521048039, 0.17895527605704442, 0.18822655588541626, 0.15385741728051894, 0.19034207828718452, 0.10969508564969199, 0.11462399441917204, 0.16327529642404548, 0.22071475406118568, 0.16030369408694312, 0.16547450679628584, 0.15938916346532261, 0.15359725984569284, 0.10954492550040795, 0.13785965372559528, 0.24305892481876945, 0.15115362306362568, 0.29838735482544654, 0.25839594350109873, 0.10779894715937155, 0.1411730042475423, 0.1560135793500096, 0.22811560852278534, 0.4441489969860518, 0.18982034020434235, 0.34580410283776397, 0.33074920303781774, 0.2308740191091856, 0.3303818855014533, 0.21882468514285658, 0.2471082032794797, 0.03686549631347458, 0.039739689728001015, 0.03655670071938222, 0.10812566701538184, 0.06769487073664282, 0.0330691015784188, 0.10920794924269217, 0.1034359695746574, 0.0740042853435674, 0.18041953374261666, 0.2017572998555135, 0.16088043829743237, 0.2139707759499142, 0.20885275841815232, 0.19165449660608425, 0.2010003615305379, 0.15789731401361984, 0.18408219750516497, 0.5339189399821194, 0.5026175337159007, 0.5436120928480516, 0.5158913256628022, 0.49946612533139656, 0.558193448483682, 0.5281211502862309, 0.5400082214223794, 0.45701764407495715, 0.0931390957609094, 0.09750472819071454, 0.08855515349688226, 0.07922233189385042, 0.08380390399707371, 0.08435645752348442, 0.08253855945855981, 0.09366958739263331, 0.09690373977883826, 0.17601288603441623, 0.1469372658166942, 0.166838921527929, 0.15127828503681173, 0.1364325482881077, 0.14886545109507954, 0.1558214925419803, 0.12684464194835787, 0.1584028877261473, 0.3281540642760866, 0.36027342556845154, 0.3311072488437601, 0.3528579349748795, 0.3059055619450535, 0.31690880750900774, 0.4128111604206661, 0.36561782672573184, 0.3923753763472013, 0.2461585985964585, 0.22898144919944396, 0.22957764373393508, 0.239013386600062, 0.21032151049802328, 0.2228958284513719, 0.2711001855649118, 0.2727073416359348, 0.2519494745452797, 0.1650051978218927, 0.17826173393682332, 0.18903541801667223, 0.2021491856660026, 0.17644669739194652, 0.1871456406272194, 0.20657396293855323, 0.1797307546143294, 0.2070029308765241, 0.23424967304589506, 0.2046998847404603, 0.26530069304414694, 0.32342092178620674, 0.2423010729617694, 0.1880655826833073, 0.1860941971944129, 0.17685838270291765, 0.1911475293150403, 0.6445031724438453, 0.4219990082821582, 0.18553786014123486, 0.5265458904897101, 0.48317705237243913, 0.47529700706969413, 0.3726302631127155, 0.5251681921186762, 0.5346418100740367, 0.5506498877562156, 0.18867649490878535, 0.6246695598109935, 0.21641282718763666, 0.2068091188717891, 0.4812080706733365, 0.7231026199318364, 0.20237308746696558, 0.20674466030682315, 0.17995467881511917, 0.18847595782356752, 0.19811739883997803, 0.20178687081301416, 0.18663921880122236, 0.19222982212582362, 0.19874805814316276, 0.1860534786141762, 0.19626136440603137, 0.06892331142672481, 0.07701595277486672, 0.07586906352249667, 0.07159088529783164, 0.07153710511442002, 0.06721199653019505, 0.08359403174043545, 0.08315506711305298, 0.06936411638231932]}, "mutation_prompt": null}
{"id": "33847b35-584a-4327-8cfd-b5c81f699281", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.1\n        self.diversity_threshold = 1e-6\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _local_search(self, individual, best_individual):\n        step_size = 0.05 + np.random.rand() * 0.1\n        local_step = np.random.uniform(-step_size, step_size, self.dim)\n        candidate = individual + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = max(0.01, self.learning_rate * (1.0 + adjustment))\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _preserve_diversity(self, population):\n        diversities = np.std(population, axis=0)\n        if np.all(diversities < self.diversity_threshold):\n            perturbation = np.random.uniform(-0.1, 0.1, (self.population_size, self.dim))\n            population += perturbation\n            population = np.clip(population, self.lb, self.ub)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            self._preserve_diversity(population)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            local_candidate = np.random.multivariate_normal(best_individual, self.covariance_matrix)\n            local_candidate = np.clip(local_candidate, self.lb, self.ub)\n            local_fitness = func(local_candidate)\n            evaluations += 1\n\n            if local_fitness < best_fitness:\n                best_individual = local_candidate\n                best_fitness = local_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "Enhanced Adaptive DELS with diversity preservation and adaptive learning rate for improved convergence and robustness.", "configspace": "", "generation": 9, "fitness": 0.30765316871413734, "feedback": "The algorithm EnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.22.", "error": "", "parent_id": "68122ad2-e998-42a0-bad4-6deb13e9cc29", "metadata": {"aucs": [0.6796868286395616, 0.6755147985423688, 0.6502027390442343, 0.69362686174656, 0.711420167799202, 0.6913613343352187, 0.6736866010897197, 0.6548807128027874, 0.6454763035677593, 0.5348474559914682, 0.5081706935844605, 0.4844953224853722, 0.5133073865145141, 0.5080232238987659, 0.5206902376778806, 0.5065230133094644, 0.523750377122102, 0.5564563945149372, 0.12709230128164417, 0.11185703866244912, 0.2829803276348478, 0.30744390002608846, 0.1386008124778476, 0.10990034773488411, 0.2697148101489544, 0.13339176857292967, 0.23073868009041343, 0.1261353986864827, 0.10087984831696362, 0.3262628180645556, 0.24058926341893472, 0.10384266253923469, 0.09243336278791758, 0.21374581712005958, 0.12537673767290902, 0.17178896689833, 0.9304485069516456, 0.9113012657246453, 0.899641278293201, 0.9320392177541923, 0.9770186266527948, 0.9526382425353037, 0.964991440956482, 0.9498271370466436, 0.9422205666854931, 0.4022944227586257, 0.4021348815128635, 0.41004003671087497, 0.4014773685268882, 0.4238267175633078, 0.4216474355239309, 0.32534814638287834, 0.4312002405068931, 0.43145052814569973, 0.5783420215186745, 0.5528268643236984, 0.572965935223662, 0.5198638129985211, 0.5413320072581541, 0.5930432512109346, 0.56601028159427, 0.5734588286594591, 0.5481458849023764, 0.14388414850260356, 0.17495045287117506, 0.1983813700139463, 0.21178791786211182, 0.16643878351203367, 0.1654728521048039, 0.17895527605704442, 0.18822655588541626, 0.15385741728051894, 0.19034207828718452, 0.10969508564969199, 0.11462399441917204, 0.16327529642404548, 0.22071475406118568, 0.16030369408694312, 0.16547450679628584, 0.15938916346532261, 0.15359725984569284, 0.10954492550040795, 0.13785965372559528, 0.24305892481876945, 0.15115362306362568, 0.29838735482544654, 0.25839594350109873, 0.10779894715937155, 0.1411730042475423, 0.1560135793500096, 0.22811560852278534, 0.4441489969860518, 0.18982034020434235, 0.34580410283776397, 0.33074920303781774, 0.2308740191091856, 0.3303818855014533, 0.21882468514285658, 0.2471082032794797, 0.03686549631347458, 0.039739689728001015, 0.03655670071938222, 0.10812566701538184, 0.06769487073664282, 0.0330691015784188, 0.10920794924269217, 0.1034359695746574, 0.0740042853435674, 0.18041953374261666, 0.2017572998555135, 0.16088043829743237, 0.2139707759499142, 0.20885275841815232, 0.19165449660608425, 0.2010003615305379, 0.15789731401361984, 0.18408219750516497, 0.5339189399821194, 0.5026175337159007, 0.5436120928480516, 0.5158913256628022, 0.49946612533139656, 0.558193448483682, 0.5281211502862309, 0.5400082214223794, 0.45701764407495715, 0.0931390957609094, 0.09750472819071454, 0.08855515349688226, 0.07922233189385042, 0.08380390399707371, 0.08435645752348442, 0.08253855945855981, 0.09366958739263331, 0.09690373977883826, 0.17601288603441623, 0.1469372658166942, 0.166838921527929, 0.15127828503681173, 0.1364325482881077, 0.14886545109507954, 0.1558214925419803, 0.12684464194835787, 0.1584028877261473, 0.3281540642760866, 0.36027342556845154, 0.3311072488437601, 0.3528579349748795, 0.3059055619450535, 0.31690880750900774, 0.4128111604206661, 0.36561782672573184, 0.3923753763472013, 0.2461585985964585, 0.22898144919944396, 0.22957764373393508, 0.239013386600062, 0.21032151049802328, 0.2228958284513719, 0.2711001855649118, 0.2727073416359348, 0.2519494745452797, 0.1650051978218927, 0.17826173393682332, 0.18903541801667223, 0.2021491856660026, 0.17644669739194652, 0.1871456406272194, 0.20657396293855323, 0.1797307546143294, 0.2070029308765241, 0.23424967304589506, 0.2046998847404603, 0.26530069304414694, 0.32342092178620674, 0.2423010729617694, 0.1880655826833073, 0.1860941971944129, 0.17685838270291765, 0.1911475293150403, 0.6445031724438453, 0.4219990082821582, 0.18553786014123486, 0.5265458904897101, 0.48317705237243913, 0.47529700706969413, 0.3726302631127155, 0.5251681921186762, 0.5346418100740367, 0.5506498877562156, 0.18867649490878535, 0.6246695598109935, 0.21641282718763666, 0.2068091188717891, 0.4812080706733365, 0.7231026199318364, 0.20237308746696558, 0.20674466030682315, 0.17995467881511917, 0.18847595782356752, 0.19811739883997803, 0.20178687081301416, 0.18663921880122236, 0.19222982212582362, 0.19874805814316276, 0.1860534786141762, 0.19626136440603137, 0.06892331142672481, 0.07701595277486672, 0.07586906352249667, 0.07159088529783164, 0.07153710511442002, 0.06721199653019505, 0.08359403174043545, 0.08315506711305298, 0.06936411638231932]}, "mutation_prompt": null}
{"id": "a1b9257a-dcbf-4cf0-bacc-987a250cf824", "solution": "import numpy as np\n\nclass RefinedEnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.exploration_weight = 0.5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _covariance_guided_mutation(self, individual, best_individual):\n        if hasattr(self, 'covariance_matrix'):\n            return np.random.multivariate_normal(\n                best_individual + self.exploration_weight * (best_individual - individual),\n                self.covariance_matrix)\n        else:\n            return individual\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.exploration_weight = np.clip(self.exploration_weight - adjustment, 0.1, 0.9)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False) + np.eye(self.dim) * 1e-6\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                guided_mutant = self._covariance_guided_mutation(population[i], best_individual)\n                trial = self._crossover(population[i], guided_mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedEnhancedAdaptiveDELS", "description": "Integration of a dynamic step-size adjustment and exploration-exploitation balance with stochastic covariance-guided mutation to improve convergence.", "configspace": "", "generation": 10, "fitness": 0.23238974783879182, "feedback": "The algorithm RefinedEnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.22.", "error": "", "parent_id": "68122ad2-e998-42a0-bad4-6deb13e9cc29", "metadata": {"aucs": [0.6866325105572744, 0.6160287581132016, 0.6464784701118467, 0.6052355249955077, 0.6872830966615466, 0.6309676519313973, 0.6949903203434605, 0.6865465472198422, 0.6820009240055822, 0.2899277896752962, 0.30073824714046127, 0.32782506078134066, 0.3367558333705327, 0.3279712098285974, 0.3381221513216791, 0.2966145709890746, 0.2703001292477655, 0.30158178441078154, 0.11613065499335007, 0.09520046586783026, 0.10212121939924057, 0.08978789273022103, 0.10125497084758261, 0.09900671652936943, 0.11144430074917822, 0.0960786906937734, 0.08973168959756661, 0.0807655283157721, 0.07477745271843872, 0.07858352616750286, 0.08943064532087153, 0.0951301353988816, 0.06178543175925566, 0.08401186802078997, 0.10374512883843778, 0.10198744995832199, 0.9863061938581452, 0.989478643679295, 0.987442596930776, 0.9857676257584376, 0.985365765268071, 0.9874608344962769, 0.9858828111433235, 0.9872104975836621, 0.9882145012461574, 0.13747032335611054, 0.09738460967246176, 0.05641033972624787, 0.11865403094037297, 0.12836498976506805, 0.12116155526656025, 0.07371158281356582, 0.1050183935094976, 0.11199452493544382, 0.6735478877898876, 0.30755440163849657, 0.31132660820204117, 0.4646870768243341, 0.586579025951961, 0.3021174204038407, 0.25423121925175285, 0.625476607411063, 0.624323590557468, 0.09447102626687409, 0.09420594885273004, 0.1306342450002983, 0.13450214618564937, 0.16819193789067322, 0.11206328403097321, 0.10983312799453993, 0.14479690803346057, 0.13535649623678236, 0.18585016930713572, 0.11071344215481238, 0.16074872188230815, 0.1709525321776384, 0.12946853767862776, 0.14499812553388625, 0.17774221214254393, 0.08247908224107248, 0.12055649260141543, 0.07201068479535966, 0.05051570593115029, 0.09618435422036486, 0.09478491789886356, 0.008312442958629984, 0.08697990112507303, 0.057748197654221234, 0.09361861868805554, 0.08519649432399423, 0.25846592454804895, 0.19140812016294095, 0.19275126009879928, 0.24870582536321895, 0.0958994742164817, 0.19147485598689407, 0.1678263081065723, 0.13135079922431336, 0.21694542672451067, 9.999999999998899e-05, 9.999999999998899e-05, 0.05721937186890791, 0.0009894784354460562, 9.999999999998899e-05, 0.013046748939539943, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15773544650007276, 0.1309589538113647, 0.14140630474822957, 0.14031740960446626, 0.1435879849224695, 0.1692130523069698, 0.1327984723044645, 0.0940062054876567, 0.13456302333207715, 0.47578152845391186, 0.4636228429420164, 0.40998625338326244, 0.519289976254226, 0.5182159851418251, 0.477792043101941, 0.5516301593702977, 0.4518524501205582, 0.49351122282636783, 0.09631330966190454, 0.08325508597217035, 0.07234302297676987, 0.09971949033425809, 0.06994075499029373, 0.07400248992215452, 0.0885412630144452, 0.0742432277772197, 0.08029008895237622, 0.1300384459673114, 0.10083584821276614, 0.12593394817505088, 0.12091917315108025, 0.12575802878948694, 0.1169666253084295, 0.11530638167383933, 0.14393288028757512, 0.1204363044362804, 0.2793827657814917, 0.19823435033962533, 0.2502449804805441, 0.32012387789350205, 0.2737655341766956, 0.3244403980255808, 0.24239448333387004, 0.3156848623694889, 0.29427750973083067, 0.24312058186854146, 0.19412993017193225, 0.20160575107119494, 0.20384344133649035, 0.11905514343759149, 0.17479752886276545, 0.22553147859549705, 0.2229219349135424, 0.20311085172975607, 0.2006894603476741, 0.15553804998329357, 0.1939868952170104, 0.18445438527344327, 0.15393168987058747, 0.17415823776771233, 0.20159927887676576, 0.15894885520514512, 0.1697151729669948, 0.17058671451803953, 0.1954880090860579, 0.1678550057725593, 0.17702469709611302, 0.17159194863187188, 0.17146445442774982, 0.16613137131173716, 0.1720380748930327, 0.17911650694435632, 0.17660585653004968, 0.13306419141412495, 0.11576877764376492, 0.18080427103064522, 0.3688539682165557, 0.14943505536128288, 0.17687032830898808, 0.342860961447253, 0.15528249709189512, 0.322758368124469, 0.17915335008013644, 0.19855644931978045, 0.3889596931601469, 0.32506967363528927, 0.2172996137002341, 0.1899135950322065, 0.1547040522869707, 0.18246128986160448, 0.15971048789768416, 0.16729287913908653, 0.17848218268768545, 0.17634304011357305, 0.16950791943238475, 0.1817424277231967, 0.17263053712975418, 0.16191992039063385, 0.1652187921124465, 0.06647521483192198, 0.070837727176573, 0.06443286407011106, 0.06928262183149814, 0.06438163392993623, 0.05889862973908189, 0.07488650382145368, 0.07508791287955008, 0.06488499542768678]}, "mutation_prompt": null}
{"id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 11, "fitness": 0.3089290465231646, "feedback": "The algorithm RefinedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.22.", "error": "", "parent_id": "68122ad2-e998-42a0-bad4-6deb13e9cc29", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "610ad7a1-600f-4413-8365-90c3c76ac3a2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELSv2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        noise = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        mutant = a + self.mutation_factor * (b - c) + noise\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n        if np.std(fitness) < 1e-5:\n            self.learning_rate *= 2\n\n    def _resize_population(self, evaluations):\n        factor = 1 - evaluations / self.budget\n        self.population_size = int(max(4 * self.dim, self.init_population_size * factor))\n        self.population_size = min(self.population_size, self.init_population_size)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELSv2", "description": "EnhancedAdaptiveDELSv2: Integrates covariance-guided mutation and dynamic population resizing with adaptive search strategies for an improved balance across diverse problem landscapes.", "configspace": "", "generation": 12, "fitness": 0.1980107081151574, "feedback": "The algorithm EnhancedAdaptiveDELSv2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.4451373739105676, 0.4229856883897424, 0.4397368089769652, 0.4142599931924409, 0.40504599436785915, 0.42000293875796657, 0.4060776486278628, 0.4249939911910757, 0.4106038112803291, 0.03303014453572928, 0.0519188762691396, 0.03685187375231058, 0.051501110994607524, 0.030873582968029223, 0.035064944056356184, 0.028136100344295478, 0.022144644365770128, 0.01514960643258434, 0.10870005980032404, 0.1181439263427132, 0.12271233309839591, 0.10531669466564564, 0.12008511787942511, 0.11739551051968178, 0.12017767018478931, 0.1071705495095362, 0.12229846500634889, 0.10418196510058553, 0.10878097934849906, 0.09269512359479026, 0.09376770781939381, 0.09267031603100473, 0.10543357133804088, 0.10442295145494318, 0.1147944349365917, 0.10231222351697267, 0.9667249123535021, 0.9669984951746272, 0.9415547127794487, 0.953968145946075, 0.9666366352357536, 0.9497996797807438, 0.9593165613050731, 0.963657002409411, 0.9617860247352678, 0.1872099777124424, 0.21785131865879237, 0.18521047972741966, 0.20095259270952048, 0.20393698366491475, 0.2131007119188445, 0.20035568408717797, 0.23292306222802295, 0.22424136979652554, 0.20069672253894555, 0.2177368155225663, 0.2964782074107214, 0.2054556468147939, 0.22933009930656667, 0.21437790920853406, 0.2216394565045975, 0.21920369397238482, 0.46254782751472434, 0.11832172787251927, 0.13677762618394862, 0.11772355965753145, 0.12904000693847884, 0.10757242095829245, 0.122377593752376, 0.12241362303217918, 0.1518716302091523, 0.10725319911950482, 0.12661541373581053, 0.10474716140175677, 0.12024045899923463, 0.14774927198297105, 0.12801486690370312, 0.10878010638502333, 0.1341698988407235, 0.12186757637468859, 0.13362204756116303, 9.999999999998899e-05, 9.999999999998899e-05, 0.005019884143869557, 9.999999999998899e-05, 9.999999999998899e-05, 0.006464939224134825, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09008119995870745, 0.07401043609434255, 0.07301567171441259, 0.06523583980624148, 0.05262882874974206, 0.05917152734061604, 0.04626660071517108, 0.08733977336511523, 0.07174039533467458, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08677275533427531, 0.0891962524844857, 0.08325360942976767, 0.10007644361085766, 0.07934700378557824, 0.08890117491248872, 0.06056340675816552, 0.09725527762137642, 0.10012780437639413, 0.37112862191682694, 0.3582476916137508, 0.39574988821726786, 0.3723917882339255, 0.35833262836401847, 0.37655580889456386, 0.3712914896911087, 0.3680342480155756, 0.3913656421043177, 0.0777313743051985, 0.1211278790202841, 0.10112692552548819, 0.11496149178605408, 0.0983360741620769, 0.09121780973246219, 0.0976617796863376, 0.14403516910197012, 0.08861221469630343, 0.17631332936543354, 0.18305993679945276, 0.16477493986646674, 0.19483966133059327, 0.18584356512957, 0.15125807840828998, 0.17528023581965968, 0.19307834866003737, 0.1549398069324216, 0.24303004175583176, 0.2490250505089706, 0.2232722804015621, 0.22727822029510658, 0.19394453327573447, 0.22094343732691912, 0.2517767901136516, 0.23471444058372282, 0.2544884402283023, 0.18994151018580374, 0.1852948370884725, 0.16296099523689478, 0.17058310981955271, 0.16475289557893302, 0.15663978679428858, 0.15446017897590247, 0.16718731959540778, 0.18968416786879994, 0.1926706056643389, 0.17470357457236385, 0.1790001368514963, 0.22560836487529923, 0.18174706306970134, 0.18241233215108377, 0.17994427909495314, 0.17938412989783015, 0.1841266076855076, 0.18611612552911305, 0.1846388601908423, 0.2135609553488469, 0.1777613201492355, 0.1862046835610991, 0.18730295104551564, 0.1845702726759414, 0.1751793032800837, 0.1797707392210317, 0.2427018065783506, 0.18043950615010795, 0.19548710943239767, 0.2673193172716819, 0.3800662020531146, 0.23971203577339473, 0.45521733370160766, 0.20223175748635513, 0.3520157617598849, 0.3211495500223501, 0.36288220834318974, 0.29043700526281413, 0.32404185494332016, 0.2845830146277383, 0.17804166566550617, 0.4199624281022515, 0.20534556734098974, 0.20549953640027774, 0.17595942681832788, 0.18816540729618136, 0.18820350049741974, 0.1742969390910124, 0.17758250852806645, 0.17350618235125026, 0.20116452308841049, 0.1859450197366117, 0.19246763540892176, 0.07423299870894862, 0.07571567841191951, 0.07257814444989685, 0.06755195399896041, 0.07488506497090197, 0.06814593161559346, 0.07627373957347228, 0.07465436770898126, 0.07438102557800375]}, "mutation_prompt": null}
{"id": "f5903345-a5c2-4ab7-8f1a-7d9d3f015ad6", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "08820985-4ab9-409b-80ab-650e103558be", "solution": "import numpy as np\n\nclass EnhancedRefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = (individual + global_step + \n                     local_step * (best_individual - individual))\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            new_size = max(4 * self.dim, self.init_population_size // 4)\n            if new_size < self.population_size:\n                self.population_size = new_size\n\n    def _update_covariance(self, population):\n        centroid = np.mean(population, axis=0)\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedRefinedAdaptiveDELS", "description": "Enhanced RefinedAdaptiveDELS with dynamic population resizing, differential covariance adaptation, and self-adaptive control parameters for improved convergence efficiency.", "configspace": "", "generation": 14, "fitness": 0.3089290465231646, "feedback": "The algorithm EnhancedRefinedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.22.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "345c1e9c-15a3-494b-b340-e12045662c48", "solution": "import numpy as np\n\nclass EnhancedDynamicAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.scale_factor = 0.5  # New scale factor for covariance adaptation\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, covariance_matrix):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + self.scale_factor * (global_step + local_step * (best_individual - individual))\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population):\n        centroid = np.mean(population, axis=0)\n        deviations = population - centroid\n        covariance_matrix = np.cov(deviations, rowvar=False)\n        return covariance_matrix + np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            new_population = np.empty_like(population)\n            new_fitness = np.empty(self.population_size)\n\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    new_population[i] = trial\n                    new_fitness[i] = trial_fitness\n                else:\n                    new_population[i] = population[i]\n                    new_fitness[i] = fitness[i]\n\n                if trial_fitness < best_fitness:\n                    best_individual = trial\n                    best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            population, fitness = new_population, new_fitness\n            self.covariance_matrix = self._update_covariance(population)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), self.covariance_matrix)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedDynamicAdaptiveDELS", "description": "Enhanced Dynamic AdaptiveDELS with covariance matrix adaptation and adaptive population size to improve search efficiency and exploit landscape information.", "configspace": "", "generation": 15, "fitness": 0.2933472030163302, "feedback": "The algorithm EnhancedDynamicAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.21.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6679791321042661, 0.6611820494919903, 0.6580418488276735, 0.6722932039930583, 0.6550160370866231, 0.6834503014633376, 0.6740561352036274, 0.6687473288356889, 0.6800200004147954, 0.44504315017860063, 0.46042714774770177, 0.45326135876195217, 0.43767515325548223, 0.4405870322684694, 0.4573552532280587, 0.4754435308927327, 0.4431304124545127, 0.4540512713239775, 0.12330954606634581, 0.11621955825276875, 0.09681893095102201, 0.10963145898966997, 0.12903985674272223, 0.12783296604230476, 0.10853236697241375, 0.12926417396871925, 0.16389273515351432, 0.0854953131224987, 0.11052221260175976, 0.10241921454355252, 0.09506776130974881, 0.1188323831195297, 0.1123006563019251, 0.10422748003407212, 0.11088560790441426, 0.09683904922120068, 0.9281573782137295, 0.9241476651238143, 0.9362262376277755, 0.9069611986770767, 0.914741584342828, 0.9385052498042404, 0.9470414303751519, 0.9533312591323806, 0.9492002619275156, 0.3832339630687054, 0.3197665239416194, 0.38239497991008853, 0.3498905901284637, 0.3945125678901531, 0.35717200576331776, 0.3518029648061545, 0.3640647645834908, 0.40273799568316804, 0.48580446453139003, 0.5025374928392856, 0.49670047052964117, 0.6301390635407429, 0.5321258317783577, 0.542889720847592, 0.54542991398566, 0.5707620167555952, 0.5505662589624073, 0.18280036498971863, 0.29121758136968323, 0.21994855026584337, 0.2389572200193819, 0.2709645609962722, 0.25975737465423576, 0.24339571306092844, 0.23158964730735154, 0.278420774987823, 0.2608126892632292, 0.3219432510499073, 0.2508757789101077, 0.2243708258244984, 0.1775295386757333, 0.2300146627952676, 0.2358111574879186, 0.20510690842598744, 0.2454128964259218, 0.13981939352718764, 0.155891441548078, 0.1787923344659883, 0.08907271154660845, 0.13478989258068064, 0.11599137875618748, 0.1475891521624031, 0.15777037340649058, 0.2233199756984957, 0.27811325868001746, 0.2407515735770176, 0.27468154885350415, 0.24964477492989945, 0.24426942904424964, 0.24637403015504455, 0.30781787543230876, 0.3075167937685521, 0.29251720270748416, 0.02154377117854056, 0.05566404199309294, 0.04889412640977442, 0.05994903683733044, 0.11884663690300079, 0.10168941125445419, 0.06798407121731964, 0.0633169731696136, 0.06791436461397693, 0.1710744200116049, 0.17717970903423208, 0.19212297781461607, 0.2298394193831581, 0.2129490569612682, 0.1767464099285413, 0.17316048154233, 0.18923295608176705, 0.18389609664213535, 0.5247382935505904, 0.48745565898178833, 0.5330860738580887, 0.5017661769387836, 0.5009780806848023, 0.5296256812619254, 0.5420251460149905, 0.49237600730060216, 0.5329455128375364, 0.09326919766434039, 0.09669181005818095, 0.08435855490403377, 0.08462014714674859, 0.08617810419079541, 0.08804456669063487, 0.08598839933787239, 0.11381527049499962, 0.08151260112592573, 0.1378437760354203, 0.1907600656686279, 0.13103450297049768, 0.15210926329708196, 0.16620563725725102, 0.15702292865782908, 0.19396508335496676, 0.13501315402404557, 0.13887518244035857, 0.30486341256244764, 0.3105165055431425, 0.3107888820207335, 0.2794836545181376, 0.349322908261008, 0.3010444352820778, 0.3271908326690236, 0.37369375136994565, 0.33109543904974525, 0.20347871665925488, 0.22699368391103514, 0.21952630254942973, 0.24250772729675318, 0.21559648039493573, 0.22456515194721183, 0.24789488844930885, 0.23850064509004865, 0.2263638972610056, 0.1697771809063846, 0.1932725271749377, 0.19871997549809617, 0.1860067956836844, 0.17289465768510748, 0.16745345342918683, 0.18084740652023945, 0.1868233849230092, 0.1953858762991838, 0.18664753543931756, 0.23930418298167644, 0.30482143408668505, 0.19822480335659654, 0.24119111689904116, 0.3343623630297692, 0.2101379314826295, 0.17673912503847733, 0.3361969833429296, 0.4503633287201393, 0.16422919569492223, 0.5908556056141727, 0.5549092862958958, 0.553986139367618, 0.18801838232098322, 0.47987808861182835, 0.4412566338069325, 0.40643955937835796, 0.1899458970037633, 0.4807458103186899, 0.38178272310740813, 0.3354875392266904, 0.17843954258773143, 0.19734584006945055, 0.20475899770052042, 0.19629334331176618, 0.2065472216081644, 0.1829563241335419, 0.17635147796651496, 0.18800214080891853, 0.18512444634763014, 0.18178473105428283, 0.18817163537816328, 0.18865557696823365, 0.1797217558428481, 0.18184702416989562, 0.07480613775076894, 0.07820941813414684, 0.07492008821336094, 0.06606708032102049, 0.08623279281630969, 0.07388025905529216, 0.07451786161945251, 0.0783053195080392, 0.07222764940512005]}, "mutation_prompt": null}
{"id": "ded8fe07-a74d-4a3b-a00b-3531d344c7cc", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.memory = {'mutation': [], 'crossover': [], 'learning': []}\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adaptive_memory_control(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.memory['mutation'].append(self.mutation_factor + adjustment)\n            self.memory['crossover'].append(self.crossover_rate + adjustment)\n            self.memory['learning'].append(self.learning_rate + 0.01 * adjustment)\n\n            if len(self.memory['mutation']) > 10:\n                self.memory['mutation'].pop(0)\n                self.memory['crossover'].pop(0)\n                self.memory['learning'].pop(0)\n\n            self.mutation_factor = np.clip(np.mean(self.memory['mutation']), 0.5, 1.0)\n            self.crossover_rate = np.clip(np.mean(self.memory['crossover']), 0.7, 1.0)\n            self.learning_rate = np.clip(np.mean(self.memory['learning']), 0.01, 0.1)\n\n    def _transition_phase(self, evaluations):\n        if evaluations < self.budget * 0.3:\n            self.population_size = self.init_population_size\n        elif evaluations < self.budget * 0.7:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        else:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adaptive_memory_control(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._transition_phase(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "EnhancedAdaptiveDELS with memory-based parameter control and dual-phase search for improved exploration-exploitation balance.", "configspace": "", "generation": 16, "fitness": 0.30119149682010254, "feedback": "The algorithm EnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.23.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6949933561477547, 0.6966777070287006, 0.6998425338292493, 0.7126966219563924, 0.6999516707831941, 0.713834589713261, 0.7108140654798802, 0.6892089183809261, 0.6816586676862446, 0.5426554691348058, 0.5952421816816451, 0.5653885693033971, 0.5532884343520953, 0.5851410381579402, 0.5445965186042447, 0.5544137207694845, 0.5364134109570171, 0.5704265092035028, 0.1182845761160175, 0.16811826248385953, 0.1379890129511605, 0.19271876091680584, 0.12665089713061572, 0.23374257435672574, 0.11706451859305211, 0.18379537333487939, 0.16202890109393608, 0.12256204288257999, 0.15642587544196918, 0.10043239055253106, 0.15327773358234986, 0.13656522883801558, 0.10544829356187824, 0.1150440889034231, 0.13839693678162968, 0.12877635681652844, 0.9169468945460314, 0.9321793313070932, 0.9111176312191491, 0.9659629877011288, 0.9718905211254943, 0.9402724978243578, 0.9302647135781107, 0.9673318904811814, 0.9687927867491667, 0.38553686586150715, 0.3732330524174221, 0.40114109246775564, 0.4401581845650342, 0.3585487427541043, 0.3777519384806146, 0.3651780355961016, 0.42815484530843495, 0.39017544379739355, 0.4525576906147385, 0.5988869349346183, 0.561184099223075, 0.5650528303105067, 0.6329001700961727, 0.6284714396447918, 0.5783276187363795, 0.6790000060337289, 0.5767634691544969, 0.185167982700716, 0.18019027952025624, 0.17750605581977652, 0.1810425913867565, 0.1905038843321576, 0.1863262815028507, 0.16750303436589364, 0.22128814690732357, 0.16826885741604114, 0.14771975228207235, 0.17418843053546884, 0.28711773134131613, 0.13639775229261408, 0.1637808818997546, 0.15314737783555088, 0.1816735411725815, 0.1813433931786309, 0.16855267493874093, 0.11240290300041555, 0.07048780085154971, 0.10742550220965308, 0.08635841251200838, 0.09250962908600291, 0.1398615385143226, 0.08849413654149862, 0.08329246586317862, 0.0882320972683317, 0.23612490653306006, 0.21608685335822697, 0.19051948660406748, 0.21128336670040793, 0.22098244186423477, 0.18346575114261654, 0.2638754724867417, 0.23183537880439642, 0.2784682028709259, 0.013526705309968912, 0.00935598045991426, 0.029968649196514208, 0.02364476019899797, 0.016627316843516593, 0.03390492660309519, 0.06858278927953232, 0.02272654097227933, 0.055807696202913926, 0.1752344899615368, 0.1473472843031285, 0.1662901006602575, 0.1555872808394272, 0.1746054606776266, 0.21043549297584385, 0.16095783795710428, 0.16215333045347324, 0.1496980688752716, 0.4941546567585541, 0.5099758851676447, 0.4976333830074253, 0.4800020781868082, 0.505096841773014, 0.508389464110607, 0.5180583121028369, 0.5040340702079531, 0.5157718299250413, 0.1050941602848059, 0.10285337147453444, 0.09818371756302313, 0.11728203264686088, 0.12799339323095227, 0.09972193044643352, 0.08882616608363714, 0.08579581313775375, 0.12666570782326614, 0.2653610855428806, 0.146303372839654, 0.1791558718893328, 0.16414367304695732, 0.1946210480220576, 0.16444191133747332, 0.14764761393429904, 0.13478808318430346, 0.12785417598703896, 0.2893223356336512, 0.3244791470113825, 0.3443279233262426, 0.2915273307459908, 0.3181176127197426, 0.3372459343786627, 0.3282450334807856, 0.3599310715007177, 0.38245060559307276, 0.2181921806435242, 0.18616824828818146, 0.233414907609505, 0.23186398694497934, 0.2269536371187849, 0.21226211290787955, 0.22942542472994842, 0.22506746960744162, 0.2780373302007463, 0.19963624140929082, 0.17495571155587475, 0.1633629107921848, 0.1638731861713595, 0.18725220313136293, 0.17136091926431785, 0.1982607781840241, 0.17891302448304736, 0.16735524256208556, 0.19725885310185987, 0.28534486814776505, 0.1952970185997679, 0.21548009047013506, 0.22379167765468533, 0.19883832982704075, 0.2097672150576535, 0.18870609535990535, 0.2054321185017105, 0.6764113241708014, 0.6556416220346735, 0.6676350035344623, 0.5641766696767105, 0.5455913401464174, 0.6040372625183594, 0.4287613221704051, 0.39148360833845464, 0.5342921486095504, 0.3683727230824072, 0.19218968370299094, 0.19988275177829495, 0.23470814593683342, 0.19576868029006467, 0.4955671874748627, 0.554203354841118, 0.4386273695782298, 0.20467051874569198, 0.18611452181890809, 0.18647163555677004, 0.17869183868190341, 0.18160691944383822, 0.19861456358127594, 0.20890410168095364, 0.19060668286338345, 0.18354062594695475, 0.19613213248650885, 0.07452288840105159, 0.06281394642946947, 0.07372518524800686, 0.07999774814176874, 0.07790961705034605, 0.07603579914721326, 0.07262916260664964, 0.08142422663896776, 0.07160534491056403]}, "mutation_prompt": null}
{"id": "efa2b77d-2296-419a-8266-8c89025fc540", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.convergence_threshold = 1e-6\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness, previous_best_fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _dynamic_strategy(self, current_best_fitness, previous_best_fitness):\n        if np.abs(current_best_fitness - previous_best_fitness) < self.convergence_threshold:\n            self.mutation_factor = 1.0\n            self.crossover_rate = 1.0\n        else:\n            self.mutation_factor = 0.8\n            self.crossover_rate = 0.9\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        previous_best_fitness = best_fitness\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness, previous_best_fitness)\n            self._dynamic_strategy(best_fitness, previous_best_fitness)\n            previous_best_fitness = best_fitness\n\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with dynamic strategy switching based on convergence rate and self-adaptive mutation and crossover parameters for improved performance.", "configspace": "", "generation": 17, "fitness": 0.2548157210528277, "feedback": "The algorithm EnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.20.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.5004588437805766, 0.5638114107469655, 0.45063875007842136, 0.5570404949925679, 0.576117469156612, 0.554603761789701, 0.47376646463107697, 0.5364821138992674, 0.41822762411825953, 0.2999422225857219, 0.33352027301745935, 0.35036719814364037, 0.3444717467272953, 0.2554670757088482, 0.31667181954861523, 0.28291310136536296, 0.37361397939326857, 0.3117448387463433, 0.09960893352890232, 0.08229244248997636, 0.10021187194524261, 0.10617766556660768, 0.10061214520716599, 0.11784397915746836, 0.0849885383390745, 0.09677884767285794, 0.12918243305602994, 0.07782173132485937, 0.07324156947558136, 0.06575079440625542, 0.0806167642125134, 0.08881533258195473, 0.08145193780633653, 0.0875292475907612, 0.08092786386438278, 0.09189399299706325, 0.9318541519814864, 0.9581685649048638, 0.9542079975351901, 0.9732949780677428, 0.9781689646009829, 0.9591687007646736, 0.9708021456991772, 0.9581332375912621, 0.90094696941292, 0.25299672682933017, 0.2810107709197609, 0.2991408613514219, 0.31284495846538685, 0.22773143314445987, 0.2945930300730102, 0.29206524397214295, 0.2881216341683134, 0.3126101862553584, 0.2918835192470277, 0.2921169193415396, 0.5086078420924647, 0.34076461463685515, 0.5026691017196518, 0.5965758605635855, 0.3081606617823369, 0.3260860268909953, 0.29047261211879283, 0.21233738630058352, 0.13085112331644033, 0.17334889091752104, 0.2844188034589936, 0.13702760230623134, 0.15525623138313827, 0.17721861975015107, 0.16040105327900334, 0.16461564162950326, 0.09837376478903259, 0.09922986329357775, 0.135734076834358, 0.23585179540527146, 0.13264943049371958, 0.20271793323916076, 0.13975239724507105, 0.23746605199120419, 0.2881572515861047, 0.11938820401084826, 0.1800233482324225, 0.11136058957610584, 0.20613461734785055, 0.0742653109962268, 0.09298114611010333, 0.19718184077957235, 0.17845958044536947, 0.07214037399773554, 0.32953727252726317, 0.2695007961795456, 0.23454741641016186, 0.2931035918925621, 0.1590430651360193, 0.2768690521122411, 0.32615793138444393, 0.25421215448403545, 0.37241343312200126, 0.036238338815440474, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09772361640642924, 0.04173073846311404, 0.021562663531082715, 0.032887548381952736, 0.12233872950428881, 0.11512827951691418, 0.20878764971310626, 0.1369525362682974, 0.20109748714371767, 0.12188772405393922, 0.18212159363380165, 0.18424388355697552, 0.18275069396353028, 0.3739869371706137, 0.5004037178910377, 0.3988105493406856, 0.39193522203509945, 0.4763079999901836, 0.387038901727214, 0.4844395632084655, 0.40609869468384796, 0.4820959790187054, 0.08119724092631897, 0.11661506314321979, 0.12036361373200122, 0.08245288131639461, 0.09770087536929073, 0.07818040137878257, 0.10412119981355716, 0.11177980693933409, 0.11844512007466579, 0.1952430164366682, 0.13742302551161445, 0.14957026717981026, 0.20532729146200934, 0.2142989166154503, 0.1493988655951145, 0.2142812682010261, 0.1712328874140634, 0.12977628986864076, 0.25096686875552476, 0.24288090696647247, 0.2667063593405723, 0.24905072494119174, 0.22752944453759738, 0.23370750770576376, 0.2621278403666275, 0.2645750748083966, 0.24747892605710675, 0.16730515862269257, 0.1820992302699983, 0.20082683762703668, 0.18911283212815544, 0.17674380735797934, 0.1808114878465037, 0.18712699631295016, 0.19261984908704266, 0.1856670769619322, 0.1619090361684059, 0.1790527268425407, 0.17987667605340807, 0.18693044504075307, 0.18966547848572857, 0.19557104266970915, 0.1720169097372316, 0.17051628229607652, 0.17227940695198396, 0.18805534252939182, 0.1756538009467129, 0.18156902564998212, 0.19209272949759004, 0.17144925688191215, 0.17705528259451553, 0.18661076580788072, 0.183935561230966, 0.17581676060740992, 0.2009076623717636, 0.1656395878598398, 0.6059384275364791, 0.4625301208342425, 0.18982702265363494, 0.5091619490554434, 0.5609005143522872, 0.5667404776792153, 0.18273811516481575, 0.5083195096732263, 0.20065758681433254, 0.19093159121017633, 0.19223662057416624, 0.19720547885384643, 0.5614189513276162, 0.6175908532327703, 0.631880045831821, 0.20308716557741768, 0.2053884861630384, 0.20666930229968328, 0.19708552372428034, 0.19999633102933423, 0.20662173353373225, 0.1842391803607163, 0.19414331777464522, 0.18479243883001184, 0.19321502736124951, 0.0866012519146292, 0.062292788820203504, 0.06804630627542518, 0.06816464611897699, 0.06369145650576524, 0.07604093454003702, 0.07273978231777711, 0.06549479622691379, 0.08395958858177288]}, "mutation_prompt": null}
{"id": "2caf8bd4-15a6-48d0-878e-b72323e6100f", "solution": "import numpy as np\n\nclass EnhancedCovarianceDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        cov_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix = cov_matrix + np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedCovarianceDE", "description": "Enhanced Differential Evolution with Adaptive Covariance Matrix and Dynamic Population Sizing for balanced exploration and exploitation.", "configspace": "", "generation": 18, "fitness": 0.3089290465231646, "feedback": "The algorithm EnhancedCovarianceDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.31 with standard deviation 0.22.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "c583de08-0ca9-4b69-9503-11c477335a77", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "c8d49604-8fed-4430-bd8c-4888f276d19c", "solution": "import numpy as np\n\nclass ImprovedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.elite_size = max(2, dim // 2)\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, centroid, covariance_matrix):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        direction = np.random.multivariate_normal(np.zeros(self.dim), covariance_matrix)\n        mutant = a + self.mutation_factor * (b - c) + direction\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, elite_population):\n        deviations = elite_population - np.mean(elite_population, axis=0)\n        covariance_matrix = np.cov(deviations, rowvar=False)\n        covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n        return covariance_matrix\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            elite_indices = np.argsort(fitness)[:self.elite_size]\n            elite_population = population[elite_indices]\n            covariance_matrix = self._update_covariance(elite_population)\n\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population, np.mean(elite_population, axis=0), covariance_matrix)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(elite_population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "ImprovedAdaptiveDELS", "description": "AdaptiveDELS with self-adaptive parameters, covariance-based mutation, and elite diverse population management for enhanced convergence and robustness.", "configspace": "", "generation": 20, "fitness": 0.263885576382726, "feedback": "The algorithm ImprovedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.20.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.5985585822293512, 0.5945575938270968, 0.6029815323771072, 0.6371191762817656, 0.6380450289770647, 0.607492471131586, 0.6327679948805753, 0.5862512451608615, 0.6370497561257586, 0.3091776229115929, 0.3020021139605228, 0.27665795106128943, 0.30233866929663045, 0.28702059164787763, 0.3299516068465609, 0.2978994334967523, 0.28411058678565404, 0.29932144565870744, 0.11600994135320974, 0.1100025672660413, 0.10369272861314727, 0.11320806279448481, 0.10676497101174898, 0.10614082798665059, 0.12526690563115894, 0.11780205525809218, 0.12645303860408297, 0.09473906979297386, 0.09109263142739432, 0.09159137803000816, 0.11197004708297265, 0.08903509863718695, 0.08487271396980411, 0.0985510395321606, 0.09603844255479632, 0.10031613052115296, 0.9268152802022086, 0.94394325910923, 0.9368487457744132, 0.9053733910260925, 0.9173670268431677, 0.9218095948350022, 0.9347535763188415, 0.8709405855997305, 0.8395402903370947, 0.35183756546810674, 0.3284023363644697, 0.32242037662198586, 0.31545817973295676, 0.3272465885941028, 0.3464706310601875, 0.351069656811522, 0.25607038436626095, 0.34499489697399166, 0.5233958161893997, 0.5859845419254169, 0.5038443649083935, 0.5196135123617764, 0.5448480564342195, 0.5779689411513678, 0.5019206027662111, 0.5331976773607292, 0.5386213276935672, 0.17042481497997886, 0.1664638109460007, 0.22694436004054308, 0.14783783977679776, 0.2978295136335317, 0.22143556999081226, 0.15465903524511837, 0.14382620737565832, 0.1688847591095357, 0.286198679439032, 0.16021568401369002, 0.27483424613394036, 0.18234030303499937, 0.1774220243205551, 0.18616676843912172, 0.17997530834022235, 0.1552251463317078, 0.1810289989926871, 0.095005189561844, 0.09177101469897375, 0.09390655696654471, 0.08919336279659362, 0.10237765984609959, 0.0919094654091317, 0.09778823756375221, 0.07405711688904593, 0.12870510968630022, 0.17818646383999914, 0.20747790747174055, 0.1494447279417429, 0.16208123681090236, 0.18098716934278358, 0.2011593385118804, 0.19331192204778425, 0.20248884876154694, 0.20107257055728656, 0.035888837953994335, 0.04218815963355449, 0.028015485898403525, 0.061273157157032965, 0.03902789901011894, 0.018451798058228275, 0.04414957487628213, 0.007972092351991478, 0.04966360869769393, 0.13126364906751153, 0.15957757389044724, 0.1535846597820113, 0.1712936247417336, 0.1650051092785927, 0.1670283453342727, 0.1373225265635476, 0.16831424045460042, 0.14507231141840293, 0.45613802254390834, 0.4503397452761453, 0.46961555111482534, 0.4807070381805968, 0.4419638536001843, 0.44197801229021905, 0.4362995980502524, 0.4468914778201992, 0.4527547026294879, 0.10649230682573363, 0.10955328957167698, 0.10331478870140276, 0.08980436274471593, 0.10698140955381918, 0.10013421304606651, 0.08507157492036332, 0.09375712362673061, 0.10808566608918191, 0.1360461944751753, 0.1595994466389351, 0.14894262742065822, 0.24133292163244535, 0.16457267726429547, 0.153046443619417, 0.16896424064800308, 0.15005886324209583, 0.18822233879398687, 0.3184573245538975, 0.30932087982107415, 0.3085434054335988, 0.3038869067721581, 0.30914574527534056, 0.2921857144228919, 0.3270757511318064, 0.3432365568740554, 0.33835841242753295, 0.2064486964414195, 0.21533429894630807, 0.2057144734353218, 0.22666007185482195, 0.19452850665524646, 0.22779284007780565, 0.2314111021988704, 0.20928918991598355, 0.22619794328836085, 0.18912360878212042, 0.18724027546582833, 0.1904527332147754, 0.18189385842589212, 0.17137413330308227, 0.2029199162661145, 0.17064855677710344, 0.18770237390980415, 0.17731137874003744, 0.1921223305753924, 0.1805947141771017, 0.17551296328198007, 0.21368636856354395, 0.18749015830483562, 0.19894375033564793, 0.17881696666414337, 0.1975279025098624, 0.20642752021910427, 0.6552777556514785, 0.4872978819875935, 0.1742824419487421, 0.3745308175472767, 0.20670827367838485, 0.16418397412453434, 0.663171616915408, 0.6850363363346489, 0.46694478786664106, 0.5406279541898682, 0.19039406654084012, 0.1545720997716633, 0.2421267810738723, 0.19088633157286727, 0.4267749352237996, 0.2114291688391592, 0.19870810294868146, 0.20630965346582364, 0.1805725307046001, 0.1732404578012674, 0.186721190312778, 0.19014862326242632, 0.1778679139526459, 0.18335495006257307, 0.1962435214721513, 0.1808701212268803, 0.18536909405364288, 0.06797997888379936, 0.06823935096363531, 0.06648173033904337, 0.07276305394923854, 0.06999865847312081, 0.06243875159464496, 0.062202704793961505, 0.06925085590883207, 0.06689432929834094]}, "mutation_prompt": null}
{"id": "58cae598-de72-4858-b661-aa4820259a63", "solution": "import numpy as np\n\nclass QuantumEnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.q_factor = 0.5  # Quantum-inspired factor\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _quantum_mutate(self, target_idx, population, best_individual):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        quantum_step = self.q_factor * np.random.normal(0, 1, self.dim)\n        mutant = a + self.mutation_factor * (b - c) + quantum_step * (best_individual - population[target_idx])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _quantum_crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        trial = np.where(cross_points, mutant, target)\n        quantum_noise = self.q_factor * np.random.normal(0, 0.1, self.dim)\n        trial += quantum_noise\n        return np.clip(trial, self.lb, self.ub)\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._quantum_mutate(i, population, best_individual)\n                trial = self._quantum_crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "QuantumEnhancedAdaptiveDELS", "description": "Quantum-enhanced AdaptiveDELS integrates quantum-inspired mutation and crossover strategies to improve exploration-exploitation balance.", "configspace": "", "generation": 21, "fitness": 0.19867948783744177, "feedback": "The algorithm QuantumEnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.18.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.4520082383501567, 0.4508509516034249, 0.4612092698561383, 0.44674925244983843, 0.42444356555513063, 0.4544077080955602, 0.44438474326418187, 0.41226116784666256, 0.450706309473498, 0.07909666538245597, 0.06905919328142462, 0.08427879247153158, 0.0733879956936706, 0.06054921634233046, 0.049827923638942395, 0.08913828272238511, 0.06310487674443466, 0.058289292298048356, 0.10806566719083843, 0.10752244476556894, 0.09205406068503885, 0.12054898441688966, 0.09618764117108713, 0.12060884660555327, 0.09718690077570569, 0.11811855730275767, 0.11878740104026297, 0.11376398641033991, 0.09246487847087315, 0.08837475920308802, 0.08749256364883318, 0.09440378953009365, 0.08643944855072971, 0.08870460889570264, 0.08218711015504343, 0.0930215083426349, 0.9435200809656542, 0.9220212439727175, 0.8868628267484718, 0.8892826051133046, 0.9252568467145225, 0.922676182758605, 0.9053012225157437, 0.911622600998035, 0.8798905439571976, 0.24087671325029436, 0.22535590930411853, 0.22628665019519267, 0.23601042557424623, 0.22395662189959287, 0.24363352219168588, 0.2451091556847611, 0.24059010518303292, 0.23680135575757444, 0.24108338794115003, 0.2513008789274246, 0.23238590380466217, 0.26389849396812737, 0.27690176813517065, 0.29353272202479264, 0.2403741882126973, 0.26770741342517945, 0.2321213236700217, 0.14656091505241986, 0.1602113541585215, 0.11949647077799075, 0.13879718284885545, 0.16528446759901994, 0.14902193052693946, 0.12911190131009187, 0.1442101631935524, 0.156018766249858, 0.10809682407952892, 0.10759787699458734, 0.11025481035557327, 0.17611288684197113, 0.148319107269403, 0.12367468146705363, 0.14567989952429106, 0.17089625638461836, 0.12322462899243769, 0.02108033614070315, 0.0037058554825732948, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.061457738194238165, 0.06353064629237193, 0.050497947295971235, 0.057665504021364944, 0.09930223015536921, 0.03964802948341983, 0.037892087885553205, 0.05097236942225791, 0.03664582153865792, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07437958976808445, 0.07642891089891923, 0.056783690743228754, 0.0796609339653771, 0.08618342329108686, 0.06549417507024669, 0.10421104160105754, 0.11248373526999944, 0.07852247936822454, 0.3863232522195609, 0.39401292308508007, 0.3653593602388213, 0.3893229704367672, 0.38562341614593665, 0.39545181218080105, 0.3871429985950554, 0.353175537607023, 0.38150334719453605, 0.11953424194476503, 0.13589608999983616, 0.09688969557405858, 0.10410722586540055, 0.11556092685784114, 0.08673234448090994, 0.0831405391518758, 0.08597753223883442, 0.09710649848116315, 0.2264247829974062, 0.16116908529185292, 0.13830489435996385, 0.2226040797445964, 0.18070038321862358, 0.16256594052436435, 0.16327995871927814, 0.14238122486100924, 0.1397439271004891, 0.255215241749028, 0.2603606425234132, 0.24719130496015873, 0.24971331308163502, 0.22685977601181495, 0.22118042052452092, 0.2454639121950335, 0.2784280000355587, 0.2667030118349869, 0.16042549251388083, 0.1776072909102957, 0.19540827166128238, 0.1671118105907381, 0.15397659646154638, 0.14769643228687168, 0.20162793141304458, 0.20477452928763396, 0.19160326943472483, 0.17585169800068068, 0.1776310421888394, 0.20056214147099483, 0.1886465709534656, 0.17092747564913358, 0.18882778036901327, 0.1759216796232066, 0.1766228625754489, 0.18767605842020707, 0.17021779227726253, 0.18385111165095291, 0.19269881057571248, 0.18256951715870395, 0.20224916059665143, 0.1818595535049753, 0.2036678843401587, 0.21931129877264743, 0.2282616946922036, 0.15926176706109163, 0.3495459214632739, 0.17820563793905875, 0.17449429234505476, 0.24952113817406651, 0.1873723906120004, 0.17289680571991994, 0.4119481387778431, 0.16571050819664557, 0.3184601982213434, 0.24819018472327303, 0.31036428467824795, 0.20077320047763236, 0.1961591907397907, 0.4459949158650276, 0.285766814382968, 0.36960673222497975, 0.20551842994234826, 0.18500657653367025, 0.18230740684385927, 0.17513080390900726, 0.1968382586353401, 0.18708470591025317, 0.18769414743856427, 0.1878998049052144, 0.19335932849112325, 0.17942592546751202, 0.07188298650083158, 0.06847545893381213, 0.07221778524592704, 0.06301488026799851, 0.06882116317972364, 0.07462917376068112, 0.0715397063744927, 0.07510686727869431, 0.07104350761362344]}, "mutation_prompt": null}
{"id": "38abdd99-1939-4568-9bbd-773a5d0ee5b1", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "c31f6e51-620c-4b52-85f0-3a7e47a23ad2", "solution": "import numpy as np\n\nclass EnhancedCovarianceGuidedAdaptiveDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.noise_threshold = 1e-5\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + self.learning_rate * (global_step + local_step * (best_individual - individual))\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness, evaluations):\n        median_fitness = np.median(fitness)\n        adjustment = self.adaptive_factor * (1 - 2 * (fitness > median_fitness))\n        self.mutation_factor = np.clip(self.mutation_factor + np.mean(adjustment), 0.5, 1.0)\n        self.crossover_rate = np.clip(self.crossover_rate + np.mean(adjustment), 0.7, 1.0)\n        self.learning_rate = np.clip(self.learning_rate + 0.01 * np.mean(adjustment), 0.01, 0.1)\n        # Dynamically adjust population size to maintain diversity\n        if evaluations > self.budget * 0.3:\n            self.population_size = max(5 * self.dim, int(self.init_population_size * (1 - evaluations / self.budget)))\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * self.noise_threshold  # Regularization for stability\n\n    def _filter_noise(self, fitness):\n        return np.where(fitness < self.noise_threshold, np.inf, fitness)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        fitness = self._filter_noise(fitness)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness, evaluations)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                trial_fitness = self._filter_noise(np.array([trial_fitness]))[0]\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            hybrid_fitness = self._filter_noise(np.array([hybrid_fitness]))[0]\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n        return best_individual, best_fitness", "name": "EnhancedCovarianceGuidedAdaptiveDE", "description": "Enhanced Covariance-Guided Adaptive DE with diversity control and adaptive noise filtering for robust exploration and exploitation balance.", "configspace": "", "generation": 23, "fitness": 0.23804345763698678, "feedback": "The algorithm EnhancedCovarianceGuidedAdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.21.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6776451683106872, 0.686324896822927, 0.6930538315264212, 0.6829619571444329, 0.7352238084031846, 0.7352844283345923, 0.12294306517494802, 0.14393591969159547, 0.13972948275480324, 0.07048600140140338, 0.07581264087714534, 0.06519976854816445, 0.11632631852868713, 0.08768977773342501, 0.08562035641322652, 0.10439475538902421, 0.11985284723687095, 0.10097103834966636, 0.034477918378195915, 0.01480309474710606, 0.011604845527308338, 0.13036144572333108, 0.11016306303980528, 0.12768076162073672, 0.11759691367081415, 0.13459435273277798, 0.10271700133402173, 0.007188377003169211, 0.021372383784616256, 0.0002446174694359371, 0.12345901929542691, 0.11379969999397488, 0.1176496239635777, 0.10267477593901675, 0.10260220656216756, 0.11761643502659058, 0.8289040946024342, 0.17708190341235674, 0.23354896717880402, 0.9614344233943215, 0.9746015691803998, 0.9609839340237225, 0.8665629787375807, 0.9646064519882457, 0.9759337811840719, 0.3864331239990826, 0.388642778494354, 0.3540946925733708, 0.37105418175735116, 0.3750100573410743, 0.4138804604072177, 0.08161992052597633, 0.13985474455928049, 0.09254577941441455, 0.6171669061903966, 0.5508360407535811, 0.5834730336685231, 0.6720432871021895, 0.6400685603878256, 0.6080688912538401, 0.6506802036639736, 0.5691096390908363, 0.6441066898911597, 0.2780573200794192, 0.3181480431317969, 0.3259994572750834, 0.05881414040558142, 0.043780438599166915, 0.047952911992730884, 0.32030939937169, 0.2757289893013807, 0.3302045573261587, 0.31394538752810763, 0.23915956605294175, 0.3651296051199666, 0.29052238545055775, 0.28751277209480486, 0.3391638814494744, 0.3029814339258221, 0.2800465275085061, 0.3058697469540549, 0.08785905611847789, 0.09755064831087623, 0.0748767749564413, 0.244668674763319, 0.24397875677562064, 0.25495660457978075, 0.025098875522480357, 0.01209685273856953, 0.01828402364193693, 0.353259374202612, 0.3884808200114982, 0.37540598218868804, 0.1431717118479191, 0.13547154544151085, 0.1298920851169123, 0.4209438665046964, 0.40094495651557915, 0.41185479252373103, 0.013082971623469941, 0.011940170028399533, 0.019131057243656713, 0.033950557749077626, 0.035309458354557344, 0.04234481239528831, 0.16143839152027484, 0.11069803956661783, 0.1296395667976119, 0.23356259086942255, 0.22458697695018914, 0.2426615748626899, 0.0684210471925557, 0.07295691283594263, 0.07341686395541147, 0.016668161661978043, 0.02537590178881477, 0.020109104902123143, 0.18034777741520724, 0.15756555760738078, 0.14838054695461433, 0.1391279201803769, 0.1267545911525373, 0.10300809641654829, 0.5790737062024693, 0.5825062500094973, 0.587120354693274, 0.10262546244148907, 0.10429392866300402, 0.1316043225737381, 0.10551995169900308, 0.10864693033546535, 0.0985266762707957, 0.09660579493868593, 0.07490414352893127, 0.07787248888853615, 0.15504629154696015, 0.1824464133685828, 0.17823849490264898, 0.1365170071539098, 0.12973996186281989, 0.14494463615908204, 0.17995754938508557, 0.1605456988253834, 0.42726135177998226, 0.1540528490416524, 0.17169559983154503, 0.16654953742037326, 0.2878216990958695, 0.30729745529021546, 0.3091434082247362, 0.3163771179862469, 0.35100266333565855, 0.3647736297034664, 0.13938842015877395, 0.13337710672818326, 0.13513263703700562, 0.24064057501350622, 0.24351891152388627, 0.26243147235396524, 0.25763761755423353, 0.23670815202579165, 0.2710434180923198, 0.13580918106743578, 0.1102310814150933, 0.14351570204567, 0.17352323969287842, 0.1902963821564565, 0.17140930990802594, 0.1867988000033144, 0.19614689020925502, 0.1791862315102002, 0.1571590151872475, 0.16045159545879228, 0.15970698409197193, 0.280111347361543, 0.2171446781752907, 0.23308497607947998, 0.20514360343746318, 0.22110752649696264, 0.18358731099408043, 0.7321220978411949, 0.5875372312846638, 0.16474213066416155, 0.18514678312925614, 0.18713520768868452, 0.30542830489587514, 0.14956844341625697, 0.12963842685675286, 0.1318382093273225, 0.14687162705929258, 0.14543571900598018, 0.11928489065980863, 0.2457516394160244, 0.1921471500273576, 0.23537180067587216, 0.17167344951634345, 0.1584619894320234, 0.14297103982320403, 0.19853065158670757, 0.17531641944434817, 0.18577949440061692, 0.17594272895150587, 0.18806282408464348, 0.1850775915840408, 0.180589377480602, 0.1856348190806999, 0.19607604913944066, 0.08584987340990269, 0.07481420041228282, 0.09150713684049838, 0.07245579606061725, 0.06788139499603152, 0.06260133884650154, 0.08133848068424432, 0.06421626730488061, 0.06857241504127176]}, "mutation_prompt": null}
{"id": "2aabe518-14ec-4986-879b-ec70b0145efa", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "ee8a5169-182a-4965-a258-929a915afbaa", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "536f9932-68aa-40df-8280-9016ec27fa04", "solution": "import numpy as np\n\nclass EnhancedCovarianceAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.max_covariance_factor = 1.0\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _adaptive_covariance_search(self, individual, centroid):\n        deviation = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        candidate = individual + self.learning_rate * deviation\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        adjustment = self.adaptive_factor * (fitness - median_fitness) / np.abs(median_fitness)\n        self.mutation_factor = np.clip(self.mutation_factor + adjustment.mean(), 0.5, 1.0)\n        self.crossover_rate = np.clip(self.crossover_rate + adjustment.mean(), 0.7, 1.0)\n        self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment.mean(), 0.01, 0.1)\n        self.max_covariance_factor = np.clip(self.max_covariance_factor - 0.01 * adjustment.mean(), 0.5, 2.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False) * self.max_covariance_factor\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            adaptive_candidate = self._adaptive_covariance_search(best_individual, centroid)\n            adaptive_fitness = func(adaptive_candidate)\n            evaluations += 1\n\n            if adaptive_fitness < best_fitness:\n                best_individual = adaptive_candidate\n                best_fitness = adaptive_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedCovarianceAdaptiveDELS", "description": "EnhancedCovarianceAdaptiveDELS with dynamic covariance adaptation and multi-phase search to improve performance across varied landscapes.", "configspace": "", "generation": 26, "fitness": 0.2677805458323058, "feedback": "The algorithm EnhancedCovarianceAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.21.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6961876283710314, 0.6592205378077522, 0.7058551928476067, 0.6829569002549885, 0.7084292794144748, 0.6849969403343996, 0.6789663138491435, 0.6742935207255509, 0.6791499365089573, 0.2905572609249232, 0.22988625280207797, 0.4874695715263323, 0.30241375866393394, 0.26846723762942426, 0.2244768371310234, 0.4346392780232181, 0.24849197229004216, 0.24796459127984993, 0.11690337577659737, 0.09914726138121821, 0.10785948780841814, 0.12855777716795946, 0.1290359694792782, 0.08674885181612735, 0.1139441887455852, 0.10205187006785144, 0.2624493843398322, 0.09057971490226668, 0.09322964291815239, 0.11977259170672039, 0.09413183656722923, 0.0785885184256202, 0.08382674479815411, 0.12055006227090193, 0.10497687654982824, 0.10425648800293397, 0.9053531926827718, 0.9423828645771506, 0.9433151304263381, 0.9037634332696936, 0.9735449708266914, 0.9718451098755777, 0.9609479143723892, 0.9569002372411335, 0.893566367349087, 0.2414574446493969, 0.29234214697657446, 0.26903145035979104, 0.2926863786176387, 0.3047615279284097, 0.26755141352704015, 0.2650807233762651, 0.2717645258589474, 0.2636321705156033, 0.5457413623994308, 0.5511705100744801, 0.5926940773548122, 0.28988659234009617, 0.31800379188155337, 0.5838506755051405, 0.27191105561873297, 0.34307789196352323, 0.30740468887255934, 0.12871511401609148, 0.12711289243322643, 0.1400694069656312, 0.12968754978952057, 0.16861720112579626, 0.16152885895089497, 0.11632238478757795, 0.16502277178885272, 0.13668103828389033, 0.11316790272656485, 0.11225837255826698, 0.021904548031610793, 0.12597980409301213, 0.12752347948521314, 0.12752965739794908, 0.1159040839483334, 0.13210808460605983, 0.23021664738408265, 0.1482740158323349, 0.1759463824551214, 0.15900454019579557, 0.18458351327079248, 0.1894655581608602, 0.2654830727177173, 0.15466065807847773, 0.13901787434006418, 0.18389096545902428, 0.2909439945198078, 0.263629995776258, 0.2831062423904498, 0.31302728166594007, 0.3902081344298768, 0.34333451819075234, 0.3392529323471135, 0.37335240570436423, 0.3490632553275044, 0.0730301130487071, 0.024849543805741114, 0.04602116265501921, 0.037539622359683555, 0.0659503004532036, 0.029974539024546387, 0.0579509908842607, 0.07855059925083863, 0.06117669004255455, 0.19299018936461543, 0.21790827844474514, 0.18836222496919386, 0.17761765634497806, 0.2323302015295221, 0.22582752509277393, 0.18301186283817428, 0.20411844716421057, 0.24040631726437767, 0.3797401217367743, 0.3827435547928596, 0.47226890508917263, 0.5649525684961626, 0.5323731305948758, 0.520374820362365, 0.5436623544484573, 0.5689779937344992, 0.5577726579024274, 0.13136533098635683, 0.11503842979974088, 0.11043421685852395, 0.11579254793687488, 0.09733195859868415, 0.12026547543232813, 0.11059213236834642, 0.10759973769981823, 0.09057007850439791, 0.1699675472132045, 0.2352441615027051, 0.16599203570694376, 0.18371230197358568, 0.1878603207850601, 0.18282143551699892, 0.16962790758368262, 0.182428448814703, 0.17296183209765292, 0.23632137200130432, 0.21824172030891054, 0.2847138261989661, 0.30713440649967216, 0.30918795142588884, 0.29135721610753484, 0.35435817582641926, 0.3229378911830566, 0.35113375535840075, 0.15920015220456207, 0.1857104224963998, 0.17858539738574541, 0.20914002751443472, 0.2538752093655856, 0.2544847807149676, 0.254616572108296, 0.2382580809986372, 0.23713431540546426, 0.1863440696979195, 0.1854634226223073, 0.18049051216438516, 0.17538590065095583, 0.17267425980409157, 0.21477532736324623, 0.18801865131106932, 0.16692384743149502, 0.1864463887134411, 0.17646814056310067, 0.16146235807750597, 0.1854442685159463, 0.22862370606070548, 0.1742940020096133, 0.206799717930493, 0.19201699691756302, 0.19251077706320951, 0.18477502792255973, 0.6930844965478519, 0.20422366331229036, 0.19255958662452277, 0.18952485161443455, 0.4523235613941602, 0.31590893742127224, 0.17733864364174023, 0.1664920283838337, 0.5418750395839314, 0.2854641033769907, 0.2040044271226764, 0.4980181132500322, 0.18446981629660708, 0.20387396443025918, 0.49622393698488143, 0.2044056708234182, 0.2022303153656544, 0.2059585725668479, 0.1884163554102587, 0.18334916042906724, 0.20601483747657234, 0.17499252738078663, 0.1706686894741617, 0.19973663518923845, 0.17999955996914363, 0.19402251472370968, 0.17541056434769853, 0.06819280821261486, 0.06962943725443216, 0.06677547862500888, 0.07532643104499925, 0.0811141687275676, 0.06972850522572005, 0.06892752642945665, 0.06910444797737925, 0.07451516335557484]}, "mutation_prompt": null}
{"id": "07e4c501-7b93-418a-b6c9-a1416ec745f2", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "eb4d680a-f7bc-458f-a3d9-f411f3641be7", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "a33005b6-3d06-4672-8f24-3aca62e3f4c3", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "b6b839d9-0141-41c2-a2d6-116c582ccd39", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "94edee76-8272-4708-9fde-fbb761eb9105", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "bf191241-bf2e-414c-ba07-36c7a2fcd6f6", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "e8ebfba8-964f-4c61-a08a-b1e5b65ba02d", "solution": "import numpy as np\n\nclass DynamicCovarianceAdaptiveStrategy:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        fitness_variance = np.var(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n            self.covariance_matrix *= 1 + 0.1 * fitness_variance / (1 + fitness_variance)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            deviations = population - centroid\n            self.covariance_matrix = np.cov(deviations, rowvar=False) + np.eye(self.dim) * 1e-6\n\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "DynamicCovarianceAdaptiveStrategy", "description": "Dynamic Covariance and Adaptive Strategy (DynCovAS) enhances population diversity and convergence by dynamically adjusting covariance and using adaptive mutation and crossover informed by fitness landscapes.", "configspace": "", "generation": 33, "fitness": 0.3013947723958328, "feedback": "The algorithm DynamicCovarianceAdaptiveStrategy got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.22.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6631854437922555, 0.6450965115902213, 0.6554777785227521, 0.6808818516955607, 0.657493997943194, 0.6707670053741894, 0.6852201074241292, 0.6592559136730451, 0.6476859287922135, 0.5284899938552752, 0.5245774182782279, 0.49568145008161113, 0.48279622103139286, 0.5116611313008426, 0.4942839999623304, 0.5169272532135518, 0.5277660817959842, 0.5165858309457574, 0.139613772048242, 0.12761693550523523, 0.2517640157762646, 0.15525953513092738, 0.13240901835646113, 0.11916140775975781, 0.3184743788864687, 0.12708249226819412, 0.22887047077199474, 0.2418458992895668, 0.1023678425675556, 0.11087052067323622, 0.09916098950196084, 0.09029557247638786, 0.10152511530713326, 0.12221360075303711, 0.11192071116562274, 0.11823577845760591, 0.9481546948856856, 0.9610437223398568, 0.9296904050510973, 0.9845844648453883, 0.976461371438196, 0.8752544218893489, 0.9279689087902091, 0.957313211588115, 0.9539228657023939, 0.4079944737401946, 0.38934181869028595, 0.39168307313217654, 0.4048512605554362, 0.37707663557285054, 0.4088271537896906, 0.3898925386171658, 0.33164052285806, 0.27705827102469116, 0.5337774074674138, 0.5488351560161249, 0.524420599963122, 0.5662714468175094, 0.5855830190072444, 0.6027343838973367, 0.5785809761284391, 0.5813966673779049, 0.6164733650676564, 0.17545232504919972, 0.18698632983891494, 0.3681500152504976, 0.1436894425710873, 0.18169116319577083, 0.16181771373110987, 0.14105247180907377, 0.2178229520709224, 0.1796198968324626, 0.13460081150208403, 0.1737440931665999, 0.1766292595298321, 0.16919462242019212, 0.3139979334808881, 0.18999266649095958, 0.13980192494265242, 0.15353652806996054, 0.1430192238824458, 0.14483352224707446, 0.15159090519884155, 0.1604062041854042, 0.24219986304197483, 0.14944879292604196, 0.12654736415300938, 0.15800213167561683, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.25304018097537184, 0.2514302542100252, 0.19634202372712384, 0.2073940447155277, 0.28923772642015, 0.34839231260431114, 0.37894166802923046, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.14894882616713767, 0.18054741561751053, 0.16895074811224953, 0.20370595147928894, 0.2215005089315144, 0.18931000662487096, 0.17878691794640544, 0.17535764977614732, 0.1852632852453746, 0.5594933374355505, 0.5438351985917448, 0.5280161223800959, 0.5376164335365972, 0.5661820705098923, 0.5324015107852988, 0.5281684481209039, 0.43615902331318435, 0.4681794512777835, 0.09669506545524709, 0.08854843996498474, 0.08250191685301111, 0.08505511231678142, 0.10144743717074978, 0.09544471084060147, 0.07370125321439103, 0.0859656270524034, 0.08525823491626938, 0.1625938330126373, 0.16461950010494764, 0.14352308894522103, 0.1363399405429231, 0.21844444794175433, 0.2189414875570087, 0.15386162242987556, 0.1496434298276207, 0.16708414516416614, 0.32268962954033487, 0.3262489552077311, 0.3245444010624111, 0.367814101822026, 0.33763775203728763, 0.36023923958404913, 0.38434531841798036, 0.32065069614544006, 0.39400091038180507, 0.22287918021471909, 0.22572629728416027, 0.235008423360618, 0.23375599406459946, 0.21537421257365408, 0.2190598018842146, 0.2695100292666529, 0.2709994316090498, 0.2569166528643665, 0.17348376250004527, 0.20372775744992855, 0.20989711570204428, 0.19059655056474734, 0.20435801233892148, 0.20656886355201454, 0.1843079388918385, 0.20707224901167898, 0.19318108382667332, 0.21121001547542528, 0.1790367707915348, 0.25131392746206627, 0.33205374122953124, 0.17716676220090266, 0.18794449878903619, 0.19377070241097805, 0.3967786504710372, 0.33789390045236756, 0.5806452009319523, 0.5964578031508154, 0.16347077928044107, 0.19577531156087202, 0.1833344185325977, 0.529883525966621, 0.223582120554224, 0.5622410373714944, 0.5486840075319579, 0.3817040596525142, 0.5682536400933873, 0.19535977254000458, 0.4657215412523228, 0.3895569079177341, 0.3753290091993654, 0.20609940191091713, 0.20129356049584402, 0.20250309901312824, 0.1940893768499864, 0.18378633380317044, 0.18332758850936848, 0.1979140172508369, 0.1978599781167385, 0.17825873667734982, 0.18582544451597593, 0.18097460151741607, 0.1869484156954212, 0.07058153253979327, 0.0679844266165961, 0.058929162914494904, 0.07360453787621357, 0.0869304086071565, 0.06773327287220998, 0.0791688319689896, 0.07202846829263543, 0.07078020880310454]}, "mutation_prompt": null}
{"id": "3b8c6ad2-34b8-47d0-a0de-4cdb5eac32cd", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.normal(0, self.learning_rate, self.dim)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.5:\n            self.population_size = max(4 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n        self.covariance_matrix = np.eye(self.dim)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined Enhanced AdaptiveDELS with hybrid local-global search strategy and adaptive learning rates for improved balance between exploration and exploitation.", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.6690284834511682, 0.6539189875707574, 0.6618962166770042, 0.6861697156857542, 0.6792049790597445, 0.6754666415960728, 0.6897592730573316, 0.6670572707093162, 0.6607226058034377, 0.5284899938552752, 0.5248818788604379, 0.4947707572375122, 0.48674305466516166, 0.5119896138015756, 0.4942839999623304, 0.5178075947004812, 0.5277660817959842, 0.5165858309457574, 0.14573166829480466, 0.15739084481421106, 0.2609545955180653, 0.1684715507220591, 0.13991335499302437, 0.13054840210606233, 0.3294347378976067, 0.13211115100981063, 0.23062728463446192, 0.2505298721896009, 0.1151373365626398, 0.11989877583350173, 0.10551869295614802, 0.09631208110293832, 0.10449388450007302, 0.13756960061213375, 0.11857815463652299, 0.12543708466959036, 0.9478331892443784, 0.9608355123642707, 0.9296979862821687, 0.9845519691572917, 0.9765051105460407, 0.9071185800127282, 0.9280226169111412, 0.9570866248859247, 0.9538779894087932, 0.42194188836375646, 0.3953287081232818, 0.39806065296961535, 0.41134867270387865, 0.3825036383949586, 0.41787331204943556, 0.3911273008700914, 0.33558104041875736, 0.28282886337173707, 0.5469600608624423, 0.5520743140738643, 0.5364297529925562, 0.5776312230078273, 0.5848269992483588, 0.6135187674803226, 0.5801780567241261, 0.586018679654468, 0.6191371340768644, 0.18029256211387035, 0.1909681927460838, 0.3721523675604619, 0.14783194136136613, 0.1888687307944782, 0.1718162765057053, 0.14424545692980772, 0.22185958730501398, 0.18417137105918246, 0.1357482409523807, 0.1769008278966807, 0.17642354052242204, 0.17279001840700348, 0.32360099299225575, 0.19601720059430883, 0.14514025930272278, 0.16341640797949042, 0.20634273802556258, 0.14483352224707446, 0.17853206016833134, 0.1604062041854042, 0.24918491438448553, 0.14943012617916607, 0.12299976162538095, 0.1593826996130272, 0.1111312175450756, 0.22347557087382197, 0.27237329676192235, 0.2446288769729189, 0.24624424611925222, 0.26009369475502675, 0.19669034797619567, 0.214424891755846, 0.2893601735127773, 0.3489729299007721, 0.37935389401471675, 0.06879441319822, 0.02971421832109078, 0.05195803988185943, 0.05303699106452875, 0.08773419301615759, 0.12034816355455458, 0.051906137838228616, 0.07365865832594387, 0.11407380999174477, 0.15097290808949093, 0.19740670866125065, 0.17126460117979625, 0.20248974595345604, 0.22837539503396498, 0.18981491766336966, 0.18220575595228894, 0.1759158055994583, 0.18589316696715952, 0.5704782334394738, 0.5474836428900611, 0.5433338636643238, 0.551578312300983, 0.5690655545413892, 0.5342215934092889, 0.5314717027689796, 0.4392952966839312, 0.4855976728412865, 0.10498867383370558, 0.10152989537233847, 0.09685957914968057, 0.1108262453545702, 0.13521273111865761, 0.13108387948104083, 0.10221973739433854, 0.11229892667267427, 0.11467061733549166, 0.1875115427476095, 0.17729805851395264, 0.16083467799812157, 0.17678451439607923, 0.22596380647140468, 0.23281732272876565, 0.1700337788184766, 0.15214606525394703, 0.20240889537717377, 0.3275366243463407, 0.33351664384207447, 0.3344406540288737, 0.37261601823260593, 0.3505634061692783, 0.36532545644125325, 0.3937871165611805, 0.3299480850182006, 0.3979583985222779, 0.22810021004655034, 0.23185537174838378, 0.24084955615727432, 0.23628342587691187, 0.22130263472237044, 0.22633962694550458, 0.2764417075869604, 0.2766949546380246, 0.2598607991193841, 0.17418305889464902, 0.2042845464797245, 0.20989711570204428, 0.19376564399824692, 0.2063673919383251, 0.20674338170389972, 0.1843079388918385, 0.20713956362176955, 0.19318108382667332, 0.22025745029640087, 0.20749879646995406, 0.2565623849329881, 0.3406941788205198, 0.18862632352890818, 0.19560249609641245, 0.2012822710679779, 0.403978900598741, 0.34324352986450224, 0.6270918464640596, 0.6091273196138434, 0.18127941817558157, 0.19796926569724305, 0.2091375324467959, 0.5448844207901312, 0.2381050099521279, 0.571481152218354, 0.573463473841128, 0.4462365010454499, 0.6131249299760102, 0.19809930546928167, 0.4793018057418724, 0.42288275440889533, 0.38393662892364844, 0.20784248583841058, 0.20333835531038746, 0.20556161636354275, 0.1940893768499864, 0.18378633380317044, 0.18333754227001187, 0.1763717548884044, 0.1978599781167385, 0.17825873667734982, 0.1860153650467843, 0.18097460151741607, 0.1869484156954212, 0.07088081950502001, 0.06913214180435678, 0.06498171005577091, 0.07360453787621357, 0.0916410286868351, 0.06774265999953566, 0.07887264837340013, 0.0698748456688163, 0.07261669397679982]}, "mutation_prompt": null}
{"id": "c08ff3a5-ba59-496b-b3f5-cbbadd23da6a", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with stochastic covariance adaptation and dynamic population resizing for robust exploration and exploitation.", "configspace": "", "generation": 35, "fitness": 0.3331566421487807, "feedback": "The algorithm EnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.24.", "error": "", "parent_id": "d637f6dc-2c56-46c5-9b22-a8fd9149a3a8", "metadata": {"aucs": [0.7528759435806445, 0.7416487662431501, 0.7502708775386513, 0.7691661414613046, 0.7527416891041585, 0.751761241092465, 0.7772788961528752, 0.7551685755157684, 0.7379173800875154, 0.6426955210723941, 0.6463555933450049, 0.633121279862906, 0.6413495572357909, 0.6363084083485118, 0.6486003230218463, 0.6529515686019043, 0.6616387077643403, 0.6491944122397993, 0.42947114592592384, 0.15850389611231108, 0.45996154667873723, 0.38191600774212087, 0.39790038326124566, 0.29500009153423956, 0.4249259770623255, 0.3224207868600303, 0.24291011666810713, 0.21499364013544808, 0.117288938563891, 0.12514089010953666, 0.3360206653375475, 0.2888012194090681, 0.11421623033764994, 0.29174224946149474, 0.12138100897266646, 0.13123457865119248, 0.9481546948856856, 0.9610437223398568, 0.9296904050510973, 0.9845844648453883, 0.976461371438196, 0.8752544218893489, 0.9279689087902091, 0.957313211588115, 0.9539228657023939, 0.5253692842705714, 0.5459095021879417, 0.3669714577572466, 0.5165554460866132, 0.3751858925157838, 0.5094134628480552, 0.4345158031082842, 0.4099831986293129, 0.3091149230977507, 0.6558831737345783, 0.6172524365697216, 0.616057217483841, 0.6668439476043622, 0.6742468511756852, 0.6440490311789498, 0.6842225081204971, 0.6804166176720201, 0.6798732923011119, 0.1564261542099874, 0.16852955310079054, 0.15447689993709612, 0.15327019630391803, 0.18215960558450717, 0.14904376318594026, 0.17103530674274425, 0.16066248187779897, 0.2068459868894379, 0.1128134540563942, 0.13626388540601297, 0.16879938086557145, 0.17119601114091165, 0.1732980359022246, 0.14747006960703835, 0.1639800480045338, 0.16032182425997343, 0.13143572667771042, 0.19790669489886137, 0.10718196043164063, 0.09415549326187245, 0.12949205167828282, 0.057629284318532537, 0.1450255092104017, 0.23000752092310717, 0.1069885980075862, 0.14922065311355692, 0.21076493430930876, 0.2284261486610073, 0.2733752356299586, 0.25420191219714083, 0.13631097505331968, 0.24373798557853388, 0.2822668525698119, 0.36912469381908364, 0.3114885702772201, 0.07448380282233957, 0.08510378838464894, 0.049454283520584785, 0.03896482965383985, 0.09177742771300257, 0.10792277655863158, 0.10111775515320476, 0.10317795646624528, 0.09100557266452036, 0.20305189188569117, 0.1952404474659335, 0.21184386675360467, 0.23549527068657672, 0.24138680578365024, 0.25964881733738165, 0.20117738326101586, 0.20078869079668038, 0.20097589973223062, 0.6044505074481423, 0.6006867607334359, 0.56391667317152, 0.5572182382832158, 0.5400793836004774, 0.5756892815245174, 0.5769499299517922, 0.5127973162338062, 0.5396948061796938, 0.10163207932427953, 0.10791622091722142, 0.08408389274288275, 0.09399730205059154, 0.08774036714561462, 0.0911194347260258, 0.09200797014788309, 0.09519312102193833, 0.10216332359134828, 0.14923560208951947, 0.1498640163970607, 0.13037350800810532, 0.1651467959752383, 0.19177615922069846, 0.15189418816477895, 0.13998645355349304, 0.13910206309836248, 0.16264885047299282, 0.37841250956098205, 0.3887451293165215, 0.3859670181973064, 0.42803859893740337, 0.44777904181981076, 0.4094977952428237, 0.5138388090597665, 0.43613349244238486, 0.510355276244937, 0.2640868439069276, 0.2492644774959767, 0.2710943683923437, 0.2648371042701533, 0.29357152259797803, 0.23851291811295428, 0.31098401304374323, 0.28658762287099626, 0.2926993053568161, 0.18271125421964185, 0.1838698122333544, 0.21518987580070192, 0.19799863792224015, 0.20435801233892148, 0.19021117969813361, 0.1863416212521054, 0.20707224901167898, 0.20289617743514787, 0.19819139371833228, 0.39576918087952284, 0.26383973657433657, 0.22926166009079307, 0.20629130136096607, 0.23121556615526884, 0.3545620365297534, 0.34848082669892233, 0.3898009698597108, 0.6470913428870022, 0.6837378436009706, 0.1603461649513207, 0.19599439927483797, 0.557099976393798, 0.1834469693257954, 0.541565107153824, 0.17809371963869092, 0.6832408594614443, 0.19364380449843588, 0.6338082525114264, 0.19675283450738557, 0.4982396903893366, 0.33235530782238254, 0.23323941103311985, 0.206123787818004, 0.20130832116211883, 0.20254901939680503, 0.1940893768499864, 0.18112717342300166, 0.1846430719496588, 0.19620873243572878, 0.1978599781167385, 0.1830836228603766, 0.19080164737633165, 0.18728816742638577, 0.18344753689117255, 0.08198378218977431, 0.07771031668578232, 0.06384986374481283, 0.07504245458984171, 0.08790094518234914, 0.08018254885696974, 0.0843146701221914, 0.0756582415358451, 0.07309108535219999]}, "mutation_prompt": null}
{"id": "79218a30-850d-4615-8ef2-3861a799c562", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _multi_strategy_search(self, individual):\n        random_step = np.random.uniform(self.lb, self.ub, self.dim)\n        perturbation = np.random.normal(0, 0.1, self.dim)\n        candidate = individual + perturbation + 0.5 * (random_step - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            multi_strategy_candidate = self._multi_strategy_search(best_individual)\n            multi_strategy_fitness = func(multi_strategy_candidate)\n            evaluations += 1\n\n            if multi_strategy_fitness < best_fitness:\n                best_individual = multi_strategy_candidate\n                best_fitness = multi_strategy_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with multi-strategy search and adaptive parameter tuning for improved exploration-exploitation balance.", "configspace": "", "generation": 36, "fitness": 0.3290722375125505, "feedback": "The algorithm EnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.23.", "error": "", "parent_id": "c08ff3a5-ba59-496b-b3f5-cbbadd23da6a", "metadata": {"aucs": [0.7568002791608646, 0.7301951071757551, 0.7491587299910312, 0.7692506549315887, 0.7482479269941356, 0.7650419724647857, 0.7454409731627804, 0.7678946139818947, 0.752140920758104, 0.6214685813922369, 0.6420907807158805, 0.652577653198683, 0.662117230581492, 0.6397206614394075, 0.619612211289676, 0.628271137785565, 0.6205832388378087, 0.6647797666059883, 0.3640220979915688, 0.23840182189349812, 0.4062375731737937, 0.2809260238149923, 0.34052536873151606, 0.3814222785608271, 0.28958740070814226, 0.4121166449876442, 0.2986651768656913, 0.43665393211421155, 0.13481450823423802, 0.13553082021906337, 0.24096362682092876, 0.29859946083056754, 0.1314068380137654, 0.1350916682119372, 0.2701860687773907, 0.22732022079789127, 0.9158127920686077, 0.9737028381717806, 0.937410446093846, 0.9490941792126083, 0.9122489850018954, 0.9163378094283788, 0.9496934682271133, 0.9513542857493508, 0.9256176907057242, 0.4049872237016888, 0.4226706746435578, 0.43810170989103236, 0.5298995692500031, 0.38457743078473206, 0.5113337872773391, 0.45499495353822317, 0.4305317469898494, 0.4778280666643131, 0.6722222026319038, 0.674990012576461, 0.6332087157437127, 0.7074848949046119, 0.6060696511116768, 0.6933150616171504, 0.6613356637586876, 0.5650223373013663, 0.6314421391623637, 0.14694443422036896, 0.1970387962207536, 0.138517545473949, 0.16520436735826793, 0.16542039148472198, 0.17551008409281255, 0.12871584708884165, 0.17481938707329137, 0.1135197671427457, 0.15829924313387345, 0.14955241103228767, 0.11272458771953975, 0.23032483349043664, 0.1395412117170004, 0.13964594410801945, 0.17171292926935455, 0.17592921571830833, 0.1505689736284883, 0.09647912561127236, 0.07934495461935365, 0.1657161885694851, 0.1520592303618551, 0.1841938958796907, 0.10049053014331599, 0.18127878596439717, 0.14960326686752579, 0.13878028441650736, 0.2465658509469153, 0.20024400686141053, 0.26313491193016925, 0.17891296540199852, 0.22868463527230165, 0.24515269379933102, 0.2652658530593499, 0.3138527833880206, 0.29602733034988826, 0.07063380228616611, 0.08160524025752025, 0.08774675092752227, 0.08243419492330972, 0.08837173307778246, 0.07651843394292568, 0.09892347328259499, 0.10356587737911738, 0.13703840561010605, 0.21213491747701063, 0.19720276223076094, 0.21399151546462536, 0.241371666423696, 0.22738671961054557, 0.2617754796959002, 0.21980016464351282, 0.1987633602335913, 0.19408952468242147, 0.5404891429927963, 0.5877669036526936, 0.5769932367364843, 0.5485189979258037, 0.5430549556384325, 0.5731661494482578, 0.5737434818207705, 0.5760539875142053, 0.5510406620788878, 0.09115538772378273, 0.10627183769495618, 0.10135712783658546, 0.09705668117122745, 0.09118878681562526, 0.08739498780898936, 0.09410860866147364, 0.08214153864203622, 0.08662413729503993, 0.17722393913021173, 0.14197659756699466, 0.13033507791799182, 0.14835456646501333, 0.14166720991436832, 0.13554551539948023, 0.1399310219340496, 0.12334538610809342, 0.1557122367336482, 0.4132239017000289, 0.40454520611005595, 0.4474520568988848, 0.4563391278520529, 0.409148401159233, 0.399445059143107, 0.44545223551173274, 0.46169185432204063, 0.418653163859559, 0.2686796674966526, 0.25951830376107365, 0.25831455555652627, 0.2325895437459763, 0.24963294932536728, 0.2704446657318377, 0.3323242788648756, 0.34152504363753666, 0.28407605633245603, 0.1836064112286293, 0.21128409175851492, 0.19218958155734622, 0.1896088294819558, 0.16370141390274917, 0.2130456024591887, 0.17963565217412347, 0.18852256419818558, 0.1732182356267825, 0.36863904864956853, 0.33017341948301604, 0.2873872997514805, 0.30855610879616113, 0.38933224663805477, 0.19352014654032956, 0.27132275008882967, 0.41321121814096873, 0.43289022707970426, 0.18525298026995352, 0.1680411229397949, 0.3954992768615383, 0.6647773231085254, 0.18209444175021328, 0.17209646622785024, 0.1840557217298393, 0.16590821938131506, 0.6854709833247652, 0.19263758859863334, 0.33610561955428786, 0.21127673991895757, 0.512662802984626, 0.1543543746078072, 0.18472416791191648, 0.6182939633987274, 0.19870684657910676, 0.20566912500871404, 0.1706660016439948, 0.1885843066899181, 0.1790756006155363, 0.17881994406251667, 0.20791081340909345, 0.18907630816386833, 0.1836516075157011, 0.20070701101772737, 0.20471781618631257, 0.07397687612886661, 0.08883217175770164, 0.08946218424734276, 0.08074652589454012, 0.08139887618373065, 0.06990872750343025, 0.0692624687938862, 0.074028497117137, 0.08374712744226342]}, "mutation_prompt": null}
{"id": "413a6bbc-952e-47cc-aa5c-27b90fb18734", "solution": "import numpy as np\n\nclass RefinedEnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        global_mutant = a + self.mutation_factor * (b - c)\n        local_mutation = np.random.uniform(-0.05, 0.05, self.dim)\n        mutant = global_mutant + local_mutation\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        adjustment = self.adaptive_factor * (fitness < median_fitness).astype(float) * 2 - 1\n        self.mutation_factor = np.clip(self.mutation_factor + adjustment.mean(), 0.5, 1.0)\n        self.crossover_rate = np.clip(self.crossover_rate + adjustment.mean(), 0.7, 1.0)\n        self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment.mean(), 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False) + np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "RefinedEnhancedAdaptiveDELS", "description": "Hybridized Dynamic Population-based Approach with Adaptive Covariance and Multi-Scale Mutation for Improved Exploitation and Exploration.", "configspace": "", "generation": 37, "fitness": 0.27182594331825854, "feedback": "The algorithm RefinedEnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.22.", "error": "", "parent_id": "c08ff3a5-ba59-496b-b3f5-cbbadd23da6a", "metadata": {"aucs": [0.5789775292907762, 0.5438668570615293, 0.5411773301288976, 0.5885192723549391, 0.553713176679768, 0.5404696517736142, 0.5420642457839244, 0.5549938540180205, 0.5586972755157191, 0.22690326462674837, 0.2314188801409971, 0.18367413335115712, 0.20938058403048943, 0.23345580699438262, 0.2151831012876515, 0.20965834764204905, 0.20313383739608226, 0.1838673322584109, 0.2149693772113428, 0.1849523749021067, 0.20417362495290714, 0.18011528665481036, 0.18267004426614264, 0.17940092204664126, 0.2152014499605842, 0.19324814149280856, 0.1536206754049919, 0.14875973428995715, 0.1385863793102391, 0.14419486901532497, 0.13370406054803063, 0.15887481499632317, 0.14552892795653372, 0.1309673664100357, 0.16385472984603566, 0.13799432111533516, 0.9579446625523351, 0.9233663775094555, 0.9444149334298757, 0.941346093957502, 0.9353877490422517, 0.9350222397952497, 0.9178987603114261, 0.9494166764905035, 0.9490626307469814, 0.3335302102713986, 0.34899164152184026, 0.3414476210935128, 0.33688058162298296, 0.362128969204103, 0.3351570213787032, 0.3446978063777091, 0.33511788843885193, 0.34108735323701156, 0.7140307931176442, 0.7371836923149939, 0.5918124487032476, 0.7049457813027296, 0.7041137661828158, 0.7178739795282233, 0.6652078797746054, 0.6508785506452492, 0.6768690658926877, 0.16832198900696782, 0.17649374366834103, 0.19175488900049487, 0.15982110132792127, 0.19763618252631465, 0.17426650701778723, 0.17426411940241904, 0.178589259043894, 0.1902717358482885, 0.18469969894801552, 0.15432013616262263, 0.18365070527167227, 0.1794450840100983, 0.1717919552006797, 0.1718301293969542, 0.18882927954296225, 0.19401900591823362, 0.2174583795678302, 0.03285489986481571, 0.04113680451579016, 0.041339124036981034, 0.0583865432923687, 0.015651666817866894, 0.04959791072505415, 0.030202758530913032, 0.03676020349305675, 0.031941261574564894, 0.11558625014696844, 0.09334608353979201, 0.11151200733108035, 0.09513733807385472, 0.07856728834203497, 0.11638396438332599, 0.12750008130096435, 0.1203538628149814, 0.13732578696449238, 0.01270573829914523, 9.999999999998899e-05, 9.999999999998899e-05, 0.007836602939393034, 0.01702800074839539, 0.006499134100195758, 0.036950932448992946, 0.020263537207068638, 0.01135200837240169, 0.1598407699943859, 0.1483389462067507, 0.12309092450260084, 0.13987201765351986, 0.13816053031720077, 0.15131430535923496, 0.1289788155854158, 0.13093080574899285, 0.1326441990083127, 0.4654097528099187, 0.44484641931625357, 0.4801995631641697, 0.4686363925777053, 0.46456928800052266, 0.46198138764581975, 0.4615352193664968, 0.45398491213764747, 0.4575646034393097, 0.10320456306367831, 0.1097111435109418, 0.10532080266849875, 0.08736366969332043, 0.1033941685889862, 0.10875321651930969, 0.10290024638288009, 0.10084256855529561, 0.10742931517734322, 0.12995418412146376, 0.12555952001622905, 0.1530996648919194, 0.13931494957486412, 0.1439706215983697, 0.1696857178519109, 0.1524894725640784, 0.160294094129378, 0.16102417872979657, 0.3244519198069613, 0.32216606564447436, 0.3105988121685145, 0.32720414460181724, 0.32575628238906573, 0.3141497411350518, 0.33766267704300024, 0.3295193561199078, 0.33887627468992365, 0.24423410392032296, 0.23605922242763067, 0.2504128379245679, 0.24207124593673013, 0.24120635213058317, 0.2547539268275494, 0.2550307905878795, 0.2629917152633582, 0.2694346185238635, 0.18851031293412635, 0.22433050493877793, 0.20827884104193695, 0.18363682190981145, 0.20010302613717434, 0.19618093542367143, 0.2198924260221755, 0.2056033482680255, 0.20459191681171018, 0.2787905057807384, 0.2589417928740001, 0.29581518520014194, 0.2704224890599083, 0.23414339516933214, 0.2254602298087477, 0.245776717294528, 0.2950946129448776, 0.2780745697874012, 0.5213005478475292, 0.20306504841209494, 0.46006578603656667, 0.579079623842489, 0.6633956220708656, 0.7052115899886788, 0.6724904326905292, 0.5450610061992388, 0.3933473578853096, 0.4981489372199207, 0.2006941343729567, 0.15871506868230678, 0.1702848224701995, 0.39863032347511596, 0.193608606135942, 0.1813663811626055, 0.20219943536934692, 0.176140678354597, 0.18944203476000732, 0.1945287470101189, 0.1788236411616243, 0.181789116272996, 0.18338535032769765, 0.19287781626438305, 0.2033133885708619, 0.1691052976376357, 0.1871402302748575, 0.0799506099679107, 0.07881864361323954, 0.07801121090162033, 0.0884499105906803, 0.08479230928614889, 0.07573123219197186, 0.08177101506925244, 0.07866276193947741, 0.07889592378106514]}, "mutation_prompt": null}
{"id": "8c7cc681-179e-4215-8930-359476b81694", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with stochastic covariance adaptation and dynamic population resizing for robust exploration and exploitation.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c08ff3a5-ba59-496b-b3f5-cbbadd23da6a", "metadata": {"aucs": [0.7528759435806445, 0.7416487662431501, 0.7502708775386513, 0.7691661414613046, 0.7527416891041585, 0.751761241092465, 0.7772788961528752, 0.7551685755157684, 0.7379173800875154, 0.6426955210723941, 0.6463555933450049, 0.633121279862906, 0.6413495572357909, 0.6363084083485118, 0.6486003230218463, 0.6529515686019043, 0.6616387077643403, 0.6491944122397993, 0.42947114592592384, 0.15850389611231108, 0.45996154667873723, 0.38191600774212087, 0.39790038326124566, 0.29500009153423956, 0.4249259770623255, 0.3224207868600303, 0.24291011666810713, 0.21499364013544808, 0.117288938563891, 0.12514089010953666, 0.3360206653375475, 0.2888012194090681, 0.11421623033764994, 0.29174224946149474, 0.12138100897266646, 0.13123457865119248, 0.9481546948856856, 0.9610437223398568, 0.9296904050510973, 0.9845844648453883, 0.976461371438196, 0.8752544218893489, 0.9279689087902091, 0.957313211588115, 0.9539228657023939, 0.5253692842705714, 0.5459095021879417, 0.3669714577572466, 0.5165554460866132, 0.3751858925157838, 0.5094134628480552, 0.4345158031082842, 0.4099831986293129, 0.3091149230977507, 0.6558831737345783, 0.6172524365697216, 0.616057217483841, 0.6668439476043622, 0.6742468511756852, 0.6440490311789498, 0.6842225081204971, 0.6804166176720201, 0.6798732923011119, 0.1564261542099874, 0.16852955310079054, 0.15447689993709612, 0.15327019630391803, 0.18215960558450717, 0.14904376318594026, 0.17103530674274425, 0.16066248187779897, 0.2068459868894379, 0.1128134540563942, 0.13626388540601297, 0.16879938086557145, 0.17119601114091165, 0.1732980359022246, 0.14747006960703835, 0.1639800480045338, 0.16032182425997343, 0.13143572667771042, 0.19790669489886137, 0.10718196043164063, 0.09415549326187245, 0.12949205167828282, 0.057629284318532537, 0.1450255092104017, 0.23000752092310717, 0.1069885980075862, 0.14922065311355692, 0.21076493430930876, 0.2284261486610073, 0.2733752356299586, 0.25420191219714083, 0.13631097505331968, 0.24373798557853388, 0.2822668525698119, 0.36912469381908364, 0.3114885702772201, 0.07448380282233957, 0.08510378838464894, 0.049454283520584785, 0.03896482965383985, 0.09177742771300257, 0.10792277655863158, 0.10111775515320476, 0.10317795646624528, 0.09100557266452036, 0.20305189188569117, 0.1952404474659335, 0.21184386675360467, 0.23549527068657672, 0.24138680578365024, 0.25964881733738165, 0.20117738326101586, 0.20078869079668038, 0.20097589973223062, 0.6044505074481423, 0.6006867607334359, 0.56391667317152, 0.5572182382832158, 0.5400793836004774, 0.5756892815245174, 0.5769499299517922, 0.5127973162338062, 0.5396948061796938, 0.10163207932427953, 0.10791622091722142, 0.08408389274288275, 0.09399730205059154, 0.08774036714561462, 0.0911194347260258, 0.09200797014788309, 0.09519312102193833, 0.10216332359134828, 0.14923560208951947, 0.1498640163970607, 0.13037350800810532, 0.1651467959752383, 0.19177615922069846, 0.15189418816477895, 0.13998645355349304, 0.13910206309836248, 0.16264885047299282, 0.37841250956098205, 0.3887451293165215, 0.3859670181973064, 0.42803859893740337, 0.44777904181981076, 0.4094977952428237, 0.5138388090597665, 0.43613349244238486, 0.510355276244937, 0.2640868439069276, 0.2492644774959767, 0.2710943683923437, 0.2648371042701533, 0.29357152259797803, 0.23851291811295428, 0.31098401304374323, 0.28658762287099626, 0.2926993053568161, 0.18271125421964185, 0.1838698122333544, 0.21518987580070192, 0.19799863792224015, 0.20435801233892148, 0.19021117969813361, 0.1863416212521054, 0.20707224901167898, 0.20289617743514787, 0.19819139371833228, 0.39576918087952284, 0.26383973657433657, 0.22926166009079307, 0.20629130136096607, 0.23121556615526884, 0.3545620365297534, 0.34848082669892233, 0.3898009698597108, 0.6470913428870022, 0.6837378436009706, 0.1603461649513207, 0.19599439927483797, 0.557099976393798, 0.1834469693257954, 0.541565107153824, 0.17809371963869092, 0.6832408594614443, 0.19364380449843588, 0.6338082525114264, 0.19675283450738557, 0.4982396903893366, 0.33235530782238254, 0.23323941103311985, 0.206123787818004, 0.20130832116211883, 0.20254901939680503, 0.1940893768499864, 0.18112717342300166, 0.1846430719496588, 0.19620873243572878, 0.1978599781167385, 0.1830836228603766, 0.19080164737633165, 0.18728816742638577, 0.18344753689117255, 0.08198378218977431, 0.07771031668578232, 0.06384986374481283, 0.07504245458984171, 0.08790094518234914, 0.08018254885696974, 0.0843146701221914, 0.0756582415358451, 0.07309108535219999]}, "mutation_prompt": null}
{"id": "dbff1002-808b-4aeb-9e16-21466d4efe0e", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - individual)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0))\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with stochastic covariance adaptation and dynamic population resizing for robust exploration and exploitation.", "configspace": "", "generation": 36, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c08ff3a5-ba59-496b-b3f5-cbbadd23da6a", "metadata": {"aucs": [0.7528759435806445, 0.7416487662431501, 0.7502708775386513, 0.7691661414613046, 0.7527416891041585, 0.751761241092465, 0.7772788961528752, 0.7551685755157684, 0.7379173800875154, 0.6426955210723941, 0.6463555933450049, 0.633121279862906, 0.6413495572357909, 0.6363084083485118, 0.6486003230218463, 0.6529515686019043, 0.6616387077643403, 0.6491944122397993, 0.42947114592592384, 0.15850389611231108, 0.45996154667873723, 0.38191600774212087, 0.39790038326124566, 0.29500009153423956, 0.4249259770623255, 0.3224207868600303, 0.24291011666810713, 0.21499364013544808, 0.117288938563891, 0.12514089010953666, 0.3360206653375475, 0.2888012194090681, 0.11421623033764994, 0.29174224946149474, 0.12138100897266646, 0.13123457865119248, 0.9481546948856856, 0.9610437223398568, 0.9296904050510973, 0.9845844648453883, 0.976461371438196, 0.8752544218893489, 0.9279689087902091, 0.957313211588115, 0.9539228657023939, 0.5253692842705714, 0.5459095021879417, 0.3669714577572466, 0.5165554460866132, 0.3751858925157838, 0.5094134628480552, 0.4345158031082842, 0.4099831986293129, 0.3091149230977507, 0.6558831737345783, 0.6172524365697216, 0.616057217483841, 0.6668439476043622, 0.6742468511756852, 0.6440490311789498, 0.6842225081204971, 0.6804166176720201, 0.6798732923011119, 0.1564261542099874, 0.16852955310079054, 0.15447689993709612, 0.15327019630391803, 0.18215960558450717, 0.14904376318594026, 0.17103530674274425, 0.16066248187779897, 0.2068459868894379, 0.1128134540563942, 0.13626388540601297, 0.16879938086557145, 0.17119601114091165, 0.1732980359022246, 0.14747006960703835, 0.1639800480045338, 0.16032182425997343, 0.13143572667771042, 0.19790669489886137, 0.10718196043164063, 0.09415549326187245, 0.12949205167828282, 0.057629284318532537, 0.1450255092104017, 0.23000752092310717, 0.1069885980075862, 0.14922065311355692, 0.21076493430930876, 0.2284261486610073, 0.2733752356299586, 0.25420191219714083, 0.13631097505331968, 0.24373798557853388, 0.2822668525698119, 0.36912469381908364, 0.3114885702772201, 0.07448380282233957, 0.08510378838464894, 0.049454283520584785, 0.03896482965383985, 0.09177742771300257, 0.10792277655863158, 0.10111775515320476, 0.10317795646624528, 0.09100557266452036, 0.20305189188569117, 0.1952404474659335, 0.21184386675360467, 0.23549527068657672, 0.24138680578365024, 0.25964881733738165, 0.20117738326101586, 0.20078869079668038, 0.20097589973223062, 0.6044505074481423, 0.6006867607334359, 0.56391667317152, 0.5572182382832158, 0.5400793836004774, 0.5756892815245174, 0.5769499299517922, 0.5127973162338062, 0.5396948061796938, 0.10163207932427953, 0.10791622091722142, 0.08408389274288275, 0.09399730205059154, 0.08774036714561462, 0.0911194347260258, 0.09200797014788309, 0.09519312102193833, 0.10216332359134828, 0.14923560208951947, 0.1498640163970607, 0.13037350800810532, 0.1651467959752383, 0.19177615922069846, 0.15189418816477895, 0.13998645355349304, 0.13910206309836248, 0.16264885047299282, 0.37841250956098205, 0.3887451293165215, 0.3859670181973064, 0.42803859893740337, 0.44777904181981076, 0.4094977952428237, 0.5138388090597665, 0.43613349244238486, 0.510355276244937, 0.2640868439069276, 0.2492644774959767, 0.2710943683923437, 0.2648371042701533, 0.29357152259797803, 0.23851291811295428, 0.31098401304374323, 0.28658762287099626, 0.2926993053568161, 0.18271125421964185, 0.1838698122333544, 0.21518987580070192, 0.19799863792224015, 0.20435801233892148, 0.19021117969813361, 0.1863416212521054, 0.20707224901167898, 0.20289617743514787, 0.19819139371833228, 0.39576918087952284, 0.26383973657433657, 0.22926166009079307, 0.20629130136096607, 0.23121556615526884, 0.3545620365297534, 0.34848082669892233, 0.3898009698597108, 0.6470913428870022, 0.6837378436009706, 0.1603461649513207, 0.19599439927483797, 0.557099976393798, 0.1834469693257954, 0.541565107153824, 0.17809371963869092, 0.6832408594614443, 0.19364380449843588, 0.6338082525114264, 0.19675283450738557, 0.4982396903893366, 0.33235530782238254, 0.23323941103311985, 0.206123787818004, 0.20130832116211883, 0.20254901939680503, 0.1940893768499864, 0.18112717342300166, 0.1846430719496588, 0.19620873243572878, 0.1978599781167385, 0.1830836228603766, 0.19080164737633165, 0.18728816742638577, 0.18344753689117255, 0.08198378218977431, 0.07771031668578232, 0.06384986374481283, 0.07504245458984171, 0.08790094518234914, 0.08018254885696974, 0.0843146701221914, 0.0756582415358451, 0.07309108535219999]}, "mutation_prompt": null}
{"id": "0c4169b8-1439-4500-a46f-6c093c831345", "solution": "import numpy as np\n\nclass ImprovedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "ImprovedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with stochastic covariance adaptation, dynamic population resizing, and adaptive learning for improved convergence and diversity.", "configspace": "", "generation": 40, "fitness": 0.33334849296221, "feedback": "The algorithm ImprovedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.24.", "error": "", "parent_id": "c08ff3a5-ba59-496b-b3f5-cbbadd23da6a", "metadata": {"aucs": [0.7532020890277368, 0.7403587836866848, 0.7499437858299032, 0.7691326695389058, 0.7527645747851255, 0.7520654204339231, 0.7771984034625594, 0.756004767155964, 0.7370725184462191, 0.6426955210723941, 0.6463555933450049, 0.633121279862906, 0.6413495572357909, 0.6352581741456758, 0.6486003230218463, 0.6529515686019043, 0.6616387077643403, 0.6491944122397993, 0.4292586571506902, 0.15850389611231108, 0.4599863566685296, 0.38191600774212087, 0.39790038326124566, 0.29500009153423956, 0.4249259770623255, 0.3224207868600303, 0.24146585676021382, 0.21499364013544808, 0.117288938563891, 0.12512022895158337, 0.33606002151527314, 0.2888012194090681, 0.11433822583709807, 0.2914347583419632, 0.12138100897266646, 0.13123457865119248, 0.9478370984349623, 0.9609245984026947, 0.9376577291215369, 0.9845820504826238, 0.976461371438196, 0.9373158032375705, 0.9279689087902091, 0.9573395746330357, 0.9538771113733663, 0.5253692842705714, 0.5459500974567755, 0.3669980137745228, 0.5166170703283723, 0.3751935388523999, 0.5094432191090205, 0.4334791327338766, 0.4089263284816058, 0.3106702852205945, 0.6558831737345783, 0.6174526460497356, 0.619501346254409, 0.666840677784478, 0.6684241024835199, 0.6440490311789498, 0.6841223081689207, 0.6791137793171813, 0.6798732923011119, 0.15761076573818777, 0.16852955310079054, 0.1545806917550815, 0.13885643422898197, 0.18215960558450717, 0.14904376318594026, 0.16994903720892307, 0.16066248187779897, 0.20623148296096194, 0.11131452320103052, 0.1357524894967297, 0.16835050367059268, 0.17119601114091165, 0.1732980359022246, 0.1474727971751303, 0.1639786652992985, 0.1603903971754096, 0.13140756481542815, 0.19790669489886137, 0.10916180134404918, 0.09415549326187245, 0.12949205167828282, 0.057629284318532537, 0.1450255092104017, 0.23000752092310717, 0.1069885980075862, 0.14922065311355692, 0.21076493430930876, 0.2284261486610073, 0.2733752356299586, 0.25420191219714083, 0.13631097505331968, 0.24373798557853388, 0.2822668525698119, 0.36912469381908364, 0.31176740323972285, 0.07448380282233957, 0.08510378838464894, 0.049454283520584785, 0.03896482965383985, 0.09177742771300257, 0.10792277655863158, 0.10111775515320476, 0.10317795646624528, 0.09100557266452036, 0.20297172261965546, 0.1952404474659335, 0.21102067185081474, 0.23540182835478296, 0.24138680578365024, 0.25957648954517043, 0.20117738326101586, 0.20078869079668038, 0.2033695438313794, 0.6044505074481423, 0.6006867607334359, 0.5637976996626466, 0.5563442794251147, 0.537310809148399, 0.5757110878590277, 0.5769388076064417, 0.5127973162338062, 0.5395421273934828, 0.10162370082767125, 0.10791622091722142, 0.08408663390940596, 0.09500877419228815, 0.08774036714561462, 0.0911194347260258, 0.09200797014788309, 0.09517514993792042, 0.10216332359134828, 0.14923560208951947, 0.1498640163970607, 0.13037350800810532, 0.18551570964605968, 0.19177615922069846, 0.15072560835079962, 0.13998645355349304, 0.13910206309836248, 0.16264885047299282, 0.3786878498149836, 0.38873871811302996, 0.3859670181973064, 0.42803859893740337, 0.447857154593738, 0.4097534185002275, 0.5138903120138612, 0.43613349244238486, 0.5102832666823924, 0.2640868439069276, 0.24916205061447283, 0.2710943683923437, 0.26483789960674553, 0.29357152259797803, 0.2380789580682554, 0.31098401304374323, 0.2866877740461966, 0.2926993053568161, 0.18271125421964185, 0.18439033575036867, 0.21518987580070192, 0.19799863792224015, 0.20435801233892148, 0.19021117969813361, 0.18647204469902912, 0.20707224901167898, 0.20289617743514787, 0.19819139371833228, 0.39576918087952284, 0.26383973657433657, 0.2292194957768824, 0.20629130136096607, 0.23121556615526884, 0.3545620365297534, 0.34848082669892233, 0.3898009698597108, 0.6470913428870022, 0.6837378436009706, 0.16020529567800967, 0.19599439927483797, 0.557099976393798, 0.1834469693257954, 0.541794157507526, 0.17809371963869092, 0.6832408594614443, 0.19364380449843588, 0.6338082525114264, 0.19735973680921082, 0.4981580221389258, 0.33235530782238254, 0.23323941103311985, 0.20612272342359161, 0.20122991240998556, 0.20254356447795085, 0.1940893768499864, 0.18112717342300166, 0.1863762372044614, 0.17014287136738826, 0.1978599781167385, 0.1830836228603766, 0.19080164737633165, 0.18728816742638577, 0.18344753689117255, 0.08283031404257746, 0.07771031668578232, 0.06429856847773296, 0.07504245458984171, 0.08790094518234914, 0.0802961445249557, 0.083923042687712, 0.07482723240436995, 0.07309108535219999]}, "mutation_prompt": null}
{"id": "7bb6eaad-d769-4666-b329-665d6fb799b8", "solution": "import numpy as np\n\nclass ImprovedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "ImprovedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with stochastic covariance adaptation, dynamic population resizing, and adaptive learning for improved convergence and diversity.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {"aucs": [0.7532020890277368, 0.7403587836866848, 0.7499437858299032, 0.7691326695389058, 0.7527645747851255, 0.7520654204339231, 0.7771984034625594, 0.756004767155964, 0.7370725184462191, 0.6426955210723941, 0.6463555933450049, 0.633121279862906, 0.6413495572357909, 0.6352581741456758, 0.6486003230218463, 0.6529515686019043, 0.6616387077643403, 0.6491944122397993, 0.4292586571506902, 0.15850389611231108, 0.4599863566685296, 0.38191600774212087, 0.39790038326124566, 0.29500009153423956, 0.4249259770623255, 0.3224207868600303, 0.24146585676021382, 0.21499364013544808, 0.117288938563891, 0.12512022895158337, 0.33606002151527314, 0.2888012194090681, 0.11433822583709807, 0.2914347583419632, 0.12138100897266646, 0.13123457865119248, 0.9478370984349623, 0.9609245984026947, 0.9376577291215369, 0.9845820504826238, 0.976461371438196, 0.9373158032375705, 0.9279689087902091, 0.9573395746330357, 0.9538771113733663, 0.5253692842705714, 0.5459500974567755, 0.3669980137745228, 0.5166170703283723, 0.3751935388523999, 0.5094432191090205, 0.4334791327338766, 0.4089263284816058, 0.3106702852205945, 0.6558831737345783, 0.6174526460497356, 0.619501346254409, 0.666840677784478, 0.6684241024835199, 0.6440490311789498, 0.6841223081689207, 0.6791137793171813, 0.6798732923011119, 0.15761076573818777, 0.16852955310079054, 0.1545806917550815, 0.13885643422898197, 0.18215960558450717, 0.14904376318594026, 0.16994903720892307, 0.16066248187779897, 0.20623148296096194, 0.11131452320103052, 0.1357524894967297, 0.16835050367059268, 0.17119601114091165, 0.1732980359022246, 0.1474727971751303, 0.1639786652992985, 0.1603903971754096, 0.13140756481542815, 0.19790669489886137, 0.10916180134404918, 0.09415549326187245, 0.12949205167828282, 0.057629284318532537, 0.1450255092104017, 0.23000752092310717, 0.1069885980075862, 0.14922065311355692, 0.21076493430930876, 0.2284261486610073, 0.2733752356299586, 0.25420191219714083, 0.13631097505331968, 0.24373798557853388, 0.2822668525698119, 0.36912469381908364, 0.31176740323972285, 0.07448380282233957, 0.08510378838464894, 0.049454283520584785, 0.03896482965383985, 0.09177742771300257, 0.10792277655863158, 0.10111775515320476, 0.10317795646624528, 0.09100557266452036, 0.20297172261965546, 0.1952404474659335, 0.21102067185081474, 0.23540182835478296, 0.24138680578365024, 0.25957648954517043, 0.20117738326101586, 0.20078869079668038, 0.2033695438313794, 0.6044505074481423, 0.6006867607334359, 0.5637976996626466, 0.5563442794251147, 0.537310809148399, 0.5757110878590277, 0.5769388076064417, 0.5127973162338062, 0.5395421273934828, 0.10162370082767125, 0.10791622091722142, 0.08408663390940596, 0.09500877419228815, 0.08774036714561462, 0.0911194347260258, 0.09200797014788309, 0.09517514993792042, 0.10216332359134828, 0.14923560208951947, 0.1498640163970607, 0.13037350800810532, 0.18551570964605968, 0.19177615922069846, 0.15072560835079962, 0.13998645355349304, 0.13910206309836248, 0.16264885047299282, 0.3786878498149836, 0.38873871811302996, 0.3859670181973064, 0.42803859893740337, 0.447857154593738, 0.4097534185002275, 0.5138903120138612, 0.43613349244238486, 0.5102832666823924, 0.2640868439069276, 0.24916205061447283, 0.2710943683923437, 0.26483789960674553, 0.29357152259797803, 0.2380789580682554, 0.31098401304374323, 0.2866877740461966, 0.2926993053568161, 0.18271125421964185, 0.18439033575036867, 0.21518987580070192, 0.19799863792224015, 0.20435801233892148, 0.19021117969813361, 0.18647204469902912, 0.20707224901167898, 0.20289617743514787, 0.19819139371833228, 0.39576918087952284, 0.26383973657433657, 0.2292194957768824, 0.20629130136096607, 0.23121556615526884, 0.3545620365297534, 0.34848082669892233, 0.3898009698597108, 0.6470913428870022, 0.6837378436009706, 0.16020529567800967, 0.19599439927483797, 0.557099976393798, 0.1834469693257954, 0.541794157507526, 0.17809371963869092, 0.6832408594614443, 0.19364380449843588, 0.6338082525114264, 0.19735973680921082, 0.4981580221389258, 0.33235530782238254, 0.23323941103311985, 0.20612272342359161, 0.20122991240998556, 0.20254356447795085, 0.1940893768499864, 0.18112717342300166, 0.1863762372044614, 0.17014287136738826, 0.1978599781167385, 0.1830836228603766, 0.19080164737633165, 0.18728816742638577, 0.18344753689117255, 0.08283031404257746, 0.07771031668578232, 0.06429856847773296, 0.07504245458984171, 0.08790094518234914, 0.0802961445249557, 0.083923042687712, 0.07482723240436995, 0.07309108535219999]}, "mutation_prompt": null}
{"id": "c7985fe5-6b83-4515-834b-64dfbc0a0b24", "solution": "import numpy as np\n\nclass RefinedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n        self.elite_fraction = 0.1\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _elitist_selection(self, population, fitness):\n        elite_size = int(self.elite_fraction * self.population_size)\n        elite_indices = np.argsort(fitness)[:elite_size]\n        return population[elite_indices], fitness[elite_indices]\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            population, fitness = self._elitist_selection(population, fitness)\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n            if evaluations % (self.budget // 5) == 0:\n                population = self._initialize_population()\n                fitness = np.apply_along_axis(func, 1, population)\n                evaluations += self.population_size\n\n        return best_individual, best_fitness", "name": "RefinedAdaptiveDELS", "description": "Refined AdaptiveDELS with self-adaptive differential evolution strategies, elitist selection, and periodic re-initialization to enhance exploration and exploitation balance.", "configspace": "", "generation": 42, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 33 is out of bounds for axis 0 with size 5').", "error": "IndexError('index 33 is out of bounds for axis 0 with size 5')", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {}, "mutation_prompt": null}
{"id": "abb86058-862f-47ef-9ce9-f9db78786b9f", "solution": "import numpy as np\n\nclass EnhancedCovarianceDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 12 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        np.random.shuffle(idxs)\n        if len(idxs) >= 3:\n            a, b, c = population[idxs[:3]]\n            mutant = a + self.mutation_factor * (b - c)\n        else:\n            mutant = np.random.uniform(self.lb, self.ub, self.dim)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _dynamic_strategy(self, individual, best_individual, centroid):\n        choice = np.random.rand()\n        if choice < 0.5:\n            step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        else:\n            step = np.random.uniform(-0.1, 0.1, self.dim) * (best_individual - centroid)\n        candidate = individual + step\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        std_fitness = np.std(fitness)\n        if std_fitness > 0:\n            diversity_index = 1 - (np.min(fitness) / np.mean(fitness))\n            adjustment = self.adaptive_factor * diversity_index\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / max(abs(self.history[-1]), 1e-10)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            dynamic_candidate = self._dynamic_strategy(best_individual, np.mean(population, axis=0), centroid)\n            dynamic_fitness = func(dynamic_candidate)\n            evaluations += 1\n\n            if dynamic_fitness < best_fitness:\n                best_individual = dynamic_candidate\n                best_fitness = dynamic_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "EnhancedCovarianceDE", "description": "Enhanced Covariance-based Adaptive DE variant using fitness diversity-driven exploration and dynamic strategy selection for robust optimization.", "configspace": "", "generation": 43, "fitness": 0.25374454209230213, "feedback": "The algorithm EnhancedCovarianceDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.21.", "error": "", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {"aucs": [0.4254238200836218, 0.46213462852644493, 0.3662112904864937, 0.6267319748027588, 0.6073794420350431, 0.6677028662692944, 0.7599697139884964, 0.7585932314842253, 0.7473780192510528, 0.2444699480210264, 0.23539531564069338, 0.2391969970058655, 0.2519627775868437, 0.2055253168829725, 0.1386799616481199, 0.24309260782110065, 0.2513877876819943, 0.20655346898752103, 0.3973032590238571, 0.4345947056011398, 0.4078547363193743, 0.0846675462086045, 0.08449914289779514, 0.07916463661999529, 0.08725430142395929, 0.092795125281529, 0.07643403204790977, 0.30971966484177205, 0.1408199920912102, 0.22133856431522358, 0.07634207092101442, 0.08523458295119779, 0.054252702060013314, 0.06102539506060689, 0.06728635224035462, 0.07955056771726665, 0.9416684639160046, 0.8901398108750984, 0.9562663860157256, 0.950001967752589, 0.9613203289425073, 0.842849765777548, 0.9820379497092989, 0.8977059790050984, 0.9645340934328431, 0.2139037936666156, 0.22801669989036066, 0.2231559003582978, 0.22118524614486335, 0.1953934261701059, 0.22497929525672788, 0.47397817886339855, 0.3476951115495762, 0.35201731629069877, 0.257881695051134, 0.24510591860113295, 0.46569242158945945, 0.2905773862275761, 0.27358113481170954, 0.5334371233487406, 0.2939851582390707, 0.265989915301617, 0.28418765389075284, 0.154267497889928, 0.12457052473844665, 0.0850534840385655, 0.14153186402639317, 0.21720331753030053, 0.151540910496897, 0.20395668020677515, 0.13782657798075237, 0.2005276671916767, 0.02860223939856621, 0.22305259145745027, 0.05463229682210824, 0.20790430527262338, 0.1056992495067488, 0.09832691748294986, 0.12042571885773556, 0.14573060897773527, 0.16479774717605655, 0.15860662866402253, 0.12721651873217799, 0.1502817802830828, 0.19499069807059854, 0.17297004967385454, 0.15902090205307684, 0.16241635812135735, 0.12461873889836639, 0.14667036256172483, 0.32624612304181666, 0.27580456911376217, 0.2231904580480445, 0.26488846890371387, 0.27004599964363196, 0.2675506703527417, 0.26281640819806873, 0.3238774060262982, 0.29374584832520456, 9.999999999998899e-05, 0.0038694306495815622, 0.017902970697861065, 0.044805346813890035, 0.0034416918543705988, 0.013960178486913666, 0.010230899728544851, 0.026744035821746337, 9.999999999998899e-05, 0.08312790237996293, 0.14534926319080277, 0.13947772165188266, 0.13694161348221368, 0.09515980418833336, 0.1446387254141106, 0.18080184781336406, 0.17023228022550174, 0.16223394329517649, 0.5889607975261442, 0.6029537670120018, 0.5176891322714376, 0.5858855828725887, 0.5695533890066079, 0.4880261881654824, 0.4145141036057348, 0.4088553595853236, 0.39901680825238295, 0.07978039753759436, 0.09011578417493715, 0.09166949446635175, 0.07936178537038718, 0.09757524269362838, 0.09096155036489051, 0.08761655015837622, 0.10005666345207143, 0.0919572894804438, 0.1506070018941369, 0.12387206279776697, 0.14666424524312005, 0.16639765935472828, 0.18668296026800024, 0.15308137299180158, 0.23265042738619868, 0.157546248858475, 0.13205404532783271, 0.4038425814549076, 0.3939958792226448, 0.43300425898723316, 0.21756624603647357, 0.21006041705010947, 0.19463804907366544, 0.3051775811862002, 0.2901641454508087, 0.30021179524917285, 0.24981189404024307, 0.2360158114350166, 0.2205058438513936, 0.18403812466389147, 0.1915546704395873, 0.1791648604354963, 0.1771358833323795, 0.17012231841338632, 0.17663853814783348, 0.2257552247827983, 0.19339905305905958, 0.19141732449409754, 0.1799211216415748, 0.17334154787831924, 0.1727752455144309, 0.18184305861836358, 0.19063808537506421, 0.1678611974710269, 0.2893140287971956, 0.2100332031135037, 0.4289530046921798, 0.18614095293621036, 0.17642445585168076, 0.18146706747649977, 0.17335879529749454, 0.1767853905331409, 0.17698544029224705, 0.18205903984267557, 0.29862744434359256, 0.18416024212762394, 0.5497445652549741, 0.17632483798023768, 0.28587799106518197, 0.5133073758717438, 0.19592280578824395, 0.3104186633547441, 0.27731033223027657, 0.16149986881925193, 0.25512846811582945, 0.18737391195647812, 0.19201437627056117, 0.5135378341466705, 0.2080452767440546, 0.20516624836556074, 0.7154836147492409, 0.1829932062985794, 0.21369066608838416, 0.1987432927348799, 0.24799969751513562, 0.19581983176179363, 0.1953495232205008, 0.2101783950910795, 0.18904939127906195, 0.1978690815881472, 0.07377200293767405, 0.05863153407948596, 0.06800088513280955, 0.06872169406395845, 0.07569998459768412, 0.07222565054876917, 0.06688898450332903, 0.06764398896892054, 0.06443086812389753]}, "mutation_prompt": null}
{"id": "97aef9a1-835b-4161-b85f-491dbb85e771", "solution": "import numpy as np\n\nclass EnhancedImprovedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n        self.sobol_seq = self._generate_sobol_sequence(self.population_size, self.dim)\n\n    def _generate_sobol_sequence(self, n_points, d):\n        try:\n            from scipy.stats.qmc import Sobol\n            sobol = Sobol(d)\n            return sobol.random(n_points) * (self.ub - self.lb) + self.lb\n        except ImportError:\n            return np.random.uniform(self.lb, self.ub, (n_points, d))\n\n    def _initialize_population(self):\n        return self.sobol_seq\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        step = self.mutation_factor * (b - c) + np.random.normal(0, 0.1, self.dim)\n        mutant = a + step\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.05, 0.05, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "EnhancedImprovedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with quasi-random initialization, adaptive Gaussian mutation, and fitness-based dynamic population adaptation for improved convergence.", "configspace": "", "generation": 44, "fitness": 0.22279356804391195, "feedback": "The algorithm EnhancedImprovedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {"aucs": [0.4530258966391525, 0.44826595883818343, 0.43712330040894354, 0.45327128828151153, 0.4775614768134324, 0.4601929540714783, 0.4523475367681027, 0.4507787224301225, 0.4540395190898753, 0.12543889972480993, 0.13032709285664057, 0.09639359942677916, 0.12825684952955585, 0.11289641718160215, 0.11696935011144738, 0.11804397215416829, 0.09982542011239326, 0.10953049806923043, 0.1149469168228554, 0.12170845400360153, 0.09761623374641981, 0.09858871055465501, 0.11431060793078063, 0.1194960290961502, 0.11985711248833364, 0.11724479071831606, 0.11489243569833596, 0.10519841689572129, 0.12379553348778338, 0.11103716251120099, 0.12392563995628658, 0.1026845366435839, 0.11342422692834786, 0.10418058251508522, 0.11393500232568932, 0.10893988577040614, 0.8446330711431587, 0.962097282858117, 0.9202148668683564, 0.897638052386391, 0.9111228371318029, 0.9060933086720443, 0.9343552762994413, 0.9856882240092566, 0.9370409667633669, 0.25547069476682105, 0.27179911420665026, 0.27716203629435, 0.2638458808392886, 0.28579968276290413, 0.26172741910794617, 0.2676816062313999, 0.27436418158453435, 0.2796663591934041, 0.3823102284210298, 0.462855307433622, 0.38749089636825873, 0.46250032305137634, 0.31903443057593883, 0.3307841252394442, 0.670860458175594, 0.5492128445553479, 0.43712769751285474, 0.13056841662722252, 0.13212503497570438, 0.14121855912859482, 0.1435118667278441, 0.15849184009603068, 0.14770108705897378, 0.1558035996359618, 0.1523367642468738, 0.1405452734540732, 0.14612103368892626, 0.17206337297830665, 0.14004678050601083, 0.13471701364004474, 0.14687292986165046, 0.13480060795346582, 0.13057615572284909, 0.1406508590195703, 0.12652467962156388, 0.00832954841086575, 0.005622131980920875, 0.00830852805275295, 0.00015786276898566154, 0.00967513426358857, 0.011237688137061053, 0.011291568788509565, 0.016846482577947075, 0.0018452432382555228, 0.07071931591015546, 0.08664327021922313, 0.08213044066257702, 0.1032662809285777, 0.08586567940205736, 0.07652476124250895, 0.0999771731921052, 0.09031851336280838, 0.09859712377604923, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10992455557707759, 0.11321844800382663, 0.1102117064156386, 0.10957407702016886, 0.11153277514568016, 0.1046506285520965, 0.09877017815083433, 0.09217313776619462, 0.09349269015827943, 0.41540964412033643, 0.39225804596937497, 0.39196640231754387, 0.4169391835972178, 0.4307413842477571, 0.4134073346192899, 0.3760671390229816, 0.4075875876584183, 0.3980581674523229, 0.1063886821016855, 0.09311052494415417, 0.10605143747165335, 0.10274728148528867, 0.11084618893200837, 0.09329569483329592, 0.09486553923455854, 0.10637537834258526, 0.08674888534818692, 0.17563590897719117, 0.1713890608221058, 0.24612721515251768, 0.18332916134805388, 0.13957863097187906, 0.1377438623003192, 0.14280652549166772, 0.2103034556611999, 0.13793300393099728, 0.29075464220479075, 0.27365461155842763, 0.27480760674439075, 0.2792292581949466, 0.2663776629805158, 0.2815895664634117, 0.27339071920590874, 0.28887616965126073, 0.29767209420341845, 0.1911434467761134, 0.1941301133587342, 0.2004777653787816, 0.19987656932080622, 0.20777518338529066, 0.1992937561761463, 0.2245972107663503, 0.21629594903974214, 0.21982836487091373, 0.16413808165055765, 0.19648931035508477, 0.18668471143907306, 0.19942027950223185, 0.18230209615161197, 0.2048231611338116, 0.21884598949741363, 0.2062030338891897, 0.17436040395128638, 0.19789915780802758, 0.23450899226513, 0.20361834326090988, 0.190679627949371, 0.2014237816124943, 0.18430234118513555, 0.19973282954177718, 0.1778340959869632, 0.19160998465918788, 0.5307252196743137, 0.43202697446056615, 0.18770490839492948, 0.1791050420798994, 0.1764721406322851, 0.5484315171906871, 0.630680439138404, 0.19359265471762965, 0.3684482786961517, 0.1998805785048957, 0.3490090253777792, 0.19850112034246725, 0.1764309192663266, 0.2992307159636093, 0.18737418321421506, 0.20173011468674917, 0.4181290867940002, 0.206839164084332, 0.17203882613131571, 0.18494770118625958, 0.193176011091043, 0.18218903397737507, 0.18211684087017788, 0.18817847549333766, 0.19869014161192022, 0.1870555849244112, 0.19520831371286684, 0.0800025146401202, 0.0836281577068525, 0.07807352891146035, 0.07230491754555479, 0.06867660872877746, 0.07394929333516465, 0.07682207815090336, 0.08371158152742064, 0.08084174454488713]}, "mutation_prompt": null}
{"id": "34d404be-1800-4e18-bb3c-277bea2d6749", "solution": "import numpy as np\n\nclass ImprovedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "ImprovedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with stochastic covariance adaptation, dynamic population resizing, and adaptive learning for improved convergence and diversity.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {"aucs": [0.7532020890277368, 0.7403587836866848, 0.7499437858299032, 0.7691326695389058, 0.7527645747851255, 0.7520654204339231, 0.7771984034625594, 0.756004767155964, 0.7370725184462191, 0.6426955210723941, 0.6463555933450049, 0.633121279862906, 0.6413495572357909, 0.6352581741456758, 0.6486003230218463, 0.6529515686019043, 0.6616387077643403, 0.6491944122397993, 0.4292586571506902, 0.15850389611231108, 0.4599863566685296, 0.38191600774212087, 0.39790038326124566, 0.29500009153423956, 0.4249259770623255, 0.3224207868600303, 0.24146585676021382, 0.21499364013544808, 0.117288938563891, 0.12512022895158337, 0.33606002151527314, 0.2888012194090681, 0.11433822583709807, 0.2914347583419632, 0.12138100897266646, 0.13123457865119248, 0.9478370984349623, 0.9609245984026947, 0.9376577291215369, 0.9845820504826238, 0.976461371438196, 0.9373158032375705, 0.9279689087902091, 0.9573395746330357, 0.9538771113733663, 0.5253692842705714, 0.5459500974567755, 0.3669980137745228, 0.5166170703283723, 0.3751935388523999, 0.5094432191090205, 0.4334791327338766, 0.4089263284816058, 0.3106702852205945, 0.6558831737345783, 0.6174526460497356, 0.619501346254409, 0.666840677784478, 0.6684241024835199, 0.6440490311789498, 0.6841223081689207, 0.6791137793171813, 0.6798732923011119, 0.15761076573818777, 0.16852955310079054, 0.1545806917550815, 0.13885643422898197, 0.18215960558450717, 0.14904376318594026, 0.16994903720892307, 0.16066248187779897, 0.20623148296096194, 0.11131452320103052, 0.1357524894967297, 0.16835050367059268, 0.17119601114091165, 0.1732980359022246, 0.1474727971751303, 0.1639786652992985, 0.1603903971754096, 0.13140756481542815, 0.19790669489886137, 0.10916180134404918, 0.09415549326187245, 0.12949205167828282, 0.057629284318532537, 0.1450255092104017, 0.23000752092310717, 0.1069885980075862, 0.14922065311355692, 0.21076493430930876, 0.2284261486610073, 0.2733752356299586, 0.25420191219714083, 0.13631097505331968, 0.24373798557853388, 0.2822668525698119, 0.36912469381908364, 0.31176740323972285, 0.07448380282233957, 0.08510378838464894, 0.049454283520584785, 0.03896482965383985, 0.09177742771300257, 0.10792277655863158, 0.10111775515320476, 0.10317795646624528, 0.09100557266452036, 0.20297172261965546, 0.1952404474659335, 0.21102067185081474, 0.23540182835478296, 0.24138680578365024, 0.25957648954517043, 0.20117738326101586, 0.20078869079668038, 0.2033695438313794, 0.6044505074481423, 0.6006867607334359, 0.5637976996626466, 0.5563442794251147, 0.537310809148399, 0.5757110878590277, 0.5769388076064417, 0.5127973162338062, 0.5395421273934828, 0.10162370082767125, 0.10791622091722142, 0.08408663390940596, 0.09500877419228815, 0.08774036714561462, 0.0911194347260258, 0.09200797014788309, 0.09517514993792042, 0.10216332359134828, 0.14923560208951947, 0.1498640163970607, 0.13037350800810532, 0.18551570964605968, 0.19177615922069846, 0.15072560835079962, 0.13998645355349304, 0.13910206309836248, 0.16264885047299282, 0.3786878498149836, 0.38873871811302996, 0.3859670181973064, 0.42803859893740337, 0.447857154593738, 0.4097534185002275, 0.5138903120138612, 0.43613349244238486, 0.5102832666823924, 0.2640868439069276, 0.24916205061447283, 0.2710943683923437, 0.26483789960674553, 0.29357152259797803, 0.2380789580682554, 0.31098401304374323, 0.2866877740461966, 0.2926993053568161, 0.18271125421964185, 0.18439033575036867, 0.21518987580070192, 0.19799863792224015, 0.20435801233892148, 0.19021117969813361, 0.18647204469902912, 0.20707224901167898, 0.20289617743514787, 0.19819139371833228, 0.39576918087952284, 0.26383973657433657, 0.2292194957768824, 0.20629130136096607, 0.23121556615526884, 0.3545620365297534, 0.34848082669892233, 0.3898009698597108, 0.6470913428870022, 0.6837378436009706, 0.16020529567800967, 0.19599439927483797, 0.557099976393798, 0.1834469693257954, 0.541794157507526, 0.17809371963869092, 0.6832408594614443, 0.19364380449843588, 0.6338082525114264, 0.19735973680921082, 0.4981580221389258, 0.33235530782238254, 0.23323941103311985, 0.20612272342359161, 0.20122991240998556, 0.20254356447795085, 0.1940893768499864, 0.18112717342300166, 0.1863762372044614, 0.17014287136738826, 0.1978599781167385, 0.1830836228603766, 0.19080164737633165, 0.18728816742638577, 0.18344753689117255, 0.08283031404257746, 0.07771031668578232, 0.06429856847773296, 0.07504245458984171, 0.08790094518234914, 0.0802961445249557, 0.083923042687712, 0.07482723240436995, 0.07309108535219999]}, "mutation_prompt": null}
{"id": "8b392b61-f1f3-44c1-9d07-e21e74e265f2", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population, best_individual):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c) + np.random.rand(self.dim) * (best_individual - population[target_idx])\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / max(abs(self.history[-1]), 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(5 * self.dim, int(self.init_population_size * 0.75))\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(3 * self.dim, int(self.init_population_size * 0.5))\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adaptive_learning(best_fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population, best_individual)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELS", "description": "EnhancedAdaptiveDELS with dynamic learning rate tuning, adaptive mutation strategy, and intelligent diversification for robust optimization across diverse problems.", "configspace": "", "generation": 46, "fitness": 0.2027360604131394, "feedback": "The algorithm EnhancedAdaptiveDELS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.21.", "error": "", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {"aucs": [0.542031812924789, 0.5409829015060512, 0.5124298538228018, 0.5739581610360207, 0.5927459623395771, 0.5878298992764953, 0.5831127019913771, 0.5951498303321929, 0.5763030146227259, 0.3377927883895291, 0.3147505604331956, 0.2933305376006232, 0.32204361845702467, 0.3357241400962777, 0.3020400475706734, 0.3327071838592949, 0.32967797736259785, 0.32163452106743295, 0.0806820597127258, 0.11400235137848891, 0.08303483724176441, 0.1067917912543338, 0.09016752770192615, 0.07326689110070617, 0.08295155450230562, 0.08826809797560531, 0.08396138246771079, 0.06620173234174598, 0.07955647629832852, 0.07487268037590766, 0.07012785652398912, 0.08940080092026492, 0.07757076804220597, 0.06739760597886213, 0.07949155423023513, 0.09578479504084458, 0.9846684882602155, 0.984388557502763, 0.9832603847592127, 0.9857297206548582, 0.991754891281388, 0.9833270914747942, 0.9859478892971435, 0.9891557009958282, 0.9934742056633286, 0.16777332477220186, 0.20349735449196849, 0.19431914960884156, 0.20597010062536347, 0.2074941490141512, 0.19377250400177848, 0.21393774716157432, 0.19118849296847795, 0.18715131694471243, 0.22802652464979956, 0.21904955073527954, 0.2570598001669989, 0.2298443223026898, 0.25247332311494897, 0.23947589503404132, 0.24979359819127334, 0.24287259846788423, 0.2356615102677999, 0.08575156490929259, 0.10533777278292311, 0.12270560215261217, 0.13666723973237316, 0.10386680765739364, 0.13066280398940233, 0.1258647543643172, 0.13079298213281143, 0.12079235023033852, 0.06220259929804839, 0.07504315857259858, 0.10981759368168298, 0.12983649093210914, 0.11090135162474546, 0.10238371793498502, 0.1255262909027144, 0.10206460926273997, 0.08736243779342823, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002393376480352316, 0.006073992354374114, 0.00033534500344245544, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05263467431343449, 0.028809515430726296, 0.09298005577794488, 0.058910504602365465, 0.0437496319237316, 0.06785232469366853, 0.05318719357555801, 0.04621213138365987, 0.06421654526450726, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07229989963201022, 0.07756382376373439, 0.06569695710718293, 0.07965129924810321, 0.07122718439711262, 0.08136380305699842, 0.08050043334604429, 0.07652523407474943, 0.073417101260155, 0.38659616461504165, 0.3944653292368405, 0.3935733565307634, 0.4235582680314466, 0.41877908411397513, 0.3910962481622151, 0.38555001585620874, 0.4155435187720098, 0.41476663359665356, 0.06836212783201967, 0.07622315444273975, 0.07701916107378115, 0.07292912528242412, 0.07629381057471674, 0.07022877736801603, 0.06790176941793036, 0.0774051591774998, 0.08349961063649858, 0.1329336489115569, 0.1448493641188363, 0.167316505891293, 0.14650162026074054, 0.14952860193759954, 0.15397033613728894, 0.20631988145194202, 0.14975758599781597, 0.14577277219691642, 0.21665031630855114, 0.22064937646292626, 0.23418018357068937, 0.21634801842049134, 0.22365619515094315, 0.21792863684013197, 0.2642986994406752, 0.27380663568446895, 0.25169975880494555, 0.16410560847111388, 0.1689866779800343, 0.16552362149636413, 0.1375789123052622, 0.15062843391783698, 0.1599970721580528, 0.17525381765082437, 0.18776780641449897, 0.1823992819355823, 0.17030896867879186, 0.18136318426741893, 0.1849559822718596, 0.19533493178723804, 0.17911361226423705, 0.2228187994503521, 0.2284323040303965, 0.17087532865618982, 0.19113447053682553, 0.1667721251799117, 0.17718657753690636, 0.16859597484812516, 0.17797519363903846, 0.1702564048647941, 0.1644979440741301, 0.1846837902094357, 0.17337516804140052, 0.16154156797518426, 0.31728541906622476, 0.25678397646003126, 0.2762841994858187, 0.19715150098612078, 0.16194376268703492, 0.14953917685693452, 0.1471866839914524, 0.2012222260950024, 0.1470215318449133, 0.21718813359679756, 0.18504942414557557, 0.1661624320753874, 0.15744361358740167, 0.1584672772950202, 0.1599300336075452, 0.20773696432494215, 0.20452039426402713, 0.20970516764934, 0.19291100160671282, 0.18448293505726443, 0.17760697001140946, 0.17722972649127966, 0.19063028115509129, 0.1700936927710225, 0.18987692370314813, 0.17156816714748258, 0.1842312056828629, 0.05988043199035742, 0.07159720604860287, 0.06438237083987919, 0.06662490301633239, 0.06798440032089437, 0.06733608418618275, 0.06790339166282178, 0.06100980586034943, 0.0700689978861283]}, "mutation_prompt": null}
{"id": "c9c8d600-faa6-4d53-923a-b00892922abb", "solution": "import numpy as np\n\nclass ImprovedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "ImprovedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with stochastic covariance adaptation, dynamic population resizing, and adaptive learning for improved convergence and diversity.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {"aucs": [0.7532020890277368, 0.7403587836866848, 0.7499437858299032, 0.7691326695389058, 0.7527645747851255, 0.7520654204339231, 0.7771984034625594, 0.756004767155964, 0.7370725184462191, 0.6426955210723941, 0.6463555933450049, 0.633121279862906, 0.6413495572357909, 0.6352581741456758, 0.6486003230218463, 0.6529515686019043, 0.6616387077643403, 0.6491944122397993, 0.4292586571506902, 0.15850389611231108, 0.4599863566685296, 0.38191600774212087, 0.39790038326124566, 0.29500009153423956, 0.4249259770623255, 0.3224207868600303, 0.24146585676021382, 0.21499364013544808, 0.117288938563891, 0.12512022895158337, 0.33606002151527314, 0.2888012194090681, 0.11433822583709807, 0.2914347583419632, 0.12138100897266646, 0.13123457865119248, 0.9478370984349623, 0.9609245984026947, 0.9376577291215369, 0.9845820504826238, 0.976461371438196, 0.9373158032375705, 0.9279689087902091, 0.9573395746330357, 0.9538771113733663, 0.5253692842705714, 0.5459500974567755, 0.3669980137745228, 0.5166170703283723, 0.3751935388523999, 0.5094432191090205, 0.4334791327338766, 0.4089263284816058, 0.3106702852205945, 0.6558831737345783, 0.6174526460497356, 0.619501346254409, 0.666840677784478, 0.6684241024835199, 0.6440490311789498, 0.6841223081689207, 0.6791137793171813, 0.6798732923011119, 0.15761076573818777, 0.16852955310079054, 0.1545806917550815, 0.13885643422898197, 0.18215960558450717, 0.14904376318594026, 0.16994903720892307, 0.16066248187779897, 0.20623148296096194, 0.11131452320103052, 0.1357524894967297, 0.16835050367059268, 0.17119601114091165, 0.1732980359022246, 0.1474727971751303, 0.1639786652992985, 0.1603903971754096, 0.13140756481542815, 0.19790669489886137, 0.10916180134404918, 0.09415549326187245, 0.12949205167828282, 0.057629284318532537, 0.1450255092104017, 0.23000752092310717, 0.1069885980075862, 0.14922065311355692, 0.21076493430930876, 0.2284261486610073, 0.2733752356299586, 0.25420191219714083, 0.13631097505331968, 0.24373798557853388, 0.2822668525698119, 0.36912469381908364, 0.31176740323972285, 0.07448380282233957, 0.08510378838464894, 0.049454283520584785, 0.03896482965383985, 0.09177742771300257, 0.10792277655863158, 0.10111775515320476, 0.10317795646624528, 0.09100557266452036, 0.20297172261965546, 0.1952404474659335, 0.21102067185081474, 0.23540182835478296, 0.24138680578365024, 0.25957648954517043, 0.20117738326101586, 0.20078869079668038, 0.2033695438313794, 0.6044505074481423, 0.6006867607334359, 0.5637976996626466, 0.5563442794251147, 0.537310809148399, 0.5757110878590277, 0.5769388076064417, 0.5127973162338062, 0.5395421273934828, 0.10162370082767125, 0.10791622091722142, 0.08408663390940596, 0.09500877419228815, 0.08774036714561462, 0.0911194347260258, 0.09200797014788309, 0.09517514993792042, 0.10216332359134828, 0.14923560208951947, 0.1498640163970607, 0.13037350800810532, 0.18551570964605968, 0.19177615922069846, 0.15072560835079962, 0.13998645355349304, 0.13910206309836248, 0.16264885047299282, 0.3786878498149836, 0.38873871811302996, 0.3859670181973064, 0.42803859893740337, 0.447857154593738, 0.4097534185002275, 0.5138903120138612, 0.43613349244238486, 0.5102832666823924, 0.2640868439069276, 0.24916205061447283, 0.2710943683923437, 0.26483789960674553, 0.29357152259797803, 0.2380789580682554, 0.31098401304374323, 0.2866877740461966, 0.2926993053568161, 0.18271125421964185, 0.18439033575036867, 0.21518987580070192, 0.19799863792224015, 0.20435801233892148, 0.19021117969813361, 0.18647204469902912, 0.20707224901167898, 0.20289617743514787, 0.19819139371833228, 0.39576918087952284, 0.26383973657433657, 0.2292194957768824, 0.20629130136096607, 0.23121556615526884, 0.3545620365297534, 0.34848082669892233, 0.3898009698597108, 0.6470913428870022, 0.6837378436009706, 0.16020529567800967, 0.19599439927483797, 0.557099976393798, 0.1834469693257954, 0.541794157507526, 0.17809371963869092, 0.6832408594614443, 0.19364380449843588, 0.6338082525114264, 0.19735973680921082, 0.4981580221389258, 0.33235530782238254, 0.23323941103311985, 0.20612272342359161, 0.20122991240998556, 0.20254356447795085, 0.1940893768499864, 0.18112717342300166, 0.1863762372044614, 0.17014287136738826, 0.1978599781167385, 0.1830836228603766, 0.19080164737633165, 0.18728816742638577, 0.18344753689117255, 0.08283031404257746, 0.07771031668578232, 0.06429856847773296, 0.07504245458984171, 0.08790094518234914, 0.0802961445249557, 0.083923042687712, 0.07482723240436995, 0.07309108535219999]}, "mutation_prompt": null}
{"id": "90ad3c37-0994-447b-8829-1ad53f87649e", "solution": "import numpy as np\n\nclass QuantumInspiredDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _quantum_superposition(self, population, best_individual):\n        phase_shift = self.learning_rate * np.random.randn(self.dim)\n        quantum_states = np.exp(1j * phase_shift)\n        quantum_population = population + np.real(quantum_states) * (best_individual - population)\n        return np.clip(quantum_population.real, self.lb, self.ub)\n\n    def _orthogonal_exploration(self, population):\n        orthogonal_population = np.zeros_like(population)\n        for i in range(self.dim):\n            permutation = np.random.permutation(self.dim)\n            orthogonal_population[:, i] = population[:, permutation[i]]\n        return orthogonal_population\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            quantum_population = self._quantum_superposition(population, best_individual)\n            orthogonal_population = self._orthogonal_exploration(quantum_population)\n            combined_population = np.vstack((population, orthogonal_population))\n            combined_fitness = np.apply_along_axis(func, 1, combined_population)\n            evaluations += combined_population.shape[0]\n\n            best_combined_idx = np.argmin(combined_fitness)\n            if combined_fitness[best_combined_idx] < best_fitness:\n                best_individual = combined_population[best_combined_idx]\n                best_fitness = combined_fitness[best_combined_idx]\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "QuantumInspiredDE", "description": "Hybrid Quantum-Inspired DE with Orthogonal Exploration integrates quantum-inspired superposition for diverse exploration and orthogonal learning for efficient convergence.", "configspace": "", "generation": 48, "fitness": 0.1662462013862211, "feedback": "The algorithm QuantumInspiredDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {"aucs": [0.4504572209342478, 0.31548100649246325, 0.473883632913634, 0.40976205081944894, 0.3888022135745792, 0.3925942028887729, 0.4426499001317813, 0.39428412817453273, 0.4447228040685296, 0.17139486688062466, 0.19777313598158175, 0.1621361792732472, 0.166620192836889, 0.1513669000788319, 0.16403144747221554, 0.1484562977973466, 0.17362325198943795, 0.14969753980184708, 0.06557240715065127, 0.08540545399771693, 0.08812214168046173, 0.07515310076902915, 0.08305199844690048, 0.08819979461923066, 0.0673108914450693, 0.07039100591218594, 0.08425056738694747, 0.06852537153031713, 0.06869053599407271, 0.07165288864253871, 0.07207551158509617, 0.06218201652904409, 0.06272253780301196, 0.07066661164776344, 0.05171504828880147, 0.06279194402573007, 0.8726399381990833, 0.9363064538799577, 0.8549015145690283, 0.903386393632364, 0.9017853083415361, 0.9570640361891645, 0.9274922655830657, 0.8936308227940088, 0.8861268639745168, 0.1280458093489062, 0.160034394425975, 0.10528703674005879, 0.13510850076892056, 0.12764377724368314, 0.1610863620999864, 0.14504727360141356, 0.1720029917600634, 0.1244064942498826, 0.21438887738883128, 0.22474566916670524, 0.1814333333007755, 0.2519076044930678, 0.1799076202310974, 0.18423807894987432, 0.21279156115206765, 0.17628320057306124, 0.19159055274545478, 0.08671469941485754, 0.08314429459565964, 0.0956246369285233, 0.08569581871740628, 0.10505331679570973, 0.060369683241244476, 0.1035401992641648, 0.06196309022652369, 0.08831259812633652, 0.07471821574784698, 0.03903564967491224, 0.05083206512689864, 0.11348062401068693, 0.08709112525145823, 0.08209930201075955, 0.06224909607074003, 0.0910244305696537, 0.06696718065704499, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0012525586287156498, 0.013293188894486274, 9.999999999998899e-05, 0.01778980137163888, 0.0011687028701317104, 0.00027838320471595956, 0.052202373118453216, 0.05662732348584465, 0.05794752289645255, 0.038344230229441556, 0.03786734936513425, 0.05846758216435688, 0.11420098443126858, 0.05136089609430017, 0.0648774195903139, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.041123986391101375, 0.04019241381402994, 0.04453614742734624, 0.06393370437870793, 0.04670165517741953, 0.04991732038882968, 0.06237776513268034, 0.06044632027011099, 0.0642449958053789, 0.3338138100299366, 0.33479267454688566, 0.35305366090662915, 0.3457485793224856, 0.310288542344333, 0.31393051051530274, 0.3402384238954731, 0.3437470052473952, 0.3378972013971615, 0.07027278978850138, 0.06556925878797992, 0.07569187304333258, 0.0846944003828668, 0.05903296289665283, 0.06641770299660588, 0.054247440060974816, 0.06608695759736471, 0.06866223199933685, 0.11395113040210003, 0.14433372514341714, 0.12123869967527989, 0.15147078465593988, 0.10852972522114013, 0.11391055168784092, 0.1225565771117465, 0.11563186447040041, 0.14110614552616518, 0.20882149764946856, 0.19902806740522516, 0.2093173915109655, 0.19331279071296725, 0.21488053097231374, 0.1925794745253161, 0.21683407393791942, 0.22684031107439473, 0.20508434519784668, 0.14449739358149927, 0.15933202479706232, 0.1416606282146935, 0.12278597580220774, 0.11997085530832208, 0.13828114332249952, 0.16677062136418352, 0.14427515832988824, 0.16686857907494324, 0.2000002919390519, 0.1672523021635276, 0.21016665588657402, 0.15336600813358203, 0.15455769433965794, 0.19229857441351983, 0.16916314750429973, 0.1838257862044923, 0.17720207842012936, 0.15500299016851626, 0.15799065093624975, 0.19102880126297306, 0.16006949271645576, 0.1687851060217972, 0.17197438697518086, 0.17584936722457478, 0.1440688021873655, 0.14282285634485092, 0.14956897791954016, 0.12600948729510708, 0.11975903903118068, 0.154645047420501, 0.1510022178168542, 0.13773185484222628, 0.1507453027909803, 0.1619585984031734, 0.13436213758401316, 0.15651730698852007, 0.15519361402079723, 0.12298786930164696, 0.113284094932253, 0.11259698797572726, 0.16071386862608505, 0.1855674027638875, 0.189242307966213, 0.17375055839176634, 0.16393468339751982, 0.17620234236860666, 0.17014779033882765, 0.18177178825292284, 0.1768425436017116, 0.1628262367705141, 0.18187447561289394, 0.16868059670004387, 0.17366159640514722, 0.05588290641957905, 0.04601953659610358, 0.05847843304893141, 0.05828051571586579, 0.06254368354849049, 0.05745193797672876, 0.06531896208016408, 0.056236464830585864, 0.05003905988246804]}, "mutation_prompt": null}
{"id": "eaa6151b-4f46-4c2c-bffd-24369d11ecf5", "solution": "import numpy as np\n\nclass ImprovedAdaptiveDELS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n            self.learning_rate = np.clip(self.learning_rate + 0.01 * adjustment, 0.01, 0.1)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6  # Regularization\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "ImprovedAdaptiveDELS", "description": "Enhanced AdaptiveDELS with stochastic covariance adaptation, dynamic population resizing, and adaptive learning for improved convergence and diversity.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {"aucs": [0.7532020890277368, 0.7403587836866848, 0.7499437858299032, 0.7691326695389058, 0.7527645747851255, 0.7520654204339231, 0.7771984034625594, 0.756004767155964, 0.7370725184462191, 0.6426955210723941, 0.6463555933450049, 0.633121279862906, 0.6413495572357909, 0.6352581741456758, 0.6486003230218463, 0.6529515686019043, 0.6616387077643403, 0.6491944122397993, 0.4292586571506902, 0.15850389611231108, 0.4599863566685296, 0.38191600774212087, 0.39790038326124566, 0.29500009153423956, 0.4249259770623255, 0.3224207868600303, 0.24146585676021382, 0.21499364013544808, 0.117288938563891, 0.12512022895158337, 0.33606002151527314, 0.2888012194090681, 0.11433822583709807, 0.2914347583419632, 0.12138100897266646, 0.13123457865119248, 0.9478370984349623, 0.9609245984026947, 0.9376577291215369, 0.9845820504826238, 0.976461371438196, 0.9373158032375705, 0.9279689087902091, 0.9573395746330357, 0.9538771113733663, 0.5253692842705714, 0.5459500974567755, 0.3669980137745228, 0.5166170703283723, 0.3751935388523999, 0.5094432191090205, 0.4334791327338766, 0.4089263284816058, 0.3106702852205945, 0.6558831737345783, 0.6174526460497356, 0.619501346254409, 0.666840677784478, 0.6684241024835199, 0.6440490311789498, 0.6841223081689207, 0.6791137793171813, 0.6798732923011119, 0.15761076573818777, 0.16852955310079054, 0.1545806917550815, 0.13885643422898197, 0.18215960558450717, 0.14904376318594026, 0.16994903720892307, 0.16066248187779897, 0.20623148296096194, 0.11131452320103052, 0.1357524894967297, 0.16835050367059268, 0.17119601114091165, 0.1732980359022246, 0.1474727971751303, 0.1639786652992985, 0.1603903971754096, 0.13140756481542815, 0.19790669489886137, 0.10916180134404918, 0.09415549326187245, 0.12949205167828282, 0.057629284318532537, 0.1450255092104017, 0.23000752092310717, 0.1069885980075862, 0.14922065311355692, 0.21076493430930876, 0.2284261486610073, 0.2733752356299586, 0.25420191219714083, 0.13631097505331968, 0.24373798557853388, 0.2822668525698119, 0.36912469381908364, 0.31176740323972285, 0.07448380282233957, 0.08510378838464894, 0.049454283520584785, 0.03896482965383985, 0.09177742771300257, 0.10792277655863158, 0.10111775515320476, 0.10317795646624528, 0.09100557266452036, 0.20297172261965546, 0.1952404474659335, 0.21102067185081474, 0.23540182835478296, 0.24138680578365024, 0.25957648954517043, 0.20117738326101586, 0.20078869079668038, 0.2033695438313794, 0.6044505074481423, 0.6006867607334359, 0.5637976996626466, 0.5563442794251147, 0.537310809148399, 0.5757110878590277, 0.5769388076064417, 0.5127973162338062, 0.5395421273934828, 0.10162370082767125, 0.10791622091722142, 0.08408663390940596, 0.09500877419228815, 0.08774036714561462, 0.0911194347260258, 0.09200797014788309, 0.09517514993792042, 0.10216332359134828, 0.14923560208951947, 0.1498640163970607, 0.13037350800810532, 0.18551570964605968, 0.19177615922069846, 0.15072560835079962, 0.13998645355349304, 0.13910206309836248, 0.16264885047299282, 0.3786878498149836, 0.38873871811302996, 0.3859670181973064, 0.42803859893740337, 0.447857154593738, 0.4097534185002275, 0.5138903120138612, 0.43613349244238486, 0.5102832666823924, 0.2640868439069276, 0.24916205061447283, 0.2710943683923437, 0.26483789960674553, 0.29357152259797803, 0.2380789580682554, 0.31098401304374323, 0.2866877740461966, 0.2926993053568161, 0.18271125421964185, 0.18439033575036867, 0.21518987580070192, 0.19799863792224015, 0.20435801233892148, 0.19021117969813361, 0.18647204469902912, 0.20707224901167898, 0.20289617743514787, 0.19819139371833228, 0.39576918087952284, 0.26383973657433657, 0.2292194957768824, 0.20629130136096607, 0.23121556615526884, 0.3545620365297534, 0.34848082669892233, 0.3898009698597108, 0.6470913428870022, 0.6837378436009706, 0.16020529567800967, 0.19599439927483797, 0.557099976393798, 0.1834469693257954, 0.541794157507526, 0.17809371963869092, 0.6832408594614443, 0.19364380449843588, 0.6338082525114264, 0.19735973680921082, 0.4981580221389258, 0.33235530782238254, 0.23323941103311985, 0.20612272342359161, 0.20122991240998556, 0.20254356447795085, 0.1940893768499864, 0.18112717342300166, 0.1863762372044614, 0.17014287136738826, 0.1978599781167385, 0.1830836228603766, 0.19080164737633165, 0.18728816742638577, 0.18344753689117255, 0.08283031404257746, 0.07771031668578232, 0.06429856847773296, 0.07504245458984171, 0.08790094518234914, 0.0802961445249557, 0.083923042687712, 0.07482723240436995, 0.07309108535219999]}, "mutation_prompt": null}
{"id": "90de0d24-be52-4d7d-a1ed-38483c1fbc26", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELSWithChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        # Using a chaotic map for better exploration at initialization\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)  # Initial chaotic seed\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)  # Logistic map\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELSWithChaos", "description": "A novel metaheuristic algorithm that employs enhanced adaptive decomposition strategies, dynamic adjustment of mutation and crossover operations, and chaotic sequence-based population initialization for robust convergence and exploration.", "configspace": "", "generation": 50, "fitness": 0.3376049550485877, "feedback": "The algorithm EnhancedAdaptiveDELSWithChaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "0c4169b8-1439-4500-a46f-6c093c831345", "metadata": {"aucs": [0.7334351479550453, 0.7435708809469002, 0.7372650220321237, 0.762754469010552, 0.7515117308343593, 0.7742680251889208, 0.7520216716607129, 0.7562744438417744, 0.7649522969884777, 0.6632959650700896, 0.6424708640805163, 0.6472865747346207, 0.6146052702704017, 0.6493691650498243, 0.6624576076048914, 0.6353631543804803, 0.6436140206455667, 0.6483294649176281, 0.41255379855637053, 0.3949857262705072, 0.3076964303845341, 0.33781670036195977, 0.35621985679724966, 0.33294577708002226, 0.14415280586942858, 0.3341446405843652, 0.2639506116672108, 0.13639890376822372, 0.22642503611876164, 0.24681878665395218, 0.38769983538373776, 0.3950509584809476, 0.13254804931575437, 0.2754803339501555, 0.13585379574160128, 0.11808307991941014, 0.9336458472785444, 0.9246956094633213, 0.9411337065114066, 0.9656648142283406, 0.9549846872110821, 0.9579686829218218, 0.9787421231659256, 0.901706749833707, 0.9196102460368236, 0.3971020077154406, 0.5124201153922774, 0.48152707923804894, 0.5031048992106628, 0.5519824322366617, 0.5187054014219232, 0.5106319368536852, 0.5332266052155872, 0.4939188410080759, 0.589164586589423, 0.5520630452863274, 0.6528332299691562, 0.5967418030141005, 0.6847556134670556, 0.6353739942427409, 0.6984511170484301, 0.6725633938937018, 0.6852956734907085, 0.14471636520180964, 0.1360248117539934, 0.1414902665590092, 0.15324357285987766, 0.16135333187627388, 0.1581110474833235, 0.24839534060703916, 0.16261286800882568, 0.20870754369216837, 0.11104486394779689, 0.14767964668101408, 0.17497241078735604, 0.1361466818825069, 0.14735592546377863, 0.1689660953485843, 0.15700223343253505, 0.14125051732996108, 0.1469589948468525, 0.15924841547124124, 0.1980743270783073, 0.18018055280327938, 0.18090813115627924, 0.07740059934445687, 0.09186140068377158, 0.18375116887031495, 0.18774139224662267, 0.1581541094786879, 0.34363052325012333, 0.3021655669984483, 0.298032380580745, 0.21034732118394217, 0.2865600660715355, 0.2307258410830394, 0.33363240375184955, 0.30762616889804517, 0.3280972754558896, 0.08170113555405334, 0.07714121486118097, 0.09671581888610015, 0.09777804195025253, 0.07327325366795956, 0.09672945662754884, 0.11690149656202142, 0.12510073058871607, 0.11578240226682845, 0.22275455122995014, 0.18774893416606908, 0.19162560941835927, 0.21408451697482822, 0.22191525032800274, 0.22270835968769065, 0.19686478765174942, 0.20185127777453138, 0.19763763200443363, 0.5294144355376335, 0.5967663179886331, 0.5399747479295018, 0.5186740007742533, 0.6038846551278994, 0.5681687622761118, 0.5823527447043452, 0.5976039120416191, 0.6065541858746616, 0.09743246346006695, 0.08856866992861956, 0.11123276283627037, 0.09063645268946241, 0.0864097877428498, 0.0910680525493015, 0.0865558907881161, 0.10535702753857423, 0.09795184426412618, 0.2550347744452899, 0.1845863561836132, 0.14041416639573712, 0.20664177301748654, 0.23339905172269582, 0.18903472461412685, 0.16814117914008397, 0.14986837656861984, 0.1574167214705312, 0.3935863863911916, 0.4124249075332781, 0.4069359670913125, 0.39035502412511924, 0.39229538807339304, 0.3844146980409835, 0.43666946237603166, 0.45813268607357027, 0.4715559468221989, 0.2569814892084751, 0.24757686001313295, 0.2683541323875781, 0.2635009433539923, 0.28272947997479203, 0.2891164323587303, 0.31803319217653814, 0.32899109968852136, 0.350951022317023, 0.18989462203528673, 0.17727703485539792, 0.19086904529536586, 0.1739126327548518, 0.16094958247006108, 0.1986116137618228, 0.19335191231266768, 0.21193971617629914, 0.2005313684689467, 0.2602964404290985, 0.30135207446634993, 0.39112952792215594, 0.22879687233768142, 0.3690324618733576, 0.29361155839303055, 0.39581770448749987, 0.29193112011116507, 0.3037158670627693, 0.6390262802985416, 0.701884229601073, 0.1656416995386074, 0.17881339673465513, 0.1608804690476654, 0.17679240802659657, 0.17718597532156988, 0.17639367728644795, 0.5899882363806122, 0.20364744611310348, 0.4833677106076767, 0.19900414228583885, 0.5813797812628521, 0.4179763479415374, 0.18671085227116668, 0.20691424745449272, 0.20701647229566134, 0.5535754652524423, 0.1831979196573167, 0.18061020932606675, 0.1843182548448632, 0.1944085927057687, 0.20894719637090475, 0.21616062486840326, 0.19483696253794103, 0.21169173960920729, 0.1787084997656193, 0.07807211537395253, 0.0780414427485221, 0.07433363164054041, 0.0766163601201375, 0.07349651790034017, 0.07312996585238163, 0.07171233421869061, 0.0738391236807604, 0.08341007429146197]}, "mutation_prompt": null}
{"id": "38a907a9-3c2c-467e-a4eb-23a4f932874f", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELSWithChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        # Using a chaotic map for better exploration at initialization\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)  # Initial chaotic seed\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)  # Logistic map\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELSWithChaos", "description": "A novel metaheuristic algorithm that employs enhanced adaptive decomposition strategies, dynamic adjustment of mutation and crossover operations, and chaotic sequence-based population initialization for robust convergence and exploration.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "90de0d24-be52-4d7d-a1ed-38483c1fbc26", "metadata": {"aucs": [0.7334351479550453, 0.7435708809469002, 0.7372650220321237, 0.762754469010552, 0.7515117308343593, 0.7742680251889208, 0.7520216716607129, 0.7562744438417744, 0.7649522969884777, 0.6632959650700896, 0.6424708640805163, 0.6472865747346207, 0.6146052702704017, 0.6493691650498243, 0.6624576076048914, 0.6353631543804803, 0.6436140206455667, 0.6483294649176281, 0.41255379855637053, 0.3949857262705072, 0.3076964303845341, 0.33781670036195977, 0.35621985679724966, 0.33294577708002226, 0.14415280586942858, 0.3341446405843652, 0.2639506116672108, 0.13639890376822372, 0.22642503611876164, 0.24681878665395218, 0.38769983538373776, 0.3950509584809476, 0.13254804931575437, 0.2754803339501555, 0.13585379574160128, 0.11808307991941014, 0.9336458472785444, 0.9246956094633213, 0.9411337065114066, 0.9656648142283406, 0.9549846872110821, 0.9579686829218218, 0.9787421231659256, 0.901706749833707, 0.9196102460368236, 0.3971020077154406, 0.5124201153922774, 0.48152707923804894, 0.5031048992106628, 0.5519824322366617, 0.5187054014219232, 0.5106319368536852, 0.5332266052155872, 0.4939188410080759, 0.589164586589423, 0.5520630452863274, 0.6528332299691562, 0.5967418030141005, 0.6847556134670556, 0.6353739942427409, 0.6984511170484301, 0.6725633938937018, 0.6852956734907085, 0.14471636520180964, 0.1360248117539934, 0.1414902665590092, 0.15324357285987766, 0.16135333187627388, 0.1581110474833235, 0.24839534060703916, 0.16261286800882568, 0.20870754369216837, 0.11104486394779689, 0.14767964668101408, 0.17497241078735604, 0.1361466818825069, 0.14735592546377863, 0.1689660953485843, 0.15700223343253505, 0.14125051732996108, 0.1469589948468525, 0.15924841547124124, 0.1980743270783073, 0.18018055280327938, 0.18090813115627924, 0.07740059934445687, 0.09186140068377158, 0.18375116887031495, 0.18774139224662267, 0.1581541094786879, 0.34363052325012333, 0.3021655669984483, 0.298032380580745, 0.21034732118394217, 0.2865600660715355, 0.2307258410830394, 0.33363240375184955, 0.30762616889804517, 0.3280972754558896, 0.08170113555405334, 0.07714121486118097, 0.09671581888610015, 0.09777804195025253, 0.07327325366795956, 0.09672945662754884, 0.11690149656202142, 0.12510073058871607, 0.11578240226682845, 0.22275455122995014, 0.18774893416606908, 0.19162560941835927, 0.21408451697482822, 0.22191525032800274, 0.22270835968769065, 0.19686478765174942, 0.20185127777453138, 0.19763763200443363, 0.5294144355376335, 0.5967663179886331, 0.5399747479295018, 0.5186740007742533, 0.6038846551278994, 0.5681687622761118, 0.5823527447043452, 0.5976039120416191, 0.6065541858746616, 0.09743246346006695, 0.08856866992861956, 0.11123276283627037, 0.09063645268946241, 0.0864097877428498, 0.0910680525493015, 0.0865558907881161, 0.10535702753857423, 0.09795184426412618, 0.2550347744452899, 0.1845863561836132, 0.14041416639573712, 0.20664177301748654, 0.23339905172269582, 0.18903472461412685, 0.16814117914008397, 0.14986837656861984, 0.1574167214705312, 0.3935863863911916, 0.4124249075332781, 0.4069359670913125, 0.39035502412511924, 0.39229538807339304, 0.3844146980409835, 0.43666946237603166, 0.45813268607357027, 0.4715559468221989, 0.2569814892084751, 0.24757686001313295, 0.2683541323875781, 0.2635009433539923, 0.28272947997479203, 0.2891164323587303, 0.31803319217653814, 0.32899109968852136, 0.350951022317023, 0.18989462203528673, 0.17727703485539792, 0.19086904529536586, 0.1739126327548518, 0.16094958247006108, 0.1986116137618228, 0.19335191231266768, 0.21193971617629914, 0.2005313684689467, 0.2602964404290985, 0.30135207446634993, 0.39112952792215594, 0.22879687233768142, 0.3690324618733576, 0.29361155839303055, 0.39581770448749987, 0.29193112011116507, 0.3037158670627693, 0.6390262802985416, 0.701884229601073, 0.1656416995386074, 0.17881339673465513, 0.1608804690476654, 0.17679240802659657, 0.17718597532156988, 0.17639367728644795, 0.5899882363806122, 0.20364744611310348, 0.4833677106076767, 0.19900414228583885, 0.5813797812628521, 0.4179763479415374, 0.18671085227116668, 0.20691424745449272, 0.20701647229566134, 0.5535754652524423, 0.1831979196573167, 0.18061020932606675, 0.1843182548448632, 0.1944085927057687, 0.20894719637090475, 0.21616062486840326, 0.19483696253794103, 0.21169173960920729, 0.1787084997656193, 0.07807211537395253, 0.0780414427485221, 0.07433363164054041, 0.0766163601201375, 0.07349651790034017, 0.07312996585238163, 0.07171233421869061, 0.0738391236807604, 0.08341007429146197]}, "mutation_prompt": null}
{"id": "fc00a289-913b-4f6c-8893-adefef599610", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELSWithDynamicChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        # Using a dynamic chaotic map for better exploration at initialization\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)  # Initial chaotic seed\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)  # Logistic map\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _dynamic_bounds(self, evaluations):\n        # Dynamically adjust the boundaries based on evaluation progress\n        dynamic_range = 5.0 * (1 - evaluations / self.budget)\n        self.lb = -dynamic_range\n        self.ub = dynamic_range\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            self._dynamic_bounds(evaluations)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELSWithDynamicChaos", "description": "An enhanced differential evolution algorithm utilizing adaptive parameter control with a novel chaotic dynamic boundary adjustment for improved exploration and exploitation balance.", "configspace": "", "generation": 52, "fitness": 0.20478354320841882, "feedback": "The algorithm EnhancedAdaptiveDELSWithDynamicChaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.14.", "error": "", "parent_id": "90de0d24-be52-4d7d-a1ed-38483c1fbc26", "metadata": {"aucs": [0.7515795916733244, 0.7443780354592641, 0.7330922658111805, 0.4062646894088823, 0.3866069857508815, 0.3860492101299756, 0.46865288712972886, 0.39939877076846786, 0.4075595261551247, 0.31557231322716983, 0.3473731867125339, 0.31807848125058, 0.6482344747956279, 0.6441330358919295, 0.6290280843686488, 0.2749635531541449, 0.3211466237522351, 0.2397637329635135, 0.1282764724633113, 0.17665884270092325, 0.13523754738018723, 0.1168641233966744, 0.12523796803620413, 0.1368744980101706, 0.09579983270582582, 0.09453866224077923, 0.1021827321043578, 0.10500335456854792, 0.11048699005800044, 0.12100614472420002, 0.11659504811688981, 0.11063942538061367, 0.10680400674359858, 0.11055367924852288, 0.09977138260052887, 0.10266759605381726, 0.1341940724387385, 0.11622724598586265, 0.145999549092507, 0.14172503230694855, 0.1416110506788133, 0.1537177772459667, 0.1708463870761754, 0.1296476839431896, 0.12510457960614096, 0.2819141839891237, 0.2517718332765214, 0.26093187113616656, 0.15713823663151838, 0.18826438436935655, 0.1821259118485209, 0.24421399845756864, 0.23608954133553106, 0.24404345498359203, 0.3230099409971362, 0.30654211118577745, 0.5893455497088692, 0.23936402157984693, 0.23874318593568522, 0.24362661705260857, 0.27468668667214446, 0.28722303256633097, 0.301769346867961, 0.1681458967285504, 0.14409524246437744, 0.12417134505171867, 0.1694893566450112, 0.13812738359006704, 0.18264660123897225, 0.146341033629517, 0.16295958773084918, 0.15282143946515392, 0.18462328367153635, 0.21373560802945557, 0.17253525722429963, 0.16111970237901718, 0.15101573278273717, 0.16290498790561592, 0.1427905662345731, 0.14996373249789396, 0.1493084609980484, 0.030324977275206777, 0.04571102162155016, 0.0012073621439647741, 0.0527343427156064, 0.008087857724512815, 0.00896539104569094, 0.06378156090373888, 0.08058693117437687, 0.08459980700502179, 0.12293117631419626, 0.19112792438241144, 0.12738116365606367, 0.17880389365063387, 0.13432951693755202, 0.13763039047912984, 0.2199718170187358, 0.17667189947697248, 0.21979123077954632, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11254987772077107, 0.12025897870372648, 0.0903476579129463, 0.10915972640933214, 0.10189899677600811, 0.09767542167397492, 0.07802128819501519, 0.08036079020339926, 0.07638934789133833, 0.5053424487249666, 0.4682497109565549, 0.46873699247772693, 0.3258524007800879, 0.43616348594263854, 0.3877051866160438, 0.5325406613634296, 0.5303905769205932, 0.5089383120862706, 0.08881147025954617, 0.09268699047915763, 0.10070281172756057, 0.08311719853505439, 0.10212649920509431, 0.090704108904755, 0.0846580913331787, 0.10403940100861087, 0.08706284598815928, 0.1817441516969699, 0.15920463859765477, 0.13151460676670523, 0.14954387780569955, 0.14176254172557223, 0.13635055643778904, 0.14871950913024956, 0.15226393421664475, 0.13900448413320465, 0.2809805414238611, 0.2882481760417622, 0.2755707091944365, 0.3766826491814992, 0.3654135801293682, 0.3266093702109043, 0.27076836963207174, 0.28289906618942395, 0.2587215445144646, 0.17524273373405397, 0.2096359524676894, 0.20768873711904634, 0.24674347604160818, 0.24815868058418322, 0.21824746926182037, 0.18909396473708684, 0.21129147862012942, 0.19326434261156933, 0.19699436706848117, 0.20094151712771446, 0.2028722202424077, 0.19897164830320846, 0.18272354375497046, 0.21864008047594075, 0.20170868761569105, 0.1872674765194814, 0.19445494340969527, 0.30343415597369194, 0.2117888087016203, 0.19743359502082103, 0.19362087509449022, 0.17573948173316, 0.25921989789028577, 0.16978073128153626, 0.24913553631541074, 0.25974235284359726, 0.3170428824706144, 0.3599532452031573, 0.17682092923769377, 0.17929502377851714, 0.16510338732395935, 0.16472013887640657, 0.1527080261730045, 0.7118275724409395, 0.16774274605015693, 0.19649516727171612, 0.19355316850142312, 0.28068200923906017, 0.18796354509211444, 0.4539291105890423, 0.19384631076877445, 0.18652582798613015, 0.1766304287832312, 0.5534045044999854, 0.18519093401746767, 0.19644586951684573, 0.1851634914826561, 0.1944085927057687, 0.18246006489823852, 0.19929540639528365, 0.19127020933561478, 0.1828497059783527, 0.18193838148753605, 0.07725990841703556, 0.08088465496896702, 0.07799624235479519, 0.07120829274439389, 0.07188867792838027, 0.06810124291499886, 0.07964084374244318, 0.08094057403255517, 0.08444335096031497]}, "mutation_prompt": null}
{"id": "1a960f76-3802-49f6-86c5-66d965d7c0cd", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELSWithChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        # Using a chaotic map for better exploration at initialization\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)  # Initial chaotic seed\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)  # Logistic map\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELSWithChaos", "description": "A novel metaheuristic algorithm that employs enhanced adaptive decomposition strategies, dynamic adjustment of mutation and crossover operations, and chaotic sequence-based population initialization for robust convergence and exploration.", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "90de0d24-be52-4d7d-a1ed-38483c1fbc26", "metadata": {"aucs": [0.7334351479550453, 0.7435708809469002, 0.7372650220321237, 0.762754469010552, 0.7515117308343593, 0.7742680251889208, 0.7520216716607129, 0.7562744438417744, 0.7649522969884777, 0.6632959650700896, 0.6424708640805163, 0.6472865747346207, 0.6146052702704017, 0.6493691650498243, 0.6624576076048914, 0.6353631543804803, 0.6436140206455667, 0.6483294649176281, 0.41255379855637053, 0.3949857262705072, 0.3076964303845341, 0.33781670036195977, 0.35621985679724966, 0.33294577708002226, 0.14415280586942858, 0.3341446405843652, 0.2639506116672108, 0.13639890376822372, 0.22642503611876164, 0.24681878665395218, 0.38769983538373776, 0.3950509584809476, 0.13254804931575437, 0.2754803339501555, 0.13585379574160128, 0.11808307991941014, 0.9336458472785444, 0.9246956094633213, 0.9411337065114066, 0.9656648142283406, 0.9549846872110821, 0.9579686829218218, 0.9787421231659256, 0.901706749833707, 0.9196102460368236, 0.3971020077154406, 0.5124201153922774, 0.48152707923804894, 0.5031048992106628, 0.5519824322366617, 0.5187054014219232, 0.5106319368536852, 0.5332266052155872, 0.4939188410080759, 0.589164586589423, 0.5520630452863274, 0.6528332299691562, 0.5967418030141005, 0.6847556134670556, 0.6353739942427409, 0.6984511170484301, 0.6725633938937018, 0.6852956734907085, 0.14471636520180964, 0.1360248117539934, 0.1414902665590092, 0.15324357285987766, 0.16135333187627388, 0.1581110474833235, 0.24839534060703916, 0.16261286800882568, 0.20870754369216837, 0.11104486394779689, 0.14767964668101408, 0.17497241078735604, 0.1361466818825069, 0.14735592546377863, 0.1689660953485843, 0.15700223343253505, 0.14125051732996108, 0.1469589948468525, 0.15924841547124124, 0.1980743270783073, 0.18018055280327938, 0.18090813115627924, 0.07740059934445687, 0.09186140068377158, 0.18375116887031495, 0.18774139224662267, 0.1581541094786879, 0.34363052325012333, 0.3021655669984483, 0.298032380580745, 0.21034732118394217, 0.2865600660715355, 0.2307258410830394, 0.33363240375184955, 0.30762616889804517, 0.3280972754558896, 0.08170113555405334, 0.07714121486118097, 0.09671581888610015, 0.09777804195025253, 0.07327325366795956, 0.09672945662754884, 0.11690149656202142, 0.12510073058871607, 0.11578240226682845, 0.22275455122995014, 0.18774893416606908, 0.19162560941835927, 0.21408451697482822, 0.22191525032800274, 0.22270835968769065, 0.19686478765174942, 0.20185127777453138, 0.19763763200443363, 0.5294144355376335, 0.5967663179886331, 0.5399747479295018, 0.5186740007742533, 0.6038846551278994, 0.5681687622761118, 0.5823527447043452, 0.5976039120416191, 0.6065541858746616, 0.09743246346006695, 0.08856866992861956, 0.11123276283627037, 0.09063645268946241, 0.0864097877428498, 0.0910680525493015, 0.0865558907881161, 0.10535702753857423, 0.09795184426412618, 0.2550347744452899, 0.1845863561836132, 0.14041416639573712, 0.20664177301748654, 0.23339905172269582, 0.18903472461412685, 0.16814117914008397, 0.14986837656861984, 0.1574167214705312, 0.3935863863911916, 0.4124249075332781, 0.4069359670913125, 0.39035502412511924, 0.39229538807339304, 0.3844146980409835, 0.43666946237603166, 0.45813268607357027, 0.4715559468221989, 0.2569814892084751, 0.24757686001313295, 0.2683541323875781, 0.2635009433539923, 0.28272947997479203, 0.2891164323587303, 0.31803319217653814, 0.32899109968852136, 0.350951022317023, 0.18989462203528673, 0.17727703485539792, 0.19086904529536586, 0.1739126327548518, 0.16094958247006108, 0.1986116137618228, 0.19335191231266768, 0.21193971617629914, 0.2005313684689467, 0.2602964404290985, 0.30135207446634993, 0.39112952792215594, 0.22879687233768142, 0.3690324618733576, 0.29361155839303055, 0.39581770448749987, 0.29193112011116507, 0.3037158670627693, 0.6390262802985416, 0.701884229601073, 0.1656416995386074, 0.17881339673465513, 0.1608804690476654, 0.17679240802659657, 0.17718597532156988, 0.17639367728644795, 0.5899882363806122, 0.20364744611310348, 0.4833677106076767, 0.19900414228583885, 0.5813797812628521, 0.4179763479415374, 0.18671085227116668, 0.20691424745449272, 0.20701647229566134, 0.5535754652524423, 0.1831979196573167, 0.18061020932606675, 0.1843182548448632, 0.1944085927057687, 0.20894719637090475, 0.21616062486840326, 0.19483696253794103, 0.21169173960920729, 0.1787084997656193, 0.07807211537395253, 0.0780414427485221, 0.07433363164054041, 0.0766163601201375, 0.07349651790034017, 0.07312996585238163, 0.07171233421869061, 0.0738391236807604, 0.08341007429146197]}, "mutation_prompt": null}
{"id": "c001e0c4-e119-4851-91a6-2fc225c40af6", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELSWithChaos:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELSWithChaos", "description": "An enhanced differential evolution algorithm with adaptive mutation and crossover rates, chaotic initialization, and dynamic covariance adaptation, improving exploration and convergence balance.", "configspace": "", "generation": 54, "fitness": 0.3376049550485877, "feedback": "The algorithm EnhancedAdaptiveDELSWithChaos got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "90de0d24-be52-4d7d-a1ed-38483c1fbc26", "metadata": {"aucs": [0.7334351479550453, 0.7435708809469002, 0.7372650220321237, 0.762754469010552, 0.7515117308343593, 0.7742680251889208, 0.7520216716607129, 0.7562744438417744, 0.7649522969884777, 0.6632959650700896, 0.6424708640805163, 0.6472865747346207, 0.6146052702704017, 0.6493691650498243, 0.6624576076048914, 0.6353631543804803, 0.6436140206455667, 0.6483294649176281, 0.41255379855637053, 0.3949857262705072, 0.3076964303845341, 0.33781670036195977, 0.35621985679724966, 0.33294577708002226, 0.14415280586942858, 0.3341446405843652, 0.2639506116672108, 0.13639890376822372, 0.22642503611876164, 0.24681878665395218, 0.38769983538373776, 0.3950509584809476, 0.13254804931575437, 0.2754803339501555, 0.13585379574160128, 0.11808307991941014, 0.9336458472785444, 0.9246956094633213, 0.9411337065114066, 0.9656648142283406, 0.9549846872110821, 0.9579686829218218, 0.9787421231659256, 0.901706749833707, 0.9196102460368236, 0.3971020077154406, 0.5124201153922774, 0.48152707923804894, 0.5031048992106628, 0.5519824322366617, 0.5187054014219232, 0.5106319368536852, 0.5332266052155872, 0.4939188410080759, 0.589164586589423, 0.5520630452863274, 0.6528332299691562, 0.5967418030141005, 0.6847556134670556, 0.6353739942427409, 0.6984511170484301, 0.6725633938937018, 0.6852956734907085, 0.14471636520180964, 0.1360248117539934, 0.1414902665590092, 0.15324357285987766, 0.16135333187627388, 0.1581110474833235, 0.24839534060703916, 0.16261286800882568, 0.20870754369216837, 0.11104486394779689, 0.14767964668101408, 0.17497241078735604, 0.1361466818825069, 0.14735592546377863, 0.1689660953485843, 0.15700223343253505, 0.14125051732996108, 0.1469589948468525, 0.15924841547124124, 0.1980743270783073, 0.18018055280327938, 0.18090813115627924, 0.07740059934445687, 0.09186140068377158, 0.18375116887031495, 0.18774139224662267, 0.1581541094786879, 0.34363052325012333, 0.3021655669984483, 0.298032380580745, 0.21034732118394217, 0.2865600660715355, 0.2307258410830394, 0.33363240375184955, 0.30762616889804517, 0.3280972754558896, 0.08170113555405334, 0.07714121486118097, 0.09671581888610015, 0.09777804195025253, 0.07327325366795956, 0.09672945662754884, 0.11690149656202142, 0.12510073058871607, 0.11578240226682845, 0.22275455122995014, 0.18774893416606908, 0.19162560941835927, 0.21408451697482822, 0.22191525032800274, 0.22270835968769065, 0.19686478765174942, 0.20185127777453138, 0.19763763200443363, 0.5294144355376335, 0.5967663179886331, 0.5399747479295018, 0.5186740007742533, 0.6038846551278994, 0.5681687622761118, 0.5823527447043452, 0.5976039120416191, 0.6065541858746616, 0.09743246346006695, 0.08856866992861956, 0.11123276283627037, 0.09063645268946241, 0.0864097877428498, 0.0910680525493015, 0.0865558907881161, 0.10535702753857423, 0.09795184426412618, 0.2550347744452899, 0.1845863561836132, 0.14041416639573712, 0.20664177301748654, 0.23339905172269582, 0.18903472461412685, 0.16814117914008397, 0.14986837656861984, 0.1574167214705312, 0.3935863863911916, 0.4124249075332781, 0.4069359670913125, 0.39035502412511924, 0.39229538807339304, 0.3844146980409835, 0.43666946237603166, 0.45813268607357027, 0.4715559468221989, 0.2569814892084751, 0.24757686001313295, 0.2683541323875781, 0.2635009433539923, 0.28272947997479203, 0.2891164323587303, 0.31803319217653814, 0.32899109968852136, 0.350951022317023, 0.18989462203528673, 0.17727703485539792, 0.19086904529536586, 0.1739126327548518, 0.16094958247006108, 0.1986116137618228, 0.19335191231266768, 0.21193971617629914, 0.2005313684689467, 0.2602964404290985, 0.30135207446634993, 0.39112952792215594, 0.22879687233768142, 0.3690324618733576, 0.29361155839303055, 0.39581770448749987, 0.29193112011116507, 0.3037158670627693, 0.6390262802985416, 0.701884229601073, 0.1656416995386074, 0.17881339673465513, 0.1608804690476654, 0.17679240802659657, 0.17718597532156988, 0.17639367728644795, 0.5899882363806122, 0.20364744611310348, 0.4833677106076767, 0.19900414228583885, 0.5813797812628521, 0.4179763479415374, 0.18671085227116668, 0.20691424745449272, 0.20701647229566134, 0.5535754652524423, 0.1831979196573167, 0.18061020932606675, 0.1843182548448632, 0.1944085927057687, 0.20894719637090475, 0.21616062486840326, 0.19483696253794103, 0.21169173960920729, 0.1787084997656193, 0.07807211537395253, 0.0780414427485221, 0.07433363164054041, 0.0766163601201375, 0.07349651790034017, 0.07312996585238163, 0.07171233421869061, 0.0738391236807604, 0.08341007429146197]}, "mutation_prompt": null}
{"id": "e154cb62-b68c-4d40-b491-81bc15f98316", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDELSWithChaosRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _hybrid_local_global_search(self, individual, best_individual, centroid):\n        global_step = np.random.multivariate_normal(np.zeros(self.dim), self.covariance_matrix)\n        local_step = np.random.uniform(-0.1, 0.1, self.dim)\n        candidate = individual + global_step + local_step * (best_individual - centroid)\n        return np.clip(candidate, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        adjustment = self.adaptive_factor * (1 - 2 * (fitness > median_fitness))\n        self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n        self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            hybrid_candidate = self._hybrid_local_global_search(best_individual, np.mean(population, axis=0), centroid)\n            hybrid_fitness = func(hybrid_candidate)\n            evaluations += 1\n\n            if hybrid_fitness < best_fitness:\n                best_individual = hybrid_candidate\n                best_fitness = hybrid_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "EnhancedAdaptiveDELSWithChaosRefined", "description": "A refined metaheuristic using enhanced adaptive decomposition, chaotic initialization, and adaptive parameter control with dynamic population resizing and covariance-guided local-global search for improved optimization.", "configspace": "", "generation": 55, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('operands could not be broadcast together with shapes (50,) (5,) ').", "error": "ValueError('operands could not be broadcast together with shapes (50,) (5,) ')", "parent_id": "90de0d24-be52-4d7d-a1ed-38483c1fbc26", "metadata": {}, "mutation_prompt": null}
{"id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 56, "fitness": 0.3420647531138353, "feedback": "The algorithm AdvancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "90de0d24-be52-4d7d-a1ed-38483c1fbc26", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "34a30661-8175-4ca6-b875-521530fe8a43", "solution": "import numpy as np\n\nclass RefinedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n        self.mutation_factors = np.random.uniform(0.5, 1.0, self.population_size)\n        self.crossover_rates = np.random.uniform(0.7, 1.0, self.population_size)\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factors[target_idx] * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant, target_idx):\n        cross_points = np.random.rand(self.dim) < self.crossover_rates[target_idx]\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position, scale):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = scale * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factors[idx] = np.clip(self.mutation_factors[idx] + adjustment, 0.5, 1.0)\n            self.crossover_rates[idx] = np.clip(self.crossover_rates[idx] + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        levy_scale = 0.01\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant, i)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid, levy_scale)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n            levy_scale = np.clip(levy_scale * (1 + 0.5 * (np.random.rand() - 0.5)), 0.005, 0.02)\n\n        return best_individual, best_fitness", "name": "RefinedHybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm utilizing self-adaptive differential evolution and dynamic Lévy flight scaling to enhance convergence speed and accuracy.", "configspace": "", "generation": 57, "fitness": 0.270622613373051, "feedback": "The algorithm RefinedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.20.", "error": "", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.5338410646786753, 0.593293574014498, 0.5858052633581168, 0.622945160867691, 0.5069207459095415, 0.5417713060392293, 0.6069876999149011, 0.5118939934784537, 0.5389249045403512, 0.24223976332726782, 0.2537028974860739, 0.32841062220291783, 0.33279229340155625, 0.3157846263550337, 0.2675787561360806, 0.26003093646925457, 0.23478849666401425, 0.29353452591625906, 0.12676552888213666, 0.11997439898075335, 0.13640656522893535, 0.14680802329594922, 0.12717781933330585, 0.1360805464748488, 0.15759463659252504, 0.14398819589500633, 0.12774051957865684, 0.12159369730560898, 0.1161323954759822, 0.11888019819874585, 0.10562038873604884, 0.10122185089750779, 0.11758022306241511, 0.12687190438091833, 0.12924408739926552, 0.1088465528771323, 0.9339064839701453, 0.9006880586149548, 0.9663154753364805, 0.9638196247240634, 0.9440548371052367, 0.979045743699905, 0.9511623561049867, 0.9555927915389542, 0.9558821309999089, 0.3170567456112795, 0.29865362036440213, 0.276647736731778, 0.32745207815582666, 0.30580423600674234, 0.28900121442720816, 0.27129292301655006, 0.26484958773213896, 0.27440856196454955, 0.31722858872076143, 0.32124567262005943, 0.2999756360598408, 0.6552904700569437, 0.3394779171943346, 0.5931304809794737, 0.6643720477592535, 0.6270426570191616, 0.6352149162331638, 0.3087565147307729, 0.13660862829258547, 0.15766891829710972, 0.1770175027765044, 0.20070007085379327, 0.25386638473632683, 0.28611535340808947, 0.33145571109269234, 0.22755356065930077, 0.07130845974384592, 0.2773711716663134, 0.23634448303244815, 0.29353133154219013, 0.2474891828318534, 0.29188602716365264, 0.13820270086974595, 0.28103382143833366, 0.15059284122754213, 0.09991792258637211, 0.14274539275533538, 0.13698520845528583, 0.18176686727775926, 0.09125740467824817, 0.11732436543679647, 0.20174163277119184, 0.10811793543966064, 0.17613551555642193, 0.2761975878815488, 0.2510774980512547, 0.21957142307144017, 0.18780877108891247, 0.26014418115457605, 0.26078735878406767, 0.289150502820831, 0.22441650448725026, 0.20347223539781545, 0.04357593512026847, 0.030152054163670616, 0.0014771703387895796, 0.017148608050256198, 0.03900040935942939, 0.03210774508831604, 0.018880097866623702, 0.04301428849081934, 0.03738501789409088, 0.13909016613084202, 0.15077823235504328, 0.15937776471524634, 0.1580989940120784, 0.13156567493055105, 0.14933728420773096, 0.15779298500199002, 0.14629980143470767, 0.1551268886243824, 0.4334660735378748, 0.4521484150394697, 0.4295477366902185, 0.4630053289309579, 0.504293884511367, 0.48199825178673306, 0.42273706516466303, 0.5008080081185169, 0.5529728341909153, 0.1376468585762357, 0.11117479950500819, 0.09857299835931921, 0.10218733527830393, 0.10062853240423797, 0.09379594796108381, 0.09829114220456814, 0.1396323214577, 0.10786546593474755, 0.2059325572896411, 0.25031448363305786, 0.22996258510701817, 0.13718093719882907, 0.15161783732446588, 0.17004858773461018, 0.17718493391459156, 0.23391802732162814, 0.22113642004630474, 0.2819980778377338, 0.2978101295181599, 0.28165668797421084, 0.26686600906803715, 0.26432856257857573, 0.248337067429509, 0.26894808276895965, 0.28219406415161485, 0.2932779049348613, 0.23259736804389897, 0.2204425744493066, 0.2191167808485719, 0.23246163289504573, 0.24191768219066812, 0.19198356843260422, 0.2458526823638758, 0.2344608438403737, 0.23943613281739629, 0.18454923155813008, 0.17491719952092522, 0.20766423043335425, 0.18093170363235078, 0.18060399933412719, 0.1805349645635832, 0.20185468538057805, 0.18727199363463876, 0.2105771107564246, 0.18917462802559626, 0.18924696214839942, 0.2593813594944998, 0.19081140730078117, 0.19563552859057676, 0.21330021631081386, 0.20527142568631984, 0.1954271430241057, 0.19259112934793376, 0.38503355987886934, 0.1927907043212419, 0.5030835839395833, 0.35571303648937147, 0.4437241017656567, 0.39543653231094966, 0.7053331188196024, 0.3485727610556625, 0.1876958909743437, 0.20202766486897106, 0.1571405091961957, 0.5446708175205464, 0.4219966694393895, 0.4640881403619467, 0.20715965938168623, 0.20328744369132334, 0.20706976230104845, 0.20743823842152276, 0.1857788612171909, 0.19487331282744214, 0.21600595370581388, 0.1956991464800426, 0.19859600725030135, 0.19610215246971419, 0.22676657596576777, 0.21495400923406116, 0.2072781500404992, 0.08552707209124988, 0.09375261737508267, 0.09096527167938984, 0.08690046015490316, 0.09439145259941395, 0.08776058576641266, 0.09667212389582014, 0.08993439024505656, 0.09404716478786446]}, "mutation_prompt": null}
{"id": "a1a7a0da-95d7-4e21-81cf-f40d8a3d408c", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "b5f6490d-64cf-489b-a267-8250888de491", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "3fd7acc2-9226-4d51-826e-e1c9c1c80352", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "439a54f2-a4f4-4f6a-8200-aab1ef0570fb", "solution": "import numpy as np\n\nclass EnhancedMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.9\n        self.crossover_rate = 0.8\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.history = []\n        self.covariance_matrix = np.eye(dim)\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.6, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.2:\n            self.population_size = max(5 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.7:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False) + np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.2, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.8, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "EnhancedMetaheuristic", "description": "Enhanced Multi-Phase Metaheuristic with Lévy Search and Self-Adaptive Strategies leveraging chaotic maps for initialization and dynamic learning rates for robust global optimization.", "configspace": "", "generation": 61, "fitness": 0.3380276123671172, "feedback": "The algorithm EnhancedMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.24.", "error": "", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7615882794873079, 0.7579809564576823, 0.7569185406029203, 0.7735995546977541, 0.7859047571675656, 0.7783134971118196, 0.784308844146885, 0.7827480862509841, 0.7894783716828575, 0.6775137739427373, 0.6608811727457339, 0.6593697614787871, 0.6556089360711745, 0.6387310312274475, 0.6225715448169868, 0.6860005484280682, 0.6436783837461644, 0.6378675660757576, 0.4301088640261861, 0.39633247632917357, 0.3097545809800619, 0.2883322853272581, 0.34303529909995345, 0.36282775304773585, 0.3542497298475733, 0.17698642741091786, 0.29423811776911457, 0.139215310648221, 0.13270231794001885, 0.12787348950260435, 0.3238923447958544, 0.11611186040578436, 0.12493817539897556, 0.12149788130642536, 0.12914420859031184, 0.1285958334210805, 0.9377728861340912, 0.9327726003562888, 0.9324875483055219, 0.946462684912834, 0.9713894010422397, 0.9790236353240662, 0.9672443961469007, 0.930460946514806, 0.9595086794603284, 0.5456013209104495, 0.5508428452515135, 0.5009293712687308, 0.4976992577589021, 0.5124129768604463, 0.5325818963637456, 0.5191263171604936, 0.4730112433794127, 0.475096193347353, 0.6838956407944177, 0.6069676414576797, 0.6753510341368167, 0.6487774414874243, 0.6200890811150401, 0.6548560783647881, 0.6853143877677299, 0.6161332863630249, 0.6132752050405715, 0.1819243615093471, 0.21172492114100594, 0.15832386503357865, 0.1993951975659416, 0.22802959513457421, 0.21924534888931035, 0.20452106905664102, 0.2373897658788945, 0.1845227907085042, 0.3370121728926817, 0.20030391005811532, 0.09882771121814715, 0.29558163953602123, 0.16281418139269666, 0.24836022276210878, 0.15487942560623924, 0.18035579925586787, 0.15044691252924203, 0.11473331175757284, 0.11468570718587034, 0.1604314910028024, 0.15474934676594077, 0.13132629044373512, 0.1646320015055056, 0.14993497068487283, 0.10802167861603229, 0.15851758245521164, 0.20787987965392796, 0.25094222796710475, 0.2827378163783745, 0.20344235768904806, 0.23553842265755798, 0.29883659163876963, 0.2959379222561581, 0.2988116250465096, 0.29473853395506655, 0.07405983615146361, 0.04344569196527159, 0.04594584735737828, 0.16330801846165777, 0.09480399467075185, 0.0728735732013065, 0.12232059571945031, 0.0467656580777257, 0.07482277003682758, 0.18825456459981893, 0.20178433001634621, 0.1986355560144255, 0.23044882245491116, 0.2216180614269866, 0.2244454906676957, 0.1909013993807217, 0.19304913132142498, 0.18586701972632613, 0.5920996035523913, 0.5567110202455975, 0.5612050669690638, 0.5872320258247664, 0.571055995558319, 0.5787472456494818, 0.5723279703656072, 0.5791247033191165, 0.5741602779646586, 0.10283492741464506, 0.14616304250329726, 0.13950617810431454, 0.10470264907413984, 0.13469170888544035, 0.1236568760380986, 0.1154162565971888, 0.10436317820144736, 0.10381805320717208, 0.21068625107793237, 0.31148789779655595, 0.14453214240692613, 0.18013526337282781, 0.22285167986419951, 0.14266290744393884, 0.17729774995636793, 0.2411383418461841, 0.17200858851870837, 0.40980671883576947, 0.35314979592272544, 0.3927836557543759, 0.36481661508520324, 0.35454557084703175, 0.4165283667605769, 0.4435900666913781, 0.42245923951711417, 0.4260242590125074, 0.262846390845624, 0.26571054937558525, 0.2521682561836446, 0.24668947312399592, 0.2355769671999165, 0.26668500942360884, 0.26305455178632087, 0.2947758525858446, 0.27297029198242695, 0.1911956085915817, 0.19100351540060867, 0.2212052505451868, 0.20491142642367122, 0.19569042947357507, 0.19791994887733522, 0.19245181604910222, 0.18853961374938732, 0.2127224170571581, 0.20087178272315853, 0.41455809935170496, 0.23264019737484576, 0.21039015303444475, 0.3348083834204706, 0.22021309926644383, 0.2944847437313819, 0.4779725116030028, 0.3773503217109675, 0.14851908223090338, 0.6244726082666429, 0.770310577804258, 0.18027513949461826, 0.17778205772118216, 0.19705442161424247, 0.18163504650591267, 0.5616894410710047, 0.5454306512866969, 0.2026967718129944, 0.16614812518478506, 0.5111835531771713, 0.22525826695523765, 0.18788301765985727, 0.15421825251778432, 0.20409199189328298, 0.7222744469094259, 0.2028745535669938, 0.17875768887638932, 0.2022040135130302, 0.19063965197992316, 0.21012368034001416, 0.19612968347024884, 0.19010225988471507, 0.20859429074052427, 0.19816944885640564, 0.20114456938191738, 0.08996809769149072, 0.0783372088474864, 0.09035855605243959, 0.08105500488872908, 0.07699306657439398, 0.08232814783539089, 0.08557416883669178, 0.08095731499958603, 0.08010929368789899]}, "mutation_prompt": null}
{"id": "2c2745f1-7e2e-4299-9761-666763bf502c", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "579025a6-fbe4-4faf-9103-b99a5c809749", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "0bf798ea-aa32-427c-ad2d-5fe6c51a7623", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "6fede957-3b34-4c68-979b-d61643f7a318", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "07895ea1-e5c1-4df2-995d-021cad94c67e", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "aa174650-1cb9-438b-9768-f0526fe0dc64", "solution": "import numpy as np\nfrom scipy.stats.qmc import Sobol\n\nclass RefinedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim) * 1e-6\n        self.history = []\n\n    def _sobol_initialization(self):\n        sampler = Sobol(d=self.dim, scramble=True)\n        samples = sampler.random_base2(m=int(np.log2(self.init_population_size)))\n        population = self.lb + samples * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False) + np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._sobol_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "RefinedHybridMetaheuristic", "description": "A refined hybrid metaheuristic integrating Chaotic Sobol sequences for diverse initialization and an enhanced adaptive covariance matrix learning for improved convergence.", "configspace": "", "generation": 67, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 34 is out of bounds for axis 0 with size 32').", "error": "IndexError('index 34 is out of bounds for axis 0 with size 32')", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {}, "mutation_prompt": null}
{"id": "86f31c99-7e83-4565-afc0-f629b36bf065", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "14be700e-2235-4c66-a797-912f2ae58295", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "b2243115-7978-4afd-b3fc-3a856fc899ea", "solution": "import numpy as np\n\nclass RefinedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        phase_weight = 1e-2 if len(self.history) > 0 and self.history[-1] > np.median(self.history) else 1e-6\n        self.covariance_matrix = np.cov(deviations, rowvar=False) + np.eye(self.dim) * phase_weight\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "RefinedHybridMetaheuristic", "description": "A refined hybrid metaheuristic algorithm with enhanced dynamic population control and multi-phase covariance adaptation to improve exploration-exploitation balance and convergence speed.", "configspace": "", "generation": 70, "fitness": 0.3420647531138353, "feedback": "The algorithm RefinedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "96797cf8-2ec2-4c11-bfad-dc13ff030480", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "ca6f61b9-45af-4200-a6b1-c7f0a16ad11f", "solution": "import numpy as np\n\nclass AdvancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / \n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        best_idx = np.argmin(fitness)\n        best_individual = population[best_idx]\n        best_fitness = fitness[best_idx]\n        evaluations = self.population_size\n        centroid = np.mean(population, axis=0)\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < best_fitness:\n                        best_individual = trial\n                        best_fitness = trial_fitness\n\n                if evaluations >= self.budget:\n                    break\n\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(best_individual, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < best_fitness:\n                best_individual = levy_candidate\n                best_fitness = levy_fitness\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(best_fitness)\n\n        return best_individual, best_fitness", "name": "AdvancedHybridMetaheuristic", "description": "An advanced hybrid metaheuristic algorithm incorporating Lévy flights for improved exploration and a novel adaptive covariance strategy enhancing convergence towards global optima.", "configspace": "", "generation": 57, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7377152848384736, 0.7553606661035553, 0.7358088656310176, 0.7779017994182015, 0.7726395801813905, 0.7651581988380234, 0.7780688092456456, 0.761174512530986, 0.7613750311282755, 0.6472193115883802, 0.6594544668653712, 0.6380646152025506, 0.6400079128200864, 0.6541815981803998, 0.6569639422839846, 0.6598802055359256, 0.6596040559635145, 0.6556428131478278, 0.4625152931291625, 0.3173492447936819, 0.41997221274060026, 0.4164438512341394, 0.31952410451090807, 0.3516365681700443, 0.31768437139621275, 0.3834481479160817, 0.4818266433277406, 0.3734641707217149, 0.27771410300728316, 0.15651315113725395, 0.32194339494696966, 0.14149393163328972, 0.12690092003495612, 0.13721257127249886, 0.16216423762303878, 0.1502504673420042, 0.9301835035786502, 0.9194141463149312, 0.939663332877925, 0.9499111831299344, 0.9509065075837745, 0.9669659368757292, 0.9745163744591837, 0.9640464696681866, 0.9364852539042683, 0.5244802665965389, 0.47078461711316344, 0.44205996828619476, 0.509220450011272, 0.5170265172677296, 0.5505937825996059, 0.4596905721040224, 0.3768472407203839, 0.33533747231728295, 0.6957780340594748, 0.6275521790340735, 0.6805550478432792, 0.6378748551860625, 0.6396027601752896, 0.6674459517245038, 0.7044912048075305, 0.629699939430691, 0.7351764859869516, 0.16914120745887118, 0.18592863057399456, 0.14903888892360595, 0.16644035645659894, 0.19548246591291063, 0.17648213448892547, 0.14926178015500102, 0.23118356547708174, 0.14530756898044217, 0.16280534024028825, 0.16616569264198644, 0.12153046608638529, 0.18173389846839672, 0.13044210595056138, 0.12353999439861252, 0.13549879376173413, 0.20645956444205438, 0.13111406928122338, 0.21311399443069978, 0.08987648318068475, 0.20710997350801397, 0.26044523492726845, 0.13994967980382422, 0.14311516548713188, 0.1513592914719757, 0.11740968090590831, 0.108273281284198, 0.2099292758598963, 0.26109957094549585, 0.25534539175763216, 0.25964675535534754, 0.22321938411285214, 0.23767844051708775, 0.3821004313653692, 0.35779241082553137, 0.3454078987709016, 0.0977032741333651, 0.06131196141898654, 0.05190351288648676, 0.11669305386790585, 0.11748781714195955, 0.10241167900223869, 0.10296110327952124, 0.07277035360852657, 0.08752494836543478, 0.20439311438458574, 0.2216921889062693, 0.2142776928535315, 0.2480418830536837, 0.2424947751279034, 0.25555714396539175, 0.1866059160611817, 0.20481058398156082, 0.17606836416976857, 0.5121191947272602, 0.5845090566592612, 0.554951537291094, 0.556403097944125, 0.5578473019455807, 0.5581334946493697, 0.5494223233882591, 0.5808456227837049, 0.5982652656654937, 0.13033378133287443, 0.09529315352782053, 0.10767195890497172, 0.12068034336859346, 0.10233660527626942, 0.12742010695279438, 0.10448081067651094, 0.09509323822157567, 0.10024275140992944, 0.1392630992949102, 0.25383902851292384, 0.22665866284956127, 0.1812550821983725, 0.1733434021162249, 0.18807089666515475, 0.18508358147960502, 0.1782900905099577, 0.16592943716773445, 0.4225911673921633, 0.3854981177671527, 0.4599292105921201, 0.4570143896000396, 0.42199977708573744, 0.3989735569246772, 0.4386760288185604, 0.5252723533291643, 0.45709377457948297, 0.2466894600998174, 0.2301153567202857, 0.26844551902735503, 0.27126862798820806, 0.29428232962167244, 0.2636794664952389, 0.3242847137323972, 0.24992692675418948, 0.33328674644788303, 0.18407523879280474, 0.22913062677904505, 0.19191055481261987, 0.18623559480890028, 0.17121524398527255, 0.1743163367410323, 0.19613220797120712, 0.1928223242230792, 0.1870155521076401, 0.32285230527803466, 0.31718751069455986, 0.21796362207079412, 0.3327884496994705, 0.30857958542935326, 0.18049198227319907, 0.28511154239134073, 0.3745292960258505, 0.39498811590127936, 0.6225433585719344, 0.6326629567662301, 0.19653983887131188, 0.5085691839939532, 0.18155467598601005, 0.6691285744754487, 0.2633208959734279, 0.3487245425506378, 0.4756912465036497, 0.2024686838949774, 0.20009952160232636, 0.16627106707770856, 0.564737241229516, 0.24036484519950385, 0.544244483172269, 0.20721852496026572, 0.12682756018083818, 0.20687085192999743, 0.18556554574972428, 0.18763534909216695, 0.18690994589554666, 0.1944085927081053, 0.19973484932595864, 0.21474091391388883, 0.17644428451414984, 0.20548513296837168, 0.1813798357014601, 0.08037923320170193, 0.08391629040445236, 0.07812437658866789, 0.0786792502281114, 0.08207296096615702, 0.06938279927882851, 0.08349372106282293, 0.08734223509771033, 0.10256942195439311]}, "mutation_prompt": null}
{"id": "dcacb24f-5e74-42f5-9a58-07e362e0d1d3", "solution": "import numpy as np\n\nclass EnhancedSwarmAdaptiveMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedSwarmAdaptiveMetaheuristic", "description": "Enhanced Metaheuristic with Swarming Dynamics and Adaptive Memory for accelerated convergence and robust exploration in diverse optimization landscapes.", "configspace": "", "generation": 73, "fitness": 0.3427917950941165, "feedback": "The algorithm EnhancedSwarmAdaptiveMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "dab87e07-5fd5-49d5-a658-6b815b6d78c3", "metadata": {"aucs": [0.7375439325811152, 0.7546378603296084, 0.7343995578424122, 0.776793489982148, 0.7706413032846013, 0.7621552006883092, 0.7754186189712295, 0.7609041951207032, 0.7616303449574675, 0.6477695092608158, 0.6597842750106202, 0.6386492763649965, 0.6401470938191859, 0.6539410837510564, 0.65438701585726, 0.6600600191861881, 0.659569716731873, 0.6562172117813825, 0.46298416828171385, 0.3128793843758153, 0.4158087835146048, 0.41474447429457584, 0.3229391655594691, 0.3472358397939379, 0.31570666795207425, 0.3785813067151721, 0.4744006237335425, 0.3955182138875307, 0.28204043084817054, 0.18732409128703353, 0.3221724953287507, 0.14231021628252916, 0.12439490972492095, 0.13959002674238852, 0.17680793785886817, 0.1451849015750598, 0.9301464230828103, 0.919384485842397, 0.9396421297508514, 0.949877461602042, 0.9508444623291467, 0.9669659368757292, 0.9745163744591837, 0.9640254231648552, 0.9368443883132028, 0.5247395445407115, 0.4736918117471569, 0.44522811414310104, 0.5101832890474913, 0.51573534408091, 0.5484883296568359, 0.4588207176087722, 0.378811569039211, 0.3338398633283739, 0.6941351253707997, 0.6274558163243453, 0.6733951268029407, 0.6280799910172261, 0.6401253955274285, 0.6639179821742509, 0.7008455722525657, 0.6260328275981535, 0.7302217583517104, 0.168288022621231, 0.18602682129316017, 0.1484513870635552, 0.156115891674533, 0.19106411602631013, 0.1666209878006819, 0.14553488749048737, 0.22650551048632284, 0.14158924445275622, 0.16750692391417055, 0.16141571663334342, 0.11692151732056211, 0.18164225603469308, 0.12933069763486915, 0.1228342682560406, 0.13579599970004042, 0.19845633186098954, 0.13031585737024398, 0.21607286333267206, 0.09198878389678544, 0.21171822423977182, 0.26173310469812316, 0.14052995386130973, 0.14799303112358575, 0.1680819704158124, 0.11815508266773178, 0.11107683140854607, 0.2047006316721678, 0.26579221481868176, 0.25775560939155884, 0.25735742333173006, 0.22283327739942704, 0.23570490029886848, 0.38405576808011077, 0.3593008976724258, 0.3471072334892056, 0.10375215876317867, 0.08425994877440868, 0.06311196576417255, 0.12381633305753714, 0.12042577964473244, 0.11464923315906561, 0.10412827946062697, 0.0903071944471967, 0.09179520662860818, 0.20289656927650201, 0.22381678305572938, 0.21448736283439773, 0.25330914367497426, 0.2506445575186157, 0.26212490343643635, 0.19663823696056915, 0.21672369526093527, 0.18328430671552876, 0.5136076760384509, 0.5870582342277264, 0.5550935305798412, 0.5635074377867891, 0.5566232986290314, 0.5564968004144395, 0.5499994303074173, 0.5809553405084456, 0.5996662685569031, 0.13076690787151524, 0.09595796054410766, 0.10856709510979379, 0.09274923724435136, 0.10031930884956963, 0.12098443461113473, 0.09892357613038294, 0.09280519650005514, 0.10690693443338828, 0.14919445085795557, 0.24549699454722373, 0.2093208077535832, 0.18157216839442147, 0.16435298992225, 0.2014101683625812, 0.18132970635511225, 0.21955768798039332, 0.17339994821615634, 0.42163389255689687, 0.3876880325133987, 0.4582604662799875, 0.4589789685022734, 0.42281190548998215, 0.3987289339154225, 0.43823111349387145, 0.5264890260311543, 0.4571581122983204, 0.24758161720775584, 0.2276973709757384, 0.272226879132499, 0.27420544082387066, 0.2956612330192534, 0.26089749209865376, 0.3240806004703747, 0.25109637228227255, 0.3358576033351839, 0.19404391608488003, 0.2301388978837834, 0.19205984486463656, 0.17704784643532878, 0.17634464670022065, 0.17617726105168496, 0.19614874707566143, 0.17913108183738935, 0.1892630518280699, 0.31772204521722247, 0.3171759311967055, 0.21010325731671897, 0.3302723971938448, 0.3293727363931225, 0.1880635605342741, 0.2822653865558674, 0.3799800594958328, 0.3887985950899774, 0.6178384144855906, 0.6269003580529335, 0.19760145353250524, 0.5072547054667367, 0.1797043977370718, 0.6645373794123317, 0.2553760414474836, 0.3643927785805101, 0.4980385596684741, 0.20145145078062365, 0.19960334633520793, 0.16588092321300718, 0.5662656539796039, 0.19106404689291034, 0.5397050659988714, 0.20611395714312652, 0.12635051689587962, 0.20642184135770647, 0.18170878382085065, 0.1949121483114834, 0.1876296398524503, 0.1944085927081053, 0.20120886914459124, 0.21656453612368376, 0.18420097424225124, 0.20548513296837168, 0.18102592391609396, 0.09421127550925179, 0.090344486588528, 0.08140725732509524, 0.08269957113029047, 0.0901023955025676, 0.07256027196658266, 0.09660279984352604, 0.08937031333897161, 0.08625145796567646]}, "mutation_prompt": null}
{"id": "f998d431-1710-4ff7-9195-89dd45155bc0", "solution": "import numpy as np\n\nclass EnhancedSwarmAdaptiveMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedSwarmAdaptiveMetaheuristic", "description": "Enhanced Metaheuristic with Swarming Dynamics and Adaptive Memory for accelerated convergence and robust exploration in diverse optimization landscapes.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dcacb24f-5e74-42f5-9a58-07e362e0d1d3", "metadata": {"aucs": [0.7375439325811152, 0.7546378603296084, 0.7343995578424122, 0.776793489982148, 0.7706413032846013, 0.7621552006883092, 0.7754186189712295, 0.7609041951207032, 0.7616303449574675, 0.6477695092608158, 0.6597842750106202, 0.6386492763649965, 0.6401470938191859, 0.6539410837510564, 0.65438701585726, 0.6600600191861881, 0.659569716731873, 0.6562172117813825, 0.46298416828171385, 0.3128793843758153, 0.4158087835146048, 0.41474447429457584, 0.3229391655594691, 0.3472358397939379, 0.31570666795207425, 0.3785813067151721, 0.4744006237335425, 0.3955182138875307, 0.28204043084817054, 0.18732409128703353, 0.3221724953287507, 0.14231021628252916, 0.12439490972492095, 0.13959002674238852, 0.17680793785886817, 0.1451849015750598, 0.9301464230828103, 0.919384485842397, 0.9396421297508514, 0.949877461602042, 0.9508444623291467, 0.9669659368757292, 0.9745163744591837, 0.9640254231648552, 0.9368443883132028, 0.5247395445407115, 0.4736918117471569, 0.44522811414310104, 0.5101832890474913, 0.51573534408091, 0.5484883296568359, 0.4588207176087722, 0.378811569039211, 0.3338398633283739, 0.6941351253707997, 0.6274558163243453, 0.6733951268029407, 0.6280799910172261, 0.6401253955274285, 0.6639179821742509, 0.7008455722525657, 0.6260328275981535, 0.7302217583517104, 0.168288022621231, 0.18602682129316017, 0.1484513870635552, 0.156115891674533, 0.19106411602631013, 0.1666209878006819, 0.14553488749048737, 0.22650551048632284, 0.14158924445275622, 0.16750692391417055, 0.16141571663334342, 0.11692151732056211, 0.18164225603469308, 0.12933069763486915, 0.1228342682560406, 0.13579599970004042, 0.19845633186098954, 0.13031585737024398, 0.21607286333267206, 0.09198878389678544, 0.21171822423977182, 0.26173310469812316, 0.14052995386130973, 0.14799303112358575, 0.1680819704158124, 0.11815508266773178, 0.11107683140854607, 0.2047006316721678, 0.26579221481868176, 0.25775560939155884, 0.25735742333173006, 0.22283327739942704, 0.23570490029886848, 0.38405576808011077, 0.3593008976724258, 0.3471072334892056, 0.10375215876317867, 0.08425994877440868, 0.06311196576417255, 0.12381633305753714, 0.12042577964473244, 0.11464923315906561, 0.10412827946062697, 0.0903071944471967, 0.09179520662860818, 0.20289656927650201, 0.22381678305572938, 0.21448736283439773, 0.25330914367497426, 0.2506445575186157, 0.26212490343643635, 0.19663823696056915, 0.21672369526093527, 0.18328430671552876, 0.5136076760384509, 0.5870582342277264, 0.5550935305798412, 0.5635074377867891, 0.5566232986290314, 0.5564968004144395, 0.5499994303074173, 0.5809553405084456, 0.5996662685569031, 0.13076690787151524, 0.09595796054410766, 0.10856709510979379, 0.09274923724435136, 0.10031930884956963, 0.12098443461113473, 0.09892357613038294, 0.09280519650005514, 0.10690693443338828, 0.14919445085795557, 0.24549699454722373, 0.2093208077535832, 0.18157216839442147, 0.16435298992225, 0.2014101683625812, 0.18132970635511225, 0.21955768798039332, 0.17339994821615634, 0.42163389255689687, 0.3876880325133987, 0.4582604662799875, 0.4589789685022734, 0.42281190548998215, 0.3987289339154225, 0.43823111349387145, 0.5264890260311543, 0.4571581122983204, 0.24758161720775584, 0.2276973709757384, 0.272226879132499, 0.27420544082387066, 0.2956612330192534, 0.26089749209865376, 0.3240806004703747, 0.25109637228227255, 0.3358576033351839, 0.19404391608488003, 0.2301388978837834, 0.19205984486463656, 0.17704784643532878, 0.17634464670022065, 0.17617726105168496, 0.19614874707566143, 0.17913108183738935, 0.1892630518280699, 0.31772204521722247, 0.3171759311967055, 0.21010325731671897, 0.3302723971938448, 0.3293727363931225, 0.1880635605342741, 0.2822653865558674, 0.3799800594958328, 0.3887985950899774, 0.6178384144855906, 0.6269003580529335, 0.19760145353250524, 0.5072547054667367, 0.1797043977370718, 0.6645373794123317, 0.2553760414474836, 0.3643927785805101, 0.4980385596684741, 0.20145145078062365, 0.19960334633520793, 0.16588092321300718, 0.5662656539796039, 0.19106404689291034, 0.5397050659988714, 0.20611395714312652, 0.12635051689587962, 0.20642184135770647, 0.18170878382085065, 0.1949121483114834, 0.1876296398524503, 0.1944085927081053, 0.20120886914459124, 0.21656453612368376, 0.18420097424225124, 0.20548513296837168, 0.18102592391609396, 0.09421127550925179, 0.090344486588528, 0.08140725732509524, 0.08269957113029047, 0.0901023955025676, 0.07256027196658266, 0.09660279984352604, 0.08937031333897161, 0.08625145796567646]}, "mutation_prompt": null}
{"id": "93e933b3-2798-4629-8ee3-b0a82ac6e592", "solution": "import numpy as np\n\nclass EnhancedSwarmAdaptiveMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.covariance_matrix = np.eye(dim)\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _chaotic_initialization(self):\n        population = np.zeros((self.population_size, self.dim))\n        z = np.random.rand(self.dim)\n        for i in range(self.population_size):\n            z = 4 * z * (1 - z)\n            population[i] = self.lb + z * (self.ub - self.lb)\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * 0.25:\n            self.population_size = max(4 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * 0.75:\n            self.population_size = max(2 * self.dim, self.init_population_size // 4)\n\n    def _update_covariance(self, population, centroid):\n        deviations = population - centroid\n        self.covariance_matrix = np.cov(deviations, rowvar=False)\n        self.covariance_matrix += np.eye(self.dim) * 1e-6\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / abs(self.history[-1])\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._chaotic_initialization()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            self._update_covariance(population, centroid)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedSwarmAdaptiveMetaheuristic", "description": "Enhanced Metaheuristic with Swarming Dynamics and Adaptive Memory for accelerated convergence and robust exploration in diverse optimization landscapes.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "dcacb24f-5e74-42f5-9a58-07e362e0d1d3", "metadata": {"aucs": [0.7375439325811152, 0.7546378603296084, 0.7343995578424122, 0.776793489982148, 0.7706413032846013, 0.7621552006883092, 0.7754186189712295, 0.7609041951207032, 0.7616303449574675, 0.6477695092608158, 0.6597842750106202, 0.6386492763649965, 0.6401470938191859, 0.6539410837510564, 0.65438701585726, 0.6600600191861881, 0.659569716731873, 0.6562172117813825, 0.46298416828171385, 0.3128793843758153, 0.4158087835146048, 0.41474447429457584, 0.3229391655594691, 0.3472358397939379, 0.31570666795207425, 0.3785813067151721, 0.4744006237335425, 0.3955182138875307, 0.28204043084817054, 0.18732409128703353, 0.3221724953287507, 0.14231021628252916, 0.12439490972492095, 0.13959002674238852, 0.17680793785886817, 0.1451849015750598, 0.9301464230828103, 0.919384485842397, 0.9396421297508514, 0.949877461602042, 0.9508444623291467, 0.9669659368757292, 0.9745163744591837, 0.9640254231648552, 0.9368443883132028, 0.5247395445407115, 0.4736918117471569, 0.44522811414310104, 0.5101832890474913, 0.51573534408091, 0.5484883296568359, 0.4588207176087722, 0.378811569039211, 0.3338398633283739, 0.6941351253707997, 0.6274558163243453, 0.6733951268029407, 0.6280799910172261, 0.6401253955274285, 0.6639179821742509, 0.7008455722525657, 0.6260328275981535, 0.7302217583517104, 0.168288022621231, 0.18602682129316017, 0.1484513870635552, 0.156115891674533, 0.19106411602631013, 0.1666209878006819, 0.14553488749048737, 0.22650551048632284, 0.14158924445275622, 0.16750692391417055, 0.16141571663334342, 0.11692151732056211, 0.18164225603469308, 0.12933069763486915, 0.1228342682560406, 0.13579599970004042, 0.19845633186098954, 0.13031585737024398, 0.21607286333267206, 0.09198878389678544, 0.21171822423977182, 0.26173310469812316, 0.14052995386130973, 0.14799303112358575, 0.1680819704158124, 0.11815508266773178, 0.11107683140854607, 0.2047006316721678, 0.26579221481868176, 0.25775560939155884, 0.25735742333173006, 0.22283327739942704, 0.23570490029886848, 0.38405576808011077, 0.3593008976724258, 0.3471072334892056, 0.10375215876317867, 0.08425994877440868, 0.06311196576417255, 0.12381633305753714, 0.12042577964473244, 0.11464923315906561, 0.10412827946062697, 0.0903071944471967, 0.09179520662860818, 0.20289656927650201, 0.22381678305572938, 0.21448736283439773, 0.25330914367497426, 0.2506445575186157, 0.26212490343643635, 0.19663823696056915, 0.21672369526093527, 0.18328430671552876, 0.5136076760384509, 0.5870582342277264, 0.5550935305798412, 0.5635074377867891, 0.5566232986290314, 0.5564968004144395, 0.5499994303074173, 0.5809553405084456, 0.5996662685569031, 0.13076690787151524, 0.09595796054410766, 0.10856709510979379, 0.09274923724435136, 0.10031930884956963, 0.12098443461113473, 0.09892357613038294, 0.09280519650005514, 0.10690693443338828, 0.14919445085795557, 0.24549699454722373, 0.2093208077535832, 0.18157216839442147, 0.16435298992225, 0.2014101683625812, 0.18132970635511225, 0.21955768798039332, 0.17339994821615634, 0.42163389255689687, 0.3876880325133987, 0.4582604662799875, 0.4589789685022734, 0.42281190548998215, 0.3987289339154225, 0.43823111349387145, 0.5264890260311543, 0.4571581122983204, 0.24758161720775584, 0.2276973709757384, 0.272226879132499, 0.27420544082387066, 0.2956612330192534, 0.26089749209865376, 0.3240806004703747, 0.25109637228227255, 0.3358576033351839, 0.19404391608488003, 0.2301388978837834, 0.19205984486463656, 0.17704784643532878, 0.17634464670022065, 0.17617726105168496, 0.19614874707566143, 0.17913108183738935, 0.1892630518280699, 0.31772204521722247, 0.3171759311967055, 0.21010325731671897, 0.3302723971938448, 0.3293727363931225, 0.1880635605342741, 0.2822653865558674, 0.3799800594958328, 0.3887985950899774, 0.6178384144855906, 0.6269003580529335, 0.19760145353250524, 0.5072547054667367, 0.1797043977370718, 0.6645373794123317, 0.2553760414474836, 0.3643927785805101, 0.4980385596684741, 0.20145145078062365, 0.19960334633520793, 0.16588092321300718, 0.5662656539796039, 0.19106404689291034, 0.5397050659988714, 0.20611395714312652, 0.12635051689587962, 0.20642184135770647, 0.18170878382085065, 0.1949121483114834, 0.1876296398524503, 0.1944085927081053, 0.20120886914459124, 0.21656453612368376, 0.18420097424225124, 0.20548513296837168, 0.18102592391609396, 0.09421127550925179, 0.090344486588528, 0.08140725732509524, 0.08269957113029047, 0.0901023955025676, 0.07256027196658266, 0.09660279984352604, 0.08937031333897161, 0.08625145796567646]}, "mutation_prompt": null}
{"id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 76, "fitness": 0.3432716670977932, "feedback": "The algorithm MultiPhaseAdaptiveSwarmHeuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "dcacb24f-5e74-42f5-9a58-07e362e0d1d3", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "b316518c-63ce-42a2-b910-70edf66fdb53", "solution": "import numpy as np\n\nclass EnhancedAdaptiveDiversitySwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.diversity_control_threshold = 0.2\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adaptive_diversity_control(self, fitness):\n        diversity = np.std(fitness) / (np.mean(fitness) + 1e-9)\n        if diversity < self.diversity_control_threshold:\n            self.mutation_factor = np.clip(self.mutation_factor * 1.1, 0.5, 1.2)\n            self.crossover_rate = np.clip(self.crossover_rate * 0.9, 0.7, 1.0)\n        else:\n            self.mutation_factor = np.clip(self.mutation_factor * 0.9, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate * 1.1, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * 0.25\n        phase2_end = self.budget * 0.5\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adaptive_diversity_control(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedAdaptiveDiversitySwarmOptimizer", "description": "Enhanced Adaptive Diversity Swarm Optimizer (EADSO) integrates adaptive diversity control with dynamic learning rates and a hybrid mutation strategy to accelerate convergence across various optimization landscapes.", "configspace": "", "generation": 77, "fitness": 0.25836763663920576, "feedback": "The algorithm EnhancedAdaptiveDiversitySwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.19.", "error": "", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.5754678111215907, 0.5485906119391306, 0.5726318794533678, 0.5975301963191844, 0.5932087788332113, 0.5802930482410938, 0.5666032034725409, 0.5974482935392076, 0.5655370793281997, 0.5029672790287343, 0.49223427666444763, 0.46532945122451697, 0.4736684925871292, 0.49285176873961245, 0.5033151687227275, 0.48603569692941406, 0.478108224423781, 0.47501451122020955, 0.14783374719475817, 0.12728812853121052, 0.14841525790157717, 0.2838702415595936, 0.19586112206994832, 0.14155650526594, 0.1380984763584453, 0.11605723769686715, 0.11746314419470649, 0.10295641508028075, 0.11063620292299237, 0.12164316825467525, 0.11370873254862124, 0.16808750147157003, 0.1502962146278478, 0.11313650416766541, 0.1303182301928646, 0.11751119156247003, 0.84077334861893, 0.9506069475111775, 0.9024449539025867, 0.9614858381757899, 0.9686134677102485, 0.9756041893908225, 0.9826042942159413, 0.95723366918794, 0.9761726137467199, 0.30705210091443125, 0.1535367077077341, 0.2750410509379815, 0.2952639097259845, 0.2212340182063185, 0.28151616310842953, 0.2621823246156356, 0.2536829819583921, 0.252069521339773, 0.22993316348762705, 0.22173949414984462, 0.24944830638474869, 0.2814304654157611, 0.26720496449094977, 0.3206802226858124, 0.3541178922585553, 0.3762542325344802, 0.3573044141706939, 0.1847789261644852, 0.3024526108641532, 0.16288146408699145, 0.18667281700055627, 0.15329181129915526, 0.1864108469620691, 0.22992024969704794, 0.17129870389331048, 0.16387250086181082, 0.25395445040634246, 0.1699379100306616, 0.1575594747943425, 0.16800261987682985, 0.18027517868398268, 0.2215043496662209, 0.22158258658880325, 0.23432460199804972, 0.21366773370326742, 0.2233818116847549, 0.15117691544798528, 0.1543829602705855, 0.15794666259272727, 0.17424242759025432, 0.18328208497948983, 0.06453555005287637, 0.08937777530296553, 0.08277927842865429, 0.19265884610655326, 0.20094413738615602, 0.1895587304370835, 0.23764437448435305, 0.2275217119074956, 0.1821166057426703, 0.24296556897897204, 0.24614506031756478, 0.2650207545984933, 0.09872457012132996, 0.1124519885205113, 0.08248485881279843, 0.17287250927997488, 0.11142427045024417, 0.10865634268072955, 0.17770686343786912, 0.3244937187869523, 0.34470975614260324, 0.17153676688654595, 0.16397224125192167, 0.14634384287400826, 0.1804156301615143, 0.19641574046233923, 0.14437968350678843, 0.10562692999616918, 0.11142068585148313, 0.10566462385932796, 0.3843432240984552, 0.3883916899380553, 0.3698124229152365, 0.3770485198094954, 0.39423831954079425, 0.38359396630569353, 0.38065928614900846, 0.40043793869544264, 0.3964545380858475, 0.07419928960601885, 0.09742831268317609, 0.13131139889425614, 0.11539609304304155, 0.08233245358736563, 0.10720907633138399, 0.127136886740027, 0.10210253616910936, 0.10606189394043763, 0.16259002032761816, 0.1736899907759063, 0.19377850291418452, 0.18708134274723864, 0.17722092114068821, 0.160824976865803, 0.17012158769910202, 0.1546160352181658, 0.16092360411321693, 0.24308347441029277, 0.24486385425321255, 0.23175307388872468, 0.2455217755142204, 0.23435498408511668, 0.22767715066713623, 0.2500905112137932, 0.27466920178284415, 0.2756342382969459, 0.19119537130052688, 0.18739779626356345, 0.18356551734439053, 0.17239297224408479, 0.17807980745332952, 0.1788726925136156, 0.16790061485194296, 0.20505170919309657, 0.1466462805657387, 0.1837892865806462, 0.17415235072505908, 0.20545905471309567, 0.1814891227263371, 0.1871658960899275, 0.21340617130848238, 0.1944274678829635, 0.1990003563493118, 0.17499834971143025, 0.18915016607000712, 0.22305800104261553, 0.21048467969244122, 0.19798286171328683, 0.21110857807985628, 0.19630773861048856, 0.22689607376002818, 0.20708588989898857, 0.1978930462158922, 0.49902214210140095, 0.358556526480694, 0.17108222043578247, 0.18275322272957029, 0.7042223965467633, 0.19016967930410655, 0.15979878615222132, 0.3931654297987186, 0.17452265486223606, 0.3272393074818799, 0.1792490207054529, 0.19272145446088207, 0.2108442753951314, 0.169044212044682, 0.17110397541599454, 0.208832711264906, 0.20732703528793195, 0.20419735207125822, 0.19918984513024474, 0.17279225198011505, 0.17753223639109417, 0.21395547129454118, 0.22352506046011633, 0.1998750036145116, 0.20295106323211576, 0.19024813412222819, 0.19507226206137385, 0.07259701533437113, 0.07543316513445275, 0.07594879260698939, 0.08185537579861923, 0.0785707817742507, 0.07640750588848588, 0.07469631967127877, 0.07379474836579303, 0.07332496740576844]}, "mutation_prompt": null}
{"id": "d6c33a5e-90aa-4e1a-8cff-d906abd61808", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "00157eb1-e9a4-4fe9-9203-c82fab159cac", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "0189f7e1-41e8-45e7-92c1-1343a3f8dc94", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "629195c8-ef8c-4edd-86bc-241136833ebe", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "7e30112d-718e-46e0-a87a-0e68c9cbaf0d", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "6606a279-6db2-44b8-9170-b29d2145af68", "solution": "import numpy as np\n\nclass EnhancedAdaptiveMultiPhaseSwarm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n        self.memory = []\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n            self.memory.append((candidate, candidate_fitness))\n            if len(self.memory) > 5:  # Retain only the last 5 best solutions\n                self.memory.pop(0)\n\n    def _progressive_memory(self, population, fitness):\n        for pos, fit in self.memory:\n            if fit < self.global_best_fitness:\n                population[np.argmax(fitness)] = pos\n                fitness[np.argmax(fitness)] = fit\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n            self._progressive_memory(population, fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedAdaptiveMultiPhaseSwarm", "description": "Enhanced Adaptive Multi-Phase Swarm with Progressive Memory (EAMPS-PM) leverages progressive memory retention, dynamic swarm adjustment, and advanced adaptive mutation for refined convergence on diverse optimization tasks.", "configspace": "", "generation": 83, "fitness": 0.3432716670977932, "feedback": "The algorithm EnhancedAdaptiveMultiPhaseSwarm got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "468ecb3d-e334-4a0e-80dd-923b8324295d", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "91a759b8-fa0d-4ca9-9472-fe0544d73805", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 20 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.7\n        self.crossover_rate = 0.9\n        self.learning_rate = 0.1\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n        self.elite_fraction = 0.1\n\n    def _initialize_population(self):\n        population = []\n        for _ in range(self.population_size):\n            individual = np.array([self.lb + (self.ub - self.lb) * np.random.random() for _ in range(self.dim)])\n            population.append(individual)\n        return np.array(population)\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adaptive_scaling(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.learning_rate * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n\n    def _elite_preservation(self, population, fitness):\n        elite_size = max(1, int(self.elite_fraction * self.population_size))\n        elite_indices = np.argsort(fitness)[:elite_size]\n        elite_population = population[elite_indices]\n        return elite_population\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adaptive_scaling(fitness)\n            elite_population = self._elite_preservation(population, fitness)\n            \n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    if trial_fitness < self.global_best_fitness:\n                        self.global_best_fitness = trial_fitness\n                        self.global_best_position = trial\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(elite_population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self.global_best_fitness = levy_fitness\n                self.global_best_position = levy_candidate\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedAdaptiveSwarmHeuristic", "description": "Enhanced Adaptive Swarm Heuristic (EASH) integrates quasi-random sampling, adaptive scaling factors, and elite preservation for improved exploration and exploitation balance.", "configspace": "", "generation": 85, "fitness": 0.19119036418152055, "feedback": "The algorithm EnhancedAdaptiveSwarmHeuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.3400890030858331, 0.36718013849687525, 0.3288068817988953, 0.4234783339116177, 0.3851820338439925, 0.4024312898035699, 0.39254911023126815, 0.3707528895781711, 0.3696850581826657, 0.20143074362726232, 0.12048716010128302, 0.11012169765931157, 0.1198801692478546, 0.15670171944499978, 0.135501257330376, 0.10799018253970394, 0.14136257651873851, 0.1216412240142678, 0.08816976307391944, 0.08406691601668148, 0.088086477315093, 0.09020564386956254, 0.08172157080040632, 0.10788389112115271, 0.09670786600441539, 0.09811198971300095, 0.10084876165784262, 0.0794661217220961, 0.0767673233967211, 0.07996324933320198, 0.08156862172067558, 0.062280344732367876, 0.06912826418623086, 0.0858309319528271, 0.06995258311277885, 0.08357309524441991, 0.9109144686950266, 0.9379985196724877, 0.8702113752129221, 0.9060512553102519, 0.8998203916809404, 0.9084592009336183, 0.938593998628966, 0.9577011900982166, 0.9091844431252902, 0.16205396967363617, 0.18529997474980453, 0.17663671175555806, 0.18473451489172388, 0.18025027071344646, 0.16678715822363577, 0.1582516046333804, 0.17663447152906686, 0.1869260162386227, 0.21130326118466547, 0.24320494255262926, 0.2152929194842813, 0.22873660768748028, 0.27788831021976934, 0.2977333922717944, 0.2241218647358879, 0.2743711012958826, 0.26663074917929286, 0.10505801604834142, 0.10112431470980898, 0.08456340040052435, 0.09268564531705592, 0.12496401325702422, 0.11178097462312742, 0.09092382060049564, 0.11807509564034968, 0.08992951174594688, 0.1595652745237789, 0.14793966756746435, 0.17374388720743883, 0.09372554616305784, 0.13322375562530875, 0.08312951807822155, 0.09557923277556513, 0.10245361487523585, 0.07975949634712054, 0.05343415030131671, 0.0198756881915666, 0.017530347784779576, 0.041149109364649994, 0.030642318201518304, 0.025916614543145755, 0.04283536155853418, 0.03664999273828651, 0.04154762443570381, 0.17881648321673294, 0.10508166558168364, 0.1232414223718381, 0.14427279486349998, 0.1232270593984669, 0.14865939701577413, 0.1307256321853374, 0.19183729382454762, 0.20055550376104347, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00023206331418546, 0.015305538483240566, 0.025270167289193513, 0.0030890572696842256, 0.002271931631553703, 0.07608380758090405, 0.06719515104005824, 0.05513355054210822, 0.07624941824879661, 0.06650925242439443, 0.09164649894557475, 0.07958075721505597, 0.11156272384192689, 0.09866408157168549, 0.3025363164048196, 0.3281522440485767, 0.374401794951847, 0.36990112807820286, 0.38751038372019786, 0.3571822111425623, 0.35479940090726536, 0.28822649451269566, 0.2871965275976667, 0.08016265891729946, 0.08679845069828285, 0.07924406278158858, 0.08847166814747431, 0.13384544538529375, 0.08754773931927684, 0.08756411838672196, 0.09024836205899212, 0.07210020366618641, 0.12757987043238972, 0.206374117520724, 0.20508668408795616, 0.16801108768260709, 0.14382815128409365, 0.13199276101968427, 0.2190640556205823, 0.13036638676917334, 0.15583239243558056, 0.24069700939085437, 0.2197546423263682, 0.21942055979354325, 0.22986352699798407, 0.23750704963255698, 0.22507416587912155, 0.24066729857613256, 0.24449134069731793, 0.23836142384809333, 0.1598734852781537, 0.18537249028034708, 0.19325464233826428, 0.1658010700609318, 0.1757447660231961, 0.16848998255562875, 0.17147072492290916, 0.15904024990649668, 0.1562226207545827, 0.2045113608345801, 0.19131966757716035, 0.17023885603898414, 0.1823289774707948, 0.1798816919720473, 0.15996896248344705, 0.17485763014992484, 0.1943487524958729, 0.17845894056928024, 0.1750081047419526, 0.17650089793480472, 0.17917955057528412, 0.17091458833013418, 0.17393519559029313, 0.17132326458919, 0.17587245223514947, 0.1775696049060056, 0.1751124413582794, 0.3238532425045423, 0.3244132017655017, 0.2878940628632093, 0.18112286098926056, 0.23782484342412413, 0.15648816244843766, 0.18025169214214942, 0.2270362984936305, 0.307896640986946, 0.20815897416500162, 0.31786881394532285, 0.18319002325950906, 0.22914530074249495, 0.14021343872940417, 0.1904444114665762, 0.19949730449280278, 0.1995865209479325, 0.19790095209494185, 0.1871136889475803, 0.18523699193478027, 0.19351234778594162, 0.1837741280725581, 0.21562131435511567, 0.20124919032470734, 0.1986618899174004, 0.2055348153702966, 0.17468900653821162, 0.09442494565619819, 0.08172588480514165, 0.0653446313189674, 0.08289361737697987, 0.07622340066092403, 0.07876680961450988, 0.061100941093816474, 0.06674350246693617, 0.0764372918021623]}, "mutation_prompt": null}
{"id": "a2d6c282-fd04-4ffe-9948-46154fa6edfb", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "3fab2247-650e-41ef-948e-7b8c81632401", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "bce4fdf6-7ce8-4a4c-989a-d30f9e9eac6f", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "aa712f03-75b6-44d3-ac78-78ec60652de3", "solution": "import numpy as np\n\nclass QuantumInspiredMultiPhaseSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n        self.quantum_prob = 0.1\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _quantum_superposition(self, population):\n        q_population = np.copy(population)\n        for i in range(self.population_size):\n            if np.random.rand() < self.quantum_prob:\n                q_population[i] = np.random.uniform(self.lb, self.ub, self.dim)\n        return q_population\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            population = self._quantum_superposition(population)\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "QuantumInspiredMultiPhaseSwarmHeuristic", "description": "Quantum-Inspired Multi-Phase Swarm Heuristic (QMPASH) integrates quantum-inspired superposition and entanglement concepts for diverse exploration and fine-grained convergence in complex optimization landscapes.", "configspace": "", "generation": 89, "fitness": 0.161095200949754, "feedback": "The algorithm QuantumInspiredMultiPhaseSwarmHeuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.19.", "error": "", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.30711982771934465, 0.33802341133295355, 0.252036856395053, 0.3008026945878589, 0.3736440312648177, 0.370523401867476, 0.34798346446768114, 0.4169822487094128, 0.2737726623802539, 9.999999999998899e-05, 0.0017515400657514002, 9.999999999998899e-05, 9.999999999998899e-05, 0.002211333036527652, 0.045587335909184956, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08647770655882592, 0.06588133191935719, 0.1499588512395088, 0.05914982508592548, 0.091326125688448, 0.06613868159275338, 0.06896149954269426, 0.1120748708922793, 0.059553690730603015, 0.1023763925247807, 0.057451302900793255, 0.09450537244115198, 0.07371635742331162, 0.06877097763066176, 0.08800478400381084, 0.04207919300420204, 0.06593199028633268, 0.03521894566238082, 0.9397166236995151, 0.9572695507176712, 0.9453420199190374, 0.9704600566171551, 0.9666502184493926, 0.9664100278759845, 0.9603813778668135, 0.950091095977248, 0.9506597705486008, 0.12567844342476286, 0.17941260143973325, 0.08574329179578921, 0.1006334862830407, 0.07453180681810412, 0.09133190159894933, 0.10734215616488241, 0.13809380706070884, 0.12281260377952863, 0.18706783252904258, 0.1655604100118766, 0.12935660489706735, 0.19518850782359543, 0.13630027754928653, 0.16887148103628447, 0.14297097985368024, 0.13753817001642843, 0.16292674526673123, 0.03187656449559839, 0.010251371270268428, 0.0918122445688141, 0.08346652957024558, 0.05160848223883019, 0.10597562077712608, 0.07790675249271661, 0.11043900018338082, 0.05606883193933698, 0.09400695866163133, 0.08127749289859021, 0.09160668665036231, 0.09582079332049054, 0.08735234941912406, 0.001327096379019732, 0.10177001506120287, 0.04334359202642535, 0.04781951061490364, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13266782095080776, 0.042736672215379023, 0.055556954741976416, 0.06078173676587306, 0.04131937318201162, 0.08660982084956281, 0.044266550745650224, 0.05433353473043312, 0.05870457344368751, 0.010487209591116375, 0.0027323564190326888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03455327768154037, 0.0251558847351383, 0.03868501522436674, 0.0328134813253973, 0.06871927547224754, 0.023761488057684632, 0.08794026815580824, 0.06182334145848012, 0.05284288658865566, 0.3253854047826701, 0.3182178603693435, 0.20412480520974408, 0.3367437684849145, 0.21808587669635582, 0.2825104773445526, 0.23602799289183662, 0.3061206625782932, 0.31169511932854965, 0.10301012420282518, 0.12174031351585013, 0.06681341379240124, 0.08793221504577575, 0.07718671747479333, 0.08572682322537162, 0.059509579250537126, 0.06306155901941224, 0.09205304335566711, 0.14806876783846434, 0.17708965581401392, 0.13870595892663695, 0.2079592752198386, 0.16331741257337473, 0.15047002476086802, 0.19412137319835032, 0.2006024904680812, 0.16444416815812146, 0.1866807640480983, 0.17048333293635332, 0.17121656209192804, 0.21047830857872674, 0.1763566944771917, 0.17254210604641684, 0.19741634345077053, 0.17822107899532402, 0.2025781720021812, 0.12183277506796109, 0.1214936653279095, 0.10734989880688262, 0.14160710836699963, 0.148182310575125, 0.12720967619700774, 0.14192595637153116, 0.1396739667271638, 0.1142956851057012, 0.1479647815809051, 0.160956881447038, 0.17364725941263692, 0.17452907039192067, 0.15843721042534875, 0.1762463324179152, 0.1762874015985304, 0.19124847036883108, 0.16397466310638886, 0.15687013821218876, 0.12930261772095986, 0.17072530205059322, 0.16731632946012975, 0.16046360594050912, 0.16903760902888953, 0.16262342867043267, 0.16881107315233623, 0.13281267205405678, 0.44218011215167574, 0.16741793681293038, 0.19289028006377162, 0.16690431394221472, 0.1591820950176951, 0.18394502375662813, 0.18660325631259034, 0.17462225517464702, 0.20983811982003908, 0.21154078083986616, 0.1681420619230699, 0.1622819897152039, 0.1886886941084176, 0.3226882232074886, 0.2541560093823019, 0.24757140988987736, 0.19408311410904222, 0.3488350713109677, 0.18918966669831327, 0.23746836988520692, 0.19817648914604247, 0.19678906514568006, 0.2236595604800954, 0.18027187334820405, 0.2057192601462272, 0.1978877664432327, 0.18888519044141672, 0.07106236682683209, 0.07349552150924377, 0.06863270969188273, 0.07291149324484036, 0.07142991718615654, 0.0800048122033078, 0.06305632076448131, 0.061061802133208776, 0.06498636578657246]}, "mutation_prompt": null}
{"id": "638ad7eb-88a0-42f5-b789-2991d515111d", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "0580afd9-4b26-478a-99b2-20495eac00c0", "solution": "import numpy as np\n\nclass EnhancedMultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n        self.trend_window = 5\n        self.no_improve_tolerance = 10\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _chaotic_perturbation(self, position):\n        chaos_factor = np.random.randn(self.dim)\n        perturbed_position = position + chaos_factor * self.learning_rate\n        return np.clip(perturbed_position, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if len(self.history) >= self.trend_window:\n            recent_trend = np.diff(np.array(self.history[-self.trend_window:]))\n            if np.all(recent_trend >= 0):\n                self.learning_rate = np.clip(self.learning_rate * 1.1, 0.01, 0.2)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.9, 0.01, 0.2)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            perturbed_candidate = self._chaotic_perturbation(self.global_best_position)\n            perturbed_fitness = func(perturbed_candidate)\n            evaluations += 1\n\n            if perturbed_fitness < self.global_best_fitness:\n                self._update_global_best(perturbed_candidate, perturbed_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedMultiPhaseAdaptiveSwarmHeuristic", "description": "Enhanced Multi-Phase Adaptive Swarm Heuristic (E-MPASH) leverages historical trend analysis, chaotic perturbations for diversification, and adaptive exploration intensification to refine convergence in complex optimization landscapes.", "configspace": "", "generation": 91, "fitness": 0.33837573031496077, "feedback": "The algorithm EnhancedMultiPhaseAdaptiveSwarmHeuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7142914231578401, 0.7483824793917022, 0.7563775937781443, 0.7454416988571799, 0.7657332232616775, 0.7545087238764211, 0.7445177659610522, 0.7607366732984482, 0.747161168424499, 0.6092254493191183, 0.6244478030262409, 0.6141593120407189, 0.6308773678859839, 0.5774228450633607, 0.6176552978435037, 0.6502329827292339, 0.617631665823946, 0.6370242659223555, 0.4382211340299347, 0.1457690432539881, 0.4678497712071503, 0.3652135721902564, 0.48673797518342454, 0.14640429615116501, 0.37403495943160525, 0.45342347593881505, 0.3042407707950504, 0.14850078035790426, 0.35426506564434823, 0.13059394225767496, 0.14566397637677442, 0.3623888305302009, 0.13746816014341168, 0.14318151743609975, 0.1393757786134342, 0.38053059086763663, 0.9453509156042446, 0.9470830229577345, 0.8778811518171823, 0.931203604260792, 0.9261643738077325, 0.9372148266383327, 0.9002662646427231, 0.9740665457938542, 0.8870260239519172, 0.46548403365125257, 0.4474730150520878, 0.5447856864217635, 0.3771116501495775, 0.4435339944035842, 0.43631288185654116, 0.38258424411678804, 0.37785471509312607, 0.354189291862937, 0.6597323296082928, 0.6274698746921619, 0.5996158568437276, 0.6655678974222938, 0.6789688423313065, 0.6489661813945833, 0.6493592229940861, 0.6056152211487009, 0.6360597775490926, 0.21383627502288238, 0.1332374146705515, 0.1394441477807744, 0.12349322307368438, 0.14690224838381605, 0.1739422802073184, 0.14618078951853786, 0.2358142452556492, 0.12934414425645724, 0.11232389266621978, 0.07493406306609818, 0.17717256436298756, 0.12575296230975075, 0.14377214970957208, 0.17505695011074873, 0.1610670964332961, 0.13866144994016472, 0.23199910547331737, 0.08536517882030525, 0.19657321079182932, 0.16032942891774815, 0.13186016922392574, 0.1078393925274207, 0.15592952370668023, 0.19158503406053462, 0.15259344006943865, 0.1810457262008054, 0.20355354179370733, 0.2712997691948478, 0.27761510669664236, 0.2373334011992444, 0.2506595171872852, 0.2420781855095916, 0.2748392458467671, 0.26864589765925717, 0.28472345341888927, 0.10198304194613117, 0.09436102633485532, 0.06568951686823254, 0.12866647556032096, 0.1188957633811546, 0.1295489071704855, 0.13599723895582116, 0.09015689115621606, 0.10282623105211641, 0.21400810819972083, 0.2192141788073243, 0.22796400768100655, 0.24719740861762407, 0.2204444602349307, 0.22578045995119056, 0.20180399176167818, 0.2221193522182503, 0.23487902370146652, 0.546256308710311, 0.5373093780063559, 0.5241764159687272, 0.5991199971483476, 0.5721298730949667, 0.5632686021166471, 0.5110650796602397, 0.5773871049440137, 0.5437536331479843, 0.1154571831969794, 0.11750287729878706, 0.10849826814047647, 0.1260403866211185, 0.13481592879483795, 0.09969010527989808, 0.1252166863171542, 0.11835383403384947, 0.13241362539192136, 0.16123747021161872, 0.1584254716118788, 0.19661788787807943, 0.18304556545504158, 0.2257891470471216, 0.16527656618090025, 0.1916716932387902, 0.24407607163106604, 0.22344318249276762, 0.3539219298058781, 0.44378081068569286, 0.4205094155876493, 0.3804847024012967, 0.48768495394109, 0.4495118211553619, 0.4950595496681096, 0.5013846684331307, 0.4761135643725475, 0.26163788015151335, 0.2873760738576223, 0.3012014570946713, 0.27692676637220903, 0.2538532966879772, 0.30211853117319887, 0.3180007672464379, 0.34426534365643624, 0.2997766515076411, 0.19246889547927504, 0.18806535987955653, 0.18732060631227654, 0.17224507938455058, 0.20955321231700663, 0.20567983953822222, 0.2111365658594112, 0.17481783442971033, 0.19759480870771484, 0.3888926622629806, 0.35229751043689717, 0.392208448312504, 0.422423856480151, 0.28427818172938446, 0.5091749483293382, 0.30731631588110064, 0.2064504000964945, 0.30536747849664336, 0.16502336836546205, 0.18179772404768113, 0.1811108776536431, 0.19796185988876447, 0.6239335002196456, 0.5193835602799945, 0.6189972636714132, 0.5520066312329963, 0.45865573108577706, 0.1830744692471853, 0.18613716492918497, 0.19972450983908263, 0.5541945207305089, 0.32800182150965684, 0.2535196956252006, 0.2069142318695083, 0.2090377785523253, 0.6889733227610364, 0.1906143801641259, 0.20348386332715396, 0.1930347950290633, 0.22069006179476947, 0.19392563666693208, 0.1928912339338653, 0.21762897683744964, 0.2104155756723931, 0.20839995905548125, 0.08424973827888393, 0.08715219890588344, 0.07772035304841451, 0.0995160317190883, 0.09288823470839525, 0.08968990963351842, 0.07994364168884527, 0.08168004533109563, 0.08887341457354303]}, "mutation_prompt": null}
{"id": "5b2523a6-e1b5-4ed5-bc3e-02d021f1b7eb", "solution": "import numpy as np\n\nclass EnhancedMultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n        self.opposition_factor = 0.3\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def _opposition_based_learning(self, population):\n        opposition_population = self.lb + self.ub - population\n        return opposition_population\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n            if np.random.rand() < self.opposition_factor:\n                opposition_population = self._opposition_based_learning(population)\n                opposition_fitness = np.apply_along_axis(func, 1, opposition_population)\n                evaluations += self.population_size\n                for i in range(self.population_size):\n                    if opposition_fitness[i] < fitness[i]:\n                        population[i] = opposition_population[i]\n                        fitness[i] = opposition_fitness[i]\n                        self._update_global_best(opposition_population[i], opposition_fitness[i])\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedMultiPhaseAdaptiveSwarmHeuristic", "description": "Enhanced Multi-Phase Adaptive Swarm Heuristic (eMPASH) integrates differential learning, adaptive opposition-based learning, and chaotic search mechanisms for robust convergence across multifaceted optimization challenges.", "configspace": "", "generation": 92, "fitness": 0.28441987580159045, "feedback": "The algorithm EnhancedMultiPhaseAdaptiveSwarmHeuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.22.", "error": "", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.6777307802969604, 0.684095229593844, 0.7045957255491566, 0.7050282444630582, 0.6978583987207959, 0.7052233114531398, 0.6803245924741473, 0.6535972811704871, 0.7106446026510346, 0.5440837453770031, 0.5386592490578916, 0.5519285926526949, 0.5359449777617518, 0.5425296386687231, 0.5463715882643657, 0.5574552405041842, 0.451154256102815, 0.5512367256032438, 0.24455318689314853, 0.11912244423986462, 0.16377634437883348, 0.25860806353609733, 0.11360766955290635, 0.2351453915338615, 0.19363363279220835, 0.10800937012680967, 0.13078976727761726, 0.10360169294295096, 0.11201474992184102, 0.12081662877669386, 0.10610193787318623, 0.10687156714412194, 0.10936052913981908, 0.14079533649583287, 0.12753808839154246, 0.1168871443912971, 0.9039745527779754, 0.9705808945150645, 0.9401277256640773, 0.9845434573797981, 0.9516607501990092, 0.9266052658187264, 0.8785003237536193, 0.9711250605752352, 0.9131315250669017, 0.3363683824578799, 0.3424250984213538, 0.323500914821347, 0.3113172078667287, 0.29923452569359654, 0.3647804117216078, 0.2038993730827906, 0.3160450780478593, 0.324706024444971, 0.5571688608559415, 0.4946527563052201, 0.4910385051148256, 0.47071721341972705, 0.574645335982176, 0.5111927410880757, 0.6276857033558745, 0.5184865073520657, 0.5394503109706776, 0.1487210947994423, 0.19651366260809977, 0.12886448359767, 0.13428043491498598, 0.14352330931588242, 0.14519202118241736, 0.15682224850588122, 0.1445297783466507, 0.1469971713421353, 0.17633366692981944, 0.16543415826916574, 0.047175259427697847, 0.2461368447988579, 0.2671825291066764, 0.24306823938929023, 0.3056790469371312, 0.20931215772931655, 0.30273373187830965, 0.048300219662770205, 0.07469158120989483, 0.11958187362356443, 0.019359668201528568, 0.08325606745368763, 0.028448649284841143, 0.026310895411383317, 0.03044121869200045, 0.09876022724661104, 0.17481151055712985, 0.15670442226931824, 0.1497451450495444, 0.11917380332494198, 0.14928117577174982, 0.1489781234659182, 0.21085479477934488, 0.1894586417975228, 0.19536725771136076, 0.04288465238450845, 0.05244582421123689, 0.03812910292045324, 0.0617027089795954, 0.03590130280864201, 0.03844803249135298, 0.05846982352417984, 0.0703850780264964, 0.08662376137914929, 0.14268047358679492, 0.13761067223274126, 0.16243843568166083, 0.15687372494409502, 0.16858807336588089, 0.15852157022159086, 0.15061157607824538, 0.1678531488186833, 0.13074496087235132, 0.5286176901258404, 0.48109504689985894, 0.4627365950319935, 0.5056075676926048, 0.48239832505006663, 0.522008451844495, 0.5016751473750408, 0.4600527204846824, 0.49545682650887035, 0.08743856941234829, 0.12094233802750842, 0.08468442841246637, 0.08496350773225991, 0.08620608496475668, 0.12198119464811008, 0.11533364617210062, 0.09932213372312615, 0.09783753271432705, 0.14184347755193472, 0.15394901478697598, 0.1561960505991199, 0.13893208213103148, 0.1928555389346046, 0.15903847088036305, 0.24056089820026705, 0.20951328830491778, 0.17544610556513474, 0.3351993191332757, 0.3363877994736003, 0.320228508783971, 0.3081578832321178, 0.3381826936082438, 0.3167695233855925, 0.33204568843422855, 0.3766239544288914, 0.37253552390285705, 0.2423479867070646, 0.24164605874736766, 0.2375332831713849, 0.2417752070693353, 0.19940664058074553, 0.23889757394890165, 0.24096728410321155, 0.24248890522648103, 0.272134825694447, 0.18551865477372198, 0.17258858170590907, 0.20412115465723868, 0.20483466388343352, 0.2154164709337847, 0.19465239716451033, 0.17539231308820913, 0.19053985935075024, 0.18613523207140115, 0.18051097217172685, 0.1948346234580849, 0.3272549309768653, 0.18916697684398975, 0.2672319763352379, 0.3405449889554002, 0.19735361377704363, 0.3046159637182456, 0.3848832474193383, 0.3545512041679403, 0.16963970610534485, 0.6983970822607237, 0.47127586099566654, 0.3255608612966293, 0.5882613296811154, 0.1670528286395625, 0.1724647352894756, 0.47005122648589326, 0.33077981374373877, 0.301287966779233, 0.4786166983985246, 0.18186101337102623, 0.22300029170163094, 0.19840915848939134, 0.2085832786152656, 0.3001692577439943, 0.20118626246593863, 0.17725942497135838, 0.18155863104058423, 0.20305088381632697, 0.19284722163664747, 0.21350423840805843, 0.1974603145791497, 0.19771479098511546, 0.20324865758498478, 0.19135387668595727, 0.07824453833825917, 0.08360567932741891, 0.09698011615908564, 0.07500579823278386, 0.0708949272681968, 0.08080437578785893, 0.08626061831776555, 0.08289974226145391, 0.07503447717277145]}, "mutation_prompt": null}
{"id": "a409f29f-84af-4543-a000-5a8923c1115a", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "246c64a4-2dd8-4a16-b1a3-ae887f7dc324", "solution": "import numpy as np\n\nclass EnhancedAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n        self.swarm_count = 3\n\n    def _initialize_population(self):\n        populations = [np.random.uniform(self.lb, self.ub, (self.population_size, self.dim)) for _ in range(self.swarm_count)]\n        return populations\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        populations = self._initialize_population()\n        fitnesses = [np.apply_along_axis(func, 1, pop) for pop in populations]\n        evaluations = self.population_size * self.swarm_count\n\n        while evaluations < self.budget:\n            for swarm_idx, (population, fitness) in enumerate(zip(populations, fitnesses)):\n                self._adapt_parameters(fitness)\n                for i in range(self.population_size):\n                    mutant = self._mutate(i, population)\n                    trial = self._crossover(population[i], mutant)\n                    trial_fitness = func(trial)\n                    evaluations += 1\n\n                    if trial_fitness < fitness[i]:\n                        population[i] = trial\n                        fitness[i] = trial_fitness\n                        self._update_global_best(trial, trial_fitness)\n\n                    if evaluations >= self.budget:\n                        break\n\n                centroid = np.mean(population, axis=0)\n                levy_candidate = self._levy_flight(self.global_best_position, centroid)\n                levy_fitness = func(levy_candidate)\n                evaluations += 1\n\n                if levy_fitness < self.global_best_fitness:\n                    self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedAdaptiveSwarmHeuristic", "description": "Enhanced Adaptive Swarm Heuristic (EASH) introduces a multi-swarm strategy, self-adaptive parameter control, and elitist learning to improve convergence and exploration balance in black-box optimization.", "configspace": "", "generation": 94, "fitness": 0.24282518169370473, "feedback": "The algorithm EnhancedAdaptiveSwarmHeuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.19.", "error": "", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.5830272338489817, 0.5543768596269876, 0.5736313356497158, 0.5786566676753638, 0.5825528385242384, 0.5940777236926886, 0.5850925685379842, 0.5940867937287976, 0.598061905751579, 0.3686873460139256, 0.37301703919724083, 0.38521150992374753, 0.36910205864447765, 0.3869682658485992, 0.39685034124058316, 0.3775344956308946, 0.3824251577676918, 0.38515675350734213, 0.12325670220103635, 0.1269158319978425, 0.1406544736250087, 0.16825860976155615, 0.20964512092529253, 0.11544624984132956, 0.1392022367795842, 0.11576794319428696, 0.11497928474005181, 0.09567135538785476, 0.09840282684029755, 0.11380310763220824, 0.1007534157157366, 0.09963209352438285, 0.11623413086593615, 0.0976871653323762, 0.1127897525971171, 0.11421385070584567, 0.8739780439119019, 0.9235223209916961, 0.9201352540703525, 0.8666709552050815, 0.9112585434179494, 0.8641946770870327, 0.8876726186786095, 0.8908430746447931, 0.8608863857791732, 0.18909810337293176, 0.252359273515674, 0.2630976573602334, 0.20346569721572583, 0.2340557167553634, 0.2461378030946273, 0.1744100437076298, 0.20112530796098405, 0.20997070449000965, 0.37537138541383275, 0.3690805690899758, 0.3902872716139867, 0.4316301370614978, 0.37365354391379957, 0.3945922650134396, 0.40669091820332137, 0.4189340122936801, 0.4316718040394816, 0.122158659196697, 0.09557621751744316, 0.12419986675543038, 0.11697492890687533, 0.13843065363569418, 0.14805628455662356, 0.11020419389392133, 0.10703986625437578, 0.16726074050157835, 0.1338973750317094, 0.10065169133279417, 0.14959062466520667, 0.1257119768561099, 0.1359393823085273, 0.11083555748782836, 0.11183049147790303, 0.11321381551303145, 0.13562315047815587, 0.048156731579645395, 0.021391342405344238, 0.026774377036196007, 0.03171632017222359, 0.04278867298157507, 0.028014037341614118, 0.039100194419762424, 0.025859481332433876, 0.03339915172344876, 0.16507982651505648, 0.19867928585189942, 0.11259028195975118, 0.11276590030453604, 0.11423689109135104, 0.09979685713135822, 0.14689319684103463, 0.14416047590431935, 0.143645045141501, 0.04872859784542538, 0.02147236490456561, 0.04412662626004604, 0.05129980421823965, 0.03348655200833617, 0.04482541277918195, 0.03236373729765851, 0.0921991699007062, 0.06466412329999416, 0.1172381842820237, 0.12034453973508175, 0.10645662471134598, 0.11965274216759425, 0.11991012969675541, 0.11652395525270476, 0.10105689768089976, 0.12471101678019825, 0.1107370630801845, 0.42449168530472847, 0.39539261727365316, 0.4078871171954481, 0.4221723970194807, 0.4139788084440984, 0.41052806412618015, 0.4212897450484725, 0.4211586370851733, 0.39567030499845535, 0.09815713912070423, 0.09436415935273412, 0.09320407803397779, 0.0854690887669658, 0.1051910829054763, 0.1039903317060401, 0.13599392615072992, 0.08924984155786897, 0.14087522080967807, 0.1509893453201241, 0.173048619332289, 0.16034788905208042, 0.20643075648990983, 0.15549497646062715, 0.17759569853276913, 0.25806527293328385, 0.25347464110383433, 0.23502449295546157, 0.2946757227991539, 0.2795417647111853, 0.25038865388424536, 0.2813762741409541, 0.27100923421577316, 0.2700512826999656, 0.30119913082230976, 0.30670847517861577, 0.2978734111770053, 0.19786202349040738, 0.19791689855428163, 0.1923813684239022, 0.2068280374614736, 0.19995922736695004, 0.1927025081518281, 0.20279337440764944, 0.19991413595442364, 0.2105548360077809, 0.18733486942855637, 0.1875167597052273, 0.18637853292105533, 0.17493980372661933, 0.1901588849829573, 0.19629965445476105, 0.1712462110094286, 0.17786373007292444, 0.19249286191139248, 0.22962396427384923, 0.20749759992481875, 0.1719485349532326, 0.2116266817880773, 0.18925110674086043, 0.23469829558783917, 0.32867507850664146, 0.19034542574798774, 0.19766187687401282, 0.5660850372020332, 0.5040841128033737, 0.454503521067545, 0.35518034560109113, 0.17328033817232424, 0.34563187194015565, 0.43004893619874207, 0.39727325748725184, 0.333921684842869, 0.15842094758133007, 0.19050163614617932, 0.38030111488790597, 0.14248418664500273, 0.26662795021390817, 0.26263916557013467, 0.2799595202582362, 0.3081131483523022, 0.3371632059081642, 0.1915676636724135, 0.19092070672944572, 0.18965117854946378, 0.18488534098792964, 0.18665324765905, 0.19983275128421352, 0.1782726278414115, 0.18877915857419403, 0.19233693635802862, 0.08458776430385151, 0.09347294854457211, 0.08413860620943048, 0.0754585693017531, 0.08339687040144239, 0.0881402057675097, 0.08475862746528451, 0.07976944636165717, 0.08989822342636566]}, "mutation_prompt": null}
{"id": "dd88bb6c-484d-4ccd-951d-dfdd59d42859", "solution": "import numpy as np\n\nclass ImprovedMultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.fitness_diversity_threshold = 1e-5\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        fitness_variance = np.var(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n        if fitness_variance < self.fitness_diversity_threshold:\n            self.mutation_factor = np.clip(self.mutation_factor * 1.2, 0.5, 1.5)\n            self.crossover_rate = np.clip(self.crossover_rate * 1.1, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def _partition_population(self, population, fitness):\n        sorted_indices = np.argsort(fitness)\n        top_half = population[sorted_indices[:self.population_size // 2]]\n        bottom_half = population[sorted_indices[self.population_size // 2:]]\n        return top_half, bottom_half\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            top_population, bottom_population = self._partition_population(population, fitness)\n\n            for i in range(len(top_population)):\n                if evaluations >= self.budget: break\n                mutant = self._mutate(i, top_population)\n                trial = self._crossover(top_population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    top_population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n            for i in range(len(bottom_population)):\n                if evaluations >= self.budget: break\n                mutant = self._mutate(i, bottom_population)\n                trial = self._crossover(bottom_population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[self.population_size // 2 + i]:\n                    bottom_population[i] = trial\n                    fitness[self.population_size // 2 + i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n            population = np.vstack((top_population, bottom_population))\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "ImprovedMultiPhaseAdaptiveSwarmHeuristic", "description": "Improved Multi-Phase Adaptive Swarm Heuristic (IMPASH) introduces a fitness diversity mechanism to avoid premature convergence and enhances search efficiency through fitness-based population partitioning.", "configspace": "", "generation": 95, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 26 is out of bounds for axis 0 with size 25').", "error": "IndexError('index 26 is out of bounds for axis 0 with size 25')", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {}, "mutation_prompt": null}
{"id": "8167efc5-b4e3-4df3-94f8-70371554b1c1", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}
{"id": "e9b5e8dc-7f75-41b0-afca-0b0755ba0608", "solution": "import numpy as np\n\nclass EnhancedMultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.history = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n        self.archive = []\n        self.archive_size = 50\n        self.phase_switch_threshold = [0.25, 0.5]\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        all_indices = list(range(self.population_size))\n        all_indices.remove(target_idx)\n        selected = np.random.choice(all_indices, 3, replace=False)\n        a, b, c = population[selected]\n        mutant = a + self.mutation_factor * (b - c)\n        if len(self.archive) > 0:\n            archive_sample = self.archive[np.random.randint(len(self.archive))]\n            mutant = (mutant + archive_sample) / 2\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        return np.where(cross_points, mutant, target)\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        return np.clip(current_position + 0.01 * step * (current_position - best_position), self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        if evaluations > self.budget * self.phase_switch_threshold[0]:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > self.budget * self.phase_switch_threshold[1]:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            self.learning_rate = np.clip(self.learning_rate * (1.05 if recent_improvement < 0.01 else 0.95), 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def _update_archive(self, candidate):\n        if len(self.archive) < self.archive_size:\n            self.archive.append(candidate)\n        else:\n            if np.random.rand() < 0.5:\n                replace_idx = np.random.randint(0, self.archive_size)\n                self.archive[replace_idx] = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n                    self._update_archive(trial)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedMultiPhaseAdaptiveSwarmHeuristic", "description": "Enhanced Multi-Phase Adaptive Swarm Heuristic (EMPASH) utilizes dynamic archive-based mutation, differential learning rates, and adaptive crossover to improve convergence and exploration-exploitation balance.", "configspace": "", "generation": 97, "fitness": 0.22392602664263178, "feedback": "The algorithm EnhancedMultiPhaseAdaptiveSwarmHeuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.18.", "error": "", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.5761538685432921, 0.8704223743618243, 0.4915525590913108, 0.24222264371748414, 0.33614367748781204, 0.33027344009245574, 0.7789130016896144, 0.36927285223140194, 0.36183504206417383, 9.999999999998899e-05, 0.11566371071440917, 9.999999999998899e-05, 0.09951109200308561, 0.03768542212909343, 0.7245585091633773, 0.11595718527774657, 0.164284842487461, 0.19433731090881834, 0.16515799169798173, 0.12278023499224489, 0.1365592814400497, 0.13575766641988407, 0.11547112301547746, 0.1392282141168698, 0.13325410765771684, 0.16499538440708306, 0.14356452817044119, 0.08922097713651578, 0.10383804496734805, 0.09906295791354802, 0.10653076096175396, 0.10597688824157903, 0.10084910134011538, 0.1224523885033808, 0.09333018359416523, 0.0705668258624843, 0.1252977203563198, 0.12711914021035242, 0.10474135222237435, 0.10567816798698715, 0.12460245253989832, 0.09113916789928589, 0.11606494560258362, 0.11913100544777122, 0.13979422623941717, 0.08197889667097902, 0.06092169895554722, 0.15152750882300114, 0.09093374624867667, 0.07626086293559642, 0.09587065291459362, 0.16398013926496824, 0.23605030540059446, 0.25145900171699054, 0.8482110985912104, 0.3232946638478814, 0.8564693737548842, 0.8531414981306777, 0.26856305891796006, 0.8572238199688635, 0.2289103573645057, 0.1988097945708881, 0.32469661672284766, 0.17760506257336695, 0.1549874749059551, 0.06766227309754358, 0.13875063273624544, 0.3684335739980793, 0.17158653675452407, 0.15561319243512794, 0.21384584190779665, 0.17409751777798133, 0.12903141985165334, 0.13901751097385528, 0.1581090384079733, 0.18933122718750928, 0.14347399623624657, 0.14210222265562045, 0.16650066584568834, 0.1433343037081557, 0.14038662830067694, 0.016624409647259197, 9.999999999998899e-05, 9.999999999998899e-05, 0.05759745360717117, 0.17536200036191696, 0.0056840445882000434, 0.08993485635775122, 0.024929308575274978, 0.09774861029949877, 0.2818917237083012, 0.12959827219165965, 0.1102654053549823, 0.09471295780646594, 0.07091252884372456, 0.09423502987775778, 0.1348343134197525, 0.14828342527430027, 0.11264305428999122, 9.999999999998899e-05, 0.17251182058219106, 0.10686177566496768, 0.08408145903031727, 0.12390527769808757, 0.1466861445667932, 0.21533694449481544, 0.06880096153809301, 0.21059350322836012, 9.999999999998899e-05, 0.17863053773231308, 0.17794340297550604, 0.16858601889939584, 0.17383724185638316, 0.08461781463220774, 0.013326279226265836, 9.999999999998899e-05, 0.07954622910775577, 0.38154974042617074, 0.49710412428860506, 0.5230495652226779, 0.5582131157065637, 0.39989952510786064, 0.46463293354432733, 0.5855358453916696, 0.299243700524251, 0.6311655740381332, 0.0636668480897139, 0.12599777008565594, 0.08875612695983237, 0.1311000043645556, 0.1093766837442608, 0.0895849887958815, 0.12430627070612321, 0.1434126052984569, 0.13886962047691964, 0.17074735864213375, 0.21642325497510995, 0.1918586854162222, 0.20835770044226087, 0.16663785496166728, 0.19019389512802365, 0.22333901964274938, 0.15496341519885792, 0.20016658364848616, 0.4449720955343913, 0.28244010846344036, 0.49647559409307607, 0.3931110282195389, 0.34616726371733353, 0.46484717614296023, 0.2439001138392377, 0.4110919303956402, 0.5413300862967905, 0.3061840193414852, 0.2558213305441519, 0.33899636786282794, 0.3885346278340175, 0.2834547580326733, 0.29392079543462113, 0.2502364023377227, 0.2531830304506605, 0.2645582906206766, 0.24635632351059122, 0.21780440387609745, 0.22604774151189277, 0.2462579608056814, 0.23617889513695067, 0.2672560383172492, 0.29112761497203, 0.24721397763207809, 0.2802980767822122, 0.265730335639615, 0.19608396269325656, 0.19992431305980407, 0.2207990210412908, 0.19537636494242527, 0.23873192280630096, 0.19415681926638895, 0.21429975088476172, 0.2046043810888567, 0.43682651355882485, 0.18595437175917573, 0.1843690423781419, 0.39553706472614936, 0.7710646272853766, 0.23246096943435923, 0.16705020078205002, 0.16983821146545164, 0.6627542077922899, 0.3385141544637389, 0.44382883050930555, 0.774908308018734, 0.856867483224469, 0.2059676352114589, 0.16630523260915686, 0.21012327375527184, 0.2632139134595147, 0.14770520774985907, 0.18628541866729875, 0.1864214451202575, 0.19400275982469817, 0.19224573129055067, 0.18373713870172004, 0.20332211413783063, 0.19297656386846207, 0.19442822140879978, 0.19209882646598664, 0.11535693061354357, 0.09465531397221238, 0.10320630435172751, 0.10696439932059598, 0.08684946474282074, 0.09284139029088345, 0.09680649355692184, 0.0932836722399385, 0.10927719359586952]}, "mutation_prompt": null}
{"id": "c3fd84a0-6557-43f3-b90f-508bf40a27c2", "solution": "import numpy as np\n\nclass EnhancedMultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n        self.diversity_threshold = 1.0\n\n    def _initialize_population(self):\n        return np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        fitness_std = np.std(fitness)\n        if fitness_std < self.diversity_threshold:\n            self.mutation_factor = min(self.mutation_factor + self.adaptive_factor, 1.0)\n            self.crossover_rate = max(self.crossover_rate - self.adaptive_factor, 0.7)\n        else:\n            self.mutation_factor = max(self.mutation_factor - self.adaptive_factor, 0.5)\n            self.crossover_rate = min(self.crossover_rate + self.adaptive_factor, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "EnhancedMultiPhaseAdaptiveSwarmHeuristic", "description": "Enhanced Multi-Phase Adaptive Swarm Heuristic (EMPASH) improves convergence by incorporating fitness diversity mechanism and adaptive mutation strategies.", "configspace": "", "generation": 98, "fitness": 0.3212208366774388, "feedback": "The algorithm EnhancedMultiPhaseAdaptiveSwarmHeuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.20.", "error": "", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7145210955873558, 0.6942452013034706, 0.7117568145868667, 0.6966732955143178, 0.7051772882256586, 0.7103089681708152, 0.7149754335446399, 0.6969980437960359, 0.6864214520699572, 0.6197072859916318, 0.6189809627945473, 0.5954955120640613, 0.6020006447653299, 0.5781845858412487, 0.5849767222169615, 0.6151084542263896, 0.6203403597623305, 0.6305560868783969, 0.12241770850833422, 0.15007998800501132, 0.12594290651307005, 0.1415112785275653, 0.12193621262058008, 0.15997621402307394, 0.1443201278437617, 0.13250788501381572, 0.12882193040856804, 0.12596568991740476, 0.11906389027722852, 0.11116000166423579, 0.09537163090193934, 0.1315383499530406, 0.13913271953425943, 0.11917113360298048, 0.11508601053855527, 0.11269156593957452, 0.7845878993085628, 0.8677101870687258, 0.8698701875021512, 0.9207846233143693, 0.8949139189198358, 0.8833411149254333, 0.9062087714154329, 0.9178096310507883, 0.9104374400798846, 0.4407509686380925, 0.1823494733957337, 0.4185425759259488, 0.4031765828572851, 0.37576373216218595, 0.39010150479892514, 0.364733867645446, 0.3940059161845685, 0.40343508623765456, 0.3579941384550155, 0.4877761286925112, 0.4726857876055167, 0.5647264814577831, 0.6115389513717362, 0.6191357905803082, 0.555255751724919, 0.5187618375773814, 0.4461481452620194, 0.36780525234630357, 0.2699270416881582, 0.253910562463981, 0.1979662978951121, 0.2930081205280116, 0.24147815485181445, 0.2573621964646713, 0.16423039780472914, 0.18454320789997458, 0.3678536370536143, 0.1656152678415923, 0.1618432619982807, 0.24442676098725602, 0.19507997596574145, 0.21031023480566624, 0.2938517448281447, 0.2785312697783945, 0.25897664229390893, 0.27204808845773787, 0.30248534707861396, 0.25191725289824285, 0.19365259858090234, 0.25840675297233096, 0.28837789506302147, 0.24136825784788418, 0.2533692971991346, 0.28814890762602186, 0.286126313364892, 0.28345185960277897, 0.3261675222772491, 0.23822327612467464, 0.28031980597727824, 0.2850292876750995, 0.30481942183806754, 0.28028240761008805, 0.3311319070860519, 0.1139723462847746, 0.1428611853233529, 0.096151111344281, 0.3728734676075176, 0.4188408987153637, 0.16989802283793431, 0.17208707041416327, 0.2291604433070391, 0.22322116668760805, 0.25633214851092656, 0.25764044170662204, 0.2515806004336191, 0.4716071622314987, 0.26235152834433617, 0.2523379956674511, 0.2740490771337639, 0.2436693881729698, 0.23730524813494158, 0.47167815536970015, 0.4678510967376961, 0.48643559400823055, 0.46287549781622017, 0.49906952353831147, 0.46967898900106997, 0.4848893737928086, 0.4928777518962951, 0.45316020252269196, 0.13283501136470044, 0.1341952690896664, 0.16294228349752427, 0.13642979269398925, 0.10936987414530686, 0.11432014076854324, 0.12681125699601015, 0.13922184565853657, 0.10782295515266904, 0.21403362063977238, 0.19711607357335847, 0.16840757517585148, 0.1543178894570978, 0.24292563905695042, 0.1962354917692294, 0.23078653184457387, 0.2002419927753052, 0.19856283077900472, 0.3142433806875773, 0.31554363023717447, 0.2904506532576413, 0.26551367694185124, 0.3225327297651719, 0.2783817500532506, 0.31479673823890886, 0.2934945003977566, 0.3277177620352395, 0.25010757897684066, 0.2592473647792163, 0.24845059830709404, 0.2224005334045419, 0.2527996609516575, 0.23747976970446638, 0.27727177117511603, 0.25962505878152553, 0.2513501139077815, 0.18854030136901012, 0.18917576179656903, 0.2299085557795938, 0.24580912108244113, 0.2291399417524177, 0.20234465168987115, 0.2024028985690557, 0.22005191551471703, 0.1886072089628411, 0.2457258246361762, 0.3418645247463039, 0.21822648739445827, 0.2740216545857598, 0.19909942485704613, 0.22040841360203334, 0.2281317093008124, 0.22344925374167668, 0.2708457313893383, 0.6578627788159495, 0.7361264674859924, 0.17028005714925187, 0.7439765458388098, 0.1889724623494876, 0.7636371007588805, 0.1849364577697996, 0.2893726965792034, 0.17727935691802654, 0.5764991539824098, 0.43405503234086695, 0.15314117263180616, 0.29539958059292304, 0.22199541571704196, 0.2008088182772062, 0.20838725005487813, 0.20641658051797107, 0.20812239971525381, 0.20735514562566904, 0.19145269018550204, 0.2062160855185995, 0.22138732728045474, 0.20346102609234162, 0.21368941052155865, 0.21081525235191023, 0.20813034550265497, 0.21705902993108583, 0.09819345964488568, 0.08181924649491501, 0.09237021654174937, 0.09963249603910684, 0.10419011245639687, 0.08260010132075646, 0.08700441358711686, 0.08865217764622446, 0.12449447167123018]}, "mutation_prompt": null}
{"id": "9fc9b552-53f6-4843-a625-2952ff0b7f76", "solution": "import numpy as np\n\nclass MultiPhaseAdaptiveSwarmHeuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lb = -5.0\n        self.ub = 5.0\n        self.init_population_size = 10 * dim\n        self.population_size = self.init_population_size\n        self.mutation_factor = 0.8\n        self.crossover_rate = 0.9\n        self.adaptive_factor = 0.1\n        self.learning_rate = 0.05\n        self.phase_switch_threshold = 0.25\n        self.history = []\n        self.best_positions = []\n        self.global_best_position = None\n        self.global_best_fitness = float('inf')\n\n    def _initialize_population(self):\n        population = np.random.uniform(self.lb, self.ub, (self.population_size, self.dim))\n        return population\n\n    def _mutate(self, target_idx, population):\n        idxs = [idx for idx in range(self.population_size) if idx != target_idx]\n        a, b, c = population[np.random.choice(idxs, 3, replace=False)]\n        mutant = a + self.mutation_factor * (b - c)\n        return np.clip(mutant, self.lb, self.ub)\n\n    def _crossover(self, target, mutant):\n        cross_points = np.random.rand(self.dim) < self.crossover_rate\n        if not np.any(cross_points):\n            cross_points[np.random.randint(0, self.dim)] = True\n        trial = np.where(cross_points, mutant, target)\n        return trial\n\n    def _levy_flight(self, current_position, best_position):\n        beta = 1.5\n        sigma = (np.math.gamma(1 + beta) * np.sin(np.pi * beta / 2) /\n                 (np.math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)\n        u = np.random.normal(0, sigma, size=self.dim)\n        v = np.random.normal(0, 1, size=self.dim)\n        step = u / abs(v) ** (1 / beta)\n        step_size = 0.01 * step * (current_position - best_position)\n        return np.clip(current_position + step_size, self.lb, self.ub)\n\n    def _adapt_parameters(self, fitness):\n        median_fitness = np.median(fitness)\n        for idx, fit in enumerate(fitness):\n            adjustment = self.adaptive_factor * (1 - 2 * (fit > median_fitness))\n            self.mutation_factor = np.clip(self.mutation_factor + adjustment, 0.5, 1.0)\n            self.crossover_rate = np.clip(self.crossover_rate + adjustment, 0.7, 1.0)\n\n    def _resize_population(self, evaluations):\n        phase1_end = self.budget * self.phase_switch_threshold\n        phase2_end = self.budget * (2 * self.phase_switch_threshold)\n        if evaluations > phase1_end:\n            self.population_size = max(6 * self.dim, self.init_population_size // 2)\n        if evaluations > phase2_end:\n            self.population_size = max(3 * self.dim, self.init_population_size // 4)\n\n    def _adaptive_learning(self, current_best_fitness):\n        if self.history:\n            recent_improvement = (self.history[-1] - current_best_fitness) / (abs(self.history[-1]) + 1e-9)\n            if recent_improvement < 0.01:\n                self.learning_rate = np.clip(self.learning_rate * 1.05, 0.01, 0.1)\n            else:\n                self.learning_rate = np.clip(self.learning_rate * 0.95, 0.01, 0.1)\n        self.history.append(current_best_fitness)\n\n    def _update_global_best(self, candidate, candidate_fitness):\n        if candidate_fitness < self.global_best_fitness:\n            self.global_best_fitness = candidate_fitness\n            self.global_best_position = candidate\n\n    def __call__(self, func):\n        population = self._initialize_population()\n        fitness = np.apply_along_axis(func, 1, population)\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            self._adapt_parameters(fitness)\n            for i in range(self.population_size):\n                mutant = self._mutate(i, population)\n                trial = self._crossover(population[i], mutant)\n                trial_fitness = func(trial)\n                evaluations += 1\n\n                if trial_fitness < fitness[i]:\n                    population[i] = trial\n                    fitness[i] = trial_fitness\n                    self._update_global_best(trial, trial_fitness)\n\n                if evaluations >= self.budget:\n                    break\n\n            centroid = np.mean(population, axis=0)\n            levy_candidate = self._levy_flight(self.global_best_position, centroid)\n            levy_fitness = func(levy_candidate)\n            evaluations += 1\n\n            if levy_fitness < self.global_best_fitness:\n                self._update_global_best(levy_candidate, levy_fitness)\n\n            self._resize_population(evaluations)\n            self._adaptive_learning(self.global_best_fitness)\n\n        return self.global_best_position, self.global_best_fitness", "name": "MultiPhaseAdaptiveSwarmHeuristic", "description": "Multi-Phase Adaptive Swarm Heuristic (MPASH) combines chaotic exploration, adaptive parameter tuning, and dynamic population resizing for enhanced convergence in diverse optimization landscapes.", "configspace": "", "generation": 77, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0b83666b-0c51-4e5c-9b21-bb6c7606a149", "metadata": {"aucs": [0.7390192824244497, 0.7584462796965682, 0.7534121936457416, 0.7617540531022393, 0.7398947041271353, 0.7424242676612396, 0.7805870812925587, 0.752035994787465, 0.7363477936917866, 0.6223092115654185, 0.6217512005395949, 0.6088396636024986, 0.6412175995018279, 0.6223760189610992, 0.6467208928267782, 0.6399988586713111, 0.6181527454027477, 0.6334615410103666, 0.35324831963551173, 0.44484450171792556, 0.3480848178514814, 0.3421559021522448, 0.13030919618730274, 0.15092842642492565, 0.381675718289177, 0.41926979691856137, 0.4014452612952094, 0.13348410060122462, 0.13276388116391058, 0.13691417052502275, 0.36043876938045505, 0.13438828542648895, 0.1252801705833464, 0.12073007931549673, 0.12446911756498102, 0.3208812312442759, 0.9296210207507029, 0.9706717520775343, 0.9390326892161077, 0.9845434573797981, 0.9666434056324633, 0.938011932791116, 0.9384021047831819, 0.9777910489632224, 0.9170885393250316, 0.3374451630637163, 0.41233339516343726, 0.4371377689347947, 0.535608931633512, 0.5246289313843178, 0.5169096575796126, 0.40015161360456564, 0.35158738453078187, 0.3609436913630867, 0.6098500289783003, 0.6749226747262387, 0.622185327960554, 0.6856947907951744, 0.628623104715829, 0.6536259242117237, 0.6118187677772314, 0.6545589406613602, 0.6996930188626695, 0.144859342140777, 0.1569596549360689, 0.1494737287462392, 0.1623222907699886, 0.1666541719341772, 0.18097154568815743, 0.14477830949847825, 0.17710382552488024, 0.17365057179020083, 0.24103839807397576, 0.11454278435151721, 0.051840228624281504, 0.16032983811501433, 0.1557121890588361, 0.13899416887658478, 0.1648204606102367, 0.1448174313705637, 0.1478891755967574, 0.1645901828620303, 0.09134958998204568, 0.14441651972924552, 0.14953899563274864, 0.2112184152337968, 0.09186239046925038, 0.08829152445938593, 0.1317288806946112, 0.19437992319416475, 0.3079584190438749, 0.23857039935756053, 0.2863750227635813, 0.18550847868951248, 0.27373882632492197, 0.20315916116668176, 0.3147140309959502, 0.27119223336855836, 0.2873909289736285, 0.09061123569083551, 0.13189176084387688, 0.0844999304129671, 0.07774913652328419, 0.14846043422460375, 0.07702663454300418, 0.12753724217787343, 0.10054656285320018, 0.1751498171284087, 0.22389159753314558, 0.20907079210976165, 0.22851788446597598, 0.23677731363361187, 0.24510266591915242, 0.2541301327789768, 0.21105757049647667, 0.1847317016038209, 0.20674135630521118, 0.5576302295985085, 0.5372828900212208, 0.5532363100587641, 0.5727895212927248, 0.5301422106634723, 0.554829866970209, 0.536628425418111, 0.5136017992928831, 0.5035484941067983, 0.10123633203777171, 0.09810158157092297, 0.11342896204941644, 0.11796300384475378, 0.11383009939085165, 0.1388651111351804, 0.1109321481256802, 0.1162120262541726, 0.11559756183296976, 0.1468942157773261, 0.16474745663373525, 0.1631587730421945, 0.26556410737085034, 0.22729819903856718, 0.17776853721602803, 0.24158186111264746, 0.23364167374647915, 0.18395986841379652, 0.3658834427969363, 0.4026170345319824, 0.4332132180778483, 0.33337756469256397, 0.38444791448742854, 0.40948991166907767, 0.5123304946399925, 0.5532264558081492, 0.5220132644663988, 0.2982413444186547, 0.30096969555606834, 0.24648239247854864, 0.2642997184196465, 0.29630508529989363, 0.27436535165672105, 0.310450111957115, 0.2908943830539089, 0.31920570912358714, 0.19086960740485348, 0.18723411982772253, 0.18738913576422978, 0.18405334268234197, 0.17470947670764403, 0.21102115590258907, 0.1774436477621888, 0.1929963680781499, 0.20225299832761545, 0.35478802880146854, 0.3490860734722525, 0.4765166943762861, 0.29342114519600726, 0.3925621623486357, 0.4528782988449952, 0.19862922838996777, 0.45165469593644525, 0.20126119186211078, 0.6485244454731676, 0.17897228572379076, 0.575196790313296, 0.17854662726585901, 0.17993497812166948, 0.6788744557473755, 0.5517483563128902, 0.36858801096339355, 0.5663847307487472, 0.30675479981484255, 0.3406310245566013, 0.7758884033835822, 0.6413193868347593, 0.40685305886020406, 0.2338175319622997, 0.20768584621584296, 0.7517768998986015, 0.20394804733800542, 0.2124367016594202, 0.20887111516981527, 0.19188869008865483, 0.19912461874271226, 0.1831646842400252, 0.19689770267209206, 0.21534325557618283, 0.20398384783083034, 0.19835278772716325, 0.08660799958458343, 0.08877796403194949, 0.08510966837457601, 0.07850873393546876, 0.0857935287447924, 0.08649956467707198, 0.08135762992963025, 0.08564382970124029, 0.08999835651923382]}, "mutation_prompt": null}

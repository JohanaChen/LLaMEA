{"id": "00db26e9-4baa-4849-8227-7cb8316d1830", "solution": "import numpy as np\n\nclass HybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w = 0.729    # Inertia weight\n        self.F = 0.8      # DE mutation factor\n        self.CR = 0.9     # DE crossover probability\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "HybridPSO_DE", "description": "A hybrid Particle Swarm Optimization (PSO) with Differential Evolution (DE) inspired mutation mechanism to adaptively explore and exploit the search space.", "configspace": "", "generation": 0, "fitness": 0.3401932206328502, "feedback": "The algorithm HybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.24.", "error": "", "parent_id": null, "metadata": {"aucs": [0.7350051461575462, 0.7511601701195377, 0.7210529198330241, 0.7348232530914178, 0.780588264800558, 0.19019772540555013, 0.7370411897604078, 0.7443126196672373, 0.7343553096171784, 0.45281745018946884, 0.5277590051581441, 0.4844309790186434, 0.5059582495338624, 0.46244652279462717, 0.49451961474912565, 0.45536101934156137, 0.488696459731627, 0.5377854069967631, 0.13801401085918585, 0.29066307875328123, 0.1442673170186356, 0.1546844484051093, 0.12403987882739964, 0.14376383491239553, 0.22781709456965016, 0.11533952561150984, 0.13318613687790637, 0.12214335954104394, 0.12396150818082463, 0.10965885149414223, 0.12040094482597719, 0.1171030714658351, 0.12547613267263802, 0.10364076701001546, 0.12832160213028, 0.13799428542366787, 0.9855096540254307, 0.9884359706217277, 0.9902062404477975, 0.988938488485559, 0.9816099033254377, 0.9813773193715131, 0.9892885253578759, 0.9858520817626097, 0.9862001185551378, 0.43888565821120296, 0.4737241865308869, 0.4225970889449634, 0.3988922113872425, 0.38469021788647595, 0.4369527373270111, 0.43574915527633307, 0.3933540972447319, 0.08800934889219914, 0.7423894805210557, 0.6692628844759876, 0.736503116063333, 0.7645952852136921, 0.7743005545218813, 0.7579832285076826, 0.6651049982086609, 0.7534066693265009, 0.6678907962213904, 0.2856365212182712, 0.3163675841905115, 0.31726708962946215, 0.3369508611890413, 0.3549555618782706, 0.29417922228834803, 0.3265248379106983, 0.25659160834379235, 0.2818257974999995, 0.24288754164008564, 0.016454723525602843, 0.12753552766225817, 0.41945913086603137, 0.391682269982192, 0.300131078347717, 0.29309338507393123, 0.31786983954359527, 0.3654604804071746, 0.28940346037346976, 0.2335673033677681, 0.21884124813758654, 0.30483604633794503, 0.2723570270358925, 0.2112025636908259, 0.18692534160154917, 0.20113210172673024, 0.28086032731959665, 0.3589692254770187, 0.4273222578849071, 0.38555793515792025, 0.3632168290274952, 0.35488993891797305, 0.3533885719555606, 0.4065436604129894, 0.47929959307895065, 0.4195257803529546, 0.0862998920161131, 0.06549287313566032, 0.0605199061835221, 0.09359106129071293, 0.1404274195767794, 0.06417218417999371, 0.09973740532397912, 0.11260646891068882, 0.079878296990466, 0.2289667259346544, 0.22268865193866483, 0.2541340453713774, 0.27194113309351087, 0.25683602081502055, 0.0060411511192097755, 0.21163299895114218, 0.250998966184076, 0.21755385133828664, 0.6194030766407252, 0.5609378545771027, 0.5926011198020007, 0.6031770274103159, 0.6124642439103961, 0.20859598775413257, 0.5814052762408262, 0.6028839396015842, 0.6837855433135532, 0.12648564283839347, 0.12277838579581535, 0.3548927383102699, 0.14039124543556225, 0.11200216923499173, 0.12983008005562302, 0.16770031667887364, 0.10473652554661617, 0.1007012459152784, 0.16490933852238798, 0.4863151638956015, 0.4277140300580137, 0.405446066873556, 0.24561978647598903, 0.31129753274265426, 0.3269121864859247, 0.13582345375714522, 0.2632611457771735, 0.388726684367366, 0.3520834237367805, 0.3787891989730874, 0.37756843361777137, 0.3932651444831258, 0.3974586825098033, 0.432476954121095, 0.41750054026133476, 0.3792142159001387, 0.30228201969095636, 0.29236788815388337, 0.23984229259832512, 0.24086515427189303, 0.24375025477022305, 0.27176981412396195, 0.28413527195146204, 0.31308773968589243, 0.2776775958028844, 0.21856208728641435, 0.2070035880815213, 0.20522734756777827, 0.22542480375918483, 0.19473226769362229, 0.22378711272143625, 0.19204209553246399, 0.19059274496642276, 0.19502072552531513, 0.2124132789057448, 0.42783860890644543, 0.2183720039353847, 0.31559359354259264, 0.5869466088271531, 0.19542092236710584, 0.21791109797969388, 0.31581451861863485, 0.19692756357056618, 0.8331692336856197, 0.18197544291994583, 0.15429149125496677, 0.741779046809673, 0.19733799175668998, 0.13447440926994636, 0.09969168006626483, 0.16975116994445327, 0.16012343181661726, 0.15775375842843875, 0.16803803312904075, 0.20573712400015443, 0.20765167697750475, 0.7419172442925157, 0.2084573289822158, 0.16103929380399318, 0.8401269127248365, 0.20896745488363766, 0.19831691183177635, 0.18931211775130752, 0.1894459163555401, 0.19397562867136964, 0.194898244331131, 0.20485387801106492, 0.19004075244585317, 0.19757305777935175, 0.18926624384838409, 0.08736039226744818, 0.08597820789290089, 0.07791223258265323, 0.083700343526116, 0.08453179289344548, 0.09049064167313914, 0.08055672186178986, 0.07510531744126514, 0.08484263165853134]}, "mutation_prompt": null}
{"id": "1c5fca1f-b682-4f3a-975b-43c180c7cd09", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w_init = 0.9  # Initial inertia weight\n        self.w_end = 0.4  # Final inertia weight\n        self.F = 0.8  # DE mutation factor\n        self.CR = 0.9  # DE crossover probability\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            # Linearly decrease inertia weight\n            w = self.w_init - (self.w_init - self.w_end) * (self.num_evals / self.budget)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < self.CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "AdaptiveHybridPSO_DE", "description": "An adaptive Hybrid PSO-DE algorithm that dynamically adjusts parameters for enhanced balance between exploration and exploitation across diverse optimization landscapes.", "configspace": "", "generation": 1, "fitness": 0.32563228555697216, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.23.", "error": "", "parent_id": "00db26e9-4baa-4849-8227-7cb8316d1830", "metadata": {"aucs": [0.6858456384919867, 0.6569040644254344, 0.6764882573150908, 0.7226749930895754, 0.7153698207174136, 0.189840960016061, 0.7057951700062628, 0.7045431602346958, 0.6829909575160036, 0.5015532355982006, 0.5048223984874765, 0.47119629693126175, 0.460898320569454, 0.4751562427796061, 0.4658627087007944, 0.4540809202443057, 0.49966423021650763, 0.52179812183336, 0.2588201644116418, 0.13344422142370183, 0.11769613973473392, 0.14872441357503263, 0.11748493841052643, 0.132690499172737, 0.13462031659217133, 0.3229872241089423, 0.13171204649071167, 0.09880216876625914, 0.12766090603614144, 0.12262987130015901, 0.1119818499320312, 0.1447755501388105, 0.33119475512153995, 0.13006418322437385, 0.10779935834748144, 0.09435541593266206, 0.9876443035340481, 0.9858478291778446, 0.9902297889487592, 0.9867873093685137, 0.9819791407969513, 0.9814597767915291, 0.9893306675384533, 0.9895785380823677, 0.9889247779731131, 0.47291945813356673, 0.4294259215228211, 0.4395670602428552, 0.4648583272198513, 0.5275976615854785, 0.4567765843066147, 0.48446879374060525, 0.44091656255155043, 0.4338709354901926, 0.6675137357271628, 0.6254419282263735, 0.6475072684784144, 0.6538351019594957, 0.6438166227610764, 0.7121058797434354, 0.6397409840464197, 0.7260225800389037, 0.6577764047770269, 0.3156713354267451, 0.3409842131845878, 0.299233610364953, 0.2515424406182347, 0.33895553129819933, 0.22281858830067758, 0.3143994598687203, 0.2972164754924381, 0.253919943869083, 0.27695937265413983, 0.053693513642045, 0.31948127758219036, 0.301313614252792, 0.2428793436657566, 0.3739479284051589, 0.3148847756220079, 0.2638649582329303, 0.26995730135229, 0.1837354336628687, 0.21340988370153136, 0.28334659679550855, 9.999999999998899e-05, 0.1406133071007729, 0.242087441597704, 0.22356080808027268, 0.2677792694872003, 0.25800596841194556, 0.37909599926657134, 0.3955371645682453, 0.36914266619564373, 0.357468090161437, 0.37983193329021503, 0.3567634286351543, 0.4204004618841355, 0.41312920040040446, 0.3653051801078433, 0.06498239697898966, 0.03991458302086015, 0.06900177132482188, 0.0955744293718952, 0.12065105030600609, 0.05630343697835183, 0.07377163716601953, 0.07140078236348368, 0.06444954199721198, 0.17659808495944085, 0.2173097960644088, 0.23189832198706306, 0.221621884323295, 0.21253961574042202, 0.22848150656937072, 0.19747338832820593, 0.047078416822068925, 0.24295334759484255, 0.5283482008417038, 0.581177370490075, 0.6064181511260244, 0.5803308497825901, 0.5787462848052844, 0.2085906918496403, 0.5243009727894872, 0.6077639060954307, 0.5834573707195292, 0.11749618776125714, 0.1050957789852871, 0.13344359529148075, 0.12973579347053166, 0.14627462698326543, 0.15481264663052774, 0.09736359908041925, 0.12118935289969268, 0.10747861931418934, 0.18840486787514543, 0.3467297163458404, 0.16536480497893535, 0.14323883875186116, 0.4637546605237164, 0.15241375289994408, 0.17677269102367776, 0.199132880237606, 0.245074199553184, 0.3592960173704203, 0.40320373858039327, 0.4035656570339684, 0.384167836230205, 0.4068384430876263, 0.3662769423003781, 0.4096875935969623, 0.4017696704459206, 0.4352362793960609, 0.2642205696990647, 0.2990685647033663, 0.2801115781326544, 0.27045629586822084, 0.24645583841531993, 0.29085284083318796, 0.3377586891691241, 0.3239797481641602, 0.31148123541090167, 0.21403333848727513, 0.18265243142963716, 0.18776660725130445, 0.20024972958867482, 0.20614077675505715, 0.24092339017318942, 0.18434090079495968, 0.18701802600115258, 0.2023796467684036, 0.2148025557001454, 0.20145195724460407, 0.19725302370775244, 0.22674115446064758, 0.44575550803549135, 0.2173120120770975, 0.4282052125748138, 0.2039383049972726, 0.3849096006176588, 0.794044616069277, 0.1617500923078231, 0.15410082995135976, 0.17618459852598467, 0.1960038913797848, 0.2042271074698765, 0.14761170935411172, 0.20725310603403546, 0.15581518263157945, 0.1497161249913641, 0.16855623979915313, 0.5978804042280512, 0.1980733445703351, 0.6978003458135968, 0.20101661856055753, 0.10485637113748492, 0.2107457860901527, 0.19494650450945805, 0.17740185552688092, 0.1791672153459174, 0.19326176179671473, 0.20967511886022328, 0.20191051341406552, 0.19808633027581513, 0.20587756333955454, 0.1789706335673713, 0.2040378867799698, 0.08653137725175075, 0.09106841348781314, 0.08359223676611005, 0.07747177231948221, 0.0743120062219057, 0.08061944881339644, 0.0842171250357645, 0.0883955317051015, 0.08626791843103532]}, "mutation_prompt": null}
{"id": "5cd8e972-ea54-4646-a307-a91a7e31084e", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_max = 0.9   # Max inertia weight\n        self.w_min = 0.4   # Min inertia weight\n        self.F = 0.8       # DE mutation factor\n        self.CR_max = 0.9  # Max DE crossover probability\n        self.CR_min = 0.1  # Min DE crossover probability\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            # Calculate adaptive parameters\n            w = self.w_max - ((self.w_max - self.w_min) * (self.num_evals / self.budget))\n            CR = self.CR_max - ((self.CR_max - self.CR_min) * (self.num_evals / self.budget))\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with adaptive CR\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + self.F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm enhanced with adaptive inertia weight and dynamic crossover rate to improve convergence and exploration-exploitation balance.", "configspace": "", "generation": 2, "fitness": 0.28423494021110296, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "00db26e9-4baa-4849-8227-7cb8316d1830", "metadata": {"aucs": [0.6586395800272721, 0.6524209409902677, 0.6792079337458237, 0.6814005181629985, 0.692511400278663, 0.18980507797348511, 0.6850399644580716, 0.6684054216928915, 0.6635416327409758, 0.5013185438504091, 0.4506443270612187, 0.44331885287897077, 0.44149270783602657, 0.4446236427572179, 0.43745567839845667, 0.45433924903190304, 0.45417658142631934, 0.4705366368932762, 0.13996351892496373, 0.30249367841205943, 0.13080111915920356, 0.11731390846864764, 0.32821763368438883, 0.13264188279501976, 0.13168452370205708, 0.1141386677035231, 0.3709194481762067, 0.11920664329043973, 0.1286991878726803, 0.1267710548652271, 0.11856806026363864, 0.12098784587247269, 0.12161854703377517, 0.12042896039720996, 0.1307536989649949, 0.2882178802794918, 0.9876450486647776, 0.9857815408455696, 0.9902269062692348, 0.9867821556201771, 0.9819776320524678, 0.981453023709238, 0.9893290780230947, 0.9895780957106904, 0.9889256373403427, 0.4445278298640746, 0.42409385272218714, 0.4869296791876694, 0.42051797373630906, 0.4865711422621407, 0.4305017653928125, 0.4586756686003871, 0.41612385792810214, 0.4096113673356041, 0.5253020606827248, 0.6167753705091161, 0.3249396059062756, 0.6126914637542389, 0.5070079437682382, 0.3805776144747509, 0.6298760893949771, 0.7102410636987226, 0.3238827802277642, 0.1527179590478125, 0.1663940722904632, 0.15465221837712684, 0.17870243923019902, 0.1756139217995154, 0.16453894835686877, 0.1691677227482129, 0.1798680056082771, 0.1541922831101601, 0.18055629099016135, 0.053426445544582424, 0.1667969976476772, 0.20935710731183788, 0.15624295884872885, 0.1853374792565372, 0.19840474151113008, 0.16098465584423338, 0.1878294766227092, 0.021783442682478893, 0.037663057333736094, 0.023285396661960278, 0.009949380403535324, 0.005778774391239305, 0.013331987110990706, 9.999999999998899e-05, 0.04229385656556117, 0.006250805182982377, 0.10999677515395956, 0.12251717036710996, 0.13507426706605852, 0.14410436830453033, 0.11154310557832248, 0.0941517893510625, 0.1869910879131419, 0.17139857799424918, 0.18497305547993692, 0.17617520004621168, 0.07398868577277795, 0.06808461674813482, 0.12501179438491128, 0.08492010117120741, 0.048402354707463235, 0.07016419307372779, 0.04435181235489161, 0.06480196557712936, 0.2065778746954846, 0.08478448043856768, 0.16975266740364403, 0.14721923248986857, 0.2490343935196303, 0.13830768982245667, 0.13929024032910908, 0.05217354803345298, 0.17636344215942423, 0.4597155200697265, 0.4505051377974856, 0.48797644569901144, 0.4846437719606881, 0.4671331103108507, 0.2087117185827162, 0.468264783210219, 0.4719226807051392, 0.5139176225996849, 0.09692358596803174, 0.10179316328605892, 0.09966101487367196, 0.12881398144182787, 0.1140053266370511, 0.09617586679277534, 0.1187695248683518, 0.1089796591669443, 0.10626930232139598, 0.1951099288359318, 0.2715279967183395, 0.16720402541393564, 0.14447307473921778, 0.27928988973053337, 0.2757614988599415, 0.1960641193596523, 0.1832518071267848, 0.15198176611733705, 0.35857625159045314, 0.36602818428904316, 0.3359165921333682, 0.3644054794998559, 0.3099130003595423, 0.2863685352452737, 0.4334575521530246, 0.4000461433724123, 0.40982837449043497, 0.23561770410430583, 0.2792526538754717, 0.23390149739463195, 0.26924861518850407, 0.1926255736067054, 0.22656442582173397, 0.2563896510381487, 0.25653512636066944, 0.2836355860286358, 0.21249232060187606, 0.1831409972020407, 0.21387317900019776, 0.2093454417172893, 0.17737734791713977, 0.21772369589369944, 0.19868156588783226, 0.20425899922080015, 0.21263353017932773, 0.44577683103804233, 0.4788329917318378, 0.30156328002845467, 0.22368620723799248, 0.3636315033231651, 0.22003213463133087, 0.21556990615077853, 0.21229100945308887, 0.2875527268130491, 0.7307783021989427, 0.16589244498712064, 0.1538394384975751, 0.6764599571507492, 0.19147110314352578, 0.16551339151653388, 0.1473436413106548, 0.1688310797121534, 0.14682849320138125, 0.14995585951186163, 0.1685077371813648, 0.5876801219428746, 0.531553767732371, 0.574642836893194, 0.20374697855326573, 0.10485120687086069, 0.209947787893475, 0.19621646673571802, 0.20137585840702954, 0.187656185220208, 0.18906997290751004, 0.1816235843868601, 0.18235288859475707, 0.20070437866019253, 0.19487577360680675, 0.1985183857061774, 0.17556800426220742, 0.07770836965286054, 0.08958730894572131, 0.07828047671997118, 0.08278920824797953, 0.0830301832303465, 0.08030065642696793, 0.09039248905955932, 0.08285969415445593, 0.08014600243442804]}, "mutation_prompt": null}
{"id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 3, "fitness": 0.3601047673290209, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.25.", "error": "", "parent_id": "00db26e9-4baa-4849-8227-7cb8316d1830", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "4ddc44f8-a514-497f-a4a2-7cf33e4b0852", "solution": "import numpy as np\n\nclass EnhancedAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5\n        self.c2 = 1.5\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.4\n        self.F_end = 0.9\n        self.CR_start = 0.7\n        self.CR_end = 0.95\n        self.local_intensity = 0.1\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                local_search_position = swarm[i] + self.local_intensity * np.random.uniform(-1, 1, self.dim)\n                local_search_position = np.clip(local_search_position, self.lower_bound, self.upper_bound)\n                local_score = func(local_search_position)\n                self.num_evals += 1\n\n                if local_score < personal_best_scores[i]:\n                    personal_best_scores[i] = local_score\n                    personal_best_positions[i] = local_search_position\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = local_search_position\n\n        return global_best_position", "name": "EnhancedAdaptivePSO_DE", "description": "An adaptive multi-phase search strategy combining PSO, DE, and local intensification to efficiently explore and exploit the search space.", "configspace": "", "generation": 4, "fitness": 0.2854972501779532, "feedback": "The algorithm EnhancedAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.23.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.6395088937852942, 0.6221256625335495, 0.6230674620842478, 0.6928691254242099, 0.6459221366700034, 0.652874708948328, 0.6538825807098212, 0.6529775919420417, 0.6699703871966681, 0.3860150145295267, 0.3531135047253491, 0.39804333723958807, 0.3585511601676622, 0.3559909213966307, 0.3887222583557667, 0.42725825388843897, 0.396999516072468, 0.415385444807409, 0.12986592204809622, 0.13868252620093913, 0.13594219046108325, 0.12886827848458582, 0.21398612192785138, 0.13405318833866786, 0.12229547659629825, 0.11278516989458442, 0.1359651043017297, 0.1415625601897058, 0.1357137522269377, 0.1029486090331988, 0.10217648208995178, 0.09385314099542919, 0.11535354245095697, 0.1180556813393534, 0.10157813778880642, 0.12776316321887293, 0.9837657088643725, 0.9800886046015761, 0.9842762436844497, 0.9828854022820253, 0.9805022959032411, 0.975705634883923, 0.9895025813637827, 0.9876291593448506, 0.9837445712957719, 0.3818714686606257, 0.41173780830309914, 0.3887054025372062, 0.39654470433159583, 0.40953945466070285, 0.3966906732172917, 0.39680089215049885, 0.37455606313326784, 0.37437850691721153, 0.6592467241927569, 0.6763495286686116, 0.6417523669304037, 0.6760852155039867, 0.6553857388756121, 0.20511716018297177, 0.6653768736180055, 0.20027985055764952, 0.1145579701077255, 0.18463752994843607, 0.23250627456929374, 0.20675144010377167, 0.11806609307388971, 0.12745624161203828, 0.19239072056133122, 0.19757834603054036, 0.19098457212475628, 0.2514311765247036, 0.22931706780321448, 0.10777939871196762, 0.24346525888902137, 0.20634225983145493, 0.1882599990753302, 0.29464249827382916, 0.23204551660820438, 0.09878766430717989, 0.10827547607598209, 0.03326300737320487, 0.03705988825086293, 0.09948469162213402, 0.037164434999751084, 0.049834030854446265, 0.04089045709510897, 0.09678240750863476, 0.09676279579078728, 0.12314973914092586, 0.1673667255302662, 0.14555673561316307, 0.25117636816921907, 0.19572836323404708, 0.071891449514223, 0.1360086064617273, 0.3172308463097826, 0.2810552294182129, 0.12523770135136236, 0.03445491707012793, 0.10181093941779018, 0.034029409492600804, 0.08624334168026182, 0.09031226413248328, 0.06139611090217478, 0.07230221440218865, 0.04435893208276487, 0.05404540747644404, 0.16003312042556062, 0.1499483906166228, 0.1506367899895873, 0.16388335416337974, 0.18198109074755464, 0.17041651092315513, 0.13888076992157716, 0.13561224406629513, 0.17057422593709548, 0.502277634344212, 0.489751830123203, 0.5013909574937248, 0.5049013093428942, 0.5029754746985059, 0.4586124944268859, 0.49301320222193856, 0.5113905335266147, 0.4953497865238038, 0.11813885194989637, 0.10843811613283505, 0.08636975305252748, 0.13125498373234334, 0.1288386558830853, 0.12064725158165834, 0.061464984416797264, 0.11925252643482598, 0.12297746940129961, 0.1666559300444651, 0.1615728690710554, 0.22571184621460239, 0.49404786697720326, 0.22424962475449817, 0.1618446120821222, 0.24342836719254857, 0.19950484190127693, 0.18585486038615606, 0.3119795723514197, 0.2506488256323177, 0.33910226979285873, 0.32575246112245904, 0.32425911545176356, 0.3658973360412747, 0.3461683089061155, 0.35043428057596804, 0.36417096145210903, 0.21786434226884788, 0.20693263956787755, 0.16860517121927843, 0.27250898139088287, 0.188190010668142, 0.26134300889937223, 0.2777844916656802, 0.27487733498197, 0.2895073594172626, 0.20345760564603343, 0.2021280993417477, 0.1990671841644357, 0.19550183778150954, 0.21636874939670436, 0.1814817501346101, 0.2018020115219269, 0.2708400829966733, 0.1972661680074581, 0.21228819621090111, 0.32985448805350914, 0.2193067751620712, 0.20822010582181882, 0.4101521041624542, 0.2780110269896976, 0.22494270643456016, 0.1892350497620343, 0.19255054276174355, 0.767327586088759, 0.16660107936796142, 0.15139463193406522, 0.6378827137635028, 0.19813017986857318, 0.6691954417970275, 0.09980345350356967, 0.16730090589252977, 0.15647149377332403, 0.545423688747076, 0.19797733709988585, 0.20667387609970778, 0.6527949662114649, 0.16457138017208583, 0.2082427156980553, 0.10432018393171316, 0.7909637355072053, 0.20314665785643848, 0.19421878788378366, 0.19953872282901164, 0.20002491305799708, 0.1957396072822053, 0.21494603497365872, 0.18350450073776114, 0.20639984757737606, 0.19878603614581225, 0.21354340595700327, 0.08076183273872406, 0.08180942671571034, 0.07993429589847689, 0.07671883241067667, 0.0798139818278174, 0.09303525775908439, 0.09018626527947982, 0.09394455292734238, 0.09277546080881349]}, "mutation_prompt": null}
{"id": "a0873015-8eeb-42a4-8dab-bf962b176c4d", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w = 0.729\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        def gaussian_perturbation(position, sigma=0.1):\n            return np.clip(position + np.random.normal(0, sigma, self.dim), self.lower_bound, self.upper_bound)\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with dynamic topology\n            neighborhood_size = max(1, int(self.population_size * (1 - self.num_evals / self.budget)))\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                local_best = min(personal_best_positions[np.random.choice(self.population_size, neighborhood_size)], \n                                 key=lambda pos: func(pos))\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (local_best - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                perturbed_trial = gaussian_perturbation(trial)\n                trial_score = func(perturbed_trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = perturbed_trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = perturbed_trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A hybrid PSO-DE algorithm with adaptive local search using Gaussian perturbations and dynamic topology to enhance exploration and exploitation.", "configspace": "", "generation": 5, "fitness": 0.12841884186201452, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.13 with standard deviation 0.17.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.23824012681039786, 0.21853884779479993, 0.2682967720976469, 0.254677860914999, 0.22858540677074557, 0.25703937546173594, 0.2711444322008939, 0.2683621829369759, 0.2301111433016998, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0008075233331806819, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05146518570789527, 0.051226507628113316, 0.051431738074232625, 0.050725357031092266, 0.05945239407318803, 0.05041286743640272, 0.06985064762276438, 0.050442287581741185, 0.06261223638403823, 0.05175989530334424, 0.04780629840566075, 0.036433727693233386, 0.054801382884560046, 0.043729892879829646, 0.04308164602881803, 0.04778813732121601, 0.03722012583026246, 0.045616264887924585, 0.883439758465423, 0.8522646096019022, 0.8511337249135973, 0.8486809031149996, 0.8525266826775042, 0.8844810399058536, 0.8459431305078401, 0.7767397604712034, 0.8823765842810126, 0.08810582373776121, 0.055292477765103154, 0.12030113621453165, 0.08210874633670229, 0.12376857704165245, 0.11832842222329965, 0.08359144490944348, 0.09646684831406183, 0.07023770533197216, 0.15902803389696873, 0.12083153070028707, 0.12350749505011227, 0.15935028369262927, 0.15619661416930308, 0.14318821019874417, 0.1549936396041337, 0.1453461260959995, 0.14031424091674138, 0.06882730343828114, 0.010502262022684006, 0.044698854727770576, 0.022246294911693276, 0.06462238674430099, 0.039548526661735695, 0.039026532445445405, 0.05872680867581581, 0.06430741780664195, 0.03643475238011906, 0.03472923878992806, 0.04156014589668244, 0.06518578495595828, 0.06687065654696855, 0.06205048115532741, 0.06914344286403995, 0.017094240809817696, 0.008629052438347773, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012894189257166344, 0.019041753275486406, 0.0789041578544567, 0.017729679517864527, 0.0002509461871591512, 0.00042197150898792835, 0.03555905011019134, 0.03915960020515252, 0.021325535793942585, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02389883169026341, 0.0013811315027615345, 0.04068287325008446, 0.01012095870563734, 0.0129417216729667, 0.02663000724534681, 0.013490535486419097, 0.023671154797062943, 0.017422628097861548, 0.24028588507623205, 0.24298460985810166, 0.24435575719179392, 0.2596843489639439, 0.2417656150367279, 0.2611134020388477, 0.23517313036044984, 0.23448879529948885, 0.2601239050116737, 0.05069582240457404, 0.056600354406701414, 0.036574447963227286, 0.053085637139238084, 0.052424672068528855, 0.08012096756611264, 0.049578797309760225, 0.046120636553286354, 0.05365567935138227, 0.13470980258651966, 0.10559867585348803, 0.0973982982945385, 0.11660717804300835, 0.10852972522114013, 0.0997977337121545, 0.13437387365726805, 0.09412572193047453, 0.10164464356496805, 0.17787043938450608, 0.17507043159092295, 0.17631228857235037, 0.1968320672435253, 0.16177505850814888, 0.1905328884096159, 0.18065551199356378, 0.20735382022217386, 0.16757730090690348, 0.10899531229790826, 0.11146063743155832, 0.10978166711734227, 0.12741172797815037, 0.11790675880222512, 0.1181985441651926, 0.10657647501289225, 0.14248444874245614, 0.07929593572525062, 0.14846150532723368, 0.1366368998159183, 0.1481866531834165, 0.14137815442545798, 0.1574274667111475, 0.16389300359578451, 0.15694258483740564, 0.15451293906008645, 0.16742979263843716, 0.13627750769926184, 0.1441094510579929, 0.14544545928389674, 0.15711616248522386, 0.13771534074688374, 0.1639553468716387, 0.1395931194370642, 0.15995843143944988, 0.14330238050329913, 0.15555305366770877, 0.13661609247897122, 0.1456348836530046, 0.14753123963694292, 0.15087603929900684, 0.15357121135410778, 0.1070538277241414, 0.15503398803489998, 0.10373078217976617, 0.20958862826417135, 0.16160058207019246, 0.09741583128821418, 0.16209263690076237, 0.17292047249961273, 0.14878849086961854, 0.13242346536922045, 0.12646700002917965, 0.17923156596922196, 0.15595535873088107, 0.16548361286349844, 0.15066954006236866, 0.15997016272361364, 0.1513875056013998, 0.16125247419705557, 0.15196462512326092, 0.15039359864983415, 0.16921655923518064, 0.047306560943496834, 0.05326804689983344, 0.049826056526854345, 0.05413920349044765, 0.04941029319486956, 0.049745415289728756, 0.053736474325088435, 0.04411887750608989, 0.05190933188842739]}, "mutation_prompt": null}
{"id": "ac5e149c-b498-4877-a48c-65dc1c05f89b", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "1fa38bba-9ef7-4505-aa86-9ec3d980bf8f", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE_Improved:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start, self.c1_end = 2.0, 0.5\n        self.c2_start, self.c2_end = 0.5, 2.0\n        self.w_start, self.w_end = 0.9, 0.4\n        self.F_start, self.F_end = 0.5, 0.9\n        self.CR_start, self.CR_end = 0.8, 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return c1, c2, w, F, CR\n\n        def opposition_based_learning(swarm):\n            return self.lower_bound + self.upper_bound - swarm\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            c1, c2, w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with opposition-based learning\n            opposite_swarm = opposition_based_learning(swarm)\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                # Evaluate both the trial and the opposite\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                opposite_trial_score = func(opposite_swarm[i])\n                self.num_evals += 1\n\n                # Choose better between trial and opposite\n                if opposite_trial_score < trial_score:\n                    trial_score = opposite_trial_score\n                    trial = opposite_swarm[i]\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE_Improved", "description": "Hybrid PSO-DE with adaptive parameters and enhanced swarm diversity using differential mutation and opposition-based learning.", "configspace": "", "generation": 7, "fitness": 0.3184655852283925, "feedback": "The algorithm EnhancedHybridPSO_DE_Improved got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.22.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.6712938657339886, 0.6944180588982958, 0.6557867926438006, 0.6885417402356186, 0.6868074877137338, 0.6961300512557503, 0.67141474736516, 0.6702611545114256, 0.6496318614182226, 0.4100181123665314, 0.39304729163586705, 0.4481193193202947, 0.42479830066242574, 0.4429715743324817, 0.40941372128209064, 0.39510111980795426, 0.43098128314461415, 0.40885981193785115, 0.13564041043123176, 0.23852761729292493, 0.13987594730707864, 0.11348740609343932, 0.12408538508440248, 0.341996873688723, 0.13310038924160994, 0.10784626831010569, 0.13208319020878023, 0.13971253178953247, 0.09088327354006975, 0.10567297675264076, 0.11709072798976672, 0.10714890593963478, 0.10879516670031697, 0.12361501665747132, 0.10973846835816459, 0.10286079204414145, 0.9761815528195578, 0.9724739707845285, 0.9682925142066817, 0.976528006619141, 0.972320624749549, 0.9772080195395353, 0.9763829231094397, 0.9713755664032977, 0.9767206429056774, 0.44622529443823666, 0.41571584408621787, 0.43462135033275473, 0.3904220069968344, 0.41665608013142275, 0.4077004108534452, 0.4110621329081796, 0.4098043117932936, 0.2857864756490558, 0.6683537102547881, 0.6254726043202117, 0.6691936925746125, 0.6180568998318688, 0.67547576319096, 0.6496342988964419, 0.6539142413310232, 0.6635020210965639, 0.6287709440772384, 0.21337226545118604, 0.24431108010353508, 0.1823520476563234, 0.19070811335240856, 0.24727618521639538, 0.22660057913314413, 0.24296863927497248, 0.23199662618631267, 0.2113717310431409, 0.22420003538334754, 0.21487285077963758, 0.23065314172272466, 0.18154915509056535, 0.2588065603687213, 0.2612391523205916, 0.29371180939001884, 0.27709810161705684, 0.23780789713301642, 0.1502575634808272, 0.11171210304677448, 0.16315959642408562, 0.18112899926976733, 0.19074198739199566, 0.11971750289570249, 0.1357982073135623, 0.19963909075019248, 0.18254167673057575, 0.34661746856601416, 0.1820291593597817, 0.2791062063405695, 0.2738886692035306, 0.2694516118135041, 0.16812341569542966, 0.3481714797960851, 0.33743026620168626, 0.3083196117484094, 0.0749225201561583, 0.0945215648460691, 0.06898517097319667, 0.08029333593661192, 0.036484389020410846, 0.07447078633684856, 0.08293704212005926, 0.0832304810061234, 0.10498198874496434, 0.14826910408108418, 0.18188908470354004, 0.19327710946437737, 0.18126624446897333, 0.20331840584365624, 0.18431055008643993, 0.18238454769790546, 0.19804710297858452, 0.1975294457324669, 0.5205717401570719, 0.5293359651116216, 0.5077861082824321, 0.53617720388494, 0.5385428159611416, 0.5405140682629024, 0.5060622941520798, 0.5484106663805562, 0.5022320575872229, 0.10882807305507469, 0.08935735321444316, 0.1338209194436969, 0.1000042849958882, 0.10575866167948078, 0.11948072068679572, 0.0956365881667589, 0.09319345785158839, 0.09674975774133676, 0.15338110214266776, 0.15986186257974044, 0.16487164942286126, 0.23396793261466542, 0.17271666485428594, 0.21422988329110748, 0.16665400033203548, 0.2819888617673595, 0.17211582109344947, 0.3701680469304641, 0.3752667693233127, 0.3870202315494856, 0.37845781229189623, 0.34863998923316275, 0.3800960395969418, 0.3799845802668508, 0.3846855543877128, 0.3686960434004989, 0.23551820397286638, 0.24978798367090005, 0.23381006351008693, 0.2719635338772364, 0.28392141152653216, 0.28432748645429307, 0.2872464904798965, 0.3117600503113256, 0.28421129057989836, 0.20798212970561503, 0.18837128266138847, 0.2142179321270169, 0.20513196414152557, 0.2064171827053407, 0.21087859629256434, 0.20713795350597086, 0.2349650609392484, 0.21187476207178502, 0.22773115553694856, 0.45716678363705987, 0.1879046065986374, 0.19205871664491136, 0.1864890716692046, 0.22357747985152832, 0.21049925322996965, 0.1967664631867514, 0.35036160382521575, 0.6370396316982727, 0.5634473425383144, 0.17769505113261386, 0.737724627863102, 0.44331264755815936, 0.7217466925230878, 0.18523071544546132, 0.6637992420539143, 0.20409536622051438, 0.5906694286808818, 0.4997832784244356, 0.6548509376906242, 0.5431869977914943, 0.19793389433519248, 0.5342083652875662, 0.20671864424022224, 0.19616596016838717, 0.1894246571079502, 0.2021589227001307, 0.19303642596369486, 0.21598583735095966, 0.1836791708574136, 0.1977794871853723, 0.17985607535662962, 0.20105677769263675, 0.19376961625318667, 0.19043865111532488, 0.07975073492998686, 0.07373634322855871, 0.090235659613779, 0.08202397483897206, 0.0807816590251692, 0.06881626896241666, 0.07614189161139906, 0.07557969086782701, 0.08190263956613053]}, "mutation_prompt": null}
{"id": "19ac53b2-5d54-44e4-a8c5-44da72db97ee", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "a555522c-2f4c-4ad5-bb39-3f02908460f6", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "105e7b93-4a72-4212-b19d-ea238b969741", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE_Diversity:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        def crowding_distance(population, scores):\n            distances = np.zeros(self.population_size)\n            sorted_indices = np.argsort(scores)\n            distances[sorted_indices[0]] = distances[sorted_indices[-1]] = np.inf\n            for d in range(self.dim):\n                sorted_indices_dim = np.argsort(population[:, d])\n                sorted_distances = np.diff(population[sorted_indices_dim, d])\n                sorted_scores = scores[sorted_indices_dim]\n                norm_factor = max(sorted_scores) - min(sorted_scores)\n                if norm_factor == 0:\n                    norm_factor = 1\n                sorted_distances /= norm_factor\n                for i in range(1, self.population_size - 1):\n                    distances[sorted_indices_dim[i]] += sorted_distances[i - 1] + sorted_distances[i]\n            return distances\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            scores = np.zeros(self.population_size)\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n                scores[i] = score\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # Calculate crowding distances\n            distances = crowding_distance(swarm, scores)\n            sorted_indices_by_distance = np.argsort(distances)[::-1]\n\n            # PSO update using diversity\n            for i in sorted_indices_by_distance:\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "AdaptiveHybridPSO_DE_Diversity", "description": "A novel Adaptive Hybrid PSO-DE with diversity preservation using crowding distance for enhanced exploration and exploitation balance.", "configspace": "", "generation": 10, "fitness": 0.3557998905414729, "feedback": "The algorithm AdaptiveHybridPSO_DE_Diversity got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.25.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.7745605558682546, 0.8000311550703021, 0.7799678530088396, 0.7894890218640132, 0.8025144292184082, 0.7981024112411161, 0.8180820329770051, 0.8029213866946247, 0.7907491130707968, 0.5304709643272439, 0.5910017991990024, 0.5602620065223702, 0.5815846066075443, 0.574320635871005, 0.5678184171063714, 0.5516685762028708, 0.5659913973218678, 0.5588758504738546, 0.1514705156637246, 0.13234794836276464, 0.15332903904779305, 0.15086847290620753, 0.13537690296354687, 0.13820760413391653, 0.11907094358899994, 0.04907735975395844, 0.13194986242954287, 0.139084976984027, 0.12721467455400803, 0.12367759186884864, 0.1303534449468049, 0.11582487768984606, 0.10514219996482965, 0.12386118969422333, 0.14950692741454097, 0.15361799145160038, 0.9904860666568112, 0.9819090857847401, 0.9889934478809813, 0.984520320060966, 0.9840949617129717, 0.9854096194775032, 0.9858319703696587, 0.9886267971048003, 0.9862294150561394, 0.45226708011606986, 0.4451886037320405, 0.5187539068503884, 0.5319762856116169, 0.5190878970185884, 0.5380325453503703, 0.5209779691163692, 0.41949687784209977, 0.44535425325594613, 0.8270922403505603, 0.7217743892476653, 0.7500294915596986, 0.718132073879768, 0.7861899001869522, 0.20374471912008862, 0.2281664003597903, 0.7569125555968115, 0.8047608359083918, 0.3215098103066736, 0.29567037734548074, 0.35210987569793284, 0.32187589075002254, 0.31159839645571297, 0.27018552743582824, 0.28800860177957066, 0.26970952675140214, 0.3332096404266346, 0.28241441606251316, 0.13408031830332656, 0.31505567010246016, 0.3468434351442662, 0.40384972612355363, 0.29803417189681847, 0.2985608378456249, 0.12119322984953651, 0.3247543435347694, 0.04684125539478812, 0.22067005192435796, 0.10406348296783308, 0.03820707630002307, 0.02465336445723476, 0.263188741119037, 0.30016716608352234, 0.1323833522458301, 0.3085392598819159, 0.4747878295939677, 0.4087667630794005, 0.39920100784753865, 0.46826186122208124, 0.2701313916132563, 0.2669480444642298, 0.5388286189444839, 0.4559408559866799, 0.46894863734948267, 0.05486420141432302, 0.21118890702416526, 0.13538086138038652, 0.20316384774737917, 0.18889563125711462, 0.15001547594409625, 0.21644135809042953, 0.12673185184074776, 0.08195690968437752, 0.040795766488672225, 0.25966339765368895, 0.2533815065168584, 0.12447207938111837, 0.3160808708712326, 0.006372031761282981, 0.24610014159146087, 0.2483989611147025, 0.24926834401477804, 0.6431464391419521, 0.6993208180133712, 0.689077965109763, 0.7013898206821176, 0.6701392927268801, 0.20910990337423674, 0.6177875696250623, 0.6623766693304821, 0.6564124725595207, 0.12677294206554723, 0.10557591779227227, 0.07668965748135903, 0.10589442879700295, 0.1171231348385845, 0.11872441859309124, 0.1464726156843692, 0.11790643184665373, 0.1366564251535265, 0.1735726044327497, 0.2601169983283006, 0.2094982700525002, 0.3785413403858269, 0.5942681901100683, 0.3190374121447167, 0.5494455632017087, 0.17512277320215908, 0.258114300359903, 0.3934391581078286, 0.429354155323445, 0.37017175369694755, 0.43938737683824625, 0.39838449853701396, 0.3827798365441042, 0.44291891805796546, 0.41812841911152465, 0.390665190019455, 0.29965592218637627, 0.3007831277254417, 0.2068660912274204, 0.3042505882899089, 0.2978897985655844, 0.3435853452581671, 0.27965143004553406, 0.352666368903475, 0.3733236971469912, 0.20231443348406797, 0.23041583887922312, 0.20758659123217849, 0.22353603867080352, 0.23536231488664883, 0.18339818005819009, 0.19105924060844492, 0.20602670279932633, 0.2463706016283822, 0.22071561476202806, 0.2212105487574869, 0.23539712678558455, 0.22741019539006724, 0.22229533452957684, 0.40384807205294215, 0.20570236487652094, 0.3889282663887308, 0.514471013632397, 0.1742701537921042, 0.1777770526179946, 0.15493187684676246, 0.8307498014153507, 0.20537451108181637, 0.13059205598374046, 0.8363685029807011, 0.16994924590246085, 0.1629078725694384, 0.08303510289438054, 0.2098217063789003, 0.7069940208841501, 0.20183977954470433, 0.7152496918672184, 0.208897105200056, 0.10457542750893412, 0.8610271521987053, 0.6571968996890584, 0.18274266852669785, 0.18130074358412807, 0.1788335123979412, 0.2017235842925199, 0.17870668678844215, 0.1833892400094459, 0.18502984754087604, 0.1855771911966474, 0.19418071879809484, 0.09044559857208223, 0.09197146393147682, 0.09198403946235889, 0.14492137578740183, 0.09320244333581218, 0.07990081807984606, 0.0946323521837299, 0.08895597577854464, 0.08067646195679934]}, "mutation_prompt": null}
{"id": "4e24e398-f801-48d5-92af-2d85bf38fd52", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "3cd3d0d0-f0f4-4ccd-8035-5c08b401408a", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "ceeb8229-f4c3-4e38-a760-709389d30897", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "7816cc6a-f563-4b63-9874-9c199ecf04a6", "solution": "import numpy as np\n\nclass DynamicMultiPhasePSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_initial = 1.5\n        self.c2_initial = 1.5\n        self.w_initial = 0.9\n        self.w_final = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            c1 = self.c1_initial * (1 - progress) + progress * 0.5\n            c2 = self.c2_initial * (1 - progress) + progress * 2.0\n            w = self.w_initial + progress * (self.w_final - self.w_initial)\n            return F, CR, c1, c2, w\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        memory_positions = np.copy(swarm)\n        memory_scores = np.full(self.population_size, np.inf)\n\n        while self.num_evals < self.budget:\n            F, CR, c1, c2, w = adapt_parameters()\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n                    if score < memory_scores[i]:\n                        memory_scores[i] = score\n                        memory_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                swarm[i] = swarm[i] + velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = memory_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "DynamicMultiPhasePSODE", "description": "A Dynamic Multi-phase Enhanced PSO-DE with Adaptive Memory for improved exploration and exploitation balance.", "configspace": "", "generation": 14, "fitness": 0.25753464808667687, "feedback": "The algorithm DynamicMultiPhasePSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.22.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.6311347205084978, 0.5846039482289203, 0.5734224146876863, 0.6575253866526627, 0.6858464392277608, 0.6526923686171159, 0.6753954288104667, 0.6025370348756642, 0.6518066613644109, 0.48889228187779055, 0.25201302283863813, 0.2352850141581373, 0.3357048514335218, 0.3540958410101286, 0.3370849793000218, 0.03745180720010299, 0.4029154561396059, 0.04175315701371707, 0.13803000727476322, 0.1294363865670659, 0.10999671111548637, 0.12581496858299324, 0.12960974523147228, 0.11180995017048012, 0.15691693847697463, 0.1348997341540138, 0.14200109665991734, 0.11013371477456169, 0.1190129526963214, 0.11097491515920122, 0.0954281038285224, 0.11064816800352728, 0.09169192539569582, 0.12720913036656623, 0.12523080241505302, 0.09364477707791374, 0.9875919978817242, 0.9877573056601734, 0.988914313277581, 0.9867503959109073, 0.9852571509887382, 0.978668974449922, 0.9916564823260131, 0.9910872294378066, 0.9870567034682277, 0.4185990766846517, 0.39275761892767536, 0.4223986679407157, 0.4153820073879164, 0.3835091053087606, 0.46968124931843025, 0.41395463290761636, 0.3678290369108045, 0.08712755000399575, 0.22009641271300784, 0.5384749142828937, 0.5605911711258582, 0.19664599002339223, 0.20744381212056573, 0.5796798354708668, 0.6183558190892802, 0.4860245054671932, 0.20623716916237567, 0.16970878196633055, 0.22585393766037043, 0.16171940267146256, 0.21612675385058477, 0.18395953758500982, 0.17975225335745837, 0.16230456974493157, 0.17823008815183128, 0.21747443776999875, 0.16734397939002132, 0.05258101942396387, 0.16973047447035938, 0.17457219657070733, 0.13543145123785238, 0.23637941347889435, 0.20208541963718885, 0.10937593714368088, 0.20226757897628223, 0.02125792352558853, 0.07480750728514418, 0.04228796527352496, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0022114362878830063, 0.0020797411259890763, 0.041939629750836316, 0.07487884338385142, 0.14287490944237347, 0.184544417544366, 0.12622604808405302, 0.019331040249985776, 0.07269353913668597, 0.12639838539891846, 0.07694783601493727, 0.1498318550140859, 0.032341290428681724, 0.02236200715590786, 0.09909833904329612, 0.09628220016803646, 0.058834225887399394, 0.048512329700388324, 0.05839903136942526, 0.061086389331049595, 0.04124125295694936, 0.03815544748962352, 0.10050400491330203, 0.14912412621516702, 0.00508108553300024, 0.12168748570109345, 0.148408392592012, 0.1172852317460118, 0.12258361355334568, 0.06902767059225023, 0.4352034105877177, 0.44605840487089343, 0.5054555124018957, 0.43574592783262, 0.45965980606117396, 0.4909615229707207, 0.45115265836502105, 0.494310513922801, 0.4818937671649709, 0.0851360730125259, 0.10869739374294973, 0.07917587025759021, 0.09073600666549464, 0.13253713395215105, 0.3050933841683562, 0.10107136080982893, 0.11042565654055758, 0.09502063253461623, 0.30718828292889755, 0.14036194615958453, 0.2032345513730338, 0.23161313630919989, 0.32577513279662407, 0.18973672080222814, 0.18889724442932665, 0.23386247044788455, 0.22563174974757916, 0.3446911265118675, 0.3515585317484531, 0.34046569018316963, 0.38920441684761253, 0.35388184305307746, 0.3174935899329653, 0.32669944291233577, 0.43892587604878763, 0.31380829991873904, 0.29754173774629755, 0.22270881418349786, 0.13421258898823907, 0.18166695833800572, 0.17766964628724802, 0.26937307100893904, 0.25351582604427503, 0.31203655988755485, 0.23162170295763962, 0.1962801174097356, 0.20599252851262417, 0.21023892348411577, 0.19585842796625608, 0.21058502069144847, 0.20154654963005958, 0.21036428675845986, 0.2113505828939185, 0.23102185670685282, 0.19645576037156753, 0.20921857470764882, 0.1891232836093144, 0.31447716428834305, 0.4234526799556778, 0.19079745963076344, 0.19377120944128523, 0.4517273112694429, 0.19704030389544736, 0.726456359799676, 0.16349017220291318, 0.15219345444789234, 0.2030338325116181, 0.19370432024327278, 0.6573767019060799, 0.14541379471769555, 0.16725884106351585, 0.17280345521325036, 0.11745225009698956, 0.16348367956278598, 0.10891723423519539, 0.1583730179463011, 0.5247697638240405, 0.20248452772518766, 0.12474394730938454, 0.1989925417842594, 0.20445010913573292, 0.19398121018092163, 0.1750462926116252, 0.19266641879519797, 0.1875647695026843, 0.1858005445693398, 0.18429215928770704, 0.21848053094351183, 0.17556147136279177, 0.18209915404385568, 0.07794374118622815, 0.08661401609399288, 0.09678687441915645, 0.07849378144714081, 0.0801858842363159, 0.08405836090696772, 0.09594354727488841, 0.0940573474578481, 0.07579343887376422]}, "mutation_prompt": null}
{"id": "d2f4ffae-8855-46b4-9851-22b0a407f3d3", "solution": "import numpy as np\n\nclass DynamicHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w_start = 0.9  # Starting inertia weight\n        self.w_end = 0.4  # Ending inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            return F, CR, w\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR, w = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crowding mechanism\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "DynamicHybridPSO_DE", "description": "A dynamic swarm and mutation strategy that enhances exploration and exploitation balance by using adaptive inertia and a crowding mechanism to maintain diversity and convergence.", "configspace": "", "generation": 15, "fitness": 0.3540911225009432, "feedback": "The algorithm DynamicHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.24.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.7180218045843446, 0.7439183910504408, 0.7258656343405582, 0.75021831714472, 0.7668434046354452, 0.1896364948701862, 0.733950807823921, 0.7364190212195287, 0.7358009265462481, 0.550107313477674, 0.4673877341477388, 0.5476348243105826, 0.5464460389640212, 0.5380902563414932, 0.5477017395107686, 0.520865610799278, 0.5363204722957357, 0.5713947725183386, 0.12697070357870832, 0.12678371034118863, 0.2893583815181129, 0.13485871653149895, 0.14074246407835866, 0.14036844310327667, 0.11638105980792335, 0.3498718606100195, 0.10757737398824663, 0.23767902789535578, 0.1300948632163612, 0.11143387478850653, 0.1213973657597478, 0.12687438162606945, 0.10362770992113035, 0.11504634545620651, 0.12196820195912894, 0.10087290710775032, 0.9875900121994992, 0.9871728311783111, 0.9902473020628226, 0.9867480820235206, 0.9846859931708151, 0.9791660835085194, 0.9916550466157732, 0.9856988071971005, 0.9850918694542827, 0.4906024154700632, 0.4893648945243265, 0.496961761510597, 0.5242036053354158, 0.558649891390899, 0.42041339414742473, 0.48024472243750216, 0.48433863374594444, 0.4979528832720749, 0.5840508074978028, 0.755113686133309, 0.7535968058392044, 0.7576288848267266, 0.7147246368165895, 0.7674249550886403, 0.6891253219675184, 0.12528672929428775, 0.7885190207817206, 0.31593929653624186, 0.2938395542724632, 0.3231992206844091, 0.30143308662135837, 0.12493155297800262, 0.3487612937076897, 0.3787596888815328, 0.35091838542929676, 0.3074125048851186, 0.2601306428796104, 0.31558151424399916, 0.33564020014798956, 0.283919822209853, 0.3960600077112505, 0.29450839847578214, 0.34355350286910113, 0.23709890444079562, 0.12696453268887908, 0.04540677482310296, 0.3453215003981913, 0.17608966462291498, 0.1432560136103631, 0.2581360546129552, 0.335077394208128, 0.35477164246425663, 0.10896228159835286, 0.3025919143938639, 0.42621049073081996, 0.3813165806280697, 0.4835167995931907, 0.3441697965142284, 0.33114924529803313, 0.16233192711674416, 0.5205094049515784, 0.48728380827976536, 0.18804857688814436, 0.08907023040157169, 0.13177270547670028, 0.06575499640818194, 0.19273382760337066, 0.09122356371530316, 0.16042678014693534, 0.11955200878410599, 0.08232800178626987, 0.1062646408463912, 0.27083622557078213, 0.22595288854039708, 0.24627152128244378, 0.26821985328147, 0.25558935179386866, 0.27608363308990047, 0.2662914282723515, 0.2662390517790165, 0.2029452490334005, 0.6819183809369429, 0.6064527597937908, 0.6683134872228138, 0.5946402924937411, 0.6263717615138811, 0.20789543146623501, 0.6256920902919034, 0.5863564707683306, 0.6294096907573787, 0.12059537447561419, 0.07258828960257269, 0.10931721117568649, 0.10821820196272003, 0.1253571207159524, 0.10433565300851222, 0.27050621832348554, 0.11891309131338135, 0.11725755297499185, 0.24176298515770156, 0.14173179105148537, 0.18453942586825578, 0.22756217538311752, 0.32028960800388184, 0.17606535218267183, 0.41610085987085765, 0.19056099590825903, 0.23995533887962706, 0.3914033855774586, 0.4439186175966895, 0.40430025507916667, 0.4222730743574272, 0.37858930855833417, 0.4554048693149503, 0.41692412411931745, 0.4368151304212109, 0.4953562662513742, 0.24116069383018923, 0.3028276977713852, 0.3272139859183545, 0.2945788978097621, 0.20633017692635636, 0.32090255101454257, 0.3155809193197644, 0.3491122028236242, 0.2953879244333527, 0.203927956786219, 0.19431892897978464, 0.22096209788399002, 0.20574208135616479, 0.18748936050161225, 0.19274281767474766, 0.19413628859978893, 0.2117309997347695, 0.2207819525684388, 0.48355755576311343, 0.45630908797067227, 0.21117183313075594, 0.1947213650620171, 0.5901481927033185, 0.22023732218690584, 0.47099543700253466, 0.45058540215373233, 0.2056508925624333, 0.851991275240008, 0.19042979077054956, 0.17344689399835733, 0.7729012121292208, 0.7374933048446847, 0.204756554336883, 0.12456056975074137, 0.1690841667747156, 0.19788894746950592, 0.740315311096134, 0.16898973201173562, 0.19984673901415106, 0.20464310873668512, 0.6972551741161477, 0.2078343591771935, 0.20656418981918379, 0.8051668563473513, 0.209466608738894, 0.1906438159198366, 0.1930735598493053, 0.20261910556485563, 0.19253438444275528, 0.210588658010619, 0.21212784744494406, 0.18993066491955302, 0.18712767711902145, 0.2253265811162053, 0.07880898643733159, 0.08312835014290998, 0.09207167920742321, 0.08471743955532096, 0.08858462115500187, 0.0904534105848046, 0.07155711057514835, 0.07900780124157192, 0.0876007361290978]}, "mutation_prompt": null}
{"id": "5bf5e689-bbcb-43f4-9c6a-b57f5c2babb6", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "2347315e-3355-4447-9903-5f1e2b1abd4b", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "79c34ac6-9ed2-4540-94a3-03595a9bc91d", "solution": "import numpy as np\n\nclass DynamicFuzzyPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_max = 0.9\n        self.w_min = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            w = self.w_max - (self.w_max - self.w_min) * progress\n            return F, CR, w\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR, w = adapt_parameters()\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.clip(a + F * (b - c), self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "DynamicFuzzyPSO_DE", "description": "A Stochastic Population-based Adaptive Hybrid PSO-DE with Dynamic Fuzzy Inertia Weight for Enhanced Exploration-Exploitation Balance.", "configspace": "", "generation": 18, "fitness": 0.3540911225009432, "feedback": "The algorithm DynamicFuzzyPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.24.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.7180218045843446, 0.7439183910504408, 0.7258656343405582, 0.75021831714472, 0.7668434046354452, 0.1896364948701862, 0.733950807823921, 0.7364190212195287, 0.7358009265462481, 0.550107313477674, 0.4673877341477388, 0.5476348243105826, 0.5464460389640212, 0.5380902563414932, 0.5477017395107686, 0.520865610799278, 0.5363204722957357, 0.5713947725183386, 0.12697070357870832, 0.12678371034118863, 0.2893583815181129, 0.13485871653149895, 0.14074246407835866, 0.14036844310327667, 0.11638105980792335, 0.3498718606100195, 0.10757737398824663, 0.23767902789535578, 0.1300948632163612, 0.11143387478850653, 0.1213973657597478, 0.12687438162606945, 0.10362770992113035, 0.11504634545620651, 0.12196820195912894, 0.10087290710775032, 0.9875900121994992, 0.9871728311783111, 0.9902473020628226, 0.9867480820235206, 0.9846859931708151, 0.9791660835085194, 0.9916550466157732, 0.9856988071971005, 0.9850918694542827, 0.4906024154700632, 0.4893648945243265, 0.496961761510597, 0.5242036053354158, 0.558649891390899, 0.42041339414742473, 0.48024472243750216, 0.48433863374594444, 0.4979528832720749, 0.5840508074978028, 0.755113686133309, 0.7535968058392044, 0.7576288848267266, 0.7147246368165895, 0.7674249550886403, 0.6891253219675184, 0.12528672929428775, 0.7885190207817206, 0.31593929653624186, 0.2938395542724632, 0.3231992206844091, 0.30143308662135837, 0.12493155297800262, 0.3487612937076897, 0.3787596888815328, 0.35091838542929676, 0.3074125048851186, 0.2601306428796104, 0.31558151424399916, 0.33564020014798956, 0.283919822209853, 0.3960600077112505, 0.29450839847578214, 0.34355350286910113, 0.23709890444079562, 0.12696453268887908, 0.04540677482310296, 0.3453215003981913, 0.17608966462291498, 0.1432560136103631, 0.2581360546129552, 0.335077394208128, 0.35477164246425663, 0.10896228159835286, 0.3025919143938639, 0.42621049073081996, 0.3813165806280697, 0.4835167995931907, 0.3441697965142284, 0.33114924529803313, 0.16233192711674416, 0.5205094049515784, 0.48728380827976536, 0.18804857688814436, 0.08907023040157169, 0.13177270547670028, 0.06575499640818194, 0.19273382760337066, 0.09122356371530316, 0.16042678014693534, 0.11955200878410599, 0.08232800178626987, 0.1062646408463912, 0.27083622557078213, 0.22595288854039708, 0.24627152128244378, 0.26821985328147, 0.25558935179386866, 0.27608363308990047, 0.2662914282723515, 0.2662390517790165, 0.2029452490334005, 0.6819183809369429, 0.6064527597937908, 0.6683134872228138, 0.5946402924937411, 0.6263717615138811, 0.20789543146623501, 0.6256920902919034, 0.5863564707683306, 0.6294096907573787, 0.12059537447561419, 0.07258828960257269, 0.10931721117568649, 0.10821820196272003, 0.1253571207159524, 0.10433565300851222, 0.27050621832348554, 0.11891309131338135, 0.11725755297499185, 0.24176298515770156, 0.14173179105148537, 0.18453942586825578, 0.22756217538311752, 0.32028960800388184, 0.17606535218267183, 0.41610085987085765, 0.19056099590825903, 0.23995533887962706, 0.3914033855774586, 0.4439186175966895, 0.40430025507916667, 0.4222730743574272, 0.37858930855833417, 0.4554048693149503, 0.41692412411931745, 0.4368151304212109, 0.4953562662513742, 0.24116069383018923, 0.3028276977713852, 0.3272139859183545, 0.2945788978097621, 0.20633017692635636, 0.32090255101454257, 0.3155809193197644, 0.3491122028236242, 0.2953879244333527, 0.203927956786219, 0.19431892897978464, 0.22096209788399002, 0.20574208135616479, 0.18748936050161225, 0.19274281767474766, 0.19413628859978893, 0.2117309997347695, 0.2207819525684388, 0.48355755576311343, 0.45630908797067227, 0.21117183313075594, 0.1947213650620171, 0.5901481927033185, 0.22023732218690584, 0.47099543700253466, 0.45058540215373233, 0.2056508925624333, 0.851991275240008, 0.19042979077054956, 0.17344689399835733, 0.7729012121292208, 0.7374933048446847, 0.204756554336883, 0.12456056975074137, 0.1690841667747156, 0.19788894746950592, 0.740315311096134, 0.16898973201173562, 0.19984673901415106, 0.20464310873668512, 0.6972551741161477, 0.2078343591771935, 0.20656418981918379, 0.8051668563473513, 0.209466608738894, 0.1906438159198366, 0.1930735598493053, 0.20261910556485563, 0.19253438444275528, 0.210588658010619, 0.21212784744494406, 0.18993066491955302, 0.18712767711902145, 0.2253265811162053, 0.07880898643733159, 0.08312835014290998, 0.09207167920742321, 0.08471743955532096, 0.08858462115500187, 0.0904534105848046, 0.07155711057514835, 0.07900780124157192, 0.0876007361290978]}, "mutation_prompt": null}
{"id": "4d01bce2-9613-4ae8-bdf8-d97f586ce1f0", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "142c3d5e-de20-44aa-b88f-f94fc826bf10", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "76bde572-ec4b-4f4b-bc94-06ef983f66bc", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "64735759-69a5-470a-bfed-3453e13f2288", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE_v2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 30  # Increased population size for better exploration\n        self.c1_start = 2.5  # Adjusted initial cognitive component\n        self.c2_start = 0.5  # Adjusted initial social component\n        self.c1_end = 0.5    # Decrease cognitive over time\n        self.c2_end = 2.5    # Increase social over time\n        self.w_start = 0.9   # Increased initial inertia weight for exploration\n        self.w_end = 0.4     # Decrease inertia over time for convergence\n        self.F_start = 0.4\n        self.F_end = 0.9\n        self.CR_start = 0.6\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, c1, c2, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE_v2", "description": "An enhanced Hybrid PSO-DE algorithm with dynamic parameter adaptation and local search for improved exploration-exploitation balance and solution accuracy.", "configspace": "", "generation": 22, "fitness": 0.28599115619617094, "feedback": "The algorithm EnhancedHybridPSO_DE_v2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.22.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.6069393046455446, 0.5794543879299331, 0.5933324515863061, 0.6280355931649875, 0.6018757921161619, 0.6389984330821119, 0.63233115795074, 0.6012616459479587, 0.6318633633284729, 0.3236064620424114, 0.3660042605658381, 0.3139537821265357, 0.3402899452323739, 0.3379572408156202, 0.3246670335813251, 0.3430219875972498, 0.3432446768546217, 0.325505762828324, 0.10509297060524625, 0.13293855950284827, 0.1528376521182303, 0.13126861548423696, 0.11427876624391742, 0.13215074953645034, 0.10521787037905672, 0.1174086379511955, 0.12178863141849383, 0.09136307067844696, 0.10940318720851172, 0.09889206283965069, 0.11890763278831695, 0.10485771768891594, 0.11415480188015659, 0.10089367670573468, 0.1209209166455203, 0.10003768359838683, 0.9777228794076481, 0.9772645317644928, 0.9732861504881491, 0.9691690693530814, 0.9801351545151957, 0.9700677621879716, 0.9675121502491851, 0.9750921777608932, 0.9769714779819086, 0.36713592620081326, 0.3493698107409696, 0.3763537415708761, 0.34637359607896856, 0.3472253129424894, 0.364097881661397, 0.3937832924059187, 0.3654351919260246, 0.3360890508795965, 0.5754728948038443, 0.4740964422488705, 0.5316696831370655, 0.6015151929103211, 0.5867173544767572, 0.5901732380839104, 0.5524991173697653, 0.3938730055705356, 0.520599467903285, 0.2553194593006408, 0.20389857680979795, 0.20514858111112066, 0.19963168529836783, 0.20140448383598641, 0.22012077964300614, 0.18877408695488074, 0.18237023398635865, 0.19281092928747756, 0.21226269325125158, 0.10238795660849431, 0.1885947991028466, 0.218484105003802, 0.2116937684041692, 0.20905061467086428, 0.18706533615679666, 0.20867050738848136, 0.21271161987922838, 0.04825218312383006, 0.03538472138816773, 0.08456629947922933, 0.08920162169798818, 0.056431756980177106, 0.04453107459936123, 0.04947679719860332, 0.0356447067248411, 0.0667011377524217, 0.18655608099859677, 0.14926705999822898, 0.19069158991023982, 0.15364294095410025, 0.1351485122197561, 0.15540042466418724, 0.22302504847133764, 0.20980301477869234, 0.1833588667698819, 0.02525865931438165, 0.023603975912959485, 0.01766108695488422, 0.05326162430358816, 0.03778018002791472, 0.021586459073438036, 0.04798768495635031, 0.031895611745068164, 0.04444871706447118, 0.13448521825225523, 0.15014714291437536, 0.11700263093739027, 0.1398331374654319, 0.1508225541593441, 0.15776962157440944, 0.14310970161074887, 0.12822459616006276, 0.11699407470259615, 0.4506031167852115, 0.45062055894656083, 0.49632822273053456, 0.4741497925671485, 0.46127485033767035, 0.46986963367731494, 0.4925110791692987, 0.45820127707411606, 0.4780196163778677, 0.10615309932572436, 0.11721801910061025, 0.0950531627804303, 0.12296394507173103, 0.13351641006241555, 0.12578817623492122, 0.18328219939762125, 0.10243740255976941, 0.1286047469615984, 0.15581807502562228, 0.17221930737984714, 0.21041975275811953, 0.20358287319607304, 0.1966289928752072, 0.16801221701774594, 0.18501631213394554, 0.1749786416016541, 0.16536294285914988, 0.35873247283645004, 0.34690701406919233, 0.3413628496569676, 0.32958545741887435, 0.3169121582748926, 0.3529664420804318, 0.37552694387106156, 0.33044936554007354, 0.3453977185881235, 0.23302338242116272, 0.27287568708607723, 0.25130341675393, 0.2275575633201965, 0.23637869028025882, 0.2646929641900445, 0.2701489601619401, 0.2697937431074384, 0.2970226738863011, 0.20099809095931154, 0.1966040953655086, 0.19350000654085298, 0.20174853087652522, 0.19752475772354894, 0.18914103136526417, 0.22140488606327002, 0.19772050084674198, 0.22703673967928673, 0.3545230507745516, 0.2004806983633467, 0.2003974380272444, 0.28640633480117594, 0.1858826978308059, 0.2102904411663562, 0.33236354433422743, 0.21783142014615675, 0.21756869869666806, 0.6425740434739791, 0.692473402414919, 0.6544900649584979, 0.5776158494285044, 0.6493263458969635, 0.19091395947096357, 0.6411547455144413, 0.5116806558982584, 0.6155831460346324, 0.5589187556530921, 0.19694932323888248, 0.5917656363443213, 0.2033362673211906, 0.41360510348599233, 0.529913764767109, 0.20262164695705687, 0.2021178585721798, 0.16400116258916753, 0.18541409526053576, 0.17550422757991568, 0.18650781726842192, 0.18344144390163108, 0.18763548466317448, 0.18890731151424878, 0.18267100228962896, 0.19911608659168245, 0.19770897763875317, 0.07757973288404851, 0.09019563203102843, 0.07561047894629247, 0.08348225764579253, 0.08451956159779261, 0.08059064376174496, 0.07343449383579903, 0.08190256343946933, 0.08631653356798674]}, "mutation_prompt": null}
{"id": "c83e14de-fa0f-45d9-a076-ff6ad104c76e", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "ecce348f-6057-4d7b-98e8-7b0365eb7ec9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "3aaa4f66-2507-468d-be04-3fd88f2672e4", "solution": "import numpy as np\n\nclass AdaptiveMemoryEnhancedPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w = 0.729\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.memory_size = 5  # Size of memory to maintain diversity\n        self.memory = []\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        def update_memory(position):\n            if len(self.memory) < self.memory_size:\n                self.memory.append(position)\n            else:\n                worst_index = np.argmax([func(mem) for mem in self.memory])\n                if func(position) < func(self.memory[worst_index]):\n                    self.memory[worst_index] = position\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n                update_memory(swarm[i])\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with memory influence\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                if self.memory:  # Use memory influence\n                    memory_influence = self.memory[np.random.choice(len(self.memory))]\n                    mutant = a + F * (b - c) + 0.1 * (memory_influence - a)\n                else:\n                    mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "AdaptiveMemoryEnhancedPSO_DE", "description": "An Adaptive Memory Enhanced PSO-DE integrating dynamic parameter tuning and memory for maintaining diversity and enhancing convergence.", "configspace": "", "generation": 25, "fitness": 0.1765518107986837, "feedback": "The algorithm AdaptiveMemoryEnhancedPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.19.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.41817736017719975, 0.3416858589665308, 0.3623581390840872, 0.41072866984957146, 0.41558704042844474, 0.39503482587228, 0.3497613408233119, 0.3800671557269194, 0.3817533523610498, 0.0830277683298365, 0.058541911929038015, 0.052671844377317756, 0.05179082088246889, 0.06518332040320529, 0.0620032369718414, 0.04424148983633369, 0.083166802414258, 0.08170605721243684, 0.07999754424548844, 0.07709438255019052, 0.07785551866650564, 0.09594394573922238, 0.0998986720817755, 0.07198269001324076, 0.08376024644636237, 0.0859491342533436, 0.0925630814613927, 0.07195056768012598, 0.06634334678159615, 0.06003583487078379, 0.07052407669203986, 0.09504636049785908, 0.07971487138031985, 0.07714661832017067, 0.06810112701834237, 0.07683428628209898, 0.9536028469734341, 0.9382189932449317, 0.9447722111093501, 0.9399192148553887, 0.9377603017191762, 0.8971907243200503, 0.9400338609749035, 0.9331813794069905, 0.9227121144569637, 0.17041544403126407, 0.1881019789613102, 0.13124774563069608, 0.1669202860510388, 0.18121351976950584, 0.18941045357201625, 0.19561944919055618, 0.08153174512171046, 0.18096410333245916, 0.20332019526293676, 0.17942939143230907, 0.22104780824935943, 0.27496487224575017, 0.22293664045403017, 0.25999210978713894, 0.14735587663582317, 0.24536862166267936, 0.20417240102542045, 0.07695110377614633, 0.10468359370263292, 0.09867718613939924, 0.10034800299715285, 0.13812073602427988, 0.11420581001371688, 0.09108572212807686, 0.10595831520091381, 0.12037974729040457, 0.10987880206237222, 0.014553323402589968, 0.1640502563675731, 0.10803643279039299, 0.12773044696030833, 0.12382249702680348, 0.10828544188336187, 0.08989353176723858, 0.06765870240413296, 9.999999999998899e-05, 9.999999999998899e-05, 0.018592265506831573, 9.999999999998899e-05, 0.004734228382075378, 0.001147044335892522, 9.999999999998899e-05, 9.999999999998899e-05, 0.0026045086533716955, 0.08242141423243587, 0.02629340193484464, 0.08711361459226807, 0.05255115264645227, 0.02914850073587716, 0.005708876768220739, 0.05187741032510762, 0.13829056492855873, 0.03957723532116686, 0.0004950894047991428, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006090186553930899, 9.999999999998899e-05, 0.0038508799203298416, 9.999999999998899e-05, 0.05513838191150566, 0.04910038467618871, 0.06306970260924571, 0.017113258139601406, 0.05926520766484178, 0.06419159495941562, 0.07798909526912468, 0.08058209117088466, 0.0593099479724184, 0.37471271978934717, 0.35358038571508643, 0.37690367853511086, 0.356685577388118, 0.3712609484438496, 0.3459688173581277, 0.3764444785782449, 0.34658041609350143, 0.3173261840230788, 0.08776223306209119, 0.0753598152630508, 0.08181748521738752, 0.06993202155244693, 0.08112686772390099, 0.08986116219861029, 0.06594131919208279, 0.09829827640010191, 0.06662983860682692, 0.1530811706154125, 0.13871783878116806, 0.12226176548797807, 0.14619859675099056, 0.13194480012743004, 0.11601119854800745, 0.1802926522762358, 0.11291263581000477, 0.11656916802272466, 0.23558731943602307, 0.25422411164262715, 0.2249980145117394, 0.25113644426335324, 0.22990789961312696, 0.24491769475490133, 0.25152429554748457, 0.26910024630360374, 0.23402439871517244, 0.15679603952769616, 0.17340881798216246, 0.12547241804373077, 0.1639438689902567, 0.17863251609933906, 0.16168280500952004, 0.1849820831667386, 0.19193776546939423, 0.16313488175343027, 0.17966769903784463, 0.1853345601932076, 0.16429420434678998, 0.16547917253248867, 0.19634702734398635, 0.15270018843498456, 0.1998096333435646, 0.18738443953651218, 0.18057202189342514, 0.15593035392301913, 0.18318514737141112, 0.16883635695469823, 0.1678956423716127, 0.16148716323422874, 0.16929728963073953, 0.1592836635307383, 0.16706289440181699, 0.17328980727531051, 0.5485161554187075, 0.1569916985514236, 0.16475498572531266, 0.4174881621780103, 0.19253156884878075, 0.18843835073916748, 0.0972787928679496, 0.16518400099883113, 0.15432340715208104, 0.15210601162062465, 0.18341596404698168, 0.18327304097046104, 0.1835943398257347, 0.38899505612054464, 0.18849832682940537, 0.101830435278358, 0.1939967722966094, 0.15765651617098042, 0.16350789378265107, 0.1668211456586961, 0.1792202272266744, 0.17000094904061458, 0.1505691690906371, 0.1583300144724531, 0.16150381016951432, 0.16810017212690886, 0.1803739519443629, 0.059941734172041516, 0.06178922085522687, 0.07003203421700432, 0.05885315807780078, 0.0677953251047757, 0.06977054963107987, 0.06852475743504782, 0.07054995983998269, 0.06735442352411825]}, "mutation_prompt": null}
{"id": "ed7dfaa8-e7be-4ba0-8316-858abc0caed4", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(self.population_size):\n                inertia = self.w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced Hybrid PSO-DE algorithm with adaptive parameters and local search to improve convergence speed and solution accuracy.", "configspace": "", "generation": 4, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.794857495770716, 0.7773066025327166, 0.779751702135648, 0.8025210429632398, 0.8080570063894578, 0.7749647090531977, 0.7809299039137151, 0.781257506179977, 0.7907624865452223, 0.6092976000112309, 0.5695768995155186, 0.577101987999401, 0.5822683820889392, 0.5374248114268197, 0.585382490826525, 0.5911013841489288, 0.5839205468968809, 0.5805949284235798, 0.3356869176601396, 0.12020241246122987, 0.43921658963616306, 0.2465259983218645, 0.13377050612678754, 0.13689451747063008, 0.13617176065869896, 0.1343998213324401, 0.1658732846947416, 0.13278853145139224, 0.10636545244530848, 0.09946247296342914, 0.13410135268318302, 0.12565280273058177, 0.12700341670201032, 0.1443998744187145, 0.1237289339086477, 0.13065764749972641, 0.9854591596994308, 0.9870426244516194, 0.9902186141782986, 0.988884818001622, 0.9845260146455683, 0.9792171283594697, 0.9911135735348187, 0.9855533716705475, 0.9844792689124515, 0.5132955940856359, 0.5012477437440073, 0.5147329772681832, 0.5248705348931486, 0.5242106942696158, 0.49479641183069856, 0.5297659262643822, 0.5207086143377181, 0.08775342375308282, 0.8260250854104765, 0.7362121322568049, 0.7499546015168822, 0.6914216115672528, 0.7768281784015749, 0.2093182168398222, 0.7687685765872293, 0.7529857911464266, 0.7742121245770603, 0.3223625648132419, 0.30199517653496666, 0.2833303128794652, 0.3938583688763222, 0.2613640010761302, 0.3213130642525388, 0.48170052273121666, 0.31826989773649716, 0.36986297662903866, 0.12984272927272944, 0.3589325902399517, 0.3537206930894615, 0.3244866889855488, 0.3289463755431803, 0.5188500619793479, 0.3817700981014903, 9.999999999998899e-05, 0.2725570379627609, 0.13704484381692905, 0.11320335324442987, 0.21254676106782688, 0.03221544748970806, 0.2892290882795516, 0.2282758026933006, 0.13205933748151932, 0.10060346686231847, 0.32666143001726766, 0.4217957016403844, 0.2328150908228045, 0.2932239746327263, 0.534508119662751, 0.45268469328535155, 0.17797321275732925, 0.5605893642056952, 0.4678395006012277, 0.4078720201222168, 0.17614196799837467, 0.08806534246753595, 0.178885878770916, 0.2170690409054995, 0.19788309358265632, 0.12804174628017317, 0.09502213608498933, 0.06556568900855198, 0.11144906428944379, 0.2614460835187299, 0.2578291501287351, 0.25622340816852796, 0.29892677212041463, 0.2923399172292084, 0.006467471464120522, 0.22220658665124104, 0.278388907535431, 0.29984153224386967, 0.7002260292414888, 0.6599344523425809, 0.7047746309011276, 0.6795828577129088, 0.6509863134103467, 0.20930571995895397, 0.6565429569040192, 0.6767188156371119, 0.6596177172199038, 0.1333102661366986, 0.11045926451642318, 0.105200836962979, 0.12294372743210935, 0.1059234619103816, 0.13186363981428006, 0.1377432483395603, 0.10780069402681658, 0.12801677753357743, 0.23919899443968184, 0.14154563636103046, 0.39965996295808304, 0.40610444425828207, 0.4389656760379723, 0.17797280797881687, 0.611798707827135, 0.1805657508189371, 0.22535860486653014, 0.4256267059779105, 0.40933467913811683, 0.39833205772861435, 0.42876288114209204, 0.41501835988426283, 0.433469011379634, 0.44185108965240605, 0.4827362247694492, 0.47485803137673976, 0.2636003530920974, 0.31324958338344455, 0.30161354311224164, 0.3179668221891452, 0.2952439901252244, 0.29876824894796605, 0.2713845045497575, 0.3499830377757357, 0.33506226259270855, 0.22738637180736265, 0.22588009645240914, 0.20423267546331414, 0.19908193541659502, 0.19826158300227403, 0.20889801384824602, 0.20004170713836, 0.216447343500764, 0.21634572451751133, 0.3149126989938631, 0.20293819033852656, 0.3370658949224751, 0.312996137953376, 0.2206560971148509, 0.22928970017658334, 0.3383738966405361, 0.22238166439885232, 0.5552597692303568, 0.8801957843399056, 0.17669074773808313, 0.15326048268659653, 0.17829571476981076, 0.20049734128789176, 0.20659883403493795, 0.09996080669989638, 0.16994442409222899, 0.16311872401903293, 0.7632800176769808, 0.1684742101388902, 0.11115351696959475, 0.7696309632694756, 0.16859459975599878, 0.21074688093962257, 0.10511748630623918, 0.21005115827983178, 0.7480627467224813, 0.19268491006576027, 0.2051939923829723, 0.19631162617359732, 0.19328486199341666, 0.19736205894674852, 0.1990438772259786, 0.20128106658355416, 0.19418996231856633, 0.19061892481617337, 0.0871609467741089, 0.08498988287958187, 0.09199279084137779, 0.08675793529384768, 0.10074611214109941, 0.07480467033748117, 0.09632512212194944, 0.08443641643504052, 0.10255651270134114]}, "mutation_prompt": null}
{"id": "f0a97386-586a-4131-860d-69f2fad24dbb", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 40  # Increased population size for better sampling\n        self.c1 = 1.49445  # Initial cognitive component\n        self.c2 = 1.49445  # Initial social component\n        self.w = 0.729    # Initial inertia weight\n        self.w_min = 0.4  # Minimum inertia weight for increased exploration\n        self.w_max = 0.9  # Maximum inertia weight for exploitation\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            w = self.w_max - progress * (self.w_max - self.w_min)\n            return F, CR, w\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        # Memory for diversity control\n        diversity_memory = []\n\n        while self.num_evals < self.budget:\n            F, CR, w = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with dynamic inertia weight\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR:\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n            # Diversity control to maintain diversity in the population\n            diversity = np.mean(np.std(swarm, axis=0))\n            diversity_memory.append(diversity)\n            if len(diversity_memory) > 5:\n                diversity_memory.pop(0)\n\n            if np.mean(diversity_memory) < 0.1:  # Arbitrary threshold for diversity\n                # Reinitialize part of the swarm for exploration\n                num_reinit = self.population_size // 5\n                reinit_indices = np.random.choice(self.population_size, num_reinit, replace=False)\n                for idx in reinit_indices:\n                    swarm[idx] = np.random.uniform(self.lower_bound, self.upper_bound, self.dim)\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An Enhanced Hybrid PSO-DE with dynamic adaptation of exploration-exploitation balance and diversity maintenance to boost solution quality and convergence.", "configspace": "", "generation": 27, "fitness": 0.2631504142933486, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.21.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.5403539570539093, 0.4948201074936187, 0.5878845788430321, 0.5926544853803926, 0.577572127852013, 0.590904167048875, 0.5803209101165099, 0.5656680548247981, 0.5259341273929232, 0.24186562229726882, 0.3032407109283787, 0.24691940857439898, 0.24695820071496244, 0.21402198686050855, 0.2320227632224967, 0.28756609676831635, 0.25696423606425445, 0.2902123336185348, 0.11887424903074784, 0.10388778134088261, 0.1099147512828893, 0.10813779704858972, 0.11900461434382958, 0.12503619734269267, 0.12296238240699131, 0.10746626491551725, 0.14041005530288053, 0.08816738147265335, 0.1006998195611879, 0.09294820826567263, 0.08534698331476287, 0.10593286776148092, 0.11149618164627295, 0.09669568063727274, 0.0905804647164532, 0.09122847676106338, 0.9791285898396346, 0.9814267220681548, 0.9823093182290955, 0.9724738691644054, 0.9821316383349508, 0.9767228292933032, 0.9765863233838663, 0.9775768342215541, 0.9816773028493078, 0.3421996071436404, 0.27570806475577603, 0.25196480776418195, 0.31883622843205794, 0.3015588279900576, 0.32269731011260205, 0.313020529319582, 0.3125327260504147, 0.2827717921513063, 0.5817315510220115, 0.46112078375515775, 0.47523462215013657, 0.6283781936175308, 0.5206983257463431, 0.5487197817477025, 0.6055299442364943, 0.5014039212744619, 0.46376833205954937, 0.18226323670205624, 0.160233027339866, 0.13241304890893657, 0.16733924978274317, 0.20170948233814967, 0.1635286804086743, 0.19033025837091178, 0.17297078004966637, 0.17288677646972628, 0.19443878981486729, 0.16600602148235122, 0.15305822368676458, 0.1922314281272106, 0.16899715152931383, 0.16723658506443717, 0.16619979508259985, 0.19413094229772787, 0.20303642397471133, 0.10502109493258427, 0.07909827543207248, 0.0635253286021149, 0.09352524611709034, 0.10572297110412532, 0.09088637962820945, 0.08996892604117968, 0.060032036266852495, 0.0710266546576408, 0.20820932240518109, 0.179764864109753, 0.19562919343979546, 0.2242678821238442, 0.18754910360071353, 0.151886956248527, 0.244553468191804, 0.18104868192573476, 0.19687956868736378, 0.008084085648914496, 0.008808429174880783, 0.013379999898237238, 0.031590864793860196, 0.05616478132218272, 0.02126257434309664, 0.01787630943381502, 0.048875739235154425, 0.028926251091647814, 0.1225559044452541, 0.13603411240099617, 0.11789204978049073, 0.1347760043677414, 0.15529367492481594, 0.14152514525707305, 0.12712881807307663, 0.14088713280918197, 0.1267364075149553, 0.4364754857482639, 0.4266263273439621, 0.42365534405099026, 0.3138956439991635, 0.44025803731958746, 0.42953658788395377, 0.4598206756130415, 0.45210301853860324, 0.45205432763223485, 0.11085095843020865, 0.09765519688424851, 0.10082331655123511, 0.12041775937984889, 0.09905739387030776, 0.10921097878243602, 0.09954148950705843, 0.09987676179034444, 0.08488391656239458, 0.17585060089186932, 0.15132297214307233, 0.24362844585838295, 0.20444567578062744, 0.18566584941403785, 0.22400901190296518, 0.1436624708836176, 0.14005795097967488, 0.19260144753433328, 0.29456534341790563, 0.330891564187332, 0.2922743985716847, 0.2938628271431717, 0.27809763068391835, 0.29516757829627127, 0.33005514459953333, 0.31902066230415727, 0.3111017860837062, 0.22035717952323086, 0.2314996801159248, 0.2142662618785358, 0.22461346210522815, 0.21778365858889137, 0.20535141112177413, 0.23396304403110757, 0.24861017086191017, 0.24002890977725033, 0.17827260317437088, 0.20179205435706193, 0.204133064554597, 0.18704787014423596, 0.19118655019341002, 0.20301431334488274, 0.2249357732939582, 0.1916468125253633, 0.2148075813077075, 0.2977094345386113, 0.20889036452718468, 0.19163920415819324, 0.19758782479391845, 0.2298131172480139, 0.235821582667323, 0.18962227236446993, 0.21831518709256403, 0.19516162643136437, 0.7339299114467863, 0.17153438093360096, 0.15194207164321238, 0.7069296895677881, 0.581899249392366, 0.587806206870449, 0.14031576993506711, 0.16724560519681508, 0.6540067472470713, 0.5562648852641933, 0.20576303230826976, 0.49008798311716206, 0.19686025508328375, 0.5524092374536629, 0.16510810691744227, 0.22279405898748728, 0.20488427460577208, 0.19660649639908412, 0.19035054546611885, 0.18442565570349556, 0.20673330183202254, 0.18997253655698387, 0.19605093879676794, 0.18835315413747344, 0.20035393990932748, 0.20056419638875977, 0.19323235667214178, 0.07712207475951294, 0.07091797497845254, 0.07227744487103116, 0.08869444492264178, 0.08292005706351135, 0.0795377141734378, 0.08010771207929279, 0.08401676519748669, 0.0795881678191156]}, "mutation_prompt": null}
{"id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm with adaptive parameter control and self-adaptive mutation strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 28, "fitness": 0.36539611979973813, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "160ab2c8-bd83-4a16-9451-fc07f9a31752", "metadata": {"aucs": [0.7448526286713765, 0.7392154961019588, 0.7572569173904389, 0.7799681274675723, 0.7770365371458084, 0.18891091175864927, 0.7547346166532488, 0.7698414894175072, 0.7846201403014895, 0.5544277888758236, 0.558274526282354, 0.5843668730635316, 0.5257672158153426, 0.5680009264841568, 0.5927018986201256, 0.5828648113653292, 0.5740945701585725, 0.560720649078597, 0.12339865847364595, 0.10609912391354936, 0.13873867455333477, 0.1300788400907733, 0.13413957663717757, 0.1316934699108786, 0.14708467378446222, 0.14711691426278506, 0.11834151431943851, 0.1127698171452286, 0.10697706726895118, 0.11897574269969025, 0.1274032583163507, 0.14233705649486383, 0.11851335702736199, 0.18757911841463282, 0.11982370166568013, 0.12135832484418374, 0.9890111720563037, 0.9887973677819772, 0.9889915848009119, 0.9872872568288366, 0.9891255673164789, 0.9800050609649302, 0.986622344131887, 0.9834399814569047, 0.984837528066702, 0.5053871767834517, 0.5337226106023258, 0.5601100071869829, 0.4760828343780448, 0.5416634893012883, 0.1503013785231968, 0.5147513930129465, 0.48459116992535456, 0.08752752387028429, 0.8217055367302777, 0.6635973393149875, 0.7094033953646979, 0.27673357683299504, 0.19198737443417013, 0.8155550789045929, 0.7086174727522947, 0.6080024262936471, 0.8213993824381152, 0.42477904099967045, 0.25804049692707265, 0.33993095892589875, 0.2692693606642228, 0.3276340857452389, 0.2595033922227622, 0.33361290470460203, 0.4120262163094388, 0.2836288606052856, 0.24657679639240615, 0.3601943290860812, 0.23784455530796123, 0.2904969219559539, 0.23912354558375581, 0.3287698496096533, 0.28114107464367566, 0.3710128315447766, 0.31975042811668963, 0.2424468953601987, 0.3126597809044883, 0.17953646038881454, 0.21698533577858492, 0.15241988894724623, 0.32377042465016703, 0.29024315932947287, 0.27202316416734285, 0.4170911627509909, 0.38996893042442804, 0.4927724276879004, 0.4580699223090704, 0.5101029252168345, 0.512798511153497, 0.5359971606141398, 0.5688079823649417, 0.5652054357015456, 0.2960062870997723, 0.21562803967912858, 0.11796955155385436, 0.10110814950160729, 0.19877275237181058, 0.3018228545609971, 0.2670054777595078, 0.12559912355922276, 0.10405464151183819, 0.13275965283033442, 0.2819081783747931, 0.30690993030097335, 0.3291902760013653, 0.2347887652931937, 0.30992021171435413, 0.28523012625376687, 0.278712259238859, 0.1345871862953003, 0.30032955627997615, 0.6561036739619437, 0.7045213403357213, 0.6840663789036974, 0.6528785102644721, 0.6807732042201116, 0.7302435108574553, 0.6400523320486493, 0.6588289690060826, 0.6293457894368318, 0.16321289590724541, 0.1383358726902867, 0.12755549639247366, 0.09651860724382166, 0.10254226631381536, 0.09270979027029147, 0.10477602285250631, 0.11726160727443202, 0.10511842154443551, 0.1874312513354358, 0.23340218578904282, 0.25687570151268624, 0.2156221698369174, 0.5113490086369419, 0.17533278006890107, 0.5673396378127507, 0.5359820870591794, 0.21982701113501835, 0.40755532361539104, 0.45789618754129124, 0.38288367855846805, 0.39781289584025115, 0.4248799735432147, 0.4465882728628088, 0.4585011020790253, 0.45743466367002894, 0.4659386325787621, 0.2973354140194501, 0.31852094688539756, 0.29452379740874157, 0.32319384507987337, 0.27248778476523006, 0.3399160751681274, 0.3964938097709676, 0.360994354931675, 0.3226018640130264, 0.1993881779519604, 0.20010524772807758, 0.1872269269161111, 0.21152073183527242, 0.1908556507745499, 0.18876754517126493, 0.19161796316814994, 0.20605202090667174, 0.2678235805960435, 0.183451284333637, 0.19608609559147616, 0.21592943921272534, 0.4386187884854288, 0.38552604932971657, 0.37126721559142783, 0.220543360096633, 0.42228726567734676, 0.4350183739816521, 0.8502343345481216, 0.8092744607057609, 0.15356341662645123, 0.7980160658194214, 0.2004867512950873, 0.19659643548645023, 0.09997677059463494, 0.16847650304502948, 0.1832139670942533, 0.15320311055063596, 0.21054089152959665, 0.20288748476332308, 0.20427064898560032, 0.8419032137630112, 0.20938881124760478, 0.2105813410848586, 0.2108078373511003, 0.7334272478516608, 0.19607129615310293, 0.19127201738621957, 0.19282312734508256, 0.19053318833302724, 0.1968648785555116, 0.2033109926408726, 0.19558029960776713, 0.183347469594077, 0.20345506576776917, 0.09673230341522232, 0.08113352350664149, 0.08226968732815099, 0.08053683439957826, 0.08680470988970046, 0.08485538662954473, 0.0795836099471875, 0.0983330241369913, 0.09367402556843207]}, "mutation_prompt": null}
{"id": "1fde9dd1-44e2-4fa7-a5cd-6958e5e08f25", "solution": "import numpy as np\n\nclass AdaptiveSwarm_DE_DynamicLeader:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        def select_leader(scores):\n            rank = np.argsort(scores)\n            leader_idx = rank[np.random.choice(max(1, len(rank)//5))]\n            return leader_idx\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                leader_idx = select_leader(personal_best_scores)\n                leader_position = personal_best_positions[leader_idx]\n\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (leader_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "AdaptiveSwarm_DE_DynamicLeader", "description": "Adaptive Swarm-DE with Dynamic Leader Selection leverages adaptive control and dynamic leader selection to balance exploration and exploitation.", "configspace": "", "generation": 29, "fitness": 0.34557722658437756, "feedback": "The algorithm AdaptiveSwarm_DE_DynamicLeader got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.24.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.730208880271857, 0.7071711841028422, 0.739307824047118, 0.7706643968888454, 0.743961210910203, 0.7698846751363262, 0.7663605404916791, 0.7384131131820677, 0.7245181141179833, 0.5551220253918943, 0.5724059146061891, 0.5725861986970341, 0.5227386628020241, 0.555094216601824, 0.5265552722750779, 0.5506878013770502, 0.5329361288612684, 0.5136868563502209, 0.11583764096262694, 0.08807471241848286, 0.3414187070051722, 0.12911763920849884, 0.10016376753276712, 0.13536960294262956, 0.10502088631699602, 0.09621045303478659, 0.09496196282868818, 0.10640633803662858, 0.0942983706771644, 0.10742460212122662, 0.09442318399101746, 0.08717610234932416, 0.11151868319561253, 0.10194370220454962, 0.1139651760275272, 0.07761065847134341, 0.988290345064525, 0.9820932165713003, 0.9847298588713067, 0.981733228494036, 0.9889029448801313, 0.9878601497933767, 0.9830583649456551, 0.988320632224109, 0.9849984807820549, 0.516858879210827, 0.5101158289351878, 0.535857026456438, 0.5185376938903309, 0.5121697872811961, 0.5002775617055297, 0.5444863802216553, 0.2672449172501631, 0.5141144448915926, 0.7725804216869766, 0.7328797427559781, 0.6701840348508195, 0.7224409745223095, 0.2093672383889862, 0.7760221621830882, 0.8014597945089513, 0.23306457583146434, 0.6915336475382678, 0.29335520664043957, 0.2601135432625624, 0.274147367791025, 0.32677413289777735, 0.28109953829830536, 0.32278840604648207, 0.37233920839700085, 0.3895662852354661, 0.29658943156548534, 0.27466700963738444, 0.21992353157624323, 0.274754481838161, 0.3741857342334016, 0.3061658501557515, 0.26807631814787436, 0.3399108450786833, 0.2569529343997259, 0.3413504807178469, 0.18228409067643636, 0.33012072621680966, 0.21783224094667641, 0.23079547010704637, 0.3250652263584094, 0.11125304355442911, 0.1614937182978352, 0.4012080618770154, 0.404072192621832, 0.3046043031174095, 0.4360465336756193, 0.21833313788875974, 0.25172669968949957, 0.1936869072174895, 0.17065890921818483, 0.5403066680234345, 0.5255435213705781, 0.12245061815256975, 0.1373052429234234, 0.08848028079821924, 0.08992930810965194, 0.16046104185847543, 0.21571690921873388, 0.2025078654927046, 0.2374513518578436, 0.17487429586069902, 0.0889440330596637, 0.2756361601714644, 0.2685712923710617, 0.2905204310428835, 0.2757042562763321, 0.3173365036862751, 0.2774352339026064, 0.2764208123623868, 0.05735255703763065, 0.27356430586157043, 0.6519739085837747, 0.6674295414155271, 0.6815885763103007, 0.6807609384618709, 0.6772351439706445, 0.5960961067748659, 0.6814640202447555, 0.669562052021712, 0.624764115952712, 0.10358433669300571, 0.10011023351995885, 0.08860292317527507, 0.11029234383748698, 0.09751932073155045, 0.0975803730794258, 0.08475967284200048, 0.1066780689151452, 0.09626680849562452, 0.20157106270104552, 0.1618914001725409, 0.1539114151514721, 0.17756592916781389, 0.2163517726116625, 0.16341880823631438, 0.1735026831090336, 0.15971971609958657, 0.1359558867696642, 0.3961758465821895, 0.39626283107786475, 0.408438165492661, 0.4084075368895055, 0.396838532301661, 0.42461501562347526, 0.38760967516962963, 0.45037702573297034, 0.40939698505399036, 0.3020514047817159, 0.2971306288505512, 0.28154726354320014, 0.2813849933883309, 0.33903824709975305, 0.24588165554734476, 0.3243485840422379, 0.3570092364222869, 0.32891693326370597, 0.21274681023551834, 0.18720104165766593, 0.18644072315438087, 0.20633619167413486, 0.2183895197142237, 0.20052704179566272, 0.20711718540903734, 0.18745085213361645, 0.18682043138195337, 0.20706066035760917, 0.18743389250733722, 0.18176194263437273, 0.18535930610517926, 0.4289688955182369, 0.21589825114003414, 0.3684125798236553, 0.21213853219266243, 0.18883338021428053, 0.1655149925297701, 0.7482329082808727, 0.15409095625781832, 0.18590935349803017, 0.1963776725465597, 0.18916663511880605, 0.7061834669936122, 0.19329895457042, 0.6949983769710776, 0.793386106864953, 0.2030378935048779, 0.6695857526227553, 0.20180869997384077, 0.1679900091279216, 0.20703266207399862, 0.20253128468836934, 0.15546828780627298, 0.7289351733333429, 0.19125438275824969, 0.18276944854318244, 0.2077147568738149, 0.1778956988351238, 0.2096143123065265, 0.19307390971935912, 0.18598153929467176, 0.1881939016259404, 0.18343800476491057, 0.07155962057826548, 0.07927283638185034, 0.08132086003349193, 0.08701122475265544, 0.07449256909687485, 0.07201096528354578, 0.07561778892261029, 0.07313299944399876, 0.08141018269569356]}, "mutation_prompt": null}
{"id": "352fb298-e509-40c5-a822-fc7ebf3460a4", "solution": "import numpy as np\n\nclass EnhancedPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        def maintain_diversity():\n            diversity_threshold = 0.1\n            mean_position = np.mean(swarm, axis=0)\n            if np.linalg.norm(mean_position - global_best_position) < diversity_threshold:\n                diversity_perturbation = np.random.uniform(-1, 1, self.dim) * 0.1\n                return mean_position + diversity_perturbation\n            return global_best_position\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n            # Maintain diversity in the swarm\n            global_best_position = maintain_diversity()\n\n        return global_best_position", "name": "EnhancedPSO_DE", "description": "An enhanced PSO-DE hybrid algorithm integrating diversity preservation and adaptive learning rates for robust global search.", "configspace": "", "generation": 30, "fitness": 0.34954244837207354, "feedback": "The algorithm EnhancedPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.24.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7320114016585231, 0.715447292067944, 0.7337258838053222, 0.7677110876983277, 0.7746049662672616, 0.5308327538150839, 0.715979852924916, 0.7652665940884718, 0.7605568105975204, 0.4760643155166423, 0.47693855980852673, 0.5280725881108285, 0.44512460124562747, 0.5254795500866732, 0.5532216001716741, 0.48055617499863046, 0.558419069369019, 0.4791398227468727, 0.12296628726776804, 0.10605231836221096, 0.13843125160314007, 0.1297961442948894, 0.1341340820301502, 0.12954153839478844, 0.14672486722845535, 0.13538198186933093, 0.12458289246938514, 0.11142785030401503, 0.10685692957204551, 0.11893041607971588, 0.13503625645485684, 0.1296978118100054, 0.12313462678054699, 0.12377681551112563, 0.1186372311023779, 0.12112685305253112, 0.9890111720563037, 0.9887973677819772, 0.9889915848009119, 0.9872872568288366, 0.9891255673164789, 0.9800050609649302, 0.986622344131887, 0.9834399814569047, 0.984837528066702, 0.39796799831889673, 0.4057849989466943, 0.4185529389834691, 0.4071992605464918, 0.36232836287483894, 0.32537236051261986, 0.40249968213358833, 0.3604657737033682, 0.3012588090490421, 0.8217055367302777, 0.6516735106981659, 0.7077552667193765, 0.27673357683299504, 0.19199180290782003, 0.8155550789045929, 0.7086174727522947, 0.555344306055991, 0.8213993824381152, 0.41832669650350296, 0.21561079444274855, 0.26550815327387967, 0.23993721456821637, 0.2611879223748822, 0.29984742233106476, 0.32508522844451404, 0.3445217942293862, 0.2989290560469561, 0.2390157392643283, 0.35131813840237336, 0.20583074753433483, 0.3058153364171541, 0.21931235373411073, 0.32283144722287915, 0.2800762194777532, 0.31644495299062836, 0.3178846754855814, 0.2503050311484699, 0.29504843896730504, 0.23057201850884723, 0.09250292593441556, 0.13055641172878862, 0.28743917934800733, 0.31249656604944676, 0.23785406173078705, 0.4102070646720889, 0.4134139550769552, 0.45324893518580256, 0.4687419052141619, 0.5115104950745724, 0.5089789730799814, 0.5141636158575298, 0.5707216341106737, 0.5529350893203304, 0.24162340625022072, 0.19322360732822885, 0.10785803105880509, 0.09724714669663115, 0.1999547647345321, 0.24737155194416882, 0.25016410959241175, 0.10964027581747027, 0.10146114705811926, 0.14358845286623, 0.2975015864892403, 0.2959202060221473, 0.3424338724408863, 0.22666504598989523, 0.2868235590052647, 0.30005523793560585, 0.28437004127440824, 0.10098533153478151, 0.31069177710071016, 0.6692359728940604, 0.6858981314057191, 0.6709301202119806, 0.6626995574231141, 0.6894956603115299, 0.7058257953353175, 0.634123762513173, 0.6595155562077719, 0.6123240673600088, 0.16184748804065097, 0.14928368684435722, 0.127666815467808, 0.09651600248316516, 0.10262555486765179, 0.09787226330434129, 0.10478102001790102, 0.11681447045636739, 0.10511771048979102, 0.1851293736006614, 0.2343081229467382, 0.2482222471841523, 0.20974041172431235, 0.38711497777611836, 0.1895520935340964, 0.4736709371935983, 0.4741688841270205, 0.21720029523691908, 0.3519249229749447, 0.3525669663388491, 0.3319430640265222, 0.3705442135483611, 0.33602987022697284, 0.3705000929184096, 0.354025146463976, 0.37622589960493324, 0.3962120579160251, 0.3036479026120139, 0.29196616219887106, 0.2609647908189362, 0.31083900197471703, 0.2660950094330867, 0.2894642945868784, 0.3226008749235725, 0.34234052528502235, 0.2722037323200994, 0.1993881779519604, 0.19951887530242307, 0.1872269269161111, 0.21152073183527242, 0.1908556507745499, 0.18876754517126493, 0.19161796316814994, 0.20605202090667174, 0.26782676778826175, 0.1834510902847507, 0.19605022232000024, 0.21587926081404663, 0.34517968655646847, 0.29475033967360165, 0.3218698253251441, 0.2205154817541991, 0.3157933464550092, 0.33262262057434233, 0.8502803941895116, 0.8092744607057609, 0.15356337121685215, 0.7954177869581875, 0.20048677162957407, 0.1965915077889152, 0.09997679791661684, 0.16847649922492602, 0.1832137034984288, 0.1532029584684793, 0.21053703704153381, 0.2028847909010747, 0.2042704650827979, 0.8419032137630112, 0.2093888743269383, 0.21058068823281517, 0.21085331662565954, 0.7309728723124282, 0.19607129615310293, 0.19127201738621957, 0.19282312734508256, 0.19053318833302724, 0.1968648785555116, 0.2033109926408726, 0.19558029960776713, 0.183347469594077, 0.20345506576776917, 0.0967201840122518, 0.08113352350664149, 0.08226968732815099, 0.08053683439957826, 0.08680470988970046, 0.08485538662954473, 0.0795836099471875, 0.09833302411362077, 0.09366359600052676]}, "mutation_prompt": null}
{"id": "27f86140-070a-4e09-af1a-e35e3d72d697", "solution": "import numpy as np\n\nclass ImprovedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.final_population_size = 5\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            current_population_size = int(self.initial_population_size - progress * (self.initial_population_size - self.final_population_size))\n            return w, F, CR, current_population_size\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR, population_size = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "ImprovedHybridPSO_DE", "description": "An improved hybrid PSO-DE algorithm employing dynamic population size and adaptive learning strategies for enhanced convergence.", "configspace": "", "generation": 31, "fitness": 0.36449856231378586, "feedback": "The algorithm ImprovedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.27.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7731219320273162, 0.7849444346668621, 0.7703837206759958, 0.815767825568228, 0.8191706071112467, 0.7986539446173111, 0.7777879364386062, 0.7868375671356249, 0.789637432753246, 0.6594219891754324, 0.5972465815918628, 9.999999999998899e-05, 0.6563255148021172, 0.05905563971034955, 0.6093472407809218, 0.6668084403873256, 0.6363149973278571, 0.5997536279912281, 0.13221911424388022, 0.1566616743683822, 0.42125242187296774, 0.15686357456499977, 0.14658474613624517, 0.44043329674883047, 0.15745551593682616, 0.14410713464333624, 0.1379494127578773, 0.12937080069472373, 0.0990584921911486, 0.13246908035776173, 0.11803002242597471, 0.1349727076706727, 0.12692928640049628, 0.14711557628500982, 0.13144334907756527, 0.12082218761296393, 0.9882500628874821, 0.9902675116046811, 0.989266098428154, 0.9901948285114637, 0.993638955381581, 0.9798560473498632, 0.989120110783922, 0.9852386203498074, 0.9857148782568113, 0.6169433390987096, 0.6288503276173477, 0.6291758084970596, 0.6024646455466468, 0.6011398754740777, 0.14999750447922156, 0.6089825971865797, 0.08780084868919735, 0.58613397869676, 0.22623367945462203, 0.7343044294677039, 0.592100830564504, 0.2698398345131613, 0.7747519848154122, 0.8089198692172694, 0.8018727662399295, 0.79108265558238, 0.22999707176064987, 0.47474298912494906, 0.2665098087804826, 0.3077914383098691, 0.12804610373879421, 0.32997385488646325, 0.12430309594745215, 0.5180093845904933, 0.3281746099533658, 0.43721302420149255, 0.2932497773987305, 0.1160321759099423, 0.24908492427018325, 0.41523852475729595, 0.27954886348226504, 0.2998752285537536, 0.41350804348825954, 0.10421526822612981, 0.2857617158259814, 0.045508964961742615, 0.0859137727893936, 0.2627553172959215, 0.09484479203093399, 0.03676551563813335, 0.15286633420190177, 0.12397522000858463, 0.06544129055663483, 0.13487251749132834, 0.14544660919878571, 0.0822884909414946, 0.4003960633431586, 0.2064232214489553, 0.16946894844719684, 0.19174040038476614, 0.6159174689445719, 0.3783290845115789, 0.3868615097128111, 0.0709606284011075, 0.1644148968803153, 0.05279690844369067, 0.1319526070724647, 0.1584859555122774, 0.09523336600654553, 0.1543621693746683, 0.08727874073807596, 0.09464832322035654, 0.13097113692986528, 0.37533510302068895, 0.2317559401461946, 0.2587796749143495, 0.30479798222053955, 0.41916030575393715, 0.33227021197770357, 0.40896107956331784, 0.1515917888619549, 0.6646453828921828, 0.6491326131221011, 0.5907953040706397, 0.6613288231743417, 0.6366229226625361, 0.6923308062235027, 0.5840862787831486, 0.6780308741834404, 0.6272744426566215, 0.3537433616827741, 0.10008257012545596, 0.11730542883223405, 0.13664444902645645, 0.10791673645384203, 0.0962186568672343, 0.1008542314271279, 0.12890669648833886, 0.13031273829855072, 0.20169989311947034, 0.5837568732014593, 0.618651217370037, 0.592600486014634, 0.23949020142815158, 0.18075546234938233, 0.2762898497853127, 0.20946108334424918, 0.1558297647306417, 0.44205511634578654, 0.535624911293123, 0.5339141332334427, 0.49634704552820363, 0.5170575658659138, 0.46248999858260176, 0.5563262009816543, 0.5969310699683446, 0.4976532225253767, 0.40531119595793696, 0.28003359738465383, 0.35035136359784724, 0.36619710396229743, 0.2149802131271933, 0.32275616981905697, 0.40044510773025355, 0.3941506486567402, 0.3631960154325641, 0.22344438879184336, 0.19043978093422265, 0.20142390869067794, 0.19640532633477115, 0.21378005888103713, 0.18478810636003828, 0.19439687571486097, 0.1984456252600778, 0.24725166868074533, 0.21513301384109573, 0.5952709308192069, 0.19441001118376555, 0.2190691486625379, 0.21905494220618382, 0.213156811761677, 0.5163350256089438, 0.22110781893991338, 0.224181290670737, 0.8527074395800542, 0.1929302773338556, 0.15427546948151616, 0.8373933243875249, 0.19974645700906923, 0.1972128124211443, 0.8381337700685604, 0.16889247308029098, 0.1560488344139549, 0.8011840946614185, 0.16856863228166463, 0.7064445647261701, 0.8107047048262198, 0.659866427855581, 0.21109403503238777, 0.10452146549942809, 0.21188544636504802, 0.7755026280570857, 0.19321165598597112, 0.18063959883224034, 0.18768053551790465, 0.21926598984730628, 0.18321729470420356, 0.1988687802907504, 0.17877246238018363, 0.190078310471123, 0.18848041474659372, 0.09296450166867598, 0.09210450584907826, 0.08401070501265673, 0.09432432197026597, 0.08549346317287743, 0.08696056705696287, 0.09071520540509759, 0.08892234798910525, 0.08877522054853548]}, "mutation_prompt": null}
{"id": "28006dbe-63f6-4cb0-ac3d-05c94c5dc30d", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm with adaptive parameter control and self-adaptive mutation strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7448526286713765, 0.7392154961019588, 0.7572569173904389, 0.7799681274675723, 0.7770365371458084, 0.18891091175864927, 0.7547346166532488, 0.7698414894175072, 0.7846201403014895, 0.5544277888758236, 0.558274526282354, 0.5843668730635316, 0.5257672158153426, 0.5680009264841568, 0.5927018986201256, 0.5828648113653292, 0.5740945701585725, 0.560720649078597, 0.12339865847364595, 0.10609912391354936, 0.13873867455333477, 0.1300788400907733, 0.13413957663717757, 0.1316934699108786, 0.14708467378446222, 0.14711691426278506, 0.11834151431943851, 0.1127698171452286, 0.10697706726895118, 0.11897574269969025, 0.1274032583163507, 0.14233705649486383, 0.11851335702736199, 0.18757911841463282, 0.11982370166568013, 0.12135832484418374, 0.9890111720563037, 0.9887973677819772, 0.9889915848009119, 0.9872872568288366, 0.9891255673164789, 0.9800050609649302, 0.986622344131887, 0.9834399814569047, 0.984837528066702, 0.5053871767834517, 0.5337226106023258, 0.5601100071869829, 0.4760828343780448, 0.5416634893012883, 0.1503013785231968, 0.5147513930129465, 0.48459116992535456, 0.08752752387028429, 0.8217055367302777, 0.6635973393149875, 0.7094033953646979, 0.27673357683299504, 0.19198737443417013, 0.8155550789045929, 0.7086174727522947, 0.6080024262936471, 0.8213993824381152, 0.42477904099967045, 0.25804049692707265, 0.33993095892589875, 0.2692693606642228, 0.3276340857452389, 0.2595033922227622, 0.33361290470460203, 0.4120262163094388, 0.2836288606052856, 0.24657679639240615, 0.3601943290860812, 0.23784455530796123, 0.2904969219559539, 0.23912354558375581, 0.3287698496096533, 0.28114107464367566, 0.3710128315447766, 0.31975042811668963, 0.2424468953601987, 0.3126597809044883, 0.17953646038881454, 0.21698533577858492, 0.15241988894724623, 0.32377042465016703, 0.29024315932947287, 0.27202316416734285, 0.4170911627509909, 0.38996893042442804, 0.4927724276879004, 0.4580699223090704, 0.5101029252168345, 0.512798511153497, 0.5359971606141398, 0.5688079823649417, 0.5652054357015456, 0.2960062870997723, 0.21562803967912858, 0.11796955155385436, 0.10110814950160729, 0.19877275237181058, 0.3018228545609971, 0.2670054777595078, 0.12559912355922276, 0.10405464151183819, 0.13275965283033442, 0.2819081783747931, 0.30690993030097335, 0.3291902760013653, 0.2347887652931937, 0.30992021171435413, 0.28523012625376687, 0.278712259238859, 0.1345871862953003, 0.30032955627997615, 0.6561036739619437, 0.7045213403357213, 0.6840663789036974, 0.6528785102644721, 0.6807732042201116, 0.7302435108574553, 0.6400523320486493, 0.6588289690060826, 0.6293457894368318, 0.16321289590724541, 0.1383358726902867, 0.12755549639247366, 0.09651860724382166, 0.10254226631381536, 0.09270979027029147, 0.10477602285250631, 0.11726160727443202, 0.10511842154443551, 0.1874312513354358, 0.23340218578904282, 0.25687570151268624, 0.2156221698369174, 0.5113490086369419, 0.17533278006890107, 0.5673396378127507, 0.5359820870591794, 0.21982701113501835, 0.40755532361539104, 0.45789618754129124, 0.38288367855846805, 0.39781289584025115, 0.4248799735432147, 0.4465882728628088, 0.4585011020790253, 0.45743466367002894, 0.4659386325787621, 0.2973354140194501, 0.31852094688539756, 0.29452379740874157, 0.32319384507987337, 0.27248778476523006, 0.3399160751681274, 0.3964938097709676, 0.360994354931675, 0.3226018640130264, 0.1993881779519604, 0.20010524772807758, 0.1872269269161111, 0.21152073183527242, 0.1908556507745499, 0.18876754517126493, 0.19161796316814994, 0.20605202090667174, 0.2678235805960435, 0.183451284333637, 0.19608609559147616, 0.21592943921272534, 0.4386187884854288, 0.38552604932971657, 0.37126721559142783, 0.220543360096633, 0.42228726567734676, 0.4350183739816521, 0.8502343345481216, 0.8092744607057609, 0.15356341662645123, 0.7980160658194214, 0.2004867512950873, 0.19659643548645023, 0.09997677059463494, 0.16847650304502948, 0.1832139670942533, 0.15320311055063596, 0.21054089152959665, 0.20288748476332308, 0.20427064898560032, 0.8419032137630112, 0.20938881124760478, 0.2105813410848586, 0.2108078373511003, 0.7334272478516608, 0.19607129615310293, 0.19127201738621957, 0.19282312734508256, 0.19053318833302724, 0.1968648785555116, 0.2033109926408726, 0.19558029960776713, 0.183347469594077, 0.20345506576776917, 0.09673230341522232, 0.08113352350664149, 0.08226968732815099, 0.08053683439957826, 0.08680470988970046, 0.08485538662954473, 0.0795836099471875, 0.0983330241369913, 0.09367402556843207]}, "mutation_prompt": null}
{"id": "eaa4d0e0-f59e-4c72-a161-e58c15533e2f", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.neighbor_size = 5  # For dynamic topology\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with dynamic topology\n            for i in range(self.population_size):\n                # Find neighbors based on Euclidean distance\n                distances = np.linalg.norm(swarm - swarm[i], axis=1)\n                neighbors = np.argsort(distances)[:self.neighbor_size]\n                neighbor_best = min(neighbors, key=lambda x: personal_best_scores[x])\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (personal_best_positions[neighbor_best] - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with adaptive scaling factor\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid PSO-DE with dynamic topology and adaptive differential evolution for improved convergence and diversity.", "configspace": "", "generation": 33, "fitness": 0.36499588444883907, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.25.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7371655198701152, 0.7267153648287793, 0.7785734383719198, 0.7593836940029042, 0.7559053469056128, 0.7674653007820161, 0.7637257296332101, 0.7679566391270072, 0.7386216394331173, 0.5441708581477896, 0.5530120970325979, 0.554721243110203, 0.5410120499813833, 0.5470892406280308, 0.5703194983923068, 0.017700957450010546, 0.5712630478908296, 0.5742320331665123, 0.3434003435665266, 0.13742616360969495, 0.418603414460208, 0.1151820831450232, 0.23499152791841826, 0.10149980468189534, 0.1251537454831534, 0.11877530190977537, 0.1192626608420243, 0.11734667478974603, 0.1198023157510163, 0.12275818757069468, 0.1038431234562609, 0.10124666313799024, 0.10548977625613065, 0.11448732444757082, 0.10847818523193964, 0.10003328836914227, 0.9814912950722627, 0.9847215548924259, 0.9851427503429153, 0.980379037699501, 0.988425777177129, 0.9845575377200613, 0.9856235317111359, 0.983251777785383, 0.9877705145993687, 0.5216789381803846, 0.5298775338379267, 0.5141482987222555, 0.5439507307433709, 0.5115299556906225, 0.5070136245167218, 0.5244817580613417, 0.5406743360834744, 0.5473929919750047, 0.23920147850483686, 0.7225023978575968, 0.7837581155420674, 0.8069290397138266, 0.24789744999992525, 0.27343768470121177, 0.7485953554215308, 0.7018851332299941, 0.7806310084265392, 0.25189313944724123, 0.3010132113572723, 0.29103036312681385, 0.12978627030035583, 0.3921341500861658, 0.12517117224520646, 0.32093925107669075, 0.33749259126002495, 0.4573964911470909, 0.2690383414234435, 0.24828014422957645, 0.24350696602750255, 0.30898420147187766, 0.2941708968144878, 0.41341345398988427, 0.3930780736063816, 0.3057958514408694, 0.4257038517340699, 0.2499877302483361, 0.1941869288341438, 0.047503759838788184, 0.12102305366660093, 0.33250686545965724, 0.053081069083491306, 0.38717714367520295, 0.2629935889008732, 0.3889310209190934, 0.5102038176074548, 0.5452018870105686, 0.4151188836443873, 0.39486876753702305, 0.38061089902736356, 0.1683991457478291, 0.55383378234856, 0.6034303981373028, 0.5583702215333028, 0.0726563506539405, 0.05289562152271643, 0.15450142436290515, 0.06790096393389744, 0.19813572561577808, 0.19797699779316758, 0.15842393327116133, 0.08665443588126742, 0.10757520518388597, 0.24641793537948442, 0.2875558972523625, 0.24689807381855966, 0.27923491209322115, 0.31258282661249637, 0.2892070411254417, 0.2757399246744263, 0.2302339462434866, 0.07861328604762152, 0.677072000244449, 0.6748384914533878, 0.6645556640796344, 0.6716897258181571, 0.6765398498334674, 0.6642099163454214, 0.6271437521846741, 0.6297129478497305, 0.6689800262391912, 0.09541308973257034, 0.1288086462802408, 0.10375286142076079, 0.1144444300910804, 0.09148245735780858, 0.14313963336728053, 0.1255296568636719, 0.09990853733720284, 0.12526765051852073, 0.286890839815757, 0.25134965024068223, 0.4201088257555369, 0.38562383779592746, 0.17857023712685005, 0.20181502096355652, 0.1935993501164991, 0.24655389583061604, 0.27149805657767156, 0.3988012745705606, 0.47519882422953774, 0.41286778418563985, 0.4011619663393289, 0.43510358340110156, 0.4419899539005171, 0.4444961070586452, 0.44509980160945883, 0.41275532669581616, 0.30942423833206834, 0.3723282085017162, 0.3117549009448962, 0.30823336860260153, 0.2764358912692756, 0.3159943598228886, 0.30695093078746694, 0.3497014843941443, 0.28114928928878047, 0.2112775998675256, 0.19273590409750374, 0.20673218851337594, 0.20989269954037548, 0.2112986611374732, 0.23584188711847331, 0.19175856539976877, 0.1944742965790185, 0.20812432109211354, 0.3987283086181296, 0.20255836832114327, 0.4521136459444447, 0.1864732787093597, 0.3003339784524637, 0.4118303711800396, 0.21417611969070227, 0.19507142146272038, 0.2160272150993765, 0.7788150572006074, 0.7597432061555948, 0.8356435157978848, 0.7937936617481562, 0.19836782718336365, 0.7814511073465654, 0.1414157770600326, 0.16929088169689566, 0.19316257796540448, 0.6086954202024417, 0.20458734461794048, 0.707053652625425, 0.20060738701047176, 0.20600931383416565, 0.6382381808062223, 0.2128136732289524, 0.1529139902654315, 0.19668219901113027, 0.1912174533037867, 0.18709269684781038, 0.23958814801585226, 0.19200039092970345, 0.1987303640923066, 0.2283755861412019, 0.1985725668947561, 0.18982406366510252, 0.2019502788188724, 0.08701629536218791, 0.07608866754094401, 0.09559532678549643, 0.09023250275510708, 0.08220547022114644, 0.08376958715839444, 0.0871953805118727, 0.0863246380194912, 0.08342589706858594]}, "mutation_prompt": null}
{"id": "a357c037-fd60-47fd-a8d0-eb9d36e060c6", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm with adaptive parameter control and self-adaptive mutation strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7448526286713765, 0.7392154961019588, 0.7572569173904389, 0.7799681274675723, 0.7770365371458084, 0.18891091175864927, 0.7547346166532488, 0.7698414894175072, 0.7846201403014895, 0.5544277888758236, 0.558274526282354, 0.5843668730635316, 0.5257672158153426, 0.5680009264841568, 0.5927018986201256, 0.5828648113653292, 0.5740945701585725, 0.560720649078597, 0.12339865847364595, 0.10609912391354936, 0.13873867455333477, 0.1300788400907733, 0.13413957663717757, 0.1316934699108786, 0.14708467378446222, 0.14711691426278506, 0.11834151431943851, 0.1127698171452286, 0.10697706726895118, 0.11897574269969025, 0.1274032583163507, 0.14233705649486383, 0.11851335702736199, 0.18757911841463282, 0.11982370166568013, 0.12135832484418374, 0.9890111720563037, 0.9887973677819772, 0.9889915848009119, 0.9872872568288366, 0.9891255673164789, 0.9800050609649302, 0.986622344131887, 0.9834399814569047, 0.984837528066702, 0.5053871767834517, 0.5337226106023258, 0.5601100071869829, 0.4760828343780448, 0.5416634893012883, 0.1503013785231968, 0.5147513930129465, 0.48459116992535456, 0.08752752387028429, 0.8217055367302777, 0.6635973393149875, 0.7094033953646979, 0.27673357683299504, 0.19198737443417013, 0.8155550789045929, 0.7086174727522947, 0.6080024262936471, 0.8213993824381152, 0.42477904099967045, 0.25804049692707265, 0.33993095892589875, 0.2692693606642228, 0.3276340857452389, 0.2595033922227622, 0.33361290470460203, 0.4120262163094388, 0.2836288606052856, 0.24657679639240615, 0.3601943290860812, 0.23784455530796123, 0.2904969219559539, 0.23912354558375581, 0.3287698496096533, 0.28114107464367566, 0.3710128315447766, 0.31975042811668963, 0.2424468953601987, 0.3126597809044883, 0.17953646038881454, 0.21698533577858492, 0.15241988894724623, 0.32377042465016703, 0.29024315932947287, 0.27202316416734285, 0.4170911627509909, 0.38996893042442804, 0.4927724276879004, 0.4580699223090704, 0.5101029252168345, 0.512798511153497, 0.5359971606141398, 0.5688079823649417, 0.5652054357015456, 0.2960062870997723, 0.21562803967912858, 0.11796955155385436, 0.10110814950160729, 0.19877275237181058, 0.3018228545609971, 0.2670054777595078, 0.12559912355922276, 0.10405464151183819, 0.13275965283033442, 0.2819081783747931, 0.30690993030097335, 0.3291902760013653, 0.2347887652931937, 0.30992021171435413, 0.28523012625376687, 0.278712259238859, 0.1345871862953003, 0.30032955627997615, 0.6561036739619437, 0.7045213403357213, 0.6840663789036974, 0.6528785102644721, 0.6807732042201116, 0.7302435108574553, 0.6400523320486493, 0.6588289690060826, 0.6293457894368318, 0.16321289590724541, 0.1383358726902867, 0.12755549639247366, 0.09651860724382166, 0.10254226631381536, 0.09270979027029147, 0.10477602285250631, 0.11726160727443202, 0.10511842154443551, 0.1874312513354358, 0.23340218578904282, 0.25687570151268624, 0.2156221698369174, 0.5113490086369419, 0.17533278006890107, 0.5673396378127507, 0.5359820870591794, 0.21982701113501835, 0.40755532361539104, 0.45789618754129124, 0.38288367855846805, 0.39781289584025115, 0.4248799735432147, 0.4465882728628088, 0.4585011020790253, 0.45743466367002894, 0.4659386325787621, 0.2973354140194501, 0.31852094688539756, 0.29452379740874157, 0.32319384507987337, 0.27248778476523006, 0.3399160751681274, 0.3964938097709676, 0.360994354931675, 0.3226018640130264, 0.1993881779519604, 0.20010524772807758, 0.1872269269161111, 0.21152073183527242, 0.1908556507745499, 0.18876754517126493, 0.19161796316814994, 0.20605202090667174, 0.2678235805960435, 0.183451284333637, 0.19608609559147616, 0.21592943921272534, 0.4386187884854288, 0.38552604932971657, 0.37126721559142783, 0.220543360096633, 0.42228726567734676, 0.4350183739816521, 0.8502343345481216, 0.8092744607057609, 0.15356341662645123, 0.7980160658194214, 0.2004867512950873, 0.19659643548645023, 0.09997677059463494, 0.16847650304502948, 0.1832139670942533, 0.15320311055063596, 0.21054089152959665, 0.20288748476332308, 0.20427064898560032, 0.8419032137630112, 0.20938881124760478, 0.2105813410848586, 0.2108078373511003, 0.7334272478516608, 0.19607129615310293, 0.19127201738621957, 0.19282312734508256, 0.19053318833302724, 0.1968648785555116, 0.2033109926408726, 0.19558029960776713, 0.183347469594077, 0.20345506576776917, 0.09673230341522232, 0.08113352350664149, 0.08226968732815099, 0.08053683439957826, 0.08680470988970046, 0.08485538662954473, 0.0795836099471875, 0.0983330241369913, 0.09367402556843207]}, "mutation_prompt": null}
{"id": "f8a55977-c649-4ef3-b56e-f6f35e1f2b46", "solution": "import numpy as np\n\nclass AdvancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0  # Initial cognitive component\n        self.c2_start = 2.0  # Initial social component\n        self.c1_end = 0.5    # Final cognitive component\n        self.c2_end = 2.5    # Final social component\n        self.w_start = 0.9   # Start inertia weight\n        self.w_end = 0.4     # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, c1, c2, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and neighborhood-based communication\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                r1, r2 = np.random.random(self.dim), np.random.random(self.dim)\n                # Neighborhood-based communication\n                neighborhood_best_position = min((personal_best_positions[j] for j in range(self.population_size)),\n                                                 key=lambda x: func(x))\n                cognitive = c1 * r1 * (personal_best_positions[i] - swarm[i])\n                social = c2 * r2 * (neighborhood_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "AdvancedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm with advanced dynamic adaptation, using neighborhood-based communication and multi-phase learning to enhance both convergence speed and solution quality.", "configspace": "", "generation": 35, "fitness": 0.11992518980562294, "feedback": "The algorithm AdvancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.17.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.20963589743313338, 0.20232932479689159, 0.1923737421189453, 0.2159532234319257, 0.2485448364399786, 0.1674593506603096, 0.23393948873552928, 0.2448490243798681, 0.2210599632762521, 9.999999999998899e-05, 9.999999999998899e-05, 0.0010378546866939287, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04040899526185526, 0.049056592356738093, 0.04271031816669202, 0.048057370844419856, 0.04029118883295246, 0.05924968343730619, 0.04892801381251333, 0.033894481530993836, 0.04072498776729605, 0.04912074712664449, 0.0347431106349686, 0.03631638391738379, 0.03586640620677295, 0.04371094957425958, 0.03709988920204288, 0.04457656700091284, 0.028154345552388826, 0.028244565285515777, 0.8774599712614883, 0.8832306938648503, 0.8821730284095674, 0.8791829077698982, 0.8815237200207711, 0.8010724791834564, 0.88122009759381, 0.87962574632641, 0.8756290938503456, 0.05156476041008884, 0.05793696562999684, 0.07924840754257745, 0.07892671918385408, 0.07605903280533788, 0.08910245456819499, 0.07513255213321668, 0.06067564985795215, 0.03503529989145793, 0.15357866984663504, 0.07705068526684988, 0.1472233639244992, 0.14628813689590936, 0.10859945493946377, 0.13674801813896575, 0.12601405675196187, 0.12490326050943845, 0.12214285035878492, 0.016404620968596628, 0.022343743682196715, 0.015600116759222016, 0.0361927669773382, 0.011047145999542596, 0.02233666726666328, 0.03274308728744768, 0.03350744587541543, 0.03163383507940376, 0.001186567760529944, 0.02232009315672623, 0.022067737621819683, 0.020042188127852745, 0.028400964881796775, 0.022855285428126426, 0.008122063094174847, 0.014269803676866255, 0.0049338223987169805, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04647229602008318, 0.011804646616238257, 0.04319144518025242, 0.02791999380586274, 0.0370489111068244, 0.007946736039842306, 0.05496281788069213, 0.03896736115782584, 0.05692101080113676, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0010624984149116834, 0.002787928634441217, 0.02120431267615952, 9.999999999998899e-05, 0.012963928922036572, 0.024355862854978816, 0.01213673284093042, 0.01139147090618775, 0.012379530018576723, 0.19379826149613444, 0.2095154632876165, 0.241793574881904, 0.24688625955734478, 0.23690621068699336, 0.2182255188466523, 0.2224674224451012, 0.22839100856318528, 0.22463872947033792, 0.04389587079370427, 0.04039224730152624, 0.043043971539336257, 0.04859079436159086, 0.0388159686833387, 0.06384731107007902, 0.04519061271849101, 0.04752704629663207, 0.051524712149611185, 0.10257920803829801, 0.10940863233039066, 0.1340465913546104, 0.10229101104829608, 0.12025824867761259, 0.09036504566832082, 0.1262801706227087, 0.09501625581745943, 0.12033999096923598, 0.15265325762552662, 0.16384059075061286, 0.1684995601228575, 0.15058919958726258, 0.15828726199401932, 0.1533180354942668, 0.16421879268559625, 0.1966233251848476, 0.16526271520648972, 0.1018041429736688, 0.10199594765747566, 0.09965404737303885, 0.10890182756137379, 0.11831616864685657, 0.10493747595617697, 0.10836711202294025, 0.13820931506929224, 0.10725279182260761, 0.14615649615063453, 0.1296156484917066, 0.15453315593934625, 0.15359044012782874, 0.1431289379742855, 0.13786998451420385, 0.15822346832543444, 0.14665391863314092, 0.14747964649342993, 0.11560287429813565, 0.13663494589054714, 0.14199331140612104, 0.1371528859513046, 0.10337222752983166, 0.1348928519368675, 0.14048947639029485, 0.10273623941593235, 0.12807435102237397, 0.26462031810448683, 0.1765766071808328, 0.13049617944102643, 0.16234277636638594, 0.15996894420150742, 0.15401175914227005, 0.09451193754311715, 0.13527792686915563, 0.10669375349989785, 0.12529284945243813, 0.14784999111955344, 0.11749119193309909, 0.11996280492262545, 0.15063961858205388, 0.15610298918075827, 0.12243303109332682, 0.09881128403943917, 0.17558800395053697, 0.15357132913134974, 0.1709083761834983, 0.15027486280689573, 0.16121878137471757, 0.17059580119592788, 0.1518516528181112, 0.15466655646762761, 0.17335787025203786, 0.1511716235094036, 0.04611944568773374, 0.054096635687745254, 0.062081571963867654, 0.047123131096544646, 0.05649988595273192, 0.03907935150599473, 0.04690153789944218, 0.04210966622092693, 0.04866156540826183]}, "mutation_prompt": null}
{"id": "0ac5ea47-56ff-4ed5-85ad-a2ced5dd336c", "solution": "import numpy as np\n\nclass EnhancedAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def chaotic_initialization(self):\n        # Use a chaotic map for initialization\n        return self.lower_bound + (self.upper_bound - self.lower_bound) * np.random.rand(self.population_size, self.dim)**2\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm with chaotic map\n        swarm = self.chaotic_initialization()\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        \n        def opposite_position(pos):\n            return self.lower_bound + self.upper_bound - pos\n            \n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation and opposition-based learning\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    opposition_trial = opposite_position(trial)\n                    opposition_score = func(opposition_trial)\n                    self.num_evals += 1\n                    if opposition_score < trial_score:\n                        personal_best_positions[i] = opposition_trial\n                        personal_best_scores[i] = opposition_score\n                        trial_score = opposition_score\n\n                if trial_score < global_best_score:\n                    global_best_score = trial_score\n                    global_best_position = personal_best_positions[i]\n\n        return global_best_position", "name": "EnhancedAdaptivePSO_DE", "description": "An enhanced adaptive PSO-DE algorithm with dynamic opposition-based learning and chaotic initialization to improve exploration and convergence.", "configspace": "", "generation": 36, "fitness": 0.33443232943305357, "feedback": "The algorithm EnhancedAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.24.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7406129354206652, 0.7002217610430432, 0.7098963702948745, 0.7319119711309061, 0.727214673026952, 0.7251451428814903, 0.7221849721399733, 0.7399798957425161, 0.7400376429436948, 0.5044898360997505, 0.497931845317954, 0.501967312100392, 0.5047063254226505, 0.4818030372870439, 0.5143720669826963, 0.5459997859207959, 0.4644614879021316, 0.49432895066313776, 0.1210673701159305, 0.2840995230993404, 0.1251889650653042, 0.11781126912391315, 0.12270371285492077, 0.1284443779864678, 0.1119421336652151, 0.13553090083137975, 0.15156479250794053, 0.1249817354267323, 0.1449967255265825, 0.10409889981687737, 0.11663305707305993, 0.10734317100244084, 0.10339834825421079, 0.13359463530664195, 0.12158775195987581, 0.10779246090505679, 0.9803996733551327, 0.9805100428740724, 0.9802374962301768, 0.9790986744947511, 0.9896209820209366, 0.9809440051940309, 0.986014920905638, 0.9863906686762773, 0.9829930636263405, 0.49612270373154344, 0.05799226137128899, 0.4546841140387575, 0.5146425136977888, 0.4229635512493558, 0.48906795494360455, 0.08865044254087784, 0.4426411830895187, 0.4276002326876692, 0.727300806765321, 0.7911994165035098, 0.790093398227031, 0.20649131034927093, 0.7571559751502839, 0.20808278356848853, 0.5988016158899896, 0.7391384319714402, 0.7239922311128291, 0.3236205938317357, 0.3332051763160082, 0.28071928878790364, 0.27296753754249514, 0.3197856330171458, 0.1177537331810854, 0.222009836933322, 0.34294097835899806, 0.35004996883227846, 0.275389661455287, 0.2695506735619556, 0.016681585406356114, 0.41794631310018715, 0.3656530898853261, 0.32898136015676305, 0.2795828813454645, 0.39732776619241805, 0.11668527083373015, 0.10856358170956282, 0.03534832833611923, 0.08320394285587385, 0.24288941992013258, 0.22623424693016803, 0.08274516747441885, 0.38710609588956146, 0.24498015540750195, 0.2764888690053484, 0.4115045860745117, 0.5151176768003454, 0.3872142124018907, 0.4249657472385643, 0.24985945603440574, 0.4051982600886569, 0.3467071566874893, 0.4735662384226679, 0.3528004923277812, 0.024644321811136627, 0.05849510970253835, 0.1165962395990442, 0.09354252082442804, 0.09421913732410414, 0.08647590115139736, 0.14836644332323246, 0.23163853413107294, 0.23794920726032964, 0.2274488741116808, 0.28996562119271097, 0.17461687064988818, 0.2808231475611104, 0.22162914715126947, 0.17460565655982796, 0.2468218006618641, 0.25614236159043113, 0.10017024953594922, 0.6453186294578575, 0.6245367263530874, 0.6314694143039994, 0.5961703102939657, 0.6393866289483496, 0.6145182310767274, 0.6377125447803709, 0.6184973313005411, 0.620381526773429, 0.13607454963786036, 0.358385897445458, 0.06126607815000973, 0.12693765066369722, 0.11556939531456878, 0.14127375168002332, 0.13864026469477553, 0.10166884671659515, 0.10757221210130796, 0.22238602206962388, 0.4410272835656066, 0.1493481247317333, 0.19573442311348688, 0.2155926824705391, 0.16211182231707266, 0.20151495077148318, 0.23729097993814896, 0.13370291957850422, 0.3829751625164548, 0.377675199560513, 0.3843278611245532, 0.3963907622542191, 0.39763008714203785, 0.19865083460485733, 0.4491565297021437, 0.4495656480410154, 0.4457891000379304, 0.2721156648861637, 0.3276329100890538, 0.27545498485661524, 0.1984035102928121, 0.3054860108614236, 0.3245840702699929, 0.1606269929995533, 0.36243823741078496, 0.34865896617998704, 0.20186511218240644, 0.19023121322429015, 0.2308688105990735, 0.1926287150341529, 0.19459588367858383, 0.19634297971741743, 0.23193417207385325, 0.20174064528139546, 0.21803931393568166, 0.21378005730365535, 0.19869316386475555, 0.20293577830652332, 0.42309555081743966, 0.20281694493906166, 0.36074461424619997, 0.4378751341056084, 0.4406371715390144, 0.19719276643791883, 0.2044616226428878, 0.8201429334092485, 0.15404211352953423, 0.8182496488971844, 0.19559076042689982, 0.1680957674829069, 0.1567283599058341, 0.1564826099858998, 0.7793427466642318, 0.20961007285194677, 0.16734182505667683, 0.2080224760080982, 0.2071213818235086, 0.19782173687943982, 0.6413175976013922, 0.20222871364723827, 0.20181274872147237, 0.21130653202873206, 0.18635237592923426, 0.20135445689915055, 0.19760722304536982, 0.19882750611081623, 0.20457378230147083, 0.17929240056510376, 0.1849228371074979, 0.18557296120415245, 0.2013815880184504, 0.09785473754674712, 0.08529809915989739, 0.09287686713372734, 0.07991331836519644, 0.08074090284650759, 0.08477964074312982, 0.08882636259917087, 0.082503560253399, 0.09494270818749151]}, "mutation_prompt": null}
{"id": "25ed2cc1-2067-4eb9-a710-ef1707ac2d84", "solution": "import numpy as np\n\nclass EnhancedAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49618  # Cognitive component\n        self.c2 = 1.49618  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.6\n        self.F_end = 0.9\n        self.CR_start = 0.7\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = np.random.normal(self.w_start - progress * (self.w_start - self.w_end), 0.1)\n            F = np.random.normal(self.F_start + progress * (self.F_end - self.F_start), 0.05)\n            CR = np.random.normal(self.CR_start + progress * (self.CR_end - self.CR_start), 0.02)\n            return np.clip(w, 0.1, 1.0), np.clip(F, 0.1, 1.0), np.clip(CR, 0.1, 1.0)\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with stochastic adjustment\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 5, replace=False)\n                a, b, c, d, e = personal_best_positions[indices]\n                mutant = a + F * (b - c + d - e)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedAdaptivePSO_DE", "description": "Enhanced Adaptive PSO-DE: Incorporates stochastic control of parameters and hybrid exploration-exploitation using L-SHADE inspired mutations for robust global search.", "configspace": "", "generation": 37, "fitness": 0.28305479026684577, "feedback": "The algorithm EnhancedAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.22.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.6052167222353364, 0.59675370820422, 0.6655675417963015, 0.6555212439167966, 0.685942632898943, 0.7026986260617001, 0.621422582452197, 0.6682342425824191, 0.6548053411222472, 0.39543507668749134, 0.4266178605102119, 0.3964414419192277, 0.4298960309394174, 0.39250580152486025, 0.4004079419078622, 0.4359467374612276, 0.43168308254185606, 0.3976645286344562, 0.1172597369937175, 0.131101918897639, 0.11935064568125964, 0.1142746242439141, 0.11759167276440452, 0.31255655193202814, 0.34487641993760965, 0.12421905786604182, 0.22425797603955422, 0.09196907177264224, 0.1259773003892346, 0.14016870454782415, 0.10813255167651259, 0.1177829640923923, 0.1090812378525261, 0.11155870887404618, 0.12422700252765095, 0.1264239531409801, 0.9911267032121722, 0.9892700608968324, 0.9905027531510588, 0.9840937222469278, 0.9909958601068591, 0.9886349802237804, 0.9869825638234029, 0.9888319664258596, 0.9877570308384168, 0.43717145911670163, 0.43630450204426774, 0.36803431978552004, 0.41138890634867553, 0.3828393723943041, 0.38853924771549686, 0.3779015404863284, 0.4120890124436165, 0.08562244641795624, 0.5801491593489094, 0.4705638988077613, 0.5417426571755697, 0.554203412799292, 0.5104829205414574, 0.5306208434739456, 0.5696408471372068, 0.6368933911031006, 0.6443740288326636, 0.20758924605643614, 0.2215873833928902, 0.2019550987102423, 0.1715933935298417, 0.20988491030718104, 0.2625322105960969, 0.24763731827404378, 0.19578607535080605, 0.11268479229248729, 0.1929268684437213, 0.1308076200911602, 0.1846287600818527, 0.18239897614653988, 0.21159856052735382, 0.11102999524183399, 0.23527120492442877, 0.22145992050477514, 0.21793348484055663, 0.07792143259785045, 0.029682124906407314, 0.05731819242353542, 0.05256534297424076, 0.056540978101827566, 0.039463966914851656, 0.06500760662249228, 0.0252194088833414, 0.0867299304637078, 0.148959773827113, 0.16063439818519165, 0.1440645959450294, 0.19607308269613177, 0.1155173759288809, 0.13766352228274592, 0.23921231766652484, 0.201321032593902, 0.07588934036458073, 0.0162224966621467, 0.04766385497058767, 0.0649628738932857, 0.047662462056177746, 0.10311451010286188, 0.05438758219520823, 0.0431452766911945, 0.062108108196717526, 0.1022927690206421, 0.17817116234186747, 0.13064907025797934, 0.14720641995697747, 0.15861055146698677, 0.13036785069915635, 0.18214102919861175, 0.13417634947791635, 0.14878666997577183, 0.1917554029262385, 0.4516634154692414, 0.4572316489353636, 0.47488297125305456, 0.4776898776867322, 0.49010561671989306, 0.5133805740132116, 0.47768958502726167, 0.4624505390763062, 0.48191726696392057, 0.10435895375075177, 0.12727502093747511, 0.12327944649591172, 0.09203207610941588, 0.10088176483576194, 0.11264018931467012, 0.1255449452430275, 0.11926269380152221, 0.10614276400099665, 0.15671739859409117, 0.2387130912797345, 0.21974656064618414, 0.167192173774671, 0.2176648867141876, 0.13852224068470498, 0.1450460017697247, 0.18937910882570952, 0.15954316892890563, 0.3716319524563594, 0.3927969212475616, 0.31463167372609346, 0.32526886341462213, 0.34239165292888474, 0.3116542159260284, 0.37072603764319023, 0.4008497302440275, 0.38981928467991567, 0.2532836617401948, 0.20907615258455725, 0.2571420176568715, 0.21064003712115253, 0.20256262921509638, 0.21521836480637657, 0.27078420481894383, 0.261544040368495, 0.28003507924977145, 0.19950433399235445, 0.1928218492389131, 0.19196086778376764, 0.19324623364919002, 0.19657891465942612, 0.188877756550206, 0.1905488102405991, 0.207342105269668, 0.19552255642755512, 0.21804485727402356, 0.20262937800030534, 0.17046898242831943, 0.2092789890876462, 0.2060047372859618, 0.18341800650195328, 0.39435990323506454, 0.19811045201191158, 0.21383266344191565, 0.7103044789910156, 0.162555439584132, 0.15381579827896075, 0.16282217919101039, 0.19377803662696247, 0.5675994075341739, 0.0997684522966159, 0.16861147626003326, 0.15740145508471692, 0.6705067013201459, 0.16645216278668995, 0.557450032805834, 0.2024570775240785, 0.18875047948468748, 0.5105915370523533, 0.6088517073753532, 0.20879720586123818, 0.21055001301997311, 0.2243172070388736, 0.1781211994048617, 0.19878623893234193, 0.21252847651191642, 0.19258721225673536, 0.20264027114942929, 0.1984295590999129, 0.1932556293063291, 0.18532264653365704, 0.08180648798395018, 0.06991948072919618, 0.0843916141412181, 0.08982266534817296, 0.07964058782869465, 0.08322289959415174, 0.08901142354286984, 0.1021808568258068, 0.07638117026747127]}, "mutation_prompt": null}
{"id": "81ef9938-8769-4420-8604-cd7291b256b5", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.elite_fraction = 0.2  # Fraction of elite solutions\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # Sort and select elite\n            elite_threshold = int(self.elite_fraction * self.population_size)\n            elite_indices = np.argsort(personal_best_scores)[:elite_threshold]\n            elite_positions = personal_best_positions[elite_indices]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                elite_partner = elite_positions[np.random.randint(0, elite_threshold)]\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                elite_influence = (elite_partner - swarm[i]) * np.random.random(self.dim)\n                velocities[i] = inertia + cognitive + social + elite_influence\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid PSO-DE algorithm incorporating elite selection and adaptive learning rates for optimized convergence efficiency.", "configspace": "", "generation": 38, "fitness": 0.3346876342202069, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.25.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7165349847364828, 0.7179868479019329, 0.7289823715043147, 0.7235714525518528, 0.7630364111333897, 0.7410677554460849, 0.7515472528299696, 0.7727623103931964, 0.7399692156307267, 0.6052848663891146, 0.562700426904513, 0.5760270092604797, 0.0638569850577525, 0.5242881993798787, 0.5030603210642414, 0.519778027049175, 0.5474926005307752, 0.5312620992986441, 0.1148645498515436, 0.10534903988805111, 0.09797194162980538, 0.09070034431817253, 0.11441447637264412, 0.12205463976062514, 0.11105979964044088, 0.09889138759749838, 0.10472616732361262, 0.0923630187959994, 0.10036168577436988, 0.09499413573860072, 0.10463575481823773, 0.09397143309395484, 0.09559238946986626, 0.11248289506373588, 0.10893522798569233, 0.08374475917882718, 0.9915033078775652, 0.9891788782002514, 0.9925326378813133, 0.9874448327736501, 0.9916721216750904, 0.9896074704147846, 0.9884283535853696, 0.9926628382774356, 0.9893547401816641, 0.43333060315476235, 0.48608485939778834, 0.4184802127067728, 0.4925896996260243, 0.4539455087457036, 0.1474183933944907, 0.4860194156386085, 0.08780820755532204, 0.49229067495808376, 0.7805912963847488, 0.7604095864587068, 0.7360996490826108, 0.7687999550614545, 0.18702981661609153, 0.7480100782816016, 0.6806207624298362, 0.7731277488931032, 0.7512028927902215, 0.29401066848424606, 0.2941067936351498, 0.3757544901901472, 0.33217615042837956, 0.12994595205206372, 0.261403502681371, 0.3098797452540404, 0.28353008547368286, 0.32999118062708643, 0.32419246657120027, 0.2858324591814798, 0.20651280605901212, 0.250556397302349, 0.3306867854667105, 0.23861578938068084, 0.3796638335088294, 0.3731542372685833, 0.2752259203880203, 0.17485331935033577, 0.06459059538336676, 0.11567790117560184, 0.09951873729899252, 0.2868628856329587, 0.21052613901073514, 0.20180074911855883, 0.11029141031452727, 0.37166975204395036, 0.49975895479592725, 0.4571517669894847, 0.38700191355051994, 0.4864960992656092, 0.14241160337154501, 0.14950432679817627, 0.36398226287865254, 0.5563350081526084, 0.5352401107659791, 0.1148852278391449, 0.0873900399074149, 0.06413701664425986, 0.21791501192383556, 0.236273243135251, 0.1837408044323886, 0.21824106018534262, 0.1860314476932834, 0.09801413894696598, 0.20604275143367967, 0.04190425186268154, 0.2690445613421967, 0.28027288145140405, 0.3149537713388487, 0.2788256487852393, 0.3227609613606073, 0.31024778551563903, 0.2759036972810196, 0.6700434796411121, 0.6941705429559708, 0.6201009954936999, 0.6033261721261847, 0.6844789815778313, 0.6881987700135664, 0.6547489974447458, 0.6460183770251302, 0.6230811987329454, 0.07910582273860722, 0.09335097319089714, 0.08556687658724627, 0.1355078423320727, 0.09089682963016898, 0.09188316465606405, 0.09764229793796164, 0.08550859654348153, 0.10111313711503467, 0.13556805721990728, 0.19448965771148552, 0.21644889894435249, 0.23338144790220128, 0.2082462825928012, 0.4260662927896782, 0.2734127745052992, 0.1428939120146262, 0.18865079468895773, 0.3793800278302941, 0.35966525770104185, 0.23440769658143612, 0.37237928148763666, 0.3445333933416339, 0.36369977767967476, 0.4453987895148712, 0.4247555124204426, 0.39786535455875294, 0.281492646928695, 0.3205374894680493, 0.28372553536987977, 0.24333987915914235, 0.30268059376963974, 0.2847262359347631, 0.31069949114767437, 0.30648496768258326, 0.26129024979042104, 0.1831611552009179, 0.1688265130976606, 0.19009809819896706, 0.1940531764854161, 0.19977276497201057, 0.18921892006412722, 0.17909027121991128, 0.20160741631136558, 0.19909023221020328, 0.19910766981942385, 0.3429691230403228, 0.2667306041250912, 0.18449841676695544, 0.425381612500524, 0.20649238659307523, 0.1975011234503713, 0.35788598388003356, 0.1962267047606705, 0.7616738955278706, 0.6639878641848365, 0.11469496778784838, 0.17790118781106923, 0.1989689583555977, 0.18934000906459636, 0.1591974972449014, 0.20835305566264117, 0.7324802500584509, 0.12562355968724603, 0.16770955004813948, 0.16373566259916783, 0.19605499394718018, 0.16754021035284727, 0.2092017962416466, 0.20332299417706934, 0.7207959201531438, 0.19251229357680288, 0.17333447801267354, 0.20473382306953714, 0.19037746516988796, 0.20301481188994397, 0.20172454617088864, 0.18919516963100336, 0.187628351216512, 0.21810858291731527, 0.1938316099999633, 0.07508482863795485, 0.075456698072079, 0.07339220644319944, 0.08232361554962608, 0.07311722746975102, 0.07674613945862419, 0.07176324902488451, 0.0829524873946329, 0.07590908144242481]}, "mutation_prompt": null}
{"id": "9e7570ef-cdc2-4ea2-8695-8b3fff00fd58", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        def local_search(position):\n            # Simple local search around a position\n            neighbors = np.clip(position + np.random.uniform(-0.1, 0.1, self.dim), self.lower_bound, self.upper_bound)\n            neighbor_score = func(neighbors)\n            self.num_evals += 1\n            if neighbor_score < func(position):\n                return neighbors, neighbor_score\n            return position, func(position)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n            # Local search and diversity preservation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                swarm[i], local_score = local_search(swarm[i])\n                if local_score < personal_best_scores[i]:\n                    personal_best_scores[i] = local_score\n                    personal_best_positions[i] = swarm[i]\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = swarm[i]\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm with adaptive parameter control, diversity preservation, and enhanced local search for improved exploration and exploitation.", "configspace": "", "generation": 39, "fitness": 0.23278789865761637, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.21.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.5296861421226451, 0.4572840156331236, 0.5124268233090082, 0.5250470879550653, 0.4891457375952033, 0.5013626611239204, 0.48963080293145, 0.5186645835339632, 0.4635380266564467, 0.21285330642247902, 0.13845298608495782, 0.17175367018940302, 0.15864000063877615, 0.20180103054298748, 0.20587150794288678, 0.22069125053037508, 0.22070731140999955, 0.1821869634623121, 0.06532694737808176, 0.10261017809054862, 0.09057224449114143, 0.08377417181248203, 0.08804243028633885, 0.06944550544226591, 0.10221299102595016, 0.09220266120434151, 0.10276752814384216, 0.07201272034318118, 0.0952291894249867, 0.07743739119450288, 0.08318986822743624, 0.09525343298717381, 0.09730497470757982, 0.09027802235110172, 0.08530436038627631, 0.08962631008089517, 0.9810135726412187, 0.9795755559566857, 0.9805981238693966, 0.9756366253658378, 0.985846051322692, 0.9600586385027385, 0.9792943984204541, 0.9751984870792634, 0.964096352139091, 0.2851093659421434, 0.24526061616959283, 0.2501179131304613, 0.22914747680018266, 0.25223222899941844, 0.2804623442516192, 0.20804162381541547, 0.18380291907205948, 0.20168100185884064, 0.2785972422936175, 0.4864078911092693, 0.4899840477835917, 0.4119501991789303, 0.4828611446066323, 0.4796524481632366, 0.33612401349117327, 0.4543010079168869, 0.43109538976313255, 0.14624678747692543, 0.14082034141659006, 0.1506695223404082, 0.13700885008563946, 0.12191625064071454, 0.1329420776660134, 0.14565929325333782, 0.13845703889881733, 0.1570418976236757, 0.13382264791951604, 0.12184830793957169, 0.1384123439736128, 0.14840144088976215, 0.12852907005453484, 0.15236174831721017, 0.12525436551592262, 0.13447229955503048, 0.10384463588457982, 0.008592651624111713, 0.0295088927372259, 0.058554900802745724, 0.05321773838172139, 0.0600296756975095, 0.06416738247623743, 0.07084731015977885, 0.061134681788164946, 0.07089293696882903, 0.15062402734405167, 0.033278769460128976, 0.22055769239609102, 0.26331660946669544, 0.10712451688486058, 0.22918991358795182, 0.3168639837794607, 0.2260308363652893, 0.11809770079979642, 0.014407736217977418, 0.054790927723958105, 0.04190108366897605, 0.008080420133649957, 0.03334991144844557, 0.03525430919052419, 0.050642436401369784, 0.017281082737656495, 0.009288011506263905, 0.10180888523337361, 0.13185974419177748, 0.10596059311458883, 0.12484273587984296, 0.06483087381552832, 0.1390446389234261, 0.16368211533114152, 0.1513931251156544, 0.11261892632508008, 0.4224462120869581, 0.4401882178268284, 0.41210903243212793, 0.4437510229180942, 0.4454460202724495, 0.4329247549151449, 0.4283395816466622, 0.45305483081643483, 0.42931723420738954, 0.11076784591170308, 0.10130647912552737, 0.05832642402679611, 0.0916606132222505, 0.07819230134480548, 0.10377907665338548, 0.06536540090637355, 0.08855478887190038, 0.08204198899820547, 0.17531381299730509, 0.14050122434002443, 0.21686206780903572, 0.3046922117839602, 0.14270107082104622, 0.15853395088008948, 0.20625536985588955, 0.25414410760792927, 0.20463960221918165, 0.2833720453540223, 0.26839382035085446, 0.27823524977795655, 0.2610857472485524, 0.25217411616915053, 0.28105570713459005, 0.2483404799921467, 0.2765095184676877, 0.22773281227325504, 0.18923063096259662, 0.1917709834236141, 0.20567146478504705, 0.19662877282884428, 0.19403018069111244, 0.19804404994134606, 0.2180316526982261, 0.24412269094259442, 0.17910408430650748, 0.1902094761442027, 0.18259431752603683, 0.16998312825180295, 0.19304048003885577, 0.18364496929570828, 0.1638240866468088, 0.17073946535964857, 0.1772175531076784, 0.20198666012369937, 0.17846630400589658, 0.18241638651974645, 0.18905998107962851, 0.24846131357613366, 0.18796530020219182, 0.19841217979581516, 0.1759388930170207, 0.18543799155466745, 0.17016638069568835, 0.7213643841882471, 0.17356621158455832, 0.15299233815000568, 0.4207326910717323, 0.19472960376351234, 0.5844935308549006, 0.09895786781362115, 0.1677127399394085, 0.15101926636456575, 0.14729454346345716, 0.19620729349011656, 0.44810062816965723, 0.6304299171348258, 0.39796326602184884, 0.2023821558008443, 0.10325181325895905, 0.19679369038687244, 0.47445587254648636, 0.19137254100058665, 0.17227189042435398, 0.1714329899017346, 0.20297752525354062, 0.18439977907435112, 0.18112270146551113, 0.16768529381204678, 0.1813630055010208, 0.18127147005210842, 0.06855798992806739, 0.0652807738504595, 0.07056884276409836, 0.06708677951667741, 0.06479180588278799, 0.08663324679835094, 0.07713135097626367, 0.06908829097510827, 0.07112968763915428]}, "mutation_prompt": null}
{"id": "bdc00b7d-5390-4244-8ed4-4466d49047ef", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        def select_neighbors(index):\n            neighbors = np.random.choice(self.population_size, 3, replace=False)\n            if index in neighbors:\n                neighbors[neighbors == index] = (index + 1) % self.population_size\n            return neighbors\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with adaptive neighborhood\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                n1, n2, n3 = select_neighbors(i)\n                a, b, c = personal_best_positions[[n1, n2, n3]]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "Hybrid PSO-DE with an adaptive neighborhood topology for improved information exchange and convergence accuracy.", "configspace": "", "generation": 40, "fitness": 0.3628185179779308, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.25.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.731814406908214, 0.7463232973911023, 0.7991877649216741, 0.7668099389834662, 0.780675188753071, 0.7720716175723068, 0.7801513053194582, 0.7707895048956133, 0.8002593423684936, 0.5658614020427999, 0.5581769291888985, 0.5905702215477543, 0.5894846193481322, 0.40807751642645085, 0.597418736969889, 0.5185430434521933, 0.5968427595375877, 0.5786243546789358, 0.1295489500807553, 0.14099778746133795, 0.26209927371155695, 0.14753573803631348, 0.13683103005792785, 0.14281453694419577, 0.13877605700544537, 0.11000891315701078, 0.14708544668110612, 0.11632667506728411, 0.1197968886378481, 0.3836009579395703, 0.09373693931738492, 0.10827044408940001, 0.1005093186978323, 0.11311989540244083, 0.09749933721485826, 0.11953205515528897, 0.9885133065644344, 0.9839063728467031, 0.9885523607668647, 0.9883844486408406, 0.9891099289424023, 0.979706772529284, 0.9864227262566769, 0.9833361977760983, 0.9877096624123514, 0.5208708861158052, 0.054827147457195524, 0.5275807610836689, 0.5396822934120519, 0.5069622853678624, 0.5489713282922846, 0.5716902130036314, 0.08897186445894134, 0.0869295741898286, 0.22450582177350342, 0.7030688396608835, 0.782480923521434, 0.26918854151768656, 0.20548281381383504, 0.7648446165352117, 0.7916729689307388, 0.7585877853489394, 0.6196058383655527, 0.11535520715412806, 0.12472904813890817, 0.29249706401606157, 0.38902189842768087, 0.3367908866051441, 0.44343406365458427, 0.3583915891869024, 0.39507995550383046, 0.37789086504294633, 0.12398122847385007, 0.009819514057352041, 0.25347351119040284, 0.3081600384071197, 0.31167521655026853, 0.12978196560443778, 0.31827722639940426, 0.17804567791140669, 0.3577656018392129, 0.19822439341389597, 0.13877910422080564, 0.3724620486627206, 0.2533594387703779, 0.28260675541620284, 0.45619825802400715, 0.38678869902997615, 0.5194343903827723, 0.47961194350776737, 0.30841484509305706, 0.2702261366422266, 0.46924255522784875, 0.1886975903668996, 0.06978140149568846, 0.20303847438726264, 0.3244971734736928, 0.5408400998412835, 0.272671503019963, 0.18516959804811395, 0.06853599519912823, 0.12311357123718791, 0.09414258456820246, 0.06750488146891198, 0.10422066782670736, 0.1361228007658266, 0.1284745254669124, 0.09206164918113358, 0.23632950214219994, 0.31717518109916754, 0.2993908676604552, 0.2970521138720915, 0.3314552678765095, 0.3374752735985468, 0.308201195073621, 0.28022039030764423, 0.31755795595109726, 0.6819888718171487, 0.6653777184411162, 0.6977560087922177, 0.6427981352136157, 0.689695070475245, 0.7207307553103188, 0.6501675284426565, 0.6303728774853552, 0.656274199517769, 0.10728352123221596, 0.10784602344479177, 0.1311825311561191, 0.13001902264670084, 0.1368471595778492, 0.16143498293863034, 0.13202319725029488, 0.0969425227840156, 0.10969227677377091, 0.2747962685209664, 0.19717343961975053, 0.1702812439231226, 0.1727447207947025, 0.22240285606489807, 0.1714634968606712, 0.6111107193750125, 0.15489288991465888, 0.49901245031432484, 0.39482490900403877, 0.4183052649150223, 0.4451049571035124, 0.4115372471764309, 0.3948927707505734, 0.4344779858516661, 0.4170944924254263, 0.45418566180963804, 0.4368367690921784, 0.2763156512256887, 0.3175446079027783, 0.2777676107479268, 0.341590349891705, 0.36576040481435823, 0.3456012259431813, 0.3447901541393791, 0.4000882429065109, 0.38348056709632106, 0.2221182348764551, 0.25480285797913127, 0.22434833753937333, 0.1927210180536043, 0.20049049636870697, 0.2140240053913529, 0.23322190850829716, 0.1944650860889322, 0.210533855196385, 0.20487789689713276, 0.22322579396635334, 0.4104680130537809, 0.20160482214717812, 0.2278057656883552, 0.22929369239794106, 0.1974782039468962, 0.5396026369866744, 0.20621729194566885, 0.8669415737331921, 0.8446156209630882, 0.15373680551311286, 0.8150307792617281, 0.7776909073472735, 0.19803916749604966, 0.09997110489620331, 0.17004536513725743, 0.6573095714501097, 0.7881336913199094, 0.21159499122867587, 0.7959131246750095, 0.20472403518755056, 0.6279903548305164, 0.20524317516061386, 0.21204361315027598, 0.20152835337434039, 0.779634583843016, 0.21889248277791784, 0.20221505432772902, 0.1870787217512927, 0.18318910345549055, 0.19989378091521237, 0.20411351080757323, 0.1883561336463192, 0.18574046864810867, 0.23235247961179306, 0.08580934426502884, 0.09847763905530194, 0.10542510805159944, 0.08914820590883266, 0.08878073948237142, 0.0892315964662661, 0.08102085458869623, 0.08173164570470559, 0.08275905165253694]}, "mutation_prompt": null}
{"id": "6b6d0fad-b429-4fae-bf61-a40c8ca2d267", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm with adaptive parameter control and self-adaptive mutation strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7448526286713765, 0.7392154961019588, 0.7572569173904389, 0.7799681274675723, 0.7770365371458084, 0.18891091175864927, 0.7547346166532488, 0.7698414894175072, 0.7846201403014895, 0.5544277888758236, 0.558274526282354, 0.5843668730635316, 0.5257672158153426, 0.5680009264841568, 0.5927018986201256, 0.5828648113653292, 0.5740945701585725, 0.560720649078597, 0.12339865847364595, 0.10609912391354936, 0.13873867455333477, 0.1300788400907733, 0.13413957663717757, 0.1316934699108786, 0.14708467378446222, 0.14711691426278506, 0.11834151431943851, 0.1127698171452286, 0.10697706726895118, 0.11897574269969025, 0.1274032583163507, 0.14233705649486383, 0.11851335702736199, 0.18757911841463282, 0.11982370166568013, 0.12135832484418374, 0.9890111720563037, 0.9887973677819772, 0.9889915848009119, 0.9872872568288366, 0.9891255673164789, 0.9800050609649302, 0.986622344131887, 0.9834399814569047, 0.984837528066702, 0.5053871767834517, 0.5337226106023258, 0.5601100071869829, 0.4760828343780448, 0.5416634893012883, 0.1503013785231968, 0.5147513930129465, 0.48459116992535456, 0.08752752387028429, 0.8217055367302777, 0.6635973393149875, 0.7094033953646979, 0.27673357683299504, 0.19198737443417013, 0.8155550789045929, 0.7086174727522947, 0.6080024262936471, 0.8213993824381152, 0.42477904099967045, 0.25804049692707265, 0.33993095892589875, 0.2692693606642228, 0.3276340857452389, 0.2595033922227622, 0.33361290470460203, 0.4120262163094388, 0.2836288606052856, 0.24657679639240615, 0.3601943290860812, 0.23784455530796123, 0.2904969219559539, 0.23912354558375581, 0.3287698496096533, 0.28114107464367566, 0.3710128315447766, 0.31975042811668963, 0.2424468953601987, 0.3126597809044883, 0.17953646038881454, 0.21698533577858492, 0.15241988894724623, 0.32377042465016703, 0.29024315932947287, 0.27202316416734285, 0.4170911627509909, 0.38996893042442804, 0.4927724276879004, 0.4580699223090704, 0.5101029252168345, 0.512798511153497, 0.5359971606141398, 0.5688079823649417, 0.5652054357015456, 0.2960062870997723, 0.21562803967912858, 0.11796955155385436, 0.10110814950160729, 0.19877275237181058, 0.3018228545609971, 0.2670054777595078, 0.12559912355922276, 0.10405464151183819, 0.13275965283033442, 0.2819081783747931, 0.30690993030097335, 0.3291902760013653, 0.2347887652931937, 0.30992021171435413, 0.28523012625376687, 0.278712259238859, 0.1345871862953003, 0.30032955627997615, 0.6561036739619437, 0.7045213403357213, 0.6840663789036974, 0.6528785102644721, 0.6807732042201116, 0.7302435108574553, 0.6400523320486493, 0.6588289690060826, 0.6293457894368318, 0.16321289590724541, 0.1383358726902867, 0.12755549639247366, 0.09651860724382166, 0.10254226631381536, 0.09270979027029147, 0.10477602285250631, 0.11726160727443202, 0.10511842154443551, 0.1874312513354358, 0.23340218578904282, 0.25687570151268624, 0.2156221698369174, 0.5113490086369419, 0.17533278006890107, 0.5673396378127507, 0.5359820870591794, 0.21982701113501835, 0.40755532361539104, 0.45789618754129124, 0.38288367855846805, 0.39781289584025115, 0.4248799735432147, 0.4465882728628088, 0.4585011020790253, 0.45743466367002894, 0.4659386325787621, 0.2973354140194501, 0.31852094688539756, 0.29452379740874157, 0.32319384507987337, 0.27248778476523006, 0.3399160751681274, 0.3964938097709676, 0.360994354931675, 0.3226018640130264, 0.1993881779519604, 0.20010524772807758, 0.1872269269161111, 0.21152073183527242, 0.1908556507745499, 0.18876754517126493, 0.19161796316814994, 0.20605202090667174, 0.2678235805960435, 0.183451284333637, 0.19608609559147616, 0.21592943921272534, 0.4386187884854288, 0.38552604932971657, 0.37126721559142783, 0.220543360096633, 0.42228726567734676, 0.4350183739816521, 0.8502343345481216, 0.8092744607057609, 0.15356341662645123, 0.7980160658194214, 0.2004867512950873, 0.19659643548645023, 0.09997677059463494, 0.16847650304502948, 0.1832139670942533, 0.15320311055063596, 0.21054089152959665, 0.20288748476332308, 0.20427064898560032, 0.8419032137630112, 0.20938881124760478, 0.2105813410848586, 0.2108078373511003, 0.7334272478516608, 0.19607129615310293, 0.19127201738621957, 0.19282312734508256, 0.19053318833302724, 0.1968648785555116, 0.2033109926408726, 0.19558029960776713, 0.183347469594077, 0.20345506576776917, 0.09673230341522232, 0.08113352350664149, 0.08226968732815099, 0.08053683439957826, 0.08680470988970046, 0.08485538662954473, 0.0795836099471875, 0.0983330241369913, 0.09367402556843207]}, "mutation_prompt": null}
{"id": "2a117152-0e9d-4bf1-b057-f7d5bea37cb9", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_interval = 0.1 * self.budget\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n            # Perform local search periodically to exploit local minima\n            if self.num_evals % self.local_search_interval < self.population_size:\n                index = self.num_evals % self.population_size\n                local_step = np.random.uniform(-0.1, 0.1, self.dim)\n                local_candidate = np.clip(personal_best_positions[index] + local_step, self.lower_bound, self.upper_bound)\n                local_score = func(local_candidate)\n                self.num_evals += 1\n\n                if local_score < personal_best_scores[index]:\n                    personal_best_scores[index] = local_score\n                    personal_best_positions[index] = local_candidate\n                    if local_score < global_best_score:\n                        global_best_score = local_score\n                        global_best_position = local_candidate\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced hybrid PSO-DE with adaptive exploration-exploitation balance via dynamic parameter scaling and periodic local search for improved convergence.", "configspace": "", "generation": 42, "fitness": 0.35735727017298724, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.25.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7233403167220257, 0.7507680263148149, 0.7532703211687106, 0.7802821700609252, 0.7717223741634783, 0.6410672510719919, 0.7453994053313076, 0.7795541377837334, 0.7704486023717468, 0.6242170227139258, 0.6184079239284453, 0.5650078873858466, 0.538133629189337, 0.5401039036145798, 0.5991663684904618, 0.5937023281919511, 0.05640868513910213, 0.5772452233562193, 0.13610863731524592, 0.1449915059511253, 0.11589034661358599, 0.13041447916762539, 0.15019574939563518, 0.07330655457615431, 0.14246739925650986, 0.1457374348902093, 0.34007841328375066, 0.12194064132844229, 0.11249284793343728, 0.11565522393761674, 0.12973004494694673, 0.12595953299092943, 0.13983692802157088, 0.11827762697040456, 0.0949482154314002, 0.10909265182996608, 0.9890111720563037, 0.9887973677819772, 0.9889915848009119, 0.9872872568288366, 0.9891255673164789, 0.9800050609649302, 0.986622344131887, 0.9834399814569047, 0.984837528066702, 0.5336701708686511, 0.4882399609013679, 0.5437833324303707, 0.49209587969198376, 0.5134467353163061, 0.18842207933632205, 0.5127341584807157, 0.4842566822560075, 0.4704497047741053, 0.7686162591113552, 0.228977553733693, 0.6793069274579739, 0.7549126185554054, 0.19188131778556827, 0.7809923161376231, 0.67372279822667, 0.21729222466270282, 0.7643529816725521, 0.3745963667515422, 0.28888144175309405, 0.2798687075021854, 0.3480349102104652, 0.13168361587601174, 0.29198942919411164, 0.31486283558602945, 0.3187239855546141, 0.33751928545350207, 0.27010676076995355, 0.3749441075954605, 0.2671242501457207, 0.35768635050753816, 0.2736066315980371, 0.35755406671804413, 0.2900357424325537, 0.28751238916274957, 0.3886866324991366, 0.12333501482271803, 0.06084925064931501, 0.1667408836510922, 0.06566376019813447, 0.22688327760767613, 0.4056477245267287, 0.3348549984996477, 0.3140710876925952, 0.3759565002063532, 0.5322611622323472, 0.3878579607440654, 0.5054048000939158, 0.4470883128875016, 0.1427884632538049, 0.5413787240515658, 0.5897732947883003, 0.5497669506786278, 0.33990737879682864, 0.15577452793789415, 0.1022641564700909, 0.09353231967620068, 0.16447491225440003, 0.15778940612630032, 0.2836989130473091, 0.1228382756751566, 0.18764439757585494, 0.1695875318431299, 0.27820181761762464, 0.2908123460207823, 0.2837583752730112, 0.22345012978254364, 0.30540842336675356, 0.31483443784393406, 0.3235305374497226, 0.12802471032084073, 0.26322970746618424, 0.6457970109905666, 0.6116825958113343, 0.6833747225337665, 0.6393226953941433, 0.7033541374806547, 0.6976614082174362, 0.6235577118980721, 0.6582445519087189, 0.6752107600325413, 0.14522681487441202, 0.1309584715266905, 0.13338431455029442, 0.12689839920265544, 0.1295498443520151, 0.12720256444641143, 0.12371923819992336, 0.09194846280336932, 0.11880580339844637, 0.2128811828651208, 0.24815361361149535, 0.1895666871141466, 0.1716265536646211, 0.5245628398924329, 0.42357625641915164, 0.3432609527427265, 0.5153624226777809, 0.259687887930646, 0.42827541570137284, 0.3679755034064328, 0.4013128433002955, 0.41198792779620963, 0.47273723558090164, 0.4072984067464176, 0.45462554709341485, 0.4760028927211881, 0.3890857068019503, 0.2920343075791124, 0.3238291966209065, 0.20145231275418984, 0.3050933866616531, 0.2899277843240108, 0.3408439168708003, 0.34727221001545217, 0.3301078745177144, 0.32074724190960635, 0.20893643249240879, 0.19076639614047253, 0.18664192068057617, 0.1873606256005842, 0.19444477220395406, 0.19239894069277896, 0.20034794483943985, 0.20017185888202926, 0.2620484176139658, 0.21170167562699227, 0.21362255008280362, 0.20059143316613903, 0.20345476661534312, 0.21088397062412578, 0.19445269722499825, 0.20427008776245925, 0.2166361112183467, 0.21450701400710337, 0.837778941153326, 0.8204688658450225, 0.15356268841463028, 0.8038040425633926, 0.20050044043529436, 0.19625628715869192, 0.09997663747922547, 0.16845988986016835, 0.16744906815923155, 0.1530662047245389, 0.21072640374950957, 0.6831319165781042, 0.20368245248900008, 0.8556236114101816, 0.2092517597418977, 0.21058640090292668, 0.21085071643943898, 0.7436698092182636, 0.1866834680970283, 0.20342262348445306, 0.18908130296409376, 0.20212404350703705, 0.19413851319494146, 0.18159779112688035, 0.2115243189457312, 0.17775347167628075, 0.19198732571035393, 0.0954618725867955, 0.08768223416665022, 0.07019306307271655, 0.084696613201244, 0.07942483837339842, 0.08002051508704677, 0.09859437365706958, 0.07984537313894835, 0.08452389255284365]}, "mutation_prompt": null}
{"id": "836bbb27-5c5f-4dc1-9518-d5d53d8d91e1", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm with adaptive parameter control and self-adaptive mutation strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7448526286713765, 0.7392154961019588, 0.7572569173904389, 0.7799681274675723, 0.7770365371458084, 0.18891091175864927, 0.7547346166532488, 0.7698414894175072, 0.7846201403014895, 0.5544277888758236, 0.558274526282354, 0.5843668730635316, 0.5257672158153426, 0.5680009264841568, 0.5927018986201256, 0.5828648113653292, 0.5740945701585725, 0.560720649078597, 0.12339865847364595, 0.10609912391354936, 0.13873867455333477, 0.1300788400907733, 0.13413957663717757, 0.1316934699108786, 0.14708467378446222, 0.14711691426278506, 0.11834151431943851, 0.1127698171452286, 0.10697706726895118, 0.11897574269969025, 0.1274032583163507, 0.14233705649486383, 0.11851335702736199, 0.18757911841463282, 0.11982370166568013, 0.12135832484418374, 0.9890111720563037, 0.9887973677819772, 0.9889915848009119, 0.9872872568288366, 0.9891255673164789, 0.9800050609649302, 0.986622344131887, 0.9834399814569047, 0.984837528066702, 0.5053871767834517, 0.5337226106023258, 0.5601100071869829, 0.4760828343780448, 0.5416634893012883, 0.1503013785231968, 0.5147513930129465, 0.48459116992535456, 0.08752752387028429, 0.8217055367302777, 0.6635973393149875, 0.7094033953646979, 0.27673357683299504, 0.19198737443417013, 0.8155550789045929, 0.7086174727522947, 0.6080024262936471, 0.8213993824381152, 0.42477904099967045, 0.25804049692707265, 0.33993095892589875, 0.2692693606642228, 0.3276340857452389, 0.2595033922227622, 0.33361290470460203, 0.4120262163094388, 0.2836288606052856, 0.24657679639240615, 0.3601943290860812, 0.23784455530796123, 0.2904969219559539, 0.23912354558375581, 0.3287698496096533, 0.28114107464367566, 0.3710128315447766, 0.31975042811668963, 0.2424468953601987, 0.3126597809044883, 0.17953646038881454, 0.21698533577858492, 0.15241988894724623, 0.32377042465016703, 0.29024315932947287, 0.27202316416734285, 0.4170911627509909, 0.38996893042442804, 0.4927724276879004, 0.4580699223090704, 0.5101029252168345, 0.512798511153497, 0.5359971606141398, 0.5688079823649417, 0.5652054357015456, 0.2960062870997723, 0.21562803967912858, 0.11796955155385436, 0.10110814950160729, 0.19877275237181058, 0.3018228545609971, 0.2670054777595078, 0.12559912355922276, 0.10405464151183819, 0.13275965283033442, 0.2819081783747931, 0.30690993030097335, 0.3291902760013653, 0.2347887652931937, 0.30992021171435413, 0.28523012625376687, 0.278712259238859, 0.1345871862953003, 0.30032955627997615, 0.6561036739619437, 0.7045213403357213, 0.6840663789036974, 0.6528785102644721, 0.6807732042201116, 0.7302435108574553, 0.6400523320486493, 0.6588289690060826, 0.6293457894368318, 0.16321289590724541, 0.1383358726902867, 0.12755549639247366, 0.09651860724382166, 0.10254226631381536, 0.09270979027029147, 0.10477602285250631, 0.11726160727443202, 0.10511842154443551, 0.1874312513354358, 0.23340218578904282, 0.25687570151268624, 0.2156221698369174, 0.5113490086369419, 0.17533278006890107, 0.5673396378127507, 0.5359820870591794, 0.21982701113501835, 0.40755532361539104, 0.45789618754129124, 0.38288367855846805, 0.39781289584025115, 0.4248799735432147, 0.4465882728628088, 0.4585011020790253, 0.45743466367002894, 0.4659386325787621, 0.2973354140194501, 0.31852094688539756, 0.29452379740874157, 0.32319384507987337, 0.27248778476523006, 0.3399160751681274, 0.3964938097709676, 0.360994354931675, 0.3226018640130264, 0.1993881779519604, 0.20010524772807758, 0.1872269269161111, 0.21152073183527242, 0.1908556507745499, 0.18876754517126493, 0.19161796316814994, 0.20605202090667174, 0.2678235805960435, 0.183451284333637, 0.19608609559147616, 0.21592943921272534, 0.4386187884854288, 0.38552604932971657, 0.37126721559142783, 0.220543360096633, 0.42228726567734676, 0.4350183739816521, 0.8502343345481216, 0.8092744607057609, 0.15356341662645123, 0.7980160658194214, 0.2004867512950873, 0.19659643548645023, 0.09997677059463494, 0.16847650304502948, 0.1832139670942533, 0.15320311055063596, 0.21054089152959665, 0.20288748476332308, 0.20427064898560032, 0.8419032137630112, 0.20938881124760478, 0.2105813410848586, 0.2108078373511003, 0.7334272478516608, 0.19607129615310293, 0.19127201738621957, 0.19282312734508256, 0.19053318833302724, 0.1968648785555116, 0.2033109926408726, 0.19558029960776713, 0.183347469594077, 0.20345506576776917, 0.09673230341522232, 0.08113352350664149, 0.08226968732815099, 0.08053683439957826, 0.08680470988970046, 0.08485538662954473, 0.0795836099471875, 0.0983330241369913, 0.09367402556843207]}, "mutation_prompt": null}
{"id": "416d8e94-da39-40ca-af3d-c297641d7af6", "solution": "import numpy as np\n\nclass OptimizedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position with random sub-dimension updating\n                rand_dim = np.random.randint(0, self.dim)\n                if np.random.rand() < 0.5:\n                    swarm[i][rand_dim] = swarm[i][rand_dim] + velocities[i][rand_dim]\n\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = np.copy(a)\n                rand_dim = np.random.randint(0, self.dim)\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == rand_dim:\n                        mutant[j] = a[j] + F * (b[j] - c[j])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial_score = func(mutant)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = mutant\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = mutant\n\n        return global_best_position", "name": "OptimizedHybridPSO_DE", "description": "An optimized hybrid PSO-DE with adaptive inertia, F and CR, employing random sub-dimension updating to enhance diversity and convergence.", "configspace": "", "generation": 44, "fitness": 0.3306545796464662, "feedback": "The algorithm OptimizedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.25.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.8604300296223208, 0.7798546331657257, 0.6557397157972589, 0.8171621110040297, 0.8591431531878702, 0.7551575110468829, 0.7907457942694194, 0.7018916327656319, 0.8451110657937311, 0.6571123199178801, 0.48473302586802103, 0.6666978939701113, 0.49016461877501805, 0.7287734105329589, 0.12401290530327003, 0.3536812671637486, 0.25583268100439327, 0.5729867992395257, 0.15012539873120623, 0.13066835683004496, 0.1487776075970043, 0.13252431808537746, 0.14344567767360294, 0.10501205387443191, 0.0777468482173832, 0.14197367238925584, 0.10966567376184244, 0.0882676156296871, 0.08349216809731075, 0.11955121879107611, 0.10174371433348584, 0.08864219219850933, 0.11364223065659429, 0.06163590395305585, 0.09246707260552955, 0.1181931092196481, 0.9562455158557603, 0.9393978352892184, 0.9571483878408559, 0.9411952653010883, 0.9498415628476529, 0.9647186307792526, 0.949150928128456, 0.9454682299895403, 0.9551491256125021, 0.2902759372268313, 0.2117886987854969, 0.41564769384741995, 0.21220810039966864, 0.1916653702448825, 0.4702342084678863, 0.2773964345341089, 0.2583275086741873, 0.3228381343952138, 0.8275846688004999, 0.843917605339447, 0.8492924399912883, 0.3944992024944368, 0.35018405681553855, 0.7578231106786996, 0.17943644638454603, 0.8315379779680143, 0.23055764277011592, 0.1615449155782318, 0.145543670669249, 0.38238125267966716, 0.40697823279696954, 0.1303222044407023, 0.13036459200031636, 0.2392708084652554, 0.18720887603633796, 0.270417429191703, 0.16607347060694844, 0.15487517457068556, 0.12747347559363575, 0.12738461263999012, 0.24288260539823714, 0.14988935515021262, 0.14408460142950463, 0.1609052243956659, 0.17615231896645023, 0.17756091483770764, 0.2699641442379308, 0.286730635107573, 0.12982310990443424, 0.49238015065323804, 0.250552836229732, 0.21827040334284176, 0.18797409050522662, 0.4922777506347198, 0.4520713558775068, 0.5414617720041506, 0.49767011261912, 0.4553462229274975, 0.17148546092052186, 0.29299188109567886, 0.5862152161738977, 0.5594002699604016, 0.5896936535177424, 0.08803140004603005, 0.08311034894015612, 0.14033354972944256, 0.2674389267088826, 0.14164685926876297, 0.12878360539989753, 0.2889836781612315, 0.10573760733245652, 0.13936329526111713, 0.3280017679929532, 0.32284941320631744, 0.315900389760312, 0.30175187041861373, 0.3643646474390142, 0.3403380337884011, 0.3941776952409757, 0.18143324248917347, 0.33796309311893835, 0.743893042802412, 0.5136062349859685, 0.5999982107763374, 0.5941354183667038, 0.6166154099137316, 0.7163834043083528, 0.777260288715637, 0.6422488778869755, 0.7064221777082985, 0.1413763420078773, 0.09124948852352632, 0.11507129124189686, 0.12476868255732787, 0.1486587396798319, 0.1335863066050631, 0.09118515980871411, 0.12616118459470604, 0.08644146278623643, 0.17972122616959785, 0.1631552828121392, 0.14577527540544977, 0.15737389624251896, 0.14095728309028965, 0.21745493143450423, 0.11963600442511613, 0.18102955811103227, 0.19325877541639225, 0.4810643735360005, 0.4387284709789958, 0.403379221090281, 0.48507369439771486, 0.4773084605799699, 0.44191468726835426, 0.46647908264303883, 0.48443107136664243, 0.4560306911034787, 0.33257423687493703, 0.30849323292989983, 0.3216590841921989, 0.25969001396450897, 0.34351931866086094, 0.3277125071101198, 0.25388776656339873, 0.33395080978515856, 0.27855594283773955, 0.17735784818263367, 0.19081825060066393, 0.21082048728154357, 0.2007410774334657, 0.2225261694228643, 0.18163931131339672, 0.22395146074085492, 0.20095504903557138, 0.19401789066062025, 0.20209827585573603, 0.2127047102302828, 0.224270128260316, 0.2126137943063411, 0.1874701974864652, 0.22237144579558643, 0.2349703820125597, 0.18612947010876346, 0.23907872894365523, 0.19479491226637569, 0.17011399294876106, 0.16808281426979688, 0.5617436147419459, 0.17634524807535457, 0.17297577309516254, 0.16015420838552052, 0.1658141861567849, 0.17640487394542304, 0.1682910855435792, 0.5199671805201471, 0.788093794705573, 0.15125513720494854, 0.16474168865169814, 0.7397103874795725, 0.19862284026889654, 0.20877598130584762, 0.8324420177690139, 0.18364782263713542, 0.17885398534926622, 0.18171265073012477, 0.18046823069471885, 0.18732934395289214, 0.1636337133424891, 0.1669281785455914, 0.16367409534118593, 0.17880133406746213, 0.06687368822849404, 0.08267474155808086, 0.07927784585635655, 0.0959991073567209, 0.08719736420828195, 0.07803511373784822, 0.08640227264898548, 0.07533892151504729, 0.07363141060255507]}, "mutation_prompt": null}
{"id": "d83753ed-d76d-4c69-bcb5-a86c777b332e", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n\n                # Update position\n                swarm[i] = swarm[i] + velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined hybrid PSO-DE algorithm with adaptive parameter control and self-adaptive mutation strategies for enhanced exploration and exploitation.", "configspace": "", "generation": 29, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7448526286713765, 0.7392154961019588, 0.7572569173904389, 0.7799681274675723, 0.7770365371458084, 0.18891091175864927, 0.7547346166532488, 0.7698414894175072, 0.7846201403014895, 0.5544277888758236, 0.558274526282354, 0.5843668730635316, 0.5257672158153426, 0.5680009264841568, 0.5927018986201256, 0.5828648113653292, 0.5740945701585725, 0.560720649078597, 0.12339865847364595, 0.10609912391354936, 0.13873867455333477, 0.1300788400907733, 0.13413957663717757, 0.1316934699108786, 0.14708467378446222, 0.14711691426278506, 0.11834151431943851, 0.1127698171452286, 0.10697706726895118, 0.11897574269969025, 0.1274032583163507, 0.14233705649486383, 0.11851335702736199, 0.18757911841463282, 0.11982370166568013, 0.12135832484418374, 0.9890111720563037, 0.9887973677819772, 0.9889915848009119, 0.9872872568288366, 0.9891255673164789, 0.9800050609649302, 0.986622344131887, 0.9834399814569047, 0.984837528066702, 0.5053871767834517, 0.5337226106023258, 0.5601100071869829, 0.4760828343780448, 0.5416634893012883, 0.1503013785231968, 0.5147513930129465, 0.48459116992535456, 0.08752752387028429, 0.8217055367302777, 0.6635973393149875, 0.7094033953646979, 0.27673357683299504, 0.19198737443417013, 0.8155550789045929, 0.7086174727522947, 0.6080024262936471, 0.8213993824381152, 0.42477904099967045, 0.25804049692707265, 0.33993095892589875, 0.2692693606642228, 0.3276340857452389, 0.2595033922227622, 0.33361290470460203, 0.4120262163094388, 0.2836288606052856, 0.24657679639240615, 0.3601943290860812, 0.23784455530796123, 0.2904969219559539, 0.23912354558375581, 0.3287698496096533, 0.28114107464367566, 0.3710128315447766, 0.31975042811668963, 0.2424468953601987, 0.3126597809044883, 0.17953646038881454, 0.21698533577858492, 0.15241988894724623, 0.32377042465016703, 0.29024315932947287, 0.27202316416734285, 0.4170911627509909, 0.38996893042442804, 0.4927724276879004, 0.4580699223090704, 0.5101029252168345, 0.512798511153497, 0.5359971606141398, 0.5688079823649417, 0.5652054357015456, 0.2960062870997723, 0.21562803967912858, 0.11796955155385436, 0.10110814950160729, 0.19877275237181058, 0.3018228545609971, 0.2670054777595078, 0.12559912355922276, 0.10405464151183819, 0.13275965283033442, 0.2819081783747931, 0.30690993030097335, 0.3291902760013653, 0.2347887652931937, 0.30992021171435413, 0.28523012625376687, 0.278712259238859, 0.1345871862953003, 0.30032955627997615, 0.6561036739619437, 0.7045213403357213, 0.6840663789036974, 0.6528785102644721, 0.6807732042201116, 0.7302435108574553, 0.6400523320486493, 0.6588289690060826, 0.6293457894368318, 0.16321289590724541, 0.1383358726902867, 0.12755549639247366, 0.09651860724382166, 0.10254226631381536, 0.09270979027029147, 0.10477602285250631, 0.11726160727443202, 0.10511842154443551, 0.1874312513354358, 0.23340218578904282, 0.25687570151268624, 0.2156221698369174, 0.5113490086369419, 0.17533278006890107, 0.5673396378127507, 0.5359820870591794, 0.21982701113501835, 0.40755532361539104, 0.45789618754129124, 0.38288367855846805, 0.39781289584025115, 0.4248799735432147, 0.4465882728628088, 0.4585011020790253, 0.45743466367002894, 0.4659386325787621, 0.2973354140194501, 0.31852094688539756, 0.29452379740874157, 0.32319384507987337, 0.27248778476523006, 0.3399160751681274, 0.3964938097709676, 0.360994354931675, 0.3226018640130264, 0.1993881779519604, 0.20010524772807758, 0.1872269269161111, 0.21152073183527242, 0.1908556507745499, 0.18876754517126493, 0.19161796316814994, 0.20605202090667174, 0.2678235805960435, 0.183451284333637, 0.19608609559147616, 0.21592943921272534, 0.4386187884854288, 0.38552604932971657, 0.37126721559142783, 0.220543360096633, 0.42228726567734676, 0.4350183739816521, 0.8502343345481216, 0.8092744607057609, 0.15356341662645123, 0.7980160658194214, 0.2004867512950873, 0.19659643548645023, 0.09997677059463494, 0.16847650304502948, 0.1832139670942533, 0.15320311055063596, 0.21054089152959665, 0.20288748476332308, 0.20427064898560032, 0.8419032137630112, 0.20938881124760478, 0.2105813410848586, 0.2108078373511003, 0.7334272478516608, 0.19607129615310293, 0.19127201738621957, 0.19282312734508256, 0.19053318833302724, 0.1968648785555116, 0.2033109926408726, 0.19558029960776713, 0.183347469594077, 0.20345506576776917, 0.09673230341522232, 0.08113352350664149, 0.08226968732815099, 0.08053683439957826, 0.08680470988970046, 0.08485538662954473, 0.0795836099471875, 0.0983330241369913, 0.09367402556843207]}, "mutation_prompt": null}
{"id": "f9a91744-135f-4322-a3cf-87e646f5c73d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                # Update position\n                swarm[i] += velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced RefinedHybridPSO_DE with dynamic velocity clamping and adaptive search-space reduction for improved convergence.", "configspace": "", "generation": 46, "fitness": 0.37389392544327765, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.25.", "error": "", "parent_id": "6f559b84-058e-4bac-9a3e-31f6325e603a", "metadata": {"aucs": [0.7461518114966716, 0.7625245164288791, 0.7480683072189542, 0.7754618260530839, 0.7484561708385722, 0.7853225711537724, 0.7429541078215409, 0.7550667808345409, 0.7544608880677254, 0.53236110662442, 0.5412297613761923, 0.5846974743686889, 0.560222403292779, 0.5707203896180959, 0.5830392586876552, 0.582936508085354, 0.5853944470691592, 0.5287669525945267, 0.1559238427277465, 0.15375124604945123, 0.1479201839959704, 0.15230096739898347, 0.137631370443708, 0.15504351431781083, 0.10881316887679349, 0.12988580792507431, 0.1466175869334886, 0.12780542113084015, 0.11836966653441561, 0.1242829403414345, 0.12126721768505266, 0.12599595945498532, 0.13364876144995874, 0.10060488967124415, 0.1147003176919994, 0.11854930712992406, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5643406822619924, 0.113912529381609, 0.555299675548109, 0.49671549732630527, 0.56495702665707, 0.14952815009826703, 0.5640807075375613, 0.5194902213943309, 0.5447915495573188, 0.2354356124968694, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.32614731729818036, 0.39874109063226604, 0.32929212914370576, 0.3404615509038922, 0.12712512973439538, 0.33960153856540565, 0.500026649430007, 0.3764071878732035, 0.33963086375490525, 0.35374115869401146, 0.25541491361514657, 0.31933527267113937, 0.35059866256106764, 0.3684891370472314, 0.336943694175293, 0.3219299438756792, 0.12787378491823087, 0.38108913310841697, 0.3982142112773852, 0.16617895926983672, 0.08462777457150117, 0.11713292735999226, 0.4276861468636224, 0.18347448552725698, 0.20534888910799032, 0.37978211126927985, 0.42999905548980444, 0.5224052157398074, 0.18155905827441532, 0.5519084922452271, 0.3589786573834657, 0.49314719275187713, 0.29897008261901337, 0.616466059124994, 0.2416183845801252, 0.5123023364516406, 0.10977936530763144, 0.03900147690488176, 0.06288556766647746, 0.11694187723797955, 0.22551756122727729, 0.21516675707994926, 0.11471352533504453, 0.1317051547900996, 0.12691973012107594, 0.19818944401131766, 0.3233426047901198, 0.3022754121278708, 0.27902772879357196, 0.20914678479796023, 0.25240783494255603, 0.29027476928690643, 0.28761026384343236, 0.24899206663978635, 0.6575089854848799, 0.6585322483223268, 0.6804463093325019, 0.6434168017941159, 0.7028274327135267, 0.696288238819782, 0.6223086514972016, 0.6568764633141351, 0.6958259512276147, 0.10014967131866093, 0.14507100387123917, 0.14090345286438954, 0.10602302276954467, 0.11890043456647559, 0.11967966756301796, 0.11513983853146603, 0.10465500873286582, 0.10036822735712225, 0.22424742761534178, 0.26244625805975486, 0.30223456764090595, 0.2184634465574231, 0.17685903561962646, 0.253270406631792, 0.22288371702361853, 0.2417961742434429, 0.2656216152857226, 0.43690489783278286, 0.39822436990762045, 0.4041664492697642, 0.3771758731392759, 0.4019200659388953, 0.4705613744471192, 0.4451701068515328, 0.4578599771913884, 0.43290904534580255, 0.3288141821419175, 0.32779677508847427, 0.2675955780360467, 0.3061894795826342, 0.19715652186288457, 0.3335362193656324, 0.34373990969765444, 0.33827655372928833, 0.34333485623054705, 0.1990625898716224, 0.2006693925607188, 0.21298330677186572, 0.2148324097933163, 0.20442730309584478, 0.2337950350590935, 0.2143036451126129, 0.1885409830220267, 0.22774327880006695, 0.19416083462491673, 0.4922087050525762, 0.5116757967444963, 0.2199588580797076, 0.23577263844111718, 0.47105627704609765, 0.4089972631695228, 0.2166966956914439, 0.2255839025644617, 0.84120936818493, 0.8246052515524153, 0.15365907878824092, 0.7584287726700076, 0.19773207454624564, 0.19473572380906523, 0.7474784313729328, 0.16991888427646318, 0.8136283511053167, 0.728069673372769, 0.1690012314244841, 0.796306663016825, 0.20612552178179522, 0.7512316653275415, 0.20919714010200308, 0.19819575336761486, 0.21134618290729745, 0.21235430762524554, 0.18738163459877066, 0.18415896535664622, 0.20321789574667293, 0.19196449328671228, 0.18482622434694762, 0.19891716307210106, 0.17930621194924767, 0.2437958904733949, 0.19155521904157868, 0.08328251008805054, 0.08539253680723469, 0.07449138046631776, 0.08552834775175744, 0.08189261938683134, 0.07613714504144808, 0.09728003420851761, 0.09707127208686683, 0.08656686364485089]}, "mutation_prompt": null}
{"id": "cee70916-b89a-42c8-8b8d-2265e6d57fbb", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                # Update personal best\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                # Update global best\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                # Update position\n                swarm[i] += velocities[i]\n                # Ensure bounds\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with self-adaptation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced RefinedHybridPSO_DE with dynamic velocity clamping and adaptive search-space reduction for improved convergence.", "configspace": "", "generation": 47, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "f9a91744-135f-4322-a3cf-87e646f5c73d", "metadata": {"aucs": [0.7461518114966716, 0.7625245164288791, 0.7480683072189542, 0.7754618260530839, 0.7484561708385722, 0.7853225711537724, 0.7429541078215409, 0.7550667808345409, 0.7544608880677254, 0.53236110662442, 0.5412297613761923, 0.5846974743686889, 0.560222403292779, 0.5707203896180959, 0.5830392586876552, 0.582936508085354, 0.5853944470691592, 0.5287669525945267, 0.1559238427277465, 0.15375124604945123, 0.1479201839959704, 0.15230096739898347, 0.137631370443708, 0.15504351431781083, 0.10881316887679349, 0.12988580792507431, 0.1466175869334886, 0.12780542113084015, 0.11836966653441561, 0.1242829403414345, 0.12126721768505266, 0.12599595945498532, 0.13364876144995874, 0.10060488967124415, 0.1147003176919994, 0.11854930712992406, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5643406822619924, 0.113912529381609, 0.555299675548109, 0.49671549732630527, 0.56495702665707, 0.14952815009826703, 0.5640807075375613, 0.5194902213943309, 0.5447915495573188, 0.2354356124968694, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.32614731729818036, 0.39874109063226604, 0.32929212914370576, 0.3404615509038922, 0.12712512973439538, 0.33960153856540565, 0.500026649430007, 0.3764071878732035, 0.33963086375490525, 0.35374115869401146, 0.25541491361514657, 0.31933527267113937, 0.35059866256106764, 0.3684891370472314, 0.336943694175293, 0.3219299438756792, 0.12787378491823087, 0.38108913310841697, 0.3982142112773852, 0.16617895926983672, 0.08462777457150117, 0.11713292735999226, 0.4276861468636224, 0.18347448552725698, 0.20534888910799032, 0.37978211126927985, 0.42999905548980444, 0.5224052157398074, 0.18155905827441532, 0.5519084922452271, 0.3589786573834657, 0.49314719275187713, 0.29897008261901337, 0.616466059124994, 0.2416183845801252, 0.5123023364516406, 0.10977936530763144, 0.03900147690488176, 0.06288556766647746, 0.11694187723797955, 0.22551756122727729, 0.21516675707994926, 0.11471352533504453, 0.1317051547900996, 0.12691973012107594, 0.19818944401131766, 0.3233426047901198, 0.3022754121278708, 0.27902772879357196, 0.20914678479796023, 0.25240783494255603, 0.29027476928690643, 0.28761026384343236, 0.24899206663978635, 0.6575089854848799, 0.6585322483223268, 0.6804463093325019, 0.6434168017941159, 0.7028274327135267, 0.696288238819782, 0.6223086514972016, 0.6568764633141351, 0.6958259512276147, 0.10014967131866093, 0.14507100387123917, 0.14090345286438954, 0.10602302276954467, 0.11890043456647559, 0.11967966756301796, 0.11513983853146603, 0.10465500873286582, 0.10036822735712225, 0.22424742761534178, 0.26244625805975486, 0.30223456764090595, 0.2184634465574231, 0.17685903561962646, 0.253270406631792, 0.22288371702361853, 0.2417961742434429, 0.2656216152857226, 0.43690489783278286, 0.39822436990762045, 0.4041664492697642, 0.3771758731392759, 0.4019200659388953, 0.4705613744471192, 0.4451701068515328, 0.4578599771913884, 0.43290904534580255, 0.3288141821419175, 0.32779677508847427, 0.2675955780360467, 0.3061894795826342, 0.19715652186288457, 0.3335362193656324, 0.34373990969765444, 0.33827655372928833, 0.34333485623054705, 0.1990625898716224, 0.2006693925607188, 0.21298330677186572, 0.2148324097933163, 0.20442730309584478, 0.2337950350590935, 0.2143036451126129, 0.1885409830220267, 0.22774327880006695, 0.19416083462491673, 0.4922087050525762, 0.5116757967444963, 0.2199588580797076, 0.23577263844111718, 0.47105627704609765, 0.4089972631695228, 0.2166966956914439, 0.2255839025644617, 0.84120936818493, 0.8246052515524153, 0.15365907878824092, 0.7584287726700076, 0.19773207454624564, 0.19473572380906523, 0.7474784313729328, 0.16991888427646318, 0.8136283511053167, 0.728069673372769, 0.1690012314244841, 0.796306663016825, 0.20612552178179522, 0.7512316653275415, 0.20919714010200308, 0.19819575336761486, 0.21134618290729745, 0.21235430762524554, 0.18738163459877066, 0.18415896535664622, 0.20321789574667293, 0.19196449328671228, 0.18482622434694762, 0.19891716307210106, 0.17930621194924767, 0.2437958904733949, 0.19155521904157868, 0.08328251008805054, 0.08539253680723469, 0.07449138046631776, 0.08552834775175744, 0.08189261938683134, 0.07613714504144808, 0.09728003420851761, 0.09707127208686683, 0.08656686364485089]}, "mutation_prompt": null}
{"id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined PSO-DE hybrid that leverages adaptive inertia, dynamic velocity clamping, and a novel multi-phase strategy to balance exploration and exploitation for enhanced convergence.", "configspace": "", "generation": 48, "fitness": 0.38534886967323384, "feedback": "The algorithm RefinedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.25.", "error": "", "parent_id": "f9a91744-135f-4322-a3cf-87e646f5c73d", "metadata": {"aucs": [0.7493444647405034, 0.7640177020858607, 0.7462845471810069, 0.7738665225993068, 0.7501843407461659, 0.7852355688912291, 0.7438687761802445, 0.7574217083427516, 0.7568859346052633, 0.5527137196963421, 0.5575660201238495, 0.5967902500213451, 0.5815732308375463, 0.5898139613955354, 0.6099648457203737, 0.5917370355402044, 0.5912194198961591, 0.5535990066052492, 0.15598205265154408, 0.42030406466672243, 0.1498756644578234, 0.15204281863341473, 0.13797520294652332, 0.1550503833775405, 0.10957714345007485, 0.12248686383063956, 0.14688454688046781, 0.14131665484981826, 0.11849964503423527, 0.11792066156440162, 0.12155976964733295, 0.1270318687081301, 0.12315454579066354, 0.09822718327874225, 0.1147510305979822, 0.11833124149005836, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5868141342193103, 0.11391254579460908, 0.5544351736189043, 0.5204782690740948, 0.5824954092230927, 0.1495289278025297, 0.5656628624740767, 0.5390426568121742, 0.5601641769045604, 0.23909004749227747, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.4067733920656822, 0.4406273911726336, 0.39356585277048683, 0.3806917789744608, 0.1271251318625498, 0.43144658050094375, 0.5398137674663014, 0.40980322077013276, 0.4255406046642397, 0.42199590330968617, 0.27181820029933434, 0.42491270601638265, 0.43903174816038304, 0.4093902502187835, 0.4375584255763165, 0.37774700308954634, 0.12787382925140267, 0.4270648933571154, 0.36259070679628935, 0.1460064059430659, 0.0846313783687187, 0.10580247177981328, 0.503249445641708, 0.1628844390004961, 0.21731864936275447, 0.3858880253263386, 0.4926441010990631, 0.6002774469266389, 0.16165603332794087, 0.5613030877040976, 0.3815459741627647, 0.4676230426131245, 0.27249370768399317, 0.6586502724321228, 0.366099295238444, 0.5535874439287358, 0.11377718143488091, 0.04220554890963124, 0.06707556934476178, 0.13989200836628513, 0.2603271126155412, 0.24961615400121162, 0.12238013535022074, 0.1418432096439426, 0.11526723864138189, 0.20812776319101567, 0.32318159534562363, 0.3302226404477544, 0.33321171250369264, 0.25254365238541376, 0.3321695686910868, 0.28415198459247826, 0.30061762586313245, 0.25215203682408727, 0.6169162626189699, 0.6149507625566845, 0.7059256864779984, 0.6352127257533673, 0.7152919680829259, 0.6645229276579401, 0.6187980743668027, 0.6378656796374813, 0.6826755588124738, 0.08463013168695632, 0.13586706444036822, 0.1409516731095264, 0.10928057441375094, 0.11596958449245953, 0.12302492063926862, 0.11634337331374067, 0.10464574235218171, 0.1003630738132888, 0.2111401374897458, 0.26130800033134893, 0.24397786220487228, 0.21853738370615683, 0.18514699602401075, 0.2529441759291139, 0.22098166853032764, 0.24268374280178928, 0.28759113856437657, 0.4216699965527476, 0.4123525712834284, 0.44843849372191136, 0.3894967808414551, 0.4208324539457089, 0.438302917585086, 0.47955268848433674, 0.4924589173141519, 0.4294883405375651, 0.3786939363478393, 0.3613506018681588, 0.26352396415517276, 0.3256799405545595, 0.19799011748799722, 0.35150077749291275, 0.4176445473735847, 0.3478468161553271, 0.3804108354615596, 0.20011898941298967, 0.20543277883666056, 0.19288463289704882, 0.21740861759744068, 0.2089479465912062, 0.22980101318255042, 0.21564207170599825, 0.19040419459436364, 0.22904056958424757, 0.19435259855919118, 0.5236286250707607, 0.5446876084804629, 0.22009735401716934, 0.23577363936528073, 0.4868030646771565, 0.4522162681540892, 0.21697591496949442, 0.22562280196635176, 0.84120936818493, 0.8246052515524153, 0.15365907878834772, 0.7584287726700076, 0.1977320756309635, 0.19473572414883578, 0.7474784313729328, 0.16991888427640423, 0.8136283511053167, 0.728069673372769, 0.16900123145459145, 0.796306663016825, 0.20612552143331975, 0.7512316653275415, 0.20919714580549753, 0.19819575336830586, 0.21134618290886864, 0.21235430764719276, 0.1875806232767434, 0.18417981884623336, 0.202881700627079, 0.19196449328671228, 0.18109891394098365, 0.20418548842554596, 0.1869049569978053, 0.2731138190158472, 0.17963403693769886, 0.0803229364907474, 0.08457257858379619, 0.07280190023865485, 0.08468779763601886, 0.08843908107866172, 0.07247930661755075, 0.09285466581986146, 0.10098686114180322, 0.08583858948120782]}, "mutation_prompt": null}
{"id": "26d49921-0a62-4721-bcf9-ef371cbe5dc6", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined PSO-DE hybrid that leverages adaptive inertia, dynamic velocity clamping, and a novel multi-phase strategy to balance exploration and exploitation for enhanced convergence.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7493444647405034, 0.7640177020858607, 0.7462845471810069, 0.7738665225993068, 0.7501843407461659, 0.7852355688912291, 0.7438687761802445, 0.7574217083427516, 0.7568859346052633, 0.5527137196963421, 0.5575660201238495, 0.5967902500213451, 0.5815732308375463, 0.5898139613955354, 0.6099648457203737, 0.5917370355402044, 0.5912194198961591, 0.5535990066052492, 0.15598205265154408, 0.42030406466672243, 0.1498756644578234, 0.15204281863341473, 0.13797520294652332, 0.1550503833775405, 0.10957714345007485, 0.12248686383063956, 0.14688454688046781, 0.14131665484981826, 0.11849964503423527, 0.11792066156440162, 0.12155976964733295, 0.1270318687081301, 0.12315454579066354, 0.09822718327874225, 0.1147510305979822, 0.11833124149005836, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5868141342193103, 0.11391254579460908, 0.5544351736189043, 0.5204782690740948, 0.5824954092230927, 0.1495289278025297, 0.5656628624740767, 0.5390426568121742, 0.5601641769045604, 0.23909004749227747, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.4067733920656822, 0.4406273911726336, 0.39356585277048683, 0.3806917789744608, 0.1271251318625498, 0.43144658050094375, 0.5398137674663014, 0.40980322077013276, 0.4255406046642397, 0.42199590330968617, 0.27181820029933434, 0.42491270601638265, 0.43903174816038304, 0.4093902502187835, 0.4375584255763165, 0.37774700308954634, 0.12787382925140267, 0.4270648933571154, 0.36259070679628935, 0.1460064059430659, 0.0846313783687187, 0.10580247177981328, 0.503249445641708, 0.1628844390004961, 0.21731864936275447, 0.3858880253263386, 0.4926441010990631, 0.6002774469266389, 0.16165603332794087, 0.5613030877040976, 0.3815459741627647, 0.4676230426131245, 0.27249370768399317, 0.6586502724321228, 0.366099295238444, 0.5535874439287358, 0.11377718143488091, 0.04220554890963124, 0.06707556934476178, 0.13989200836628513, 0.2603271126155412, 0.24961615400121162, 0.12238013535022074, 0.1418432096439426, 0.11526723864138189, 0.20812776319101567, 0.32318159534562363, 0.3302226404477544, 0.33321171250369264, 0.25254365238541376, 0.3321695686910868, 0.28415198459247826, 0.30061762586313245, 0.25215203682408727, 0.6169162626189699, 0.6149507625566845, 0.7059256864779984, 0.6352127257533673, 0.7152919680829259, 0.6645229276579401, 0.6187980743668027, 0.6378656796374813, 0.6826755588124738, 0.08463013168695632, 0.13586706444036822, 0.1409516731095264, 0.10928057441375094, 0.11596958449245953, 0.12302492063926862, 0.11634337331374067, 0.10464574235218171, 0.1003630738132888, 0.2111401374897458, 0.26130800033134893, 0.24397786220487228, 0.21853738370615683, 0.18514699602401075, 0.2529441759291139, 0.22098166853032764, 0.24268374280178928, 0.28759113856437657, 0.4216699965527476, 0.4123525712834284, 0.44843849372191136, 0.3894967808414551, 0.4208324539457089, 0.438302917585086, 0.47955268848433674, 0.4924589173141519, 0.4294883405375651, 0.3786939363478393, 0.3613506018681588, 0.26352396415517276, 0.3256799405545595, 0.19799011748799722, 0.35150077749291275, 0.4176445473735847, 0.3478468161553271, 0.3804108354615596, 0.20011898941298967, 0.20543277883666056, 0.19288463289704882, 0.21740861759744068, 0.2089479465912062, 0.22980101318255042, 0.21564207170599825, 0.19040419459436364, 0.22904056958424757, 0.19435259855919118, 0.5236286250707607, 0.5446876084804629, 0.22009735401716934, 0.23577363936528073, 0.4868030646771565, 0.4522162681540892, 0.21697591496949442, 0.22562280196635176, 0.84120936818493, 0.8246052515524153, 0.15365907878834772, 0.7584287726700076, 0.1977320756309635, 0.19473572414883578, 0.7474784313729328, 0.16991888427640423, 0.8136283511053167, 0.728069673372769, 0.16900123145459145, 0.796306663016825, 0.20612552143331975, 0.7512316653275415, 0.20919714580549753, 0.19819575336830586, 0.21134618290886864, 0.21235430764719276, 0.1875806232767434, 0.18417981884623336, 0.202881700627079, 0.19196449328671228, 0.18109891394098365, 0.20418548842554596, 0.1869049569978053, 0.2731138190158472, 0.17963403693769886, 0.0803229364907474, 0.08457257858379619, 0.07280190023865485, 0.08468779763601886, 0.08843908107866172, 0.07247930661755075, 0.09285466581986146, 0.10098686114180322, 0.08583858948120782]}, "mutation_prompt": null}
{"id": "815ed99f-28b3-4283-a7d0-c872488138db", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                # Chaos-inspired mutation\n                r = np.random.rand()\n                chaotic_factor = 4 * r * (1 - r)\n                mutant = a + F * chaotic_factor * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced PSO-DE hybrid utilizing adaptive parameter tuning, strategic leader selection, and chaos-inspired mutation for robust exploration and swift convergence.", "configspace": "", "generation": 50, "fitness": 0.3307920223436084, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.26.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7754999686244319, 0.7680356701753825, 0.792759750948182, 0.7986139091399728, 0.7863745973667546, 0.7842303039816153, 0.7803297603354566, 0.7876782761443054, 0.7855505000907201, 0.6106780320439504, 0.5842552018164935, 0.5330734197343867, 0.550130860184428, 0.5416775040117381, 0.5404075692095317, 0.5679813097485019, 0.5666453960100006, 0.5820478735876375, 0.17014670646027774, 0.49578420342982676, 0.1631182867590989, 0.5305589724849447, 0.1350743404004765, 0.14770509216575234, 0.17134615748215998, 0.1309898014387545, 0.1721704821506539, 0.14495438866352073, 0.14059298094157735, 0.15375101176663208, 0.15396925382014925, 0.13851604143438712, 0.12928079885238353, 0.15273034810421726, 0.12627440991716554, 0.16244096553562026, 0.9788507100626839, 0.9846363102302551, 0.988561683871636, 0.9854337501919447, 0.9856580669035383, 0.9796897691130148, 0.9842967719024248, 0.984753506631366, 0.9849414046493464, 0.5883159802579624, 0.5230813765025021, 0.5905217144759054, 0.5636873603779009, 0.5671192794200165, 0.5221650117239247, 0.08928894444933844, 0.5448850961608057, 0.050906377721840035, 0.2255468307912999, 0.1666798550250127, 0.8127978783909418, 0.8224951778464538, 0.2710721065166689, 0.18883185555206405, 0.7890142621108145, 0.865492816345964, 0.21982699971398656, 0.3797335348581796, 0.4080874304058745, 0.23963156430519128, 0.1266443098871457, 0.4004484644061632, 0.22994975294248865, 0.12847933081617524, 0.22048390231568815, 0.6326088670925909, 0.2551475645325121, 0.13230015940712947, 0.24772719036747015, 0.2743351071296314, 0.2449692093178092, 0.311879760555967, 0.2827646166271439, 0.29199911185488336, 0.13209311486744169, 0.08276164656486895, 0.015108020817561685, 0.032494279379543856, 9.999999999998899e-05, 0.0925079462224434, 0.018758347249295704, 0.006052091752799971, 0.021619122503284793, 0.15936344948766057, 0.19874893244348724, 0.06740164327951137, 0.1562300361820429, 0.1965272088820702, 0.03112359184214697, 0.08960929339920509, 0.2764451107621262, 0.2088168797989901, 0.149681696679846, 0.10525738730346934, 0.09483940873970864, 0.04542376906755052, 0.1384444103469421, 0.09769032368058417, 0.2571762926814991, 0.12866612182805315, 0.08328754189566567, 0.1236969273892784, 0.09645557399791438, 0.24767685735812106, 0.17365397951615957, 9.999999999998899e-05, 0.14080708907801176, 0.2111470744241556, 0.1099972543821961, 0.39063189505091556, 0.0798021130540505, 0.5223485522237996, 0.512738708021238, 0.536405571741682, 0.5386461034477144, 0.5801531259636701, 0.5122583778396816, 0.5402790857184703, 0.6469600459507516, 0.565888635430292, 0.11048839400661925, 0.09929234695470202, 0.12474932323679677, 0.14589001341104757, 0.11052674406214114, 0.12449576444936084, 0.14682578018046188, 0.11053620337292036, 0.12119537527210655, 0.23025177926146878, 0.24089010429500646, 0.19684668804523153, 0.41128851168019587, 0.34517309251985084, 0.21788960825902226, 0.4664760399884391, 0.22909641356347, 0.20227116547062118, 0.4140223151730442, 0.43002249424873285, 0.4867236819792894, 0.47006242619052396, 0.37040391377741755, 0.4940953680291613, 0.377628003879495, 0.3391250003779196, 0.39063908721317375, 0.18323973055684306, 0.22513326335603534, 0.27144076724354305, 0.28465509474885364, 0.3628888547138849, 0.3397375968509406, 0.21755721433980602, 0.38575378024750806, 0.2969083079858299, 0.22930893015667275, 0.21502042781736885, 0.18889231116344884, 0.21093719862404792, 0.2250389879785223, 0.28510225189283944, 0.23175343452596586, 0.22156568984566283, 0.21132209967896542, 0.1814376309827428, 0.21801748122937747, 0.19532625614563182, 0.20029378198961845, 0.6966794469975082, 0.23768498553071604, 0.19267108588084703, 0.20083125167399496, 0.23027006688228335, 0.893186412335569, 0.16798938899677907, 0.17333727757006523, 0.1692765468764319, 0.20035144817352812, 0.18759959027279016, 0.12309646165927224, 0.1702694800830199, 0.15240847173460692, 0.7266806006319947, 0.7102293768336079, 0.6951303453302502, 0.7980791528513422, 0.16609606664285692, 0.2106114371052128, 0.10472305567041162, 0.8292345635501939, 0.8644688699323633, 0.21799911715495557, 0.19731016375556987, 0.20304359799550187, 0.19181825283376985, 0.18778561910233782, 0.1957229273361487, 0.23194237005439178, 0.21223989528080112, 0.25984507128397827, 0.09074628405338536, 0.09316852571097356, 0.09137669899385636, 0.09591059822380121, 0.08978506687540089, 0.09818781845319768, 0.09033185444785397, 0.08718229958158152, 0.09054899392528837]}, "mutation_prompt": null}
{"id": "2513930a-78e1-4a89-9f07-9ac1db5eeddc", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined PSO-DE hybrid that leverages adaptive inertia, dynamic velocity clamping, and a novel multi-phase strategy to balance exploration and exploitation for enhanced convergence.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7493444647405034, 0.7640177020858607, 0.7462845471810069, 0.7738665225993068, 0.7501843407461659, 0.7852355688912291, 0.7438687761802445, 0.7574217083427516, 0.7568859346052633, 0.5527137196963421, 0.5575660201238495, 0.5967902500213451, 0.5815732308375463, 0.5898139613955354, 0.6099648457203737, 0.5917370355402044, 0.5912194198961591, 0.5535990066052492, 0.15598205265154408, 0.42030406466672243, 0.1498756644578234, 0.15204281863341473, 0.13797520294652332, 0.1550503833775405, 0.10957714345007485, 0.12248686383063956, 0.14688454688046781, 0.14131665484981826, 0.11849964503423527, 0.11792066156440162, 0.12155976964733295, 0.1270318687081301, 0.12315454579066354, 0.09822718327874225, 0.1147510305979822, 0.11833124149005836, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5868141342193103, 0.11391254579460908, 0.5544351736189043, 0.5204782690740948, 0.5824954092230927, 0.1495289278025297, 0.5656628624740767, 0.5390426568121742, 0.5601641769045604, 0.23909004749227747, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.4067733920656822, 0.4406273911726336, 0.39356585277048683, 0.3806917789744608, 0.1271251318625498, 0.43144658050094375, 0.5398137674663014, 0.40980322077013276, 0.4255406046642397, 0.42199590330968617, 0.27181820029933434, 0.42491270601638265, 0.43903174816038304, 0.4093902502187835, 0.4375584255763165, 0.37774700308954634, 0.12787382925140267, 0.4270648933571154, 0.36259070679628935, 0.1460064059430659, 0.0846313783687187, 0.10580247177981328, 0.503249445641708, 0.1628844390004961, 0.21731864936275447, 0.3858880253263386, 0.4926441010990631, 0.6002774469266389, 0.16165603332794087, 0.5613030877040976, 0.3815459741627647, 0.4676230426131245, 0.27249370768399317, 0.6586502724321228, 0.366099295238444, 0.5535874439287358, 0.11377718143488091, 0.04220554890963124, 0.06707556934476178, 0.13989200836628513, 0.2603271126155412, 0.24961615400121162, 0.12238013535022074, 0.1418432096439426, 0.11526723864138189, 0.20812776319101567, 0.32318159534562363, 0.3302226404477544, 0.33321171250369264, 0.25254365238541376, 0.3321695686910868, 0.28415198459247826, 0.30061762586313245, 0.25215203682408727, 0.6169162626189699, 0.6149507625566845, 0.7059256864779984, 0.6352127257533673, 0.7152919680829259, 0.6645229276579401, 0.6187980743668027, 0.6378656796374813, 0.6826755588124738, 0.08463013168695632, 0.13586706444036822, 0.1409516731095264, 0.10928057441375094, 0.11596958449245953, 0.12302492063926862, 0.11634337331374067, 0.10464574235218171, 0.1003630738132888, 0.2111401374897458, 0.26130800033134893, 0.24397786220487228, 0.21853738370615683, 0.18514699602401075, 0.2529441759291139, 0.22098166853032764, 0.24268374280178928, 0.28759113856437657, 0.4216699965527476, 0.4123525712834284, 0.44843849372191136, 0.3894967808414551, 0.4208324539457089, 0.438302917585086, 0.47955268848433674, 0.4924589173141519, 0.4294883405375651, 0.3786939363478393, 0.3613506018681588, 0.26352396415517276, 0.3256799405545595, 0.19799011748799722, 0.35150077749291275, 0.4176445473735847, 0.3478468161553271, 0.3804108354615596, 0.20011898941298967, 0.20543277883666056, 0.19288463289704882, 0.21740861759744068, 0.2089479465912062, 0.22980101318255042, 0.21564207170599825, 0.19040419459436364, 0.22904056958424757, 0.19435259855919118, 0.5236286250707607, 0.5446876084804629, 0.22009735401716934, 0.23577363936528073, 0.4868030646771565, 0.4522162681540892, 0.21697591496949442, 0.22562280196635176, 0.84120936818493, 0.8246052515524153, 0.15365907878834772, 0.7584287726700076, 0.1977320756309635, 0.19473572414883578, 0.7474784313729328, 0.16991888427640423, 0.8136283511053167, 0.728069673372769, 0.16900123145459145, 0.796306663016825, 0.20612552143331975, 0.7512316653275415, 0.20919714580549753, 0.19819575336830586, 0.21134618290886864, 0.21235430764719276, 0.1875806232767434, 0.18417981884623336, 0.202881700627079, 0.19196449328671228, 0.18109891394098365, 0.20418548842554596, 0.1869049569978053, 0.2731138190158472, 0.17963403693769886, 0.0803229364907474, 0.08457257858379619, 0.07280190023865485, 0.08468779763601886, 0.08843908107866172, 0.07247930661755075, 0.09285466581986146, 0.10098686114180322, 0.08583858948120782]}, "mutation_prompt": null}
{"id": "8766fb1c-1403-4dd7-b1d2-06741cffbc51", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        def adaptive_population_size():\n            return int(self.initial_population_size * (1 + 0.5 * np.sin(self.num_evals / self.budget * np.pi)))\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.initial_population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.initial_population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            population_size = adaptive_population_size()\n\n            # Evaluate current swarm\n            for i in range(population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update\n            for i in range(population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -1, 1)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "Enhanced PSO-DE algorithm with adaptive population size and hybrid exploitation strategies for improved convergence.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 20 is out of bounds for axis 0 with size 20').", "error": "IndexError('index 20 is out of bounds for axis 0 with size 20')", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {}, "mutation_prompt": null}
{"id": "9cfccb0a-a5c0-4b47-9bd6-308a3943194e", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        def opposition_based_learning(swarm):\n            opposite_swarm = self.lower_bound + self.upper_bound - swarm\n            opposite_swarm = np.clip(opposite_swarm, self.lower_bound, self.upper_bound)\n            return opposite_swarm\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm and opposition-based learning\n            if self.num_evals < self.budget // 2:\n                opposite_swarm = opposition_based_learning(swarm)\n                for i in range(self.population_size):\n                    if self.num_evals >= self.budget:\n                        break\n                    score = func(swarm[i])\n                    opposite_score = func(opposite_swarm[i])\n                    self.num_evals += 2\n\n                    if score < personal_best_scores[i]:\n                        personal_best_scores[i] = score\n                        personal_best_positions[i] = swarm[i]\n\n                    if opposite_score < personal_best_scores[i]:\n                        personal_best_scores[i] = opposite_score\n                        personal_best_positions[i] = opposite_swarm[i]\n\n                    if score < global_best_score:\n                        global_best_score = score\n                        global_best_position = swarm[i]\n\n                    if opposite_score < global_best_score:\n                        global_best_score = opposite_score\n                        global_best_position = opposite_swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced PSO-DE hybrid using adaptive opposition-based learning and multi-velocity adaptation to improve exploration and convergence efficiency.", "configspace": "", "generation": 53, "fitness": 0.3559781033169102, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.23.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.6783167835955994, 0.7011539476798199, 0.6806495884982333, 0.7046266000448296, 0.710463279577231, 0.6881078211274029, 0.7101987715869511, 0.6917626667104996, 0.6817122024115181, 0.5324308077218013, 0.521583904997522, 0.5106485892008059, 0.526146145315013, 0.5275215877349038, 0.5216633080281049, 0.4982100467599816, 0.5151523639513662, 0.5076846620054389, 0.1417919062320807, 0.12935431612711745, 0.12732444750650462, 0.11639835923198172, 0.13059694751901207, 0.10535769481168078, 0.10969826352699075, 0.12286597912018338, 0.11932595283387348, 0.09978199723724668, 0.13407766314571945, 0.10459112268869397, 0.10267056139632347, 0.09733683765031043, 0.09607641653901611, 0.10387911495545576, 0.12625515572024937, 0.10293210066228964, 0.9803320771956685, 0.9832430167532267, 0.9834322237533768, 0.9802781511862654, 0.9830121591999628, 0.9823557949815577, 0.9767577658637635, 0.9689441734020777, 0.9810635316948544, 0.5273743123505652, 0.5155652174770566, 0.5147869322442444, 0.5266051241002607, 0.5365446240023093, 0.5403917759315652, 0.08299665995109595, 0.5073392780327757, 0.08609758905869369, 0.5861570302684321, 0.635230871178487, 0.6527846797930601, 0.7185634677301385, 0.20430124821323492, 0.6944504221291043, 0.6489344271878419, 0.6791195638850152, 0.3326382229741063, 0.4206903605426092, 0.4399277562172712, 0.3813144388306966, 0.44840793799402867, 0.4776440148482898, 0.4421726819721914, 0.44986861982981396, 0.46030279689629516, 0.12071240861732424, 0.41602517592979127, 0.41479598081894564, 0.35934115129920075, 0.4444244000877188, 0.4133574918853278, 0.5024992244048999, 0.3554102758308961, 0.40049326423254694, 0.441046241303091, 0.31223863387480255, 0.1980557680145616, 0.24549001474831456, 0.2451404472044193, 0.253177001579466, 0.45071884676808716, 0.3535483678909742, 0.3703982254328735, 0.2808980832218425, 0.4733733735694118, 0.24222432404898941, 0.3369139054119431, 0.3563020466746515, 0.3127572354279702, 0.19918665077531317, 0.41558655226190244, 0.3990609054262194, 0.49926169508927876, 0.11663352052588338, 0.13288608062138085, 0.07597942482772702, 0.3149880620861444, 0.3680090951680296, 0.08613423237297868, 0.08167141648677756, 0.14232980467395295, 0.15153759083616292, 0.2360877906651483, 0.3019556240676601, 0.2785975823609601, 0.2825773608412959, 0.2819093113432557, 0.2599885117169046, 0.23758274987990358, 0.25671167642364856, 0.25111385278713905, 0.5616314437857232, 0.6789873903898551, 0.5542370634767357, 0.6795234263509469, 0.5391219001459786, 0.5971620575222414, 0.5613123361723862, 0.5978116362223838, 0.5633749617741655, 0.1106567861793799, 0.07188106047251297, 0.1205423066801442, 0.09294299206702339, 0.11112156801089945, 0.0989875404644508, 0.11354166409731681, 0.10747907927356115, 0.09091231253420451, 0.2608909923468782, 0.24021142085578284, 0.15532133881052523, 0.20455978447186562, 0.25510117424900713, 0.25351885068547486, 0.2400114806964886, 0.14176874484747692, 0.16298296761894504, 0.4092986058925985, 0.33092346282876706, 0.4109363208543696, 0.3428675547099652, 0.372676413422219, 0.4260326203608299, 0.4940961934814154, 0.4172443744436759, 0.5211191577296466, 0.34961548537420595, 0.278033106171376, 0.2971417833171641, 0.28161947802655585, 0.27738665522099915, 0.3150226193969188, 0.30367699063405695, 0.31495637288081335, 0.31656813818475216, 0.21864301364783167, 0.20121214174544844, 0.19301855564141324, 0.20429070215621137, 0.2231320413212875, 0.19288693816986857, 0.20461220464451169, 0.19566176452878659, 0.2058119870825873, 0.19013929268158258, 0.5186051705899941, 0.19291498755156578, 0.19081862750844958, 0.1868798940457217, 0.494342224071158, 0.22059543979477603, 0.20837061262454248, 0.21466516988933404, 0.632628899735683, 0.18072355342747248, 0.15109403592023862, 0.6379004843793616, 0.19767288467480637, 0.8018564112267282, 0.12334148931159195, 0.16692665447338206, 0.6531652121856388, 0.704673831239389, 0.19896462376649104, 0.7674200506395675, 0.6379006168803598, 0.16082456563403724, 0.5650553966430588, 0.19707539547346042, 0.20524397512424097, 0.5943752282119164, 0.18671385594342504, 0.18354541672130076, 0.18695067890405526, 0.17762010530359618, 0.18264105805451458, 0.19584191168878218, 0.1882542606307115, 0.18960977548967894, 0.18698649355994534, 0.0856510222871748, 0.09114101260474594, 0.08152687961320026, 0.07153010341107835, 0.08241255477256582, 0.06869013828915871, 0.08975276924745612, 0.0981826453358482, 0.10885770378278137]}, "mutation_prompt": null}
{"id": "7ffbadc2-263d-414f-a5c1-18cfd520016f", "solution": "import numpy as np\n\nclass EnhancedMultiPhasePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.restart_probability = 0.05  # Probability of stochastic restart\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            population_size = int(self.initial_population_size * (1 + progress))\n            return w, F, CR, population_size\n\n        def initialize_population(size):\n            return np.random.uniform(self.lower_bound, self.upper_bound, (size, self.dim)), np.random.uniform(-1, 1, (size, self.dim))\n\n        # Initialize swarm\n        swarm, velocities = initialize_population(self.initial_population_size)\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.initial_population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR, population_size = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Reinitialize population based on adaptive size\n            if population_size != swarm.shape[0]:\n                swarm, velocities = initialize_population(population_size)\n                personal_best_positions = np.copy(swarm)\n                personal_best_scores = np.full(population_size, np.inf)\n\n            # Evaluate current swarm\n            for i in range(population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # Stochastic restarts for better exploration\n            if np.random.rand() < self.restart_probability:\n                swarm, velocities = initialize_population(population_size)\n                continue\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedMultiPhasePSO_DE", "description": "Enhanced Multi-phase PSO-DE with Stochastic Restarts and Adaptive Population Size for Improved Convergence and Robustness.", "configspace": "", "generation": 54, "fitness": 0.17818939339476345, "feedback": "The algorithm EnhancedMultiPhasePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.19.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.2954996968398288, 0.3135267578280466, 0.31015998600938643, 0.2961106806067131, 0.30150198584748455, 0.3075386778508885, 0.2783027498242179, 0.29755840278540413, 0.3157594409183977, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0013057701858161241, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08000749461955403, 0.07789739232419235, 0.09272970680821435, 0.07124849416032175, 0.08035709626658949, 0.07941081848729481, 0.09677973016293273, 0.10017936006607775, 0.06678658429798123, 0.0673071962684677, 0.07146610847401447, 0.0577838357969338, 0.07093805863173552, 0.07194142195441688, 0.07500777188006069, 0.06621719632468925, 0.07872628610531007, 0.0765797428436148, 0.9881399998670041, 0.9844772799518489, 0.9890824747580569, 0.9844231589734621, 0.9882193721749115, 0.9873094004635081, 0.9872747337644816, 0.9852854925652198, 0.9882091325543111, 0.14951479653387556, 0.1535168316250125, 0.1444720783219795, 0.1704031860541907, 0.18600975667698727, 0.14100426972308377, 0.1550024110273509, 0.17990522760467142, 0.14157546579311497, 0.2167353860195752, 0.2782148421435855, 0.19933809171586636, 0.21499577403523595, 0.25267969203722496, 0.2124737754533611, 0.21637482593777302, 0.2279315863857806, 0.2103638661348035, 0.09920002421039176, 0.08389362533561162, 0.11203112589690611, 0.09399069936322302, 0.09796160595789294, 0.04678055414901372, 0.1238550028572909, 0.106775107973195, 0.09685314051878735, 0.119113159277496, 0.045406049686857686, 0.11803720882765756, 0.11058725192785823, 0.1150489442803233, 0.1079273025539853, 0.09999506610200082, 0.10497924145379511, 0.10369462705144161, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004347543218177985, 9.999999999998899e-05, 9.999999999998899e-05, 0.0997397887348177, 0.12337545721881693, 0.09630364314254569, 0.1208728446257803, 0.04911393589357327, 0.13377551354903572, 0.11103897055694212, 0.09098925653511591, 0.12324742269051636, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04436925777163181, 0.028509705909179894, 0.037901304390067336, 0.046903879397122705, 0.038514210478759026, 0.04697961322504818, 0.038358025433219534, 0.046979290523635586, 0.04016244740517827, 0.30650576263029927, 0.3125272279904503, 0.2944677903522158, 0.29842148743174735, 0.3017544679501899, 0.2949716138542985, 0.3429502847158614, 0.27521273958713965, 0.29143385649427467, 0.07753228584350058, 0.08367966723821008, 0.08516259107334734, 0.09305793498221304, 0.10319908017697921, 0.10477598490256701, 0.07834718132539586, 0.07541635449659156, 0.0675063985009785, 0.12899967157444403, 0.15252685865656135, 0.13921128467986799, 0.12758302845499603, 0.12505814223188394, 0.13540504722828572, 0.14938527206863073, 0.14323213230477627, 0.1693275759338232, 0.21758328353583134, 0.22520571359040764, 0.20819210960865653, 0.2294169987295125, 0.22293055195059563, 0.2333356034431282, 0.23053613891688973, 0.23167481966917092, 0.2194507957250441, 0.17590499703396512, 0.1680142180234392, 0.13694701626727002, 0.16421752606691953, 0.16223575407170432, 0.17458621858672918, 0.16941796004140797, 0.16485779926766042, 0.15259258373445406, 0.17674704457531676, 0.17485125051242412, 0.19371975884149217, 0.20813181848045448, 0.18864415865209205, 0.18948571096635636, 0.18502453369082617, 0.18383552341806575, 0.19024248690600354, 0.1786595732593631, 0.17590260783234368, 0.19345929738998624, 0.18133676989334924, 0.180510379277251, 0.18782487845423013, 0.17879620055425438, 0.17472931559885985, 0.1809685341927889, 0.36145794170635526, 0.19526715448485787, 0.22006693053262938, 0.3215432127083322, 0.34277887306016896, 0.3077205977293703, 0.3074725395070951, 0.40515737360368287, 0.39056218324241276, 0.23857862567491517, 0.1883702365089942, 0.23840269841335537, 0.3261338136410774, 0.18396754188271325, 0.1980742948721902, 0.2938266505048518, 0.2055844347907141, 0.2631666794616505, 0.19761808382630952, 0.17470198314311625, 0.19586567787627207, 0.20077958157807463, 0.2024482410128674, 0.19702017139306205, 0.18421161448423617, 0.18090930658061366, 0.18578990876936163, 0.06791914343434657, 0.08085728903296696, 0.07086340985012807, 0.08690793006624031, 0.08097603028695344, 0.06857180293942733, 0.07307727120147134, 0.06736406703037179, 0.07560082441219051]}, "mutation_prompt": null}
{"id": "57bf5f0c-f00c-40f2-b6ff-0bc4a2a3c00b", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Improved phase-switching logic\n        def switch_phase(iteration):\n            return (iteration < 0.7 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with enhanced exploration and exploitation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced PSO-DE hybrid employing progressive adaptation of parameters and strategic exploitative phases to improve convergence and solution precision across diverse optimization landscapes.", "configspace": "", "generation": 55, "fitness": 0.37755431137737505, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.25.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7461518114966716, 0.7625245164288791, 0.7480683072189542, 0.7754618260530839, 0.7484561708385722, 0.7853225711537724, 0.7429541078215409, 0.7550667808345409, 0.7544608880677254, 0.5323323109179555, 0.5410380255705276, 0.5846974743686889, 0.5607896813411862, 0.5701599382316167, 0.58274703252041, 0.582936508085354, 0.5853944470691592, 0.5285856864996752, 0.1559238437216276, 0.15375122413418663, 0.1479204613275371, 0.1523009701142266, 0.1376313580402142, 0.1550435149296946, 0.10881356265986764, 0.12988586922923584, 0.14661757687467247, 0.12780532182705973, 0.11836968101213374, 0.1242851921646041, 0.12126723266403838, 0.12599646882946347, 0.13365299443636847, 0.10060707782152822, 0.11470031556976101, 0.11854931025527804, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5694106904923288, 0.11391252941075003, 0.5563681181620206, 0.5033929849521832, 0.5684558140735705, 0.14952814885814225, 0.5616664274744787, 0.5233839626412113, 0.5495262211325622, 0.23550169787426767, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.3570385980052413, 0.4201988396408808, 0.37278409915887023, 0.3678657428130704, 0.12712512981973467, 0.36727534849507726, 0.5128374360170748, 0.4030353980802083, 0.37628762166628005, 0.38773050543907317, 0.272429273078552, 0.33102425112597555, 0.36364340347798385, 0.39543585301602624, 0.3584681903657031, 0.352019808260557, 0.12787378467076083, 0.4073451757442763, 0.4330347062787653, 0.17113011889291052, 0.08462777537387611, 0.1006338278640374, 0.447949905396997, 0.1695258999244479, 0.1832389513185788, 0.4050185191639848, 0.42907873729582635, 0.5389177742636375, 0.20008148587191454, 0.565926508948344, 0.3750712315268514, 0.4911044095663294, 0.2975447778304118, 0.6211202595482037, 0.2621277054789781, 0.5313244263537346, 0.11444431947250033, 0.044036152816120944, 0.06473992881925583, 0.10644239081536, 0.227596591211484, 0.2344582448946363, 0.11500270240134747, 0.13655973827197665, 0.12539986136569747, 0.21160829895421762, 0.3242551682676592, 0.3029915666998807, 0.30791007028060136, 0.20823179976114625, 0.2630340759636368, 0.2892970413752488, 0.3028228235058542, 0.2555536837530714, 0.6679133865375095, 0.6642891168836336, 0.6896944097507769, 0.6485993086878155, 0.7040249135588119, 0.6992159547935092, 0.6283583944085829, 0.665000384789012, 0.6970591552190801, 0.1001583646748786, 0.1451266570066302, 0.14090345719160124, 0.10602363461941022, 0.11900796734875962, 0.11964358288587551, 0.11515050649826553, 0.10465500864028687, 0.10036785845897411, 0.2239232135748187, 0.2635897903271971, 0.30957843292310716, 0.21847771306465946, 0.17771803243010054, 0.25308935873996696, 0.2229113098330826, 0.2418669780757825, 0.26540546086502625, 0.42719887282671976, 0.4033535731653233, 0.40192701049311985, 0.3780311603504314, 0.40529622279724575, 0.47992079803265697, 0.4329344482910632, 0.4632425813446762, 0.43010627072425, 0.31895722548882843, 0.3289308008378985, 0.2817264757236032, 0.32227942703417145, 0.1976264680766665, 0.3370558481420879, 0.3426228865197509, 0.341742076141482, 0.3347907611132378, 0.2025169339919024, 0.20718193830907083, 0.21298330677186572, 0.21483234891601466, 0.20048100575239103, 0.23379318476170585, 0.21575146639382614, 0.18908981533391178, 0.22774327880006695, 0.19416084348938578, 0.49540185220667987, 0.5164729065042443, 0.21995888804372454, 0.23577263851519759, 0.47336301400716607, 0.4165740890038502, 0.2166967195650049, 0.2255839036685814, 0.84120936818493, 0.8246052515524153, 0.15365907878824092, 0.7584287726700076, 0.1977320745463218, 0.19473572380889925, 0.7474784313729328, 0.16991888427646318, 0.8136283511053167, 0.728069673372769, 0.1690012314244841, 0.796306663016825, 0.20612552178185728, 0.7512316653275415, 0.20919714010320234, 0.19819575336761486, 0.21134618290729745, 0.21235430762525098, 0.18738163459877066, 0.18416920267000614, 0.2032178957591384, 0.19886973426409216, 0.19639645953800877, 0.19891716307223928, 0.1821334811888744, 0.23251961216167238, 0.1915929052105093, 0.08321046340111204, 0.08654929782630083, 0.07913302126937194, 0.08552834775175744, 0.08370667283874478, 0.07768695887068111, 0.0972807429782051, 0.0989929825332252, 0.08718464303748319]}, "mutation_prompt": null}
{"id": "f1f93bda-a71f-4b40-868a-984e7ac0a96f", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined PSO-DE hybrid that leverages adaptive inertia, dynamic velocity clamping, and a novel multi-phase strategy to balance exploration and exploitation for enhanced convergence.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7493444647405034, 0.7640177020858607, 0.7462845471810069, 0.7738665225993068, 0.7501843407461659, 0.7852355688912291, 0.7438687761802445, 0.7574217083427516, 0.7568859346052633, 0.5527137196963421, 0.5575660201238495, 0.5967902500213451, 0.5815732308375463, 0.5898139613955354, 0.6099648457203737, 0.5917370355402044, 0.5912194198961591, 0.5535990066052492, 0.15598205265154408, 0.42030406466672243, 0.1498756644578234, 0.15204281863341473, 0.13797520294652332, 0.1550503833775405, 0.10957714345007485, 0.12248686383063956, 0.14688454688046781, 0.14131665484981826, 0.11849964503423527, 0.11792066156440162, 0.12155976964733295, 0.1270318687081301, 0.12315454579066354, 0.09822718327874225, 0.1147510305979822, 0.11833124149005836, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5868141342193103, 0.11391254579460908, 0.5544351736189043, 0.5204782690740948, 0.5824954092230927, 0.1495289278025297, 0.5656628624740767, 0.5390426568121742, 0.5601641769045604, 0.23909004749227747, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.4067733920656822, 0.4406273911726336, 0.39356585277048683, 0.3806917789744608, 0.1271251318625498, 0.43144658050094375, 0.5398137674663014, 0.40980322077013276, 0.4255406046642397, 0.42199590330968617, 0.27181820029933434, 0.42491270601638265, 0.43903174816038304, 0.4093902502187835, 0.4375584255763165, 0.37774700308954634, 0.12787382925140267, 0.4270648933571154, 0.36259070679628935, 0.1460064059430659, 0.0846313783687187, 0.10580247177981328, 0.503249445641708, 0.1628844390004961, 0.21731864936275447, 0.3858880253263386, 0.4926441010990631, 0.6002774469266389, 0.16165603332794087, 0.5613030877040976, 0.3815459741627647, 0.4676230426131245, 0.27249370768399317, 0.6586502724321228, 0.366099295238444, 0.5535874439287358, 0.11377718143488091, 0.04220554890963124, 0.06707556934476178, 0.13989200836628513, 0.2603271126155412, 0.24961615400121162, 0.12238013535022074, 0.1418432096439426, 0.11526723864138189, 0.20812776319101567, 0.32318159534562363, 0.3302226404477544, 0.33321171250369264, 0.25254365238541376, 0.3321695686910868, 0.28415198459247826, 0.30061762586313245, 0.25215203682408727, 0.6169162626189699, 0.6149507625566845, 0.7059256864779984, 0.6352127257533673, 0.7152919680829259, 0.6645229276579401, 0.6187980743668027, 0.6378656796374813, 0.6826755588124738, 0.08463013168695632, 0.13586706444036822, 0.1409516731095264, 0.10928057441375094, 0.11596958449245953, 0.12302492063926862, 0.11634337331374067, 0.10464574235218171, 0.1003630738132888, 0.2111401374897458, 0.26130800033134893, 0.24397786220487228, 0.21853738370615683, 0.18514699602401075, 0.2529441759291139, 0.22098166853032764, 0.24268374280178928, 0.28759113856437657, 0.4216699965527476, 0.4123525712834284, 0.44843849372191136, 0.3894967808414551, 0.4208324539457089, 0.438302917585086, 0.47955268848433674, 0.4924589173141519, 0.4294883405375651, 0.3786939363478393, 0.3613506018681588, 0.26352396415517276, 0.3256799405545595, 0.19799011748799722, 0.35150077749291275, 0.4176445473735847, 0.3478468161553271, 0.3804108354615596, 0.20011898941298967, 0.20543277883666056, 0.19288463289704882, 0.21740861759744068, 0.2089479465912062, 0.22980101318255042, 0.21564207170599825, 0.19040419459436364, 0.22904056958424757, 0.19435259855919118, 0.5236286250707607, 0.5446876084804629, 0.22009735401716934, 0.23577363936528073, 0.4868030646771565, 0.4522162681540892, 0.21697591496949442, 0.22562280196635176, 0.84120936818493, 0.8246052515524153, 0.15365907878834772, 0.7584287726700076, 0.1977320756309635, 0.19473572414883578, 0.7474784313729328, 0.16991888427640423, 0.8136283511053167, 0.728069673372769, 0.16900123145459145, 0.796306663016825, 0.20612552143331975, 0.7512316653275415, 0.20919714580549753, 0.19819575336830586, 0.21134618290886864, 0.21235430764719276, 0.1875806232767434, 0.18417981884623336, 0.202881700627079, 0.19196449328671228, 0.18109891394098365, 0.20418548842554596, 0.1869049569978053, 0.2731138190158472, 0.17963403693769886, 0.0803229364907474, 0.08457257858379619, 0.07280190023865485, 0.08468779763601886, 0.08843908107866172, 0.07247930661755075, 0.09285466581986146, 0.10098686114180322, 0.08583858948120782]}, "mutation_prompt": null}
{"id": "41b811ec-7835-43db-862d-6fd424b3f67e", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a dynamic neighborhood strategy\n        def calculate_diversity(swarm):\n            return np.mean(np.std(swarm, axis=0))\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # Adjust inertia based on neighborhood diversity\n            diversity = calculate_diversity(swarm)\n            adjusted_inertia = w * (1 + (diversity / 10.0))\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = adjusted_inertia * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with an elitist selection approach\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced PSO-DE hybrid with adaptive neighborhood strategy, inertia scaling based on neighborhood diversity, and elitist selection to improve convergence.", "configspace": "", "generation": 57, "fitness": 0.3522043285583252, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.25.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7025420032303666, 0.7207634651469856, 0.7351628838641265, 0.7434640302146687, 0.7350453827126262, 0.7713887833302469, 0.7401901859057465, 0.7256423446436404, 0.7157839454665516, 0.5559719812911494, 0.46905409481357896, 0.5618540012302115, 0.5197094881279045, 0.5661576408794254, 0.5655778906748129, 0.5354751494484373, 0.5724116835717574, 0.5472404308134533, 0.11206681943616914, 0.1267556825479742, 0.11602351472807382, 0.13682561684315986, 0.12371906864624815, 0.12005967843941834, 0.12306699393223697, 0.13384631836093597, 0.11291116715958793, 0.11992576833911006, 0.09471075696058728, 0.09713856817754896, 0.0978672790349212, 0.10310074009280612, 0.10769571880989426, 0.09534576864737243, 0.1385411799857713, 0.10433325135249938, 0.987486141071882, 0.9887503714993957, 0.9888696185305007, 0.9880047674084856, 0.9884628176061097, 0.9791631372856952, 0.9855745200580568, 0.9815002452257663, 0.987672438474892, 0.5048505395385521, 0.45870940561701046, 0.5146550514551254, 0.5300187668843075, 0.533054354429962, 0.14701112567855656, 0.4654310323327656, 0.49624745619330735, 0.5042328282214821, 0.22586053705136533, 0.7273633055926396, 0.767596190342632, 0.7313920521107509, 0.8110600040532038, 0.7087495950290301, 0.7427880631022958, 0.678330460753837, 0.7349764635835205, 0.25013568907389616, 0.3706478631499083, 0.323545191549244, 0.30087127068155084, 0.41718361416930216, 0.36024031838132775, 0.47413166871464796, 0.33935345377900616, 0.33592803829545104, 0.28009770628603803, 0.1985516084043113, 0.12513193515597432, 0.3382135268455535, 0.3063972825197656, 0.35693581636578076, 0.3418004577370567, 0.3626022945573093, 0.3690868558149748, 0.5189773240991868, 0.046097369987312065, 0.34361553811001244, 9.999999999998899e-05, 0.31806026590631564, 0.13328800544010355, 0.31428989702780974, 0.3136839295733075, 0.34676874845504746, 0.21941270897965803, 0.500413222729307, 0.2670176076112617, 0.4768416404774358, 0.19996188878795873, 0.1194555198688586, 0.5384664000830752, 0.5786046955583464, 0.5735536943944083, 0.104992847866888, 0.05412867799855525, 0.18085445979605552, 0.21206718893281162, 0.08910865594385176, 0.3034614432070746, 0.1248583553617213, 0.0806735951950941, 0.09283109411128376, 0.31946556065010945, 0.3332177515323491, 0.34070967820381637, 0.3059010773678942, 0.31903843172982294, 0.2910892014241898, 0.2903680197785885, 0.26251790482496895, 0.17114997820478495, 0.5618746000564634, 0.7165128465276784, 0.6175807738679321, 0.20878708354004005, 0.6061672317467829, 0.6680641996222465, 0.5609707109801121, 0.6202126016410359, 0.6016643160411884, 0.11135559227347802, 0.103917294434828, 0.11665852937748655, 0.1252846913816571, 0.12553717654308616, 0.10197839162526356, 0.094311273839778, 0.10873636080033944, 0.12692018406355032, 0.15618216587003209, 0.19720137374589253, 0.24254094865428455, 0.1989883639470047, 0.20926270320243634, 0.19131199000043753, 0.161921281156853, 0.17020374303171015, 0.19033488669294507, 0.41271282268778087, 0.42654819967651114, 0.4132079959378301, 0.45111188363825583, 0.38412372034099196, 0.3744302492393554, 0.4920756471262876, 0.4391211973816549, 0.36591812578166927, 0.24400093251777566, 0.2788889501392482, 0.33292282316047783, 0.3450689179063199, 0.3233435076920076, 0.3017130038187844, 0.2182221960677505, 0.4386627652158862, 0.3406682943700744, 0.19994589534664697, 0.21060355007255804, 0.1979751010140679, 0.19993504071872514, 0.21083516411936887, 0.20757132961948588, 0.20092966544470414, 0.20340491939069494, 0.189592577405426, 0.18432395709939353, 0.21876117805119988, 0.20698978334005247, 0.20619844724799763, 0.19127061504738097, 0.47477206500359603, 0.2005127045755587, 0.1945877770127391, 0.20408168273615435, 0.8192463624154558, 0.7762084720221601, 0.1536635785759528, 0.6332495362917256, 0.19576764890060372, 0.19472976228028638, 0.7143284827229455, 0.17002684740572638, 0.7669640587903795, 0.7271570739765525, 0.11173218889732883, 0.16487502235004192, 0.5970622330054896, 0.16141558715300086, 0.2068015043974376, 0.21135111458485933, 0.20707830198874588, 0.19758742684949282, 0.18432033791211466, 0.19618888431635573, 0.19307803984042338, 0.18497551494548625, 0.17908216428385404, 0.19417562765394258, 0.1803612460648939, 0.1918102081935359, 0.20284307282392544, 0.07857896068044501, 0.08537597233396499, 0.08441338828135814, 0.08013282116204479, 0.08455475676328228, 0.07895640370487433, 0.07696303307786567, 0.08326081310356204, 0.08722698354768166]}, "mutation_prompt": null}
{"id": "57c7a592-709b-403f-b15e-4388786f315a", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined PSO-DE hybrid that leverages adaptive inertia, dynamic velocity clamping, and a novel multi-phase strategy to balance exploration and exploitation for enhanced convergence.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7493444647405034, 0.7640177020858607, 0.7462845471810069, 0.7738665225993068, 0.7501843407461659, 0.7852355688912291, 0.7438687761802445, 0.7574217083427516, 0.7568859346052633, 0.5527137196963421, 0.5575660201238495, 0.5967902500213451, 0.5815732308375463, 0.5898139613955354, 0.6099648457203737, 0.5917370355402044, 0.5912194198961591, 0.5535990066052492, 0.15598205265154408, 0.42030406466672243, 0.1498756644578234, 0.15204281863341473, 0.13797520294652332, 0.1550503833775405, 0.10957714345007485, 0.12248686383063956, 0.14688454688046781, 0.14131665484981826, 0.11849964503423527, 0.11792066156440162, 0.12155976964733295, 0.1270318687081301, 0.12315454579066354, 0.09822718327874225, 0.1147510305979822, 0.11833124149005836, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5868141342193103, 0.11391254579460908, 0.5544351736189043, 0.5204782690740948, 0.5824954092230927, 0.1495289278025297, 0.5656628624740767, 0.5390426568121742, 0.5601641769045604, 0.23909004749227747, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.4067733920656822, 0.4406273911726336, 0.39356585277048683, 0.3806917789744608, 0.1271251318625498, 0.43144658050094375, 0.5398137674663014, 0.40980322077013276, 0.4255406046642397, 0.42199590330968617, 0.27181820029933434, 0.42491270601638265, 0.43903174816038304, 0.4093902502187835, 0.4375584255763165, 0.37774700308954634, 0.12787382925140267, 0.4270648933571154, 0.36259070679628935, 0.1460064059430659, 0.0846313783687187, 0.10580247177981328, 0.503249445641708, 0.1628844390004961, 0.21731864936275447, 0.3858880253263386, 0.4926441010990631, 0.6002774469266389, 0.16165603332794087, 0.5613030877040976, 0.3815459741627647, 0.4676230426131245, 0.27249370768399317, 0.6586502724321228, 0.366099295238444, 0.5535874439287358, 0.11377718143488091, 0.04220554890963124, 0.06707556934476178, 0.13989200836628513, 0.2603271126155412, 0.24961615400121162, 0.12238013535022074, 0.1418432096439426, 0.11526723864138189, 0.20812776319101567, 0.32318159534562363, 0.3302226404477544, 0.33321171250369264, 0.25254365238541376, 0.3321695686910868, 0.28415198459247826, 0.30061762586313245, 0.25215203682408727, 0.6169162626189699, 0.6149507625566845, 0.7059256864779984, 0.6352127257533673, 0.7152919680829259, 0.6645229276579401, 0.6187980743668027, 0.6378656796374813, 0.6826755588124738, 0.08463013168695632, 0.13586706444036822, 0.1409516731095264, 0.10928057441375094, 0.11596958449245953, 0.12302492063926862, 0.11634337331374067, 0.10464574235218171, 0.1003630738132888, 0.2111401374897458, 0.26130800033134893, 0.24397786220487228, 0.21853738370615683, 0.18514699602401075, 0.2529441759291139, 0.22098166853032764, 0.24268374280178928, 0.28759113856437657, 0.4216699965527476, 0.4123525712834284, 0.44843849372191136, 0.3894967808414551, 0.4208324539457089, 0.438302917585086, 0.47955268848433674, 0.4924589173141519, 0.4294883405375651, 0.3786939363478393, 0.3613506018681588, 0.26352396415517276, 0.3256799405545595, 0.19799011748799722, 0.35150077749291275, 0.4176445473735847, 0.3478468161553271, 0.3804108354615596, 0.20011898941298967, 0.20543277883666056, 0.19288463289704882, 0.21740861759744068, 0.2089479465912062, 0.22980101318255042, 0.21564207170599825, 0.19040419459436364, 0.22904056958424757, 0.19435259855919118, 0.5236286250707607, 0.5446876084804629, 0.22009735401716934, 0.23577363936528073, 0.4868030646771565, 0.4522162681540892, 0.21697591496949442, 0.22562280196635176, 0.84120936818493, 0.8246052515524153, 0.15365907878834772, 0.7584287726700076, 0.1977320756309635, 0.19473572414883578, 0.7474784313729328, 0.16991888427640423, 0.8136283511053167, 0.728069673372769, 0.16900123145459145, 0.796306663016825, 0.20612552143331975, 0.7512316653275415, 0.20919714580549753, 0.19819575336830586, 0.21134618290886864, 0.21235430764719276, 0.1875806232767434, 0.18417981884623336, 0.202881700627079, 0.19196449328671228, 0.18109891394098365, 0.20418548842554596, 0.1869049569978053, 0.2731138190158472, 0.17963403693769886, 0.0803229364907474, 0.08457257858379619, 0.07280190023865485, 0.08468779763601886, 0.08843908107866172, 0.07247930661755075, 0.09285466581986146, 0.10098686114180322, 0.08583858948120782]}, "mutation_prompt": null}
{"id": "42e8b75f-b4bf-4a99-b4b0-072c2f250684", "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\nclass EnhancedDualPhasePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # Apply clustering in the exploration phase\n            if exploration_phase:\n                kmeans = KMeans(n_clusters=int(self.population_size / 2), random_state=0).fit(swarm)\n                cluster_centers = kmeans.cluster_centers_\n                velocities[:len(cluster_centers)] = np.random.uniform(-1, 1, (len(cluster_centers), self.dim))\n                swarm[:len(cluster_centers)] = cluster_centers\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with adaptive clustering\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedDualPhasePSO_DE", "description": "Enhanced Dual-Phase PSO-DE Algorithm using Adaptive Clustering for Diversified Exploration and Intensified Exploitation.", "configspace": "", "generation": 59, "fitness": -Infinity, "feedback": "An exception occurred: ModuleNotFoundError(\"No module named 'sklearn'\").", "error": "ModuleNotFoundError(\"No module named 'sklearn'\")", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {}, "mutation_prompt": null}
{"id": "727f184e-04a8-47a8-bd6e-a17dec2d96ae", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49618  # Cognitive component\n        self.c2 = 1.49618  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.niche_radius = 0.1  # Dynamic niching parameter\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach with adaptive strategies\n        def switch_phase(iteration):\n            return (iteration < 0.3 * self.budget or iteration > 0.7 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with dynamic niching in exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                    mutant = a + F * (b - c)\n                else:\n                    distances = np.linalg.norm(swarm - swarm[i], axis=1)\n                    niche_candidates = np.where(distances < self.niche_radius)[0]\n                    if len(niche_candidates) > 2:\n                        a, b, c = personal_best_positions[np.random.choice(niche_candidates, 3, replace=False)]\n                    else:\n                        a, b, c = personal_best_positions[np.random.choice(self.population_size, 3, replace=False)]\n                    mutant = a + F * (b - c)\n\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "A multi-phase PSO-DE hybrid algorithm utilizing adaptive strategy transitions and dynamic niching mechanisms to balance local and global search for improved optimization.", "configspace": "", "generation": 60, "fitness": 0.36416902459126194, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.24.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7626020734992696, 0.7500755754890216, 0.7485192362586854, 0.7765726204450489, 0.7427483497978811, 0.764335676828093, 0.7574374875342342, 0.7703803552254368, 0.7747656229785393, 0.5726529510079792, 0.5825781323936318, 0.5946422404909002, 0.5653423589085915, 0.5571392187292606, 0.5743266819029483, 0.5723603300571363, 0.5989847069806737, 0.5353657347100922, 0.12093838164140047, 0.1226745800905028, 0.1160225588906193, 0.13670707921365066, 0.1139754350891915, 0.1486696544690843, 0.11818561031944297, 0.11624962786590409, 0.14037117648462138, 0.10754110353484392, 0.11583318410560606, 0.12962904016337473, 0.12528306925033483, 0.11647968875731807, 0.10827408227774082, 0.11387613884321168, 0.12466923109832351, 0.11587716318112451, 0.9874231625088142, 0.9887758022545784, 0.9888381617901739, 0.985697563645805, 0.9886801517567907, 0.9798251573679498, 0.9843594307358214, 0.9792588949469567, 0.987628021617333, 0.5356263497665708, 0.553928691444191, 0.5191916523686197, 0.5334183988743308, 0.5294774010326445, 0.429997950300123, 0.5116766280943021, 0.5157240908459435, 0.08773440061739912, 0.7658256413668256, 0.30211882081069363, 0.7895786697319986, 0.7582103984505486, 0.2106950599386771, 0.37514453353335997, 0.7619621661821677, 0.7598993698528125, 0.7211664423595519, 0.3748631541793608, 0.2867321753165657, 0.301739482373924, 0.2643203454643408, 0.1272592843327346, 0.3581728398838038, 0.33538995180322073, 0.3619795639787252, 0.3121911488491971, 0.29494810070363975, 0.27149617724919883, 0.2991916927964262, 0.3409203825067678, 0.286425283658279, 0.321714339499488, 0.27977707566798427, 0.2811482130316686, 0.4183446274873409, 0.36513733147937155, 0.06444677530924126, 0.40718622280502514, 0.3218514712988563, 0.38855455715355125, 0.3391331483386991, 0.3825982798316686, 0.3783560640158258, 0.2995846564721374, 0.4298703263234325, 0.30356745787415884, 0.3571317187585731, 0.3958624117931214, 0.2575904539810977, 0.1338208405068162, 0.614073935164978, 0.5110299052382321, 0.18913464455204587, 0.11992639997068855, 0.049545234403773564, 0.08895525944349847, 0.2224686074445904, 0.23006197095493663, 0.19374062963098893, 0.11546431780249955, 0.09478554206954681, 0.13156269568797818, 0.16907739705824243, 0.26239525986300727, 0.2856345651698655, 0.2700976936307371, 0.23063112760365645, 0.28081696398205913, 0.3084211231141095, 0.3030745928957955, 0.21999336833487337, 0.6745175835981637, 0.641537665107671, 0.6692529714627612, 0.6021223528232126, 0.7035856416347257, 0.5721124764016529, 0.5900546759362792, 0.6752883661658349, 0.6181990501138317, 0.11769193197441796, 0.10662714725875488, 0.13000926663644974, 0.14002038568000752, 0.13830331787853734, 0.13074178791373015, 0.11895801142558482, 0.09212036994707828, 0.10977883287767076, 0.2029594047691109, 0.23265920845707588, 0.3286830192870148, 0.37844674479965146, 0.3097182461590382, 0.24447211222860532, 0.26217860408614757, 0.1948252930192066, 0.18292232287394494, 0.419244623072869, 0.45721794554212825, 0.4318654837376028, 0.3849355642673421, 0.4323613235816566, 0.39649930220402596, 0.43644454770454755, 0.4534347208474617, 0.3894095093709591, 0.31208751640048793, 0.33090490155114016, 0.3035718171047922, 0.37522694660974765, 0.3162902166028002, 0.34090389221824624, 0.3525972483938483, 0.3273915721193362, 0.38558274539044335, 0.2021965362705851, 0.2012639751910288, 0.19980352796442724, 0.21320652183364885, 0.19797980594326614, 0.19154210788502712, 0.21159138006617373, 0.19278239266478892, 0.21202919351272487, 0.19816038348406295, 0.4524826751239185, 0.5220237008401313, 0.461888217259943, 0.23266949162880146, 0.49490951555706264, 0.43231845630338506, 0.22141030923496996, 0.4491064256143461, 0.8397522266651483, 0.8334483559311155, 0.1539343302985371, 0.773487486527324, 0.19719928372007867, 0.19484503200611347, 0.15282668840392666, 0.1698674013183088, 0.8126470446667303, 0.6186991102158261, 0.20468462377098218, 0.7950585885460418, 0.20653562668785863, 0.12596162330024996, 0.20891341434155875, 0.1984043495011487, 0.2109029233214389, 0.2123026379916816, 0.2066252855165479, 0.1837590363744983, 0.21575782766017548, 0.17555611136530114, 0.19281137214343058, 0.18474563352585127, 0.20824397902858982, 0.18132232746269805, 0.18249901756657405, 0.08716552644032927, 0.07430883305736302, 0.09263632051446369, 0.08285512563149755, 0.0869470829941843, 0.09824341981187068, 0.07850587912418816, 0.08711176876907012, 0.07467677444893939]}, "mutation_prompt": null}
{"id": "ddf659a1-1d7c-4d47-a7b9-18cc15149fcc", "solution": "import numpy as np\n\nclass MultiPhaseAdaptivePSO_DE_LocalSearch:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        def local_search(position):\n            perturbation = np.random.normal(0, 0.1, size=self.dim)\n            candidate = position + perturbation\n            candidate = np.clip(candidate, self.lower_bound, self.upper_bound)\n            return candidate\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Apply local search in the exploitation phase\n                if not exploration_phase and np.random.rand() < 0.1:\n                    local_candidate = local_search(personal_best_positions[i])\n                    local_score = func(local_candidate)\n                    self.num_evals += 1\n\n                    if local_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_score\n                        personal_best_positions[i] = local_candidate\n                        if local_score < global_best_score:\n                            global_best_score = local_score\n                            global_best_position = local_candidate\n\n        return global_best_position", "name": "MultiPhaseAdaptivePSO_DE_LocalSearch", "description": "Multi-Phase Adaptive PSO-DE with Local Search: A multi-phase adaptive PSO-DE that integrates local search in later iterations to refine solutions and improve convergence.", "configspace": "", "generation": 61, "fitness": 0.3809866303114749, "feedback": "The algorithm MultiPhaseAdaptivePSO_DE_LocalSearch got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.26.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7507438736223548, 0.7641623746671291, 0.7468099797753817, 0.7741984468161907, 0.7496615294845882, 0.7851315949642804, 0.7445734107467965, 0.7578332546847913, 0.7566857736695665, 0.5597608066176579, 0.5548481911012433, 0.5896546342108446, 0.5836950260436642, 0.5885557643737485, 0.6053985132202877, 0.5842879662677487, 0.5909757066122523, 0.552815229211421, 0.15601339029351236, 0.15410217103294377, 0.13559092392941474, 0.15233054785464684, 0.13853233989092384, 0.155101202146956, 0.11493571608528197, 0.12247666392312495, 0.14683641116519774, 0.12815057870512048, 0.11862172610199595, 0.13820906098506403, 0.12199850051629635, 0.12712066338274985, 0.12474520328739858, 0.10124012798601911, 0.11477648795904094, 0.1183836614337953, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5795262178639227, 0.3574174538525946, 0.5661546517000824, 0.5175707431233982, 0.5939484737197553, 0.20823533204142264, 0.5696610139535739, 0.5439427868813509, 0.5648423294554296, 0.23572461104016995, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.3876110501856387, 0.47356160535654945, 0.39369236006509767, 0.3823276208050087, 0.12712512261390652, 0.40015075067819394, 0.5082641415752738, 0.4415154913563817, 0.3666526392589805, 0.41648664633451704, 0.2865736100654449, 0.35573211146277195, 0.4243734945959152, 0.37165130988852046, 0.4105512789336997, 0.3510941097418082, 0.12787380723784703, 0.4600212496176649, 0.4790332552838922, 0.17244989922027176, 0.08462880933017691, 0.06741058932137312, 0.37482851473738865, 0.06682218131857753, 0.18147240381469454, 0.3762843011461712, 0.4357430568149203, 0.5801118729527559, 0.18570011234043304, 0.5200145040842321, 0.3196313526168951, 0.4399334539496004, 0.29367589328120824, 0.6559616808863813, 0.3677242987398085, 0.4636147576343511, 0.11513183133429172, 0.048608266838547354, 0.061056104993819416, 0.08400098977539161, 0.24962332762196615, 0.2115569368007758, 0.12405496324415055, 0.14502682247965115, 0.11750435442686136, 0.2326802995375975, 0.3185228166990022, 0.32177644288008855, 0.3093789095181614, 0.24676861595990418, 0.2979796543708827, 0.25445253937734336, 0.2578677381248803, 0.20097821253572268, 0.6981687406261372, 0.6919142841303865, 0.7151530628836689, 0.6251069838928274, 0.6844655070088213, 0.707906129327107, 0.6338595032459782, 0.6533885116416633, 0.717441962438135, 0.08460900406976324, 0.14881802488578144, 0.14093428778957318, 0.10718142243350581, 0.12419800469464548, 0.12314375969729063, 0.11771063476086985, 0.10460847687320352, 0.10020781054377004, 0.21629981852458424, 0.2556845060178088, 0.24075276326477546, 0.21883197719461056, 0.1988878096941451, 0.25364511521650124, 0.2213732706763315, 0.24260300266674872, 0.2728626687464236, 0.4628679828443708, 0.4215105271558137, 0.42171046473473517, 0.36551930307486746, 0.3864771660499615, 0.4698290496959885, 0.4263092131164765, 0.4717991419035593, 0.48800660477279556, 0.35600772632880295, 0.346707088281729, 0.2884723112819545, 0.3543339203888599, 0.1987026865296716, 0.3663559628455533, 0.3744365380145178, 0.34673775851564026, 0.3611271833505614, 0.2105116884273025, 0.20154869932097386, 0.19148384299862242, 0.2149646319339389, 0.2047383218485067, 0.22089134256140464, 0.2169054376296612, 0.19081454100901518, 0.22774327849191667, 0.19439525736279362, 0.5195715525234833, 0.5420776185404095, 0.22059642225194775, 0.2357729376399098, 0.47441985406761633, 0.20322121001816573, 0.2173488198486917, 0.2256349916505107, 0.84120936818493, 0.8246052515524153, 0.15365907878834917, 0.7584287726700076, 0.19773207551345706, 0.19473572536438255, 0.7474784313729328, 0.16991888427787616, 0.8136283511053167, 0.728069673372769, 0.16900123144779355, 0.796306663016825, 0.2061255204385397, 0.7512316653275415, 0.20919714293676805, 0.2032233697602961, 0.21134618292597962, 0.21235430767550223, 0.1874579900858282, 0.1845213499554903, 0.20334196146383843, 0.19325364933081268, 0.18110175636218617, 0.19907574672599782, 0.1793065408136425, 0.23827653049720598, 0.1869735848484987, 0.08439553515710341, 0.08503804016091943, 0.07817347620441506, 0.08885636317465961, 0.08322828196211995, 0.07343952767030582, 0.09583942282504654, 0.09920518420180013, 0.08831218320342338]}, "mutation_prompt": null}
{"id": "6b0f66f0-a438-463e-bab4-979eaf953697", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            if iteration < 0.3 * self.budget:\n                return \"exploration\"\n            elif iteration < 0.7 * self.budget:\n                return \"exploitation\"\n            else:\n                return \"intensification\"\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if phase == \"exploration\":\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                elif phase == \"exploitation\":\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n                else:\n                    top_k = int(0.1 * self.population_size)\n                    sorted_indices = np.argsort(personal_best_scores)\n                    selected = sorted_indices[:top_k]\n                    a, b, c = personal_best_positions[np.random.choice(selected, 3, replace=False)]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced PSO-DE hybrid introducing adaptive selection pressure and a dynamic multi-phase mechanism to improve convergence efficiency.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "An exception occurred: ValueError(\"Cannot take a larger sample than population when 'replace=False'\").", "error": "ValueError(\"Cannot take a larger sample than population when 'replace=False'\")", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {}, "mutation_prompt": null}
{"id": "5d7290cf-e326-4e73-8483-97edb5bb20b8", "solution": "import numpy as np\n\nclass EnhancedAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.4  # Cognitive component\n        self.c2 = 1.4  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a dynamic phase-based approach with stochastic sampling\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                # Stochastic sampling for evaluation\n                score = np.mean([func(swarm[i] + np.random.normal(0, 0.1, self.dim)) for _ in range(3)])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with adaptive exploration\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedAdaptivePSO_DE", "description": "Enhanced Adaptive PSO-DE with a Time-Variant Strategy and Stochastic Sampling for Improved Robustness and Convergence.", "configspace": "", "generation": 63, "fitness": 0.24978640344593633, "feedback": "The algorithm EnhancedAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.21.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.4876791758788648, 0.5156522976891011, 0.504946021776453, 0.5425737493148307, 0.5038935772844881, 0.5790571706835151, 0.5025084397219381, 0.531061649159061, 0.5344652049383872, 0.21496248599441814, 0.2264894180975311, 0.09867571412580434, 0.20625350170047507, 0.2501000003376155, 0.1887650113943682, 0.23625183973689823, 0.23173966759545828, 0.2498621886519884, 0.11187633871275615, 0.10611293968393476, 0.10755090249349064, 0.10173683047908122, 0.08951273329699783, 0.0888375767546149, 0.09417406682627316, 0.10028100456425304, 0.10326724049964908, 0.08043816724859609, 0.07644255278758483, 0.08319800512740383, 0.0883490920342801, 0.10121620321019531, 0.07395994915264159, 0.08774838441520483, 0.07622053391162076, 0.10076201935852946, 0.9673223182427831, 0.9702909363994501, 0.976036225978334, 0.9588284491460319, 0.9733592305628685, 0.9714788068156661, 0.9744080849003502, 0.966713319217035, 0.9376925005282762, 0.21613596078397046, 0.2566504411053213, 0.27667512444738174, 0.2963655981811174, 0.25169617369043673, 0.25158963998369077, 0.25140038160712974, 0.2374923711397664, 0.26567786834587026, 0.6324325901124532, 0.5115283553396862, 0.47570754049118114, 0.5837335026954527, 0.5558022742515333, 0.5901977626472017, 0.5397719261265259, 0.5904172058879136, 0.6492361342266395, 0.1633145216270646, 0.22172470195994343, 0.12773901209276994, 0.21507504631882823, 0.13498919988001112, 0.1222488876300637, 0.1648543834790267, 0.15151864424879624, 0.14995163102205533, 0.13770596725541928, 0.0852285681761632, 0.12435235144622347, 0.18204869332598317, 0.17840109424753658, 0.13605046476286242, 0.14677005976218516, 0.12842075490993554, 0.1285018027544631, 0.10632864375427853, 0.10719244778033044, 0.10319562567658636, 0.14706165549796202, 0.05275114799154801, 0.03519057038889806, 0.1602290193560435, 0.020632293185118722, 0.12471363810493985, 0.11267523863889639, 0.22846228410124714, 0.2529962876275679, 0.2710011996510988, 0.09311906693729521, 0.13675842839291652, 0.2967942079125985, 0.24937169061487674, 0.23187319215588398, 0.06752677748298008, 0.026763932164758808, 0.030632985455315564, 0.06616757101298298, 0.04535015117931873, 0.05340470962782362, 0.04473271217579544, 0.08368236317037714, 0.03129065146025445, 0.14692055714995989, 0.1469778545339162, 0.16524331875875375, 0.04501670951195191, 0.1480756556280397, 0.1160693597111978, 0.1386686494351015, 0.15752700246080165, 0.14786447021067128, 0.4430427416931859, 0.4753036413437751, 0.47483523100539493, 0.493781683993866, 0.4750250436347774, 0.4281072596956119, 0.4326005891708624, 0.4534295691736949, 0.46848823909440773, 0.08675108364321071, 0.09347160017789535, 0.09943354779242619, 0.09346344947206542, 0.09962722409445246, 0.08611895919667656, 0.08945002571535421, 0.08629718614849158, 0.07929356938512888, 0.18990103558959603, 0.1602558099680449, 0.14710775066141613, 0.21185167190544574, 0.15675784893090827, 0.13033674629250036, 0.22550163755558938, 0.15301275751018006, 0.1772112371054353, 0.29947939305953875, 0.27609422620722623, 0.26501441870142495, 0.27102214942512215, 0.2944299643579463, 0.2977683867704596, 0.2936914868465317, 0.3372750996893137, 0.26483176019547616, 0.19565422815014477, 0.19625988696879748, 0.21002450531904993, 0.23674228084190385, 0.23050929309884027, 0.21348683556811998, 0.23678567283869634, 0.2447982817879223, 0.21119469756468356, 0.19041674374803985, 0.20650853957870374, 0.19929648537931144, 0.2270708245013533, 0.21574547876597117, 0.18752790501657413, 0.20102747172740487, 0.23130781416765533, 0.19629550358301417, 0.17781307113849876, 0.1792020073633448, 0.17248242077235032, 0.1881736149438613, 0.17934833891459911, 0.18374210591864992, 0.17268062129076678, 0.16946648418545207, 0.17777207206882673, 0.7204223812266953, 0.6341451920864156, 0.1473853174993479, 0.19099184669972769, 0.19776820176865317, 0.19419973647673228, 0.16588321434979592, 0.16664138542991636, 0.6187627682478032, 0.640030520589534, 0.16615360059617812, 0.47353726883353353, 0.19633098847124542, 0.25738183057879493, 0.20187987594752044, 0.19802054527020496, 0.13393334978925464, 0.2038213396118128, 0.1790937784824187, 0.1898942245097479, 0.18130226073015654, 0.19055847246983337, 0.19564464552212513, 0.18247661497355816, 0.19819473169536705, 0.18109476402047264, 0.2046800408050401, 0.07420054668040044, 0.07670051097147101, 0.07938185012971988, 0.08638180424052422, 0.07491581547499371, 0.09065456889869106, 0.06731887757825117, 0.07681888228024214, 0.07944394969030655]}, "mutation_prompt": null}
{"id": "2738a6aa-c6f5-4207-a60e-c71553df1a0a", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        # Introduce a phase-based approach\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with a focus on the exploration phase\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE", "description": "A refined PSO-DE hybrid that leverages adaptive inertia, dynamic velocity clamping, and a novel multi-phase strategy to balance exploration and exploitation for enhanced convergence.", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7493444647405034, 0.7640177020858607, 0.7462845471810069, 0.7738665225993068, 0.7501843407461659, 0.7852355688912291, 0.7438687761802445, 0.7574217083427516, 0.7568859346052633, 0.5527137196963421, 0.5575660201238495, 0.5967902500213451, 0.5815732308375463, 0.5898139613955354, 0.6099648457203737, 0.5917370355402044, 0.5912194198961591, 0.5535990066052492, 0.15598205265154408, 0.42030406466672243, 0.1498756644578234, 0.15204281863341473, 0.13797520294652332, 0.1550503833775405, 0.10957714345007485, 0.12248686383063956, 0.14688454688046781, 0.14131665484981826, 0.11849964503423527, 0.11792066156440162, 0.12155976964733295, 0.1270318687081301, 0.12315454579066354, 0.09822718327874225, 0.1147510305979822, 0.11833124149005836, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5868141342193103, 0.11391254579460908, 0.5544351736189043, 0.5204782690740948, 0.5824954092230927, 0.1495289278025297, 0.5656628624740767, 0.5390426568121742, 0.5601641769045604, 0.23909004749227747, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.4067733920656822, 0.4406273911726336, 0.39356585277048683, 0.3806917789744608, 0.1271251318625498, 0.43144658050094375, 0.5398137674663014, 0.40980322077013276, 0.4255406046642397, 0.42199590330968617, 0.27181820029933434, 0.42491270601638265, 0.43903174816038304, 0.4093902502187835, 0.4375584255763165, 0.37774700308954634, 0.12787382925140267, 0.4270648933571154, 0.36259070679628935, 0.1460064059430659, 0.0846313783687187, 0.10580247177981328, 0.503249445641708, 0.1628844390004961, 0.21731864936275447, 0.3858880253263386, 0.4926441010990631, 0.6002774469266389, 0.16165603332794087, 0.5613030877040976, 0.3815459741627647, 0.4676230426131245, 0.27249370768399317, 0.6586502724321228, 0.366099295238444, 0.5535874439287358, 0.11377718143488091, 0.04220554890963124, 0.06707556934476178, 0.13989200836628513, 0.2603271126155412, 0.24961615400121162, 0.12238013535022074, 0.1418432096439426, 0.11526723864138189, 0.20812776319101567, 0.32318159534562363, 0.3302226404477544, 0.33321171250369264, 0.25254365238541376, 0.3321695686910868, 0.28415198459247826, 0.30061762586313245, 0.25215203682408727, 0.6169162626189699, 0.6149507625566845, 0.7059256864779984, 0.6352127257533673, 0.7152919680829259, 0.6645229276579401, 0.6187980743668027, 0.6378656796374813, 0.6826755588124738, 0.08463013168695632, 0.13586706444036822, 0.1409516731095264, 0.10928057441375094, 0.11596958449245953, 0.12302492063926862, 0.11634337331374067, 0.10464574235218171, 0.1003630738132888, 0.2111401374897458, 0.26130800033134893, 0.24397786220487228, 0.21853738370615683, 0.18514699602401075, 0.2529441759291139, 0.22098166853032764, 0.24268374280178928, 0.28759113856437657, 0.4216699965527476, 0.4123525712834284, 0.44843849372191136, 0.3894967808414551, 0.4208324539457089, 0.438302917585086, 0.47955268848433674, 0.4924589173141519, 0.4294883405375651, 0.3786939363478393, 0.3613506018681588, 0.26352396415517276, 0.3256799405545595, 0.19799011748799722, 0.35150077749291275, 0.4176445473735847, 0.3478468161553271, 0.3804108354615596, 0.20011898941298967, 0.20543277883666056, 0.19288463289704882, 0.21740861759744068, 0.2089479465912062, 0.22980101318255042, 0.21564207170599825, 0.19040419459436364, 0.22904056958424757, 0.19435259855919118, 0.5236286250707607, 0.5446876084804629, 0.22009735401716934, 0.23577363936528073, 0.4868030646771565, 0.4522162681540892, 0.21697591496949442, 0.22562280196635176, 0.84120936818493, 0.8246052515524153, 0.15365907878834772, 0.7584287726700076, 0.1977320756309635, 0.19473572414883578, 0.7474784313729328, 0.16991888427640423, 0.8136283511053167, 0.728069673372769, 0.16900123145459145, 0.796306663016825, 0.20612552143331975, 0.7512316653275415, 0.20919714580549753, 0.19819575336830586, 0.21134618290886864, 0.21235430764719276, 0.1875806232767434, 0.18417981884623336, 0.202881700627079, 0.19196449328671228, 0.18109891394098365, 0.20418548842554596, 0.1869049569978053, 0.2731138190158472, 0.17963403693769886, 0.0803229364907474, 0.08457257858379619, 0.07280190023865485, 0.08468779763601886, 0.08843908107866172, 0.07247930661755075, 0.09285466581986146, 0.10098686114180322, 0.08583858948120782]}, "mutation_prompt": null}
{"id": "61e2a835-ae1c-4506-acea-7a2d9f5f4cc6", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49618  # Cognitive component\n        self.c2 = 1.49618  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.4\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 1.0\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + (1 - progress) * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # Elitism-based DE-inspired mutation and crossover\n            elite_indices = np.argsort(personal_best_scores)[:max(2, self.population_size // 4)]\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                candidates = np.random.choice(elite_indices, 3, replace=False)\n                a, b, c = personal_best_positions[candidates]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced PSO-DE hybrid with self-adaptive parameter adjustments and elitist learning strategies for improved exploration and exploitation balance.", "configspace": "", "generation": 65, "fitness": 0.2676207231120753, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.24.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7829258374923257, 0.7334678809889807, 0.769951878537831, 0.7731272936597895, 0.8352772886825579, 0.1813904567411092, 0.7737657994293623, 0.7761585091371371, 0.7707116050034201, 0.5435754052151902, 0.6166638658134527, 0.03329100825235276, 0.6745117043145066, 0.5668331504305166, 0.535377553571946, 0.5283393123434517, 0.5801270233375422, 0.5155110721652809, 0.13375927426898848, 0.17645652829392855, 0.11369555933970932, 0.13089576482607101, 0.1437495863212982, 0.6602225717491865, 0.5871331255129117, 0.6738647930563967, 0.11891447049214143, 0.11814502598308096, 0.16838255700173088, 0.1064365054027554, 0.13174467237523935, 0.044239763453111536, 0.10812397947083796, 0.14828128836198107, 0.10647061138532699, 0.052565563511660196, 0.9847375812202093, 0.98489234894369, 0.9888427649384463, 0.98467574955362, 0.9855335470140437, 0.985548252791981, 0.9812879329202217, 0.9851109756726483, 0.9876922532986838, 0.5600130102822127, 0.5950991821983437, 0.578816399310804, 0.5719474394285979, 0.14739371946283664, 0.14548305726857802, 0.5625120457957006, 0.08774632568918272, 0.5640236952307995, 0.22964563429627183, 0.3401976229566218, 0.2180407042406891, 0.259186731777757, 0.11352773099135305, 0.35467972217515853, 0.22126049515899615, 0.1322335908407063, 0.23359341646241627, 0.2232532407738994, 0.1849211942019129, 0.18441077022050967, 0.19907664699868388, 0.1886674360023033, 0.22786925757417076, 0.2242883016635122, 0.22373787068606765, 0.20216344147228194, 0.21129405101197585, 0.18781616945201507, 0.12997992992197993, 0.19882169843673592, 0.12385000541464253, 0.14568219814994032, 0.11970038012955697, 0.09776335011491777, 0.19679435296165304, 0.00010274543621513477, 0.0010414768178835798, 0.007513785373553072, 0.024387806555710045, 0.010333661276743067, 0.05454053685461091, 0.018496577606209597, 9.999999999998899e-05, 9.999999999998899e-05, 0.19777426328633008, 0.07699074175481746, 0.09870391580807314, 0.05890853127090645, 0.033597075333516635, 0.015251696319494856, 0.19507026388156512, 0.030118452632296844, 0.05794278364000094, 0.22681629978396922, 0.06199354904431964, 0.06456826273156602, 0.0664398610330269, 0.14746473588878906, 0.12251179156624148, 0.09994090422679214, 0.07642664691529244, 0.05821618378960047, 0.06765877450506996, 0.12079304093814658, 0.14083643962086134, 9.999999999998899e-05, 0.013691942376350963, 0.16918713187266077, 0.12143650203113554, 0.19687270121673484, 0.08119732848374062, 0.5003981616727498, 0.48468921396939724, 0.47699424717484584, 0.5222779668836897, 0.466074657462346, 0.48621876177923073, 0.49081975354943175, 0.49704892033554415, 0.49829206235275036, 0.06827325399082307, 0.15411799064663534, 0.1187776341947765, 0.1079460922575034, 0.12295723448963036, 0.17289489945596104, 0.13888034928882442, 0.07583561812952544, 0.129623829518131, 0.19685911419746305, 0.1531795351973818, 0.15434064725112107, 0.22744039502383173, 0.18274802107016563, 0.1483035611231589, 0.30834516278546786, 0.2548256011382649, 0.16571752287042218, 0.27642073784365284, 0.236443734820581, 0.35386991227213127, 0.3151987197433469, 0.2471826450621304, 0.2915001547198345, 0.3331044959706113, 0.25648576325624917, 0.2866212300654769, 0.1888484186636804, 0.2232074235307696, 0.1286443204007668, 0.19775561693838595, 0.2642627728853355, 0.20203611390623955, 0.17870234915466676, 0.21895706042878238, 0.09877080216695544, 0.17170408198181197, 0.27722937642304046, 0.21364923556646798, 0.20933074506464067, 0.21641190958063095, 0.21427481972472562, 0.23309455919574074, 0.19762163529347299, 0.2455326709798762, 0.19173560864355554, 0.2103220967329571, 0.21971999543940035, 0.22286616671195736, 0.23894033741109877, 0.20644691627017397, 0.18492777629418378, 0.20551850233871416, 0.19202831811397247, 0.8182560970802895, 0.16392652103553373, 0.15333022374171834, 0.11927278418122045, 0.1999162711958622, 0.1953403409361847, 0.12291444399182871, 0.17008174911227247, 0.15897798166015076, 0.15308679436135864, 0.20530122578656096, 0.11060372315142541, 0.20248701036666272, 0.5382402567009842, 0.20428734315227104, 0.1049910582599205, 0.6029251767006126, 0.11275695605059843, 0.18310387927966643, 0.2105839231796245, 0.1837007122470885, 0.20448161379191931, 0.16483316736104003, 0.19493486447875807, 0.19615794117204466, 0.19360194388497343, 0.19277993108647062, 0.08625503212629104, 0.08719863105521819, 0.09032425336230898, 0.07823195681369366, 0.10124063681684925, 0.08507971693950278, 0.08733860242070246, 0.09995684874286492, 0.09130242767603924]}, "mutation_prompt": null}
{"id": "03edb8ab-6896-43fe-bdb8-f8d541a48977", "solution": "import numpy as np\n\nclass AdaptiveMultiPhasePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.5  # Cognitive component\n        self.c2 = 1.5  # Social component\n        self.w_start = 0.8  # Start inertia weight\n        self.w_end = 0.3    # End inertia weight\n        self.F_start = 0.4\n        self.F_end = 0.8\n        self.CR_start = 0.7\n        self.CR_end = 0.9\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n        \n        def fitness_scaling(scores):\n            min_score = np.min(scores)\n            max_score = np.max(scores)\n            scaled_scores = (scores - min_score) / (max_score - min_score + 1e-8)\n            return scaled_scores\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        elite_position = None\n        elite_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.4 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n                if score < elite_score:\n                    elite_score = score\n                    elite_position = swarm[i]\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            scaled_scores = fitness_scaling(personal_best_scores)\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover with elite preservation\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: scaled_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n        return elite_position if elite_score < global_best_score else global_best_position", "name": "AdaptiveMultiPhasePSO_DE", "description": "The adaptive Multi-Phase PSO-DE utilizes a novel fitness-scaling mechanism, adaptive parameter reinforcement, and elite preservation to enhance convergence speed and solution quality across dynamic phases.", "configspace": "", "generation": 66, "fitness": 0.34951002385130575, "feedback": "The algorithm AdaptiveMultiPhasePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.26.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.8042012113056145, 0.7938487954331319, 0.796988688174548, 0.8067395576800069, 0.7999207628803114, 0.8127768976118177, 0.8181926733254696, 0.7943800586963286, 0.8026542241341632, 0.6279197889133123, 0.6232406456727231, 0.649885421169917, 0.6266000612315599, 0.648242184984477, 0.6413275269427676, 0.6064893388337314, 0.5678844331534352, 0.6623358644154833, 0.13869946732064964, 0.13929915467786558, 0.14890428373408449, 0.1377821479590544, 0.4587366639327217, 0.15826172725589294, 0.12902471875444133, 0.17052056911968572, 0.13934037650628683, 0.1359589731854618, 0.15705908223535148, 0.12347519133876506, 0.1159722940319905, 0.1416365786837025, 0.1251695036895475, 0.13856804713812687, 0.12333985089926158, 0.12019136529460461, 0.9857085039535481, 0.986633657916423, 0.9939496301882118, 0.9854788581242514, 0.9885041473895, 0.9881291036474001, 0.9832580642507242, 0.9848889185891796, 0.9855848340532322, 0.599987225879449, 0.6358389153616251, 0.6252394088578617, 0.6068953078944648, 0.6593032554082046, 0.6396280205888587, 0.6533944937215095, 0.6348949286985486, 0.6285992200834265, 0.366923275187808, 0.21996633115959896, 0.22529578222096003, 0.209420282685857, 0.8554567132692057, 0.18383077972223638, 0.12618258874743826, 0.2269904907138247, 0.24078102808861257, 0.4677350845483148, 0.3562728287629906, 0.44270736989120485, 0.12361486200867533, 0.3865530589392896, 0.12339330128789949, 0.43580505933195723, 0.4825766804966315, 0.382949270857076, 0.2594935434750971, 0.00988746059128176, 0.29671441794421527, 0.5205513999788157, 0.43856132466412234, 0.4238070898757029, 0.3501550922001817, 0.1200888908437533, 0.4521230067185624, 0.04880346234621791, 0.02659504944777613, 0.12360675913152552, 0.14092614590770658, 0.12250109412148613, 0.2510270293233341, 0.09250937703237083, 0.15790270969812648, 0.04932529803505259, 0.3369676678743304, 0.11020902170599689, 0.1935716933889855, 0.14670367293154885, 0.2443029660373538, 0.11757714849375422, 0.3982752560498244, 0.22053145519970452, 0.13153735584671356, 0.05294395488276893, 0.08045443508079919, 0.16044539058578944, 0.11333679817186182, 0.166695544502671, 0.1249298392898589, 0.08799677107072457, 0.0841514262642784, 0.11153003494921054, 0.17132885845816914, 0.19934579118426832, 0.27704930107697734, 0.3159906242172278, 0.0059289933924207006, 0.006126315240879143, 0.27432067606771504, 0.23329897312685188, 0.13835421516787283, 0.6270632277461199, 0.6687892215180602, 0.6559503505607912, 0.6874234612740067, 0.6079018097909841, 0.5861623414940192, 0.6914749636121378, 0.6364062877705513, 0.6534462720674366, 0.09597323067579278, 0.14785879021593662, 0.09864828629366207, 0.12183336348357532, 0.1460514500438136, 0.11345018363019022, 0.14021621189692035, 0.09921160680518837, 0.11166986459500716, 0.21770344873674552, 0.21452233835860868, 0.16469110901655581, 0.6278575679213182, 0.6408027700122338, 0.20350897208355978, 0.22177277101156723, 0.1851871992488041, 0.15304476549713508, 0.4252514711165749, 0.4267291000769734, 0.5011243352326029, 0.5684434478162891, 0.5704511558401526, 0.4763925109243702, 0.5920156104525006, 0.6084262329629476, 0.535137584485935, 0.37440269272274995, 0.34786069158835975, 0.40456805403126017, 0.29791549514734084, 0.4532743349549003, 0.38166526621377683, 0.4638126541930607, 0.5021469052952147, 0.1573981980527719, 0.22304184146010253, 0.2579778616263678, 0.2538313482399881, 0.20550751922936727, 0.2123504497796006, 0.20222438196298265, 0.1834925948829762, 0.21995345328138494, 0.23127325026330603, 0.1989624191493088, 0.22013313066037477, 0.23566390169364004, 0.6670854074078215, 0.6578099057250177, 0.2374107721750759, 0.19528109163679996, 0.6649403232919174, 0.22487292650058188, 0.8421921270468344, 0.16408333417398513, 0.12438714137059725, 0.18333409758318442, 0.1999953463007874, 0.1971027768680702, 0.12250642953282453, 0.16951255865765613, 0.1517518628576734, 0.15369113070206875, 0.2104314437516568, 0.2049635128603583, 0.20239552985315612, 0.646474140587239, 0.20641086218659588, 0.10524795231646289, 0.8244684829329948, 0.8509807428874694, 0.1808796007034792, 0.19554371088945643, 0.19580107443611472, 0.2084375974187508, 0.18654477538921554, 0.19225639565683006, 0.1825456591040292, 0.19130862570317464, 0.19198566623907565, 0.08652879841408667, 0.1000114913064919, 0.09080831659864885, 0.08845194854316452, 0.09197767247258437, 0.08567002216548902, 0.08617389104748874, 0.10675799199350366, 0.07867951145954033]}, "mutation_prompt": null}
{"id": "a3b2f411-e93f-4e71-bfa8-e1243a58beef", "solution": "import numpy as np\n\nclass EnhancedPSO_DE_Elite:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.elite_archive_size = 5  # Elite archive capacity\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        elite_archive = []  # Archive for elite solutions\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def update_elite_archive(candidate, score):\n            if len(elite_archive) < self.elite_archive_size:\n                elite_archive.append((candidate, score))\n            else:\n                worst_score_index = max(range(len(elite_archive)), key=lambda i: elite_archive[i][1])\n                if score < elite_archive[worst_score_index][1]:\n                    elite_archive[worst_score_index] = (candidate, score)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n                update_elite_archive(swarm[i], score)\n\n            # PSO update with adaptive inertia and dynamic velocity clamping\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover using elite archive\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(len(elite_archive), 3, replace=False)\n                a, b, c = (elite_archive[idx][0] for idx in indices)\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                update_elite_archive(trial, trial_score)\n\n        return global_best_position", "name": "EnhancedPSO_DE_Elite", "description": "Enhanced PSO-DE hybrid using adaptive learning rates and an elite archive mechanism to improve convergence and robustness in diverse optimization landscapes.", "configspace": "", "generation": 67, "fitness": 0.2838421510938302, "feedback": "The algorithm EnhancedPSO_DE_Elite got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.26.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.8075986781904729, 0.848231253049649, 0.857537236320513, 0.15708103231263504, 0.8283460818225736, 0.8495669751752303, 0.849445994935377, 0.853178843738053, 0.8418451982096098, 0.5525876928836251, 9.999999999998899e-05, 0.06836692788099863, 0.6341323722931517, 0.6261626359771674, 0.6543973713100414, 0.5752100210849236, 0.7078008838432868, 0.04879794340614774, 0.12891291038587405, 0.12889142214929417, 0.16798778653553215, 0.16742444346666074, 0.6518820889662611, 0.6997980225653598, 0.6901129582488059, 0.67598409532723, 0.13799737877979712, 0.17519612034219612, 0.174946252884412, 0.18014162069334105, 0.6710562989562012, 0.5662107469332462, 0.1324685520780955, 0.12763462052101182, 0.15684690440811355, 0.07438246922612746, 0.9851095978962804, 0.9784313088048817, 0.9889598389724291, 0.9863371658004295, 0.9863298979740683, 0.9796515737198667, 0.9859821465557597, 0.990581293865378, 0.9899836285046643, 0.5998858338729758, 0.5410755502284952, 0.05986130594926731, 0.565513846836689, 0.5584934110004002, 0.6074742541192872, 0.12440821617241382, 0.08859867111060471, 0.08793570484383217, 0.16871828082259122, 0.13400219069983632, 0.22466717079074783, 0.19102916389298696, 0.19312129647331133, 0.1948820190371241, 0.237165011402811, 0.21878106736063518, 0.1682838070975533, 0.20144747860260914, 0.20121794491892464, 0.17736053345917824, 0.13629862860960895, 0.1986141275963329, 0.10131536976994415, 0.13207439332983306, 0.1345229438625114, 0.26872959926858464, 0.20428700041209147, 0.010124224430517637, 0.17346790136365164, 0.2183708297493312, 0.1845811427963363, 0.1818712292464164, 0.224302108248164, 0.12777829538341445, 0.22307760365020002, 0.00012526564463388734, 9.999999999998899e-05, 9.999999999998899e-05, 0.012010303376275955, 0.00696695803797176, 0.006683554243462786, 0.0392104891888474, 0.021340103904104346, 0.06733766473329361, 0.10991049405361697, 0.0354702062295954, 0.14329781557033494, 0.07764668240550998, 0.02736952099183476, 0.11750893848531996, 0.19962814925502326, 0.06255955335552221, 0.06542651908905683, 0.04045278686730158, 0.04228468738339031, 0.13788020234976062, 0.067658701461487, 0.06753210744318727, 0.06444955749844561, 0.0835250133587595, 0.16375134537835945, 0.06703825947767472, 0.1269649573855124, 0.10529081217283365, 0.1169620418105749, 0.1099509879181525, 0.13034037476895066, 0.06670459010462437, 0.11038756244238679, 0.08959238696887728, 0.078496865896591, 0.4755850693860755, 0.47184907263533005, 0.4866301263974868, 0.5061441848145549, 0.5244845181372791, 0.5088641328630013, 0.5034136122137715, 0.4954444666458391, 0.4798015498907061, 0.07267697919328708, 0.11383063277161853, 0.09779272745000489, 0.11897650636037782, 0.14893077171981384, 0.11272232926018766, 0.13042378844680225, 0.12576289458354373, 0.08808472226979303, 0.18329402236714742, 0.1672256930685324, 0.18949654991507836, 0.19140715502185268, 0.23606406663496837, 0.3369335612925488, 0.2006135012325112, 0.18592447168209336, 0.1827644332673607, 0.41490659313125866, 0.3069715260902208, 0.2220745103690901, 0.23564518014878, 0.26389390795673395, 0.26882841468848606, 0.37818880760359097, 0.3413129055718187, 0.33804394996543574, 0.20392078720939177, 0.18187414168030358, 0.1527138429489704, 0.23079192666237502, 0.18682964593939988, 0.18145498995902432, 0.17638619883488604, 0.2924591573310882, 0.2371780342276908, 0.21628514897608564, 0.19469483589856051, 0.2006451822425792, 0.255366912304849, 0.19330322663666244, 0.26676696316139836, 0.18118142031512463, 0.20038425547368577, 0.23063058893187705, 0.2179971296394111, 0.21326059937521846, 0.19164757868122306, 0.1849968870461346, 0.19962322618743722, 0.22732721803467948, 0.6938401494839825, 0.19309586502260023, 0.17822100694899567, 0.8314189190644595, 0.16987923009758032, 0.1481220940110337, 0.8141448849019047, 0.2015688046622255, 0.16219523628871502, 0.8081070142886899, 0.16994048108077386, 0.1630215908852588, 0.5118944297925855, 0.21134334511230968, 0.12476817684176167, 0.5080301846485289, 0.16738938537550951, 0.2097942976717938, 0.10515588792939523, 0.5716066582979358, 0.5825986978507753, 0.22291741964944978, 0.18036509048559768, 0.19856146467786762, 0.19059793580963857, 0.18571008092271335, 0.19441635559293313, 0.18913842758350585, 0.2391953768906473, 0.2519267046908016, 0.07922860509300533, 0.09036334425277548, 0.10040981670118942, 0.08605146872206637, 0.09577722137896993, 0.06142960377755935, 0.07418504505933743, 0.0827675500060524, 0.07307764931610239]}, "mutation_prompt": null}
{"id": "2a0e1c1d-4648-48bb-b70c-ea28631143a1", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445  # Cognitive component\n        self.c2 = 1.49445  # Social component\n        self.w_start = 0.9  # Start inertia weight\n        self.w_end = 0.4    # End inertia weight\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.restart_threshold = 0.1  # Restart threshold for stagnation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        # Initialize swarm\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n        previous_best_score = global_best_score\n\n        # Neighborhood influence\n        neighborhood_size = max(1, self.population_size // 5)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n\n            # Evaluate current swarm\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            # Adaptive inertia and dynamic velocity clamping with neighborhood influence\n            for i in range(self.population_size):\n                neighborhood_indices = np.random.choice(self.population_size, neighborhood_size, replace=False)\n                local_best = min(neighborhood_indices, key=lambda idx: personal_best_scores[idx])\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (personal_best_positions[local_best] - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            # DE-inspired mutation and crossover\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n            # Check for stagnation and restart if necessary\n            if global_best_score < previous_best_score:\n                previous_best_score = global_best_score\n            elif self.num_evals / self.budget > self.restart_threshold:\n                swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n                velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n                personal_best_positions = np.copy(swarm)\n                personal_best_scores = np.full(self.population_size, np.inf)\n                global_best_position = None\n                global_best_score = np.inf\n                previous_best_score = np.inf\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "An enhanced PSO-DE hybrid with adaptive learning rates, neighborhood influence, and stochastic restarts to improve convergence and robustness.", "configspace": "", "generation": 68, "fitness": 0.17083844586207417, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.19.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.30809065727004326, 0.3019300162714956, 0.3132191708921054, 0.28627741398695594, 0.36190439029617805, 0.3127928046316526, 0.2888384235412679, 0.3207189684973034, 0.3334617120174028, 0.0436414310762695, 0.010248686046304245, 0.012012343056907238, 0.04381165732436876, 0.035962120676621856, 0.02082062118617889, 9.999999999998899e-05, 0.06185815512812276, 9.999999999998899e-05, 0.07920404547791782, 0.06578112755339538, 0.07434550327810796, 0.06731397443659459, 0.06810364253327184, 0.07642557076786871, 0.07948997924972412, 0.06648920362656208, 0.07594309550764189, 0.06536254770076344, 0.06547929694242649, 0.06478685855315902, 0.06440630249024393, 0.053699161960442665, 0.04724683797900875, 0.05826315222117262, 0.04423304341889234, 0.0603280547833811, 0.984721352388245, 0.9863519496361648, 0.9846088627755516, 0.9798830577471217, 0.9801777450887244, 0.9804613247753875, 0.9841125590090527, 0.9844206274443942, 0.9747381936539684, 0.1746978239159791, 0.1415083951888304, 0.15138228446444757, 0.1294980382225569, 0.17249569163931866, 0.1940513349858919, 0.14578341782368465, 0.11277015209528563, 0.1667859830977535, 0.20815992559799257, 0.21653517660691035, 0.22834584248935275, 0.197314853884607, 0.20704576184404977, 0.2261160206568984, 0.23817069726036555, 0.22871908940936958, 0.23860327651980218, 0.0672565762237275, 0.10393400564645039, 0.1154001203516355, 0.09715837705190822, 0.10006641186519971, 0.1094689907845039, 0.09867233171422085, 0.10470814755103552, 0.11062967761490106, 0.09348345159701998, 0.11516853197990162, 0.07818586327846366, 0.08340090054575289, 0.06644068190889052, 0.09939362631181647, 0.13108499539896168, 0.11158556666636577, 0.050561487812539996, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10066428650117665, 0.07881320075149945, 0.09521165492012529, 0.10085556005875096, 0.13715171871692744, 0.05530200589159717, 0.10225992769303571, 0.10818010352485685, 0.1014310991183931, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028242067977232943, 0.03378382453381468, 0.042185121595193276, 0.011542625752112512, 0.07418884999922015, 0.0344949544769001, 0.03481799990007217, 0.050317363700262296, 0.03247589547930152, 0.30414332499409846, 0.300695710084943, 0.2933243691160846, 0.29828126366925567, 0.33072741858373866, 0.3463632808156616, 0.29021781038694483, 0.2774943388114117, 0.2895086269647813, 0.06389486951015111, 0.07460265195358406, 0.09239263438915535, 0.08255465250180627, 0.06969572477718322, 0.07674733634812725, 0.06608860401787475, 0.07574237121144778, 0.08455074074803437, 0.1277797265232452, 0.12979963754013135, 0.15078116309199086, 0.133098939768038, 0.14170949104943809, 0.13348334482556345, 0.129017107109756, 0.147128642665053, 0.1348937132313769, 0.2524770364010872, 0.19578585807091597, 0.21336064234862973, 0.2123472591420481, 0.2113932808176754, 0.2497618637079323, 0.21068460885782392, 0.24495614820027445, 0.23884408109459287, 0.15736048094830457, 0.1646939812575764, 0.19434069047917624, 0.1595026456954156, 0.15747223358782536, 0.16442705789022494, 0.1363665096885157, 0.1795773585509467, 0.1620032003521401, 0.17538153024918013, 0.21614239546141667, 0.18629524993152013, 0.18773116553397318, 0.19267475224372188, 0.1811213274789485, 0.19412053054377532, 0.18829056131165545, 0.17147988736528497, 0.1680007008205594, 0.191659039798184, 0.15956437210611274, 0.16546478368264883, 0.16792321850032876, 0.17262957384811795, 0.16578400391531467, 0.1694139880919302, 0.17846935795897756, 0.22168778320821958, 0.18220172230966636, 0.1949321906636461, 0.1953242287792576, 0.20037230712320375, 0.2230244653915492, 0.30191496343863466, 0.20533506520346856, 0.21119742640327144, 0.28063616302340855, 0.20057468343162066, 0.26885426384975186, 0.16913651755006054, 0.18938751081666239, 0.19626931448704732, 0.20759227150552928, 0.2740660402026519, 0.18429056144882838, 0.17386520277220785, 0.1885024674158693, 0.17712728014801438, 0.18757299139475014, 0.17482448083546076, 0.1869799590560728, 0.17881222703623534, 0.1775135926614113, 0.18145532229689743, 0.06339307711225262, 0.06486183022491043, 0.06237575753826019, 0.06111709553192157, 0.05843010606795851, 0.06772603513805575, 0.06653746973673058, 0.06890962431219683, 0.061616023975471945]}, "mutation_prompt": null}
{"id": "b0899110-29ee-441a-ad2d-6c040148af99", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive local search integrates stochastic local search during the exploitation phase to fine-tune solutions, improving convergence.", "configspace": "", "generation": 69, "fitness": 0.38729304767463985, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.25.", "error": "", "parent_id": "c8599c66-1495-4311-be5c-d9385ee66b3b", "metadata": {"aucs": [0.7484446623911813, 0.7641959616134506, 0.7454935917560436, 0.7739165448992121, 0.7503369513780392, 0.7850689451818347, 0.7441573421917299, 0.757048975842525, 0.7560956547381288, 0.5511217848626917, 0.5534940920845292, 0.5898154743946036, 0.5833014660834138, 0.5864772087377433, 0.6032773373992211, 0.5879284436963637, 0.5852356364220255, 0.5413456665976439, 0.15595470356938457, 0.38611731172949826, 0.14940958434307283, 0.15232885840101662, 0.13809870666113855, 0.15517969717517477, 0.11413971844586901, 0.12245078328049219, 0.14688284767351745, 0.1284512986202797, 0.11876364137337736, 0.11241333395694963, 0.12155039247607347, 0.12681657239112176, 0.12347843940326964, 0.11814245563904291, 0.11475437406818367, 0.1184604231894184, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.574987503643695, 0.36236539684146163, 0.5598280834848447, 0.5333306681833292, 0.5869161621356457, 0.41290135386328375, 0.5647969674564006, 0.5319182427638542, 0.5514831017421311, 0.35166821444125373, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.37616349355184775, 0.44573216332895094, 0.4256645392915912, 0.3755234518841395, 0.12712513770038336, 0.43919414519682776, 0.5323062714079179, 0.4564353894288965, 0.38483607581573354, 0.45654425797354603, 0.24102894690104082, 0.36877841016580637, 0.41202143560433946, 0.4011731964025135, 0.4094292308859071, 0.42515834039424294, 0.12787378640385905, 0.46751618513433024, 0.43931190266616005, 0.11907677004713513, 0.08462963710927363, 0.10296864385537685, 0.5018343580168942, 0.15752583221647598, 0.2043281620453602, 0.4265246341056622, 0.5070397195068126, 0.5550423913750391, 0.15433929385789724, 0.547887014935069, 0.2904022538128461, 0.5022872083750254, 0.25867005411518773, 0.6346643410274144, 0.23639098918948276, 0.5746054984985068, 0.11407980325712597, 0.04520801581034428, 0.0637175041077277, 0.12610842237279962, 0.19267263458538297, 0.26581780370465025, 0.1180591471567537, 0.13238964399108843, 0.13394321409626064, 0.2140676787240372, 0.3048848251704821, 0.3284412347909531, 0.3122908060609827, 0.24029939711003045, 0.29903786809230903, 0.2596462561830435, 0.29887689146203344, 0.20502659201201345, 0.692710933271237, 0.6889920786532941, 0.7101782607910303, 0.6167715725016916, 0.7118263741862114, 0.6591818280749686, 0.6486542541631908, 0.6098766279644814, 0.7108677174038628, 0.08459038225516557, 0.13828841609983644, 0.14089102894867866, 0.10558472212882664, 0.11718958330084828, 0.14205872277450726, 0.11595882493925858, 0.10462779878594208, 0.10027945708054753, 0.21082042329980788, 0.27019449220850855, 0.38780460015415397, 0.21790625764118454, 0.28452531124307456, 0.25447609519107595, 0.22186303474475855, 0.24238543877722207, 0.28227957674727255, 0.42110039637806407, 0.41295421612730265, 0.4348135635977971, 0.4285312717439306, 0.4335960432743873, 0.45737053765074265, 0.4670316987401285, 0.44955115252738787, 0.38956101714044566, 0.35307153811666725, 0.39733578395434, 0.31894459241213546, 0.2848809272189028, 0.19857500046836696, 0.3576677084428712, 0.38640134423118533, 0.3510280292107191, 0.3708795456214532, 0.20609929467634824, 0.19840129074252044, 0.18733417557415732, 0.21420735571712923, 0.20120315219167018, 0.21499467144149997, 0.2261047341666974, 0.19106703129556868, 0.22774327812644335, 0.19431687177135393, 0.5081442142304832, 0.5418807545956155, 0.22045106948895932, 0.23577356850188258, 0.48331630547375315, 0.4295719154123203, 0.21722885110021173, 0.22561090549837426, 0.84120936818493, 0.8246052515524153, 0.15365907878832352, 0.7584287726700076, 0.19773207571633888, 0.19473572510129877, 0.7474784313729328, 0.1699188842761722, 0.8136283511053167, 0.728069673372769, 0.16900123142277734, 0.796306663016825, 0.20612552074207746, 0.7512316653275415, 0.20919714311183368, 0.20312448297505548, 0.21134618292626584, 0.21235430771612906, 0.18744115569601416, 0.18416953756248333, 0.20322798131072473, 0.19195054504461473, 0.18110442905772872, 0.1989409021320092, 0.18592104279289523, 0.26051659353653156, 0.180219359644603, 0.08250401841628008, 0.08472686814662556, 0.07313885569068002, 0.08491506339076893, 0.08164601453501641, 0.07388060604354973, 0.09546596892887449, 0.09662588323739296, 0.08577158806399288]}, "mutation_prompt": null}
{"id": "9a58364a-4d21-47d3-a5c0-14d09f96358d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive local search integrates stochastic local search during the exploitation phase to fine-tune solutions, improving convergence.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7484446623911813, 0.7641959616134506, 0.7454935917560436, 0.7739165448992121, 0.7503369513780392, 0.7850689451818347, 0.7441573421917299, 0.757048975842525, 0.7560956547381288, 0.5511217848626917, 0.5534940920845292, 0.5898154743946036, 0.5833014660834138, 0.5864772087377433, 0.6032773373992211, 0.5879284436963637, 0.5852356364220255, 0.5413456665976439, 0.15595470356938457, 0.38611731172949826, 0.14940958434307283, 0.15232885840101662, 0.13809870666113855, 0.15517969717517477, 0.11413971844586901, 0.12245078328049219, 0.14688284767351745, 0.1284512986202797, 0.11876364137337736, 0.11241333395694963, 0.12155039247607347, 0.12681657239112176, 0.12347843940326964, 0.11814245563904291, 0.11475437406818367, 0.1184604231894184, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.574987503643695, 0.36236539684146163, 0.5598280834848447, 0.5333306681833292, 0.5869161621356457, 0.41290135386328375, 0.5647969674564006, 0.5319182427638542, 0.5514831017421311, 0.35166821444125373, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.37616349355184775, 0.44573216332895094, 0.4256645392915912, 0.3755234518841395, 0.12712513770038336, 0.43919414519682776, 0.5323062714079179, 0.4564353894288965, 0.38483607581573354, 0.45654425797354603, 0.24102894690104082, 0.36877841016580637, 0.41202143560433946, 0.4011731964025135, 0.4094292308859071, 0.42515834039424294, 0.12787378640385905, 0.46751618513433024, 0.43931190266616005, 0.11907677004713513, 0.08462963710927363, 0.10296864385537685, 0.5018343580168942, 0.15752583221647598, 0.2043281620453602, 0.4265246341056622, 0.5070397195068126, 0.5550423913750391, 0.15433929385789724, 0.547887014935069, 0.2904022538128461, 0.5022872083750254, 0.25867005411518773, 0.6346643410274144, 0.23639098918948276, 0.5746054984985068, 0.11407980325712597, 0.04520801581034428, 0.0637175041077277, 0.12610842237279962, 0.19267263458538297, 0.26581780370465025, 0.1180591471567537, 0.13238964399108843, 0.13394321409626064, 0.2140676787240372, 0.3048848251704821, 0.3284412347909531, 0.3122908060609827, 0.24029939711003045, 0.29903786809230903, 0.2596462561830435, 0.29887689146203344, 0.20502659201201345, 0.692710933271237, 0.6889920786532941, 0.7101782607910303, 0.6167715725016916, 0.7118263741862114, 0.6591818280749686, 0.6486542541631908, 0.6098766279644814, 0.7108677174038628, 0.08459038225516557, 0.13828841609983644, 0.14089102894867866, 0.10558472212882664, 0.11718958330084828, 0.14205872277450726, 0.11595882493925858, 0.10462779878594208, 0.10027945708054753, 0.21082042329980788, 0.27019449220850855, 0.38780460015415397, 0.21790625764118454, 0.28452531124307456, 0.25447609519107595, 0.22186303474475855, 0.24238543877722207, 0.28227957674727255, 0.42110039637806407, 0.41295421612730265, 0.4348135635977971, 0.4285312717439306, 0.4335960432743873, 0.45737053765074265, 0.4670316987401285, 0.44955115252738787, 0.38956101714044566, 0.35307153811666725, 0.39733578395434, 0.31894459241213546, 0.2848809272189028, 0.19857500046836696, 0.3576677084428712, 0.38640134423118533, 0.3510280292107191, 0.3708795456214532, 0.20609929467634824, 0.19840129074252044, 0.18733417557415732, 0.21420735571712923, 0.20120315219167018, 0.21499467144149997, 0.2261047341666974, 0.19106703129556868, 0.22774327812644335, 0.19431687177135393, 0.5081442142304832, 0.5418807545956155, 0.22045106948895932, 0.23577356850188258, 0.48331630547375315, 0.4295719154123203, 0.21722885110021173, 0.22561090549837426, 0.84120936818493, 0.8246052515524153, 0.15365907878832352, 0.7584287726700076, 0.19773207571633888, 0.19473572510129877, 0.7474784313729328, 0.1699188842761722, 0.8136283511053167, 0.728069673372769, 0.16900123142277734, 0.796306663016825, 0.20612552074207746, 0.7512316653275415, 0.20919714311183368, 0.20312448297505548, 0.21134618292626584, 0.21235430771612906, 0.18744115569601416, 0.18416953756248333, 0.20322798131072473, 0.19195054504461473, 0.18110442905772872, 0.1989409021320092, 0.18592104279289523, 0.26051659353653156, 0.180219359644603, 0.08250401841628008, 0.08472686814662556, 0.07313885569068002, 0.08491506339076893, 0.08164601453501641, 0.07388060604354973, 0.09546596892887449, 0.09662588323739296, 0.08577158806399288]}, "mutation_prompt": null}
{"id": "8e8e2690-f55e-41c3-b3d1-a3aa629377e8", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive local search integrates stochastic local search during the exploitation phase to fine-tune solutions, improving convergence.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7484446623911813, 0.7641959616134506, 0.7454935917560436, 0.7739165448992121, 0.7503369513780392, 0.7850689451818347, 0.7441573421917299, 0.757048975842525, 0.7560956547381288, 0.5511217848626917, 0.5534940920845292, 0.5898154743946036, 0.5833014660834138, 0.5864772087377433, 0.6032773373992211, 0.5879284436963637, 0.5852356364220255, 0.5413456665976439, 0.15595470356938457, 0.38611731172949826, 0.14940958434307283, 0.15232885840101662, 0.13809870666113855, 0.15517969717517477, 0.11413971844586901, 0.12245078328049219, 0.14688284767351745, 0.1284512986202797, 0.11876364137337736, 0.11241333395694963, 0.12155039247607347, 0.12681657239112176, 0.12347843940326964, 0.11814245563904291, 0.11475437406818367, 0.1184604231894184, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.574987503643695, 0.36236539684146163, 0.5598280834848447, 0.5333306681833292, 0.5869161621356457, 0.41290135386328375, 0.5647969674564006, 0.5319182427638542, 0.5514831017421311, 0.35166821444125373, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.37616349355184775, 0.44573216332895094, 0.4256645392915912, 0.3755234518841395, 0.12712513770038336, 0.43919414519682776, 0.5323062714079179, 0.4564353894288965, 0.38483607581573354, 0.45654425797354603, 0.24102894690104082, 0.36877841016580637, 0.41202143560433946, 0.4011731964025135, 0.4094292308859071, 0.42515834039424294, 0.12787378640385905, 0.46751618513433024, 0.43931190266616005, 0.11907677004713513, 0.08462963710927363, 0.10296864385537685, 0.5018343580168942, 0.15752583221647598, 0.2043281620453602, 0.4265246341056622, 0.5070397195068126, 0.5550423913750391, 0.15433929385789724, 0.547887014935069, 0.2904022538128461, 0.5022872083750254, 0.25867005411518773, 0.6346643410274144, 0.23639098918948276, 0.5746054984985068, 0.11407980325712597, 0.04520801581034428, 0.0637175041077277, 0.12610842237279962, 0.19267263458538297, 0.26581780370465025, 0.1180591471567537, 0.13238964399108843, 0.13394321409626064, 0.2140676787240372, 0.3048848251704821, 0.3284412347909531, 0.3122908060609827, 0.24029939711003045, 0.29903786809230903, 0.2596462561830435, 0.29887689146203344, 0.20502659201201345, 0.692710933271237, 0.6889920786532941, 0.7101782607910303, 0.6167715725016916, 0.7118263741862114, 0.6591818280749686, 0.6486542541631908, 0.6098766279644814, 0.7108677174038628, 0.08459038225516557, 0.13828841609983644, 0.14089102894867866, 0.10558472212882664, 0.11718958330084828, 0.14205872277450726, 0.11595882493925858, 0.10462779878594208, 0.10027945708054753, 0.21082042329980788, 0.27019449220850855, 0.38780460015415397, 0.21790625764118454, 0.28452531124307456, 0.25447609519107595, 0.22186303474475855, 0.24238543877722207, 0.28227957674727255, 0.42110039637806407, 0.41295421612730265, 0.4348135635977971, 0.4285312717439306, 0.4335960432743873, 0.45737053765074265, 0.4670316987401285, 0.44955115252738787, 0.38956101714044566, 0.35307153811666725, 0.39733578395434, 0.31894459241213546, 0.2848809272189028, 0.19857500046836696, 0.3576677084428712, 0.38640134423118533, 0.3510280292107191, 0.3708795456214532, 0.20609929467634824, 0.19840129074252044, 0.18733417557415732, 0.21420735571712923, 0.20120315219167018, 0.21499467144149997, 0.2261047341666974, 0.19106703129556868, 0.22774327812644335, 0.19431687177135393, 0.5081442142304832, 0.5418807545956155, 0.22045106948895932, 0.23577356850188258, 0.48331630547375315, 0.4295719154123203, 0.21722885110021173, 0.22561090549837426, 0.84120936818493, 0.8246052515524153, 0.15365907878832352, 0.7584287726700076, 0.19773207571633888, 0.19473572510129877, 0.7474784313729328, 0.1699188842761722, 0.8136283511053167, 0.728069673372769, 0.16900123142277734, 0.796306663016825, 0.20612552074207746, 0.7512316653275415, 0.20919714311183368, 0.20312448297505548, 0.21134618292626584, 0.21235430771612906, 0.18744115569601416, 0.18416953756248333, 0.20322798131072473, 0.19195054504461473, 0.18110442905772872, 0.1989409021320092, 0.18592104279289523, 0.26051659353653156, 0.180219359644603, 0.08250401841628008, 0.08472686814662556, 0.07313885569068002, 0.08491506339076893, 0.08164601453501641, 0.07388060604354973, 0.09546596892887449, 0.09662588323739296, 0.08577158806399288]}, "mutation_prompt": null}
{"id": "5d1c2b2a-a008-4fe5-8e5d-14df36455155", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive local search integrates stochastic local search during the exploitation phase to fine-tune solutions, improving convergence.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7484446623911813, 0.7641959616134506, 0.7454935917560436, 0.7739165448992121, 0.7503369513780392, 0.7850689451818347, 0.7441573421917299, 0.757048975842525, 0.7560956547381288, 0.5511217848626917, 0.5534940920845292, 0.5898154743946036, 0.5833014660834138, 0.5864772087377433, 0.6032773373992211, 0.5879284436963637, 0.5852356364220255, 0.5413456665976439, 0.15595470356938457, 0.38611731172949826, 0.14940958434307283, 0.15232885840101662, 0.13809870666113855, 0.15517969717517477, 0.11413971844586901, 0.12245078328049219, 0.14688284767351745, 0.1284512986202797, 0.11876364137337736, 0.11241333395694963, 0.12155039247607347, 0.12681657239112176, 0.12347843940326964, 0.11814245563904291, 0.11475437406818367, 0.1184604231894184, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.574987503643695, 0.36236539684146163, 0.5598280834848447, 0.5333306681833292, 0.5869161621356457, 0.41290135386328375, 0.5647969674564006, 0.5319182427638542, 0.5514831017421311, 0.35166821444125373, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.37616349355184775, 0.44573216332895094, 0.4256645392915912, 0.3755234518841395, 0.12712513770038336, 0.43919414519682776, 0.5323062714079179, 0.4564353894288965, 0.38483607581573354, 0.45654425797354603, 0.24102894690104082, 0.36877841016580637, 0.41202143560433946, 0.4011731964025135, 0.4094292308859071, 0.42515834039424294, 0.12787378640385905, 0.46751618513433024, 0.43931190266616005, 0.11907677004713513, 0.08462963710927363, 0.10296864385537685, 0.5018343580168942, 0.15752583221647598, 0.2043281620453602, 0.4265246341056622, 0.5070397195068126, 0.5550423913750391, 0.15433929385789724, 0.547887014935069, 0.2904022538128461, 0.5022872083750254, 0.25867005411518773, 0.6346643410274144, 0.23639098918948276, 0.5746054984985068, 0.11407980325712597, 0.04520801581034428, 0.0637175041077277, 0.12610842237279962, 0.19267263458538297, 0.26581780370465025, 0.1180591471567537, 0.13238964399108843, 0.13394321409626064, 0.2140676787240372, 0.3048848251704821, 0.3284412347909531, 0.3122908060609827, 0.24029939711003045, 0.29903786809230903, 0.2596462561830435, 0.29887689146203344, 0.20502659201201345, 0.692710933271237, 0.6889920786532941, 0.7101782607910303, 0.6167715725016916, 0.7118263741862114, 0.6591818280749686, 0.6486542541631908, 0.6098766279644814, 0.7108677174038628, 0.08459038225516557, 0.13828841609983644, 0.14089102894867866, 0.10558472212882664, 0.11718958330084828, 0.14205872277450726, 0.11595882493925858, 0.10462779878594208, 0.10027945708054753, 0.21082042329980788, 0.27019449220850855, 0.38780460015415397, 0.21790625764118454, 0.28452531124307456, 0.25447609519107595, 0.22186303474475855, 0.24238543877722207, 0.28227957674727255, 0.42110039637806407, 0.41295421612730265, 0.4348135635977971, 0.4285312717439306, 0.4335960432743873, 0.45737053765074265, 0.4670316987401285, 0.44955115252738787, 0.38956101714044566, 0.35307153811666725, 0.39733578395434, 0.31894459241213546, 0.2848809272189028, 0.19857500046836696, 0.3576677084428712, 0.38640134423118533, 0.3510280292107191, 0.3708795456214532, 0.20609929467634824, 0.19840129074252044, 0.18733417557415732, 0.21420735571712923, 0.20120315219167018, 0.21499467144149997, 0.2261047341666974, 0.19106703129556868, 0.22774327812644335, 0.19431687177135393, 0.5081442142304832, 0.5418807545956155, 0.22045106948895932, 0.23577356850188258, 0.48331630547375315, 0.4295719154123203, 0.21722885110021173, 0.22561090549837426, 0.84120936818493, 0.8246052515524153, 0.15365907878832352, 0.7584287726700076, 0.19773207571633888, 0.19473572510129877, 0.7474784313729328, 0.1699188842761722, 0.8136283511053167, 0.728069673372769, 0.16900123142277734, 0.796306663016825, 0.20612552074207746, 0.7512316653275415, 0.20919714311183368, 0.20312448297505548, 0.21134618292626584, 0.21235430771612906, 0.18744115569601416, 0.18416953756248333, 0.20322798131072473, 0.19195054504461473, 0.18110442905772872, 0.1989409021320092, 0.18592104279289523, 0.26051659353653156, 0.180219359644603, 0.08250401841628008, 0.08472686814662556, 0.07313885569068002, 0.08491506339076893, 0.08164601453501641, 0.07388060604354973, 0.09546596892887449, 0.09662588323739296, 0.08577158806399288]}, "mutation_prompt": null}
{"id": "d41fffaa-a791-4a99-b798-f9725d53e9a3", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_base = 0.5\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2\n        self.diversity_factor = 0.1  # New parameter for diversity-based mutation adjustment\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            population_mean = np.mean(swarm, axis=0)\n            population_std = np.std(swarm, axis=0)\n            diversity = np.mean(population_std)\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                F_dynamic = self.F_base * (1 + self.diversity_factor * diversity)\n                mutant = a + F_dynamic * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1 * (1 - progress), self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE_V2", "description": "Hybrid PSO-DE with adaptive mutation intensity enhances exploration-exploitation balance by dynamically adjusting mutation strength based on population diversity and convergence rate.", "configspace": "", "generation": 73, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'progress' is not defined\").", "error": "NameError(\"name 'progress' is not defined\")", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {}, "mutation_prompt": null}
{"id": "6eae2a41-a942-45c3-bbe3-b4788d57bc9d", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE_V2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.initial_local_search_prob = 0.1\n        self.final_local_search_prob = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.initial_local_search_prob + progress * (self.final_local_search_prob - self.initial_local_search_prob)\n            return w, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with dynamic probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE_V2", "description": "Hybrid algorithm combining adaptive PSO with DE and dynamic local search frequency for better exploration-exploitation balance.", "configspace": "", "generation": 74, "fitness": 0.38085029744921983, "feedback": "The algorithm EnhancedHybridPSO_DE_V2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.25.", "error": "", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7504915357964523, 0.7638491305343792, 0.7462562248309981, 0.7747400098319629, 0.7507267949414103, 0.7853065003156985, 0.7460871774184951, 0.7570651502492475, 0.7557863376037139, 0.5509094400987018, 0.5598718743150439, 0.5876162667391167, 0.5793964771190909, 0.5898884804081568, 0.6011437673333071, 0.582141684933938, 0.5833227356754882, 0.5441196984401835, 0.1559893996599896, 0.1538361685194568, 0.15026558261220657, 0.1523449180132962, 0.15150103888008193, 0.15511612652336138, 0.10950089642368088, 0.12245991118150579, 0.14713219350298112, 0.12693533483813024, 0.11851692749630527, 0.11211273426452939, 0.12166197753790275, 0.12634118782805304, 0.13578732759224044, 0.11139019679327777, 0.11475934064967319, 0.11840298660041682, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.580075441330997, 0.3072173927442481, 0.5445501474280274, 0.5171333815187793, 0.5763986949630517, 0.3559949088970997, 0.5681410779280754, 0.530568884763992, 0.5444901338926385, 0.22706765206810653, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.39719145587529414, 0.4032955110210745, 0.3856336439418494, 0.3881933423502667, 0.12712512949603372, 0.35018337106377007, 0.5147655472613508, 0.4268213868516072, 0.4288516637252189, 0.37917892799738584, 0.24863519756220298, 0.3414779256442311, 0.32904878915698943, 0.3732931660454655, 0.43069418127197545, 0.3875405044793754, 0.12787378706691122, 0.44167013175682057, 0.3845334493516195, 0.13504511520356954, 0.08462928670213787, 0.12192571956615683, 0.44133788831482046, 0.13730897818956778, 0.13297339146047293, 0.40887056038671055, 0.4788780251758695, 0.5282511702828644, 0.1574355041320321, 0.5805426251706107, 0.36709579234103973, 0.44810918471647354, 0.33461929769653, 0.6401209643436708, 0.3580254203148414, 0.4394165357165052, 0.10803636418621065, 0.03861775447901039, 0.06648437185692324, 0.11186036216981099, 0.2684548647889534, 0.24262556452326667, 0.11608557879909986, 0.12630843981538198, 0.11617837168795997, 0.22234564399375578, 0.31867796062482534, 0.2825937272858412, 0.3147370688668554, 0.21481702840376315, 0.23505910599419233, 0.29118971996769594, 0.2624507005824428, 0.258072867067912, 0.6415423478196489, 0.6714441145862136, 0.7084310355329431, 0.626968929342931, 0.6701870991178275, 0.6572054776623102, 0.6387679779643871, 0.5991389633291189, 0.6794164286134947, 0.08460907426686204, 0.1368926948699667, 0.14091175886181606, 0.10597259829519134, 0.1203357230755604, 0.12296261021807764, 0.11726270777530845, 0.10462050187691352, 0.10007905630669844, 0.226269031044793, 0.26798054853865694, 0.26069640993374577, 0.21899297247081118, 0.317466955019036, 0.2505446681488208, 0.22093868329425048, 0.24267340090943013, 0.288543146072338, 0.4474410635892938, 0.3986529948707267, 0.43290471368951333, 0.4125695390658157, 0.38501519636424963, 0.4572518818446497, 0.45551683391732223, 0.46101044935344704, 0.46252829410681784, 0.35614628971190476, 0.36394425044126144, 0.2844614772986881, 0.30961027886992387, 0.19832813972964036, 0.3273148263075919, 0.3775421509276472, 0.38505408054357027, 0.3938786057337197, 0.19997756624241547, 0.1998901619193879, 0.18194675043757802, 0.2131557326433784, 0.21344833353010972, 0.23049360321599477, 0.21530954354461396, 0.18551280912301027, 0.2277432775939382, 0.19438709879662652, 0.5188063029998022, 0.5268835301086323, 0.22057202198157844, 0.23577352338574464, 0.46623119849666583, 0.39992606648380824, 0.2171759465196419, 0.22562910205009112, 0.84120936818493, 0.8246052515524153, 0.15365907878836316, 0.7584287726700076, 0.19773207527137915, 0.1947357257820722, 0.7474784313729328, 0.16991888427723767, 0.8136283511053167, 0.728069673372769, 0.16900123145802914, 0.796306663016825, 0.20612552156022257, 0.7512316653275415, 0.209197148844118, 0.20323975734717337, 0.21134618292310747, 0.21235430766495988, 0.18709049224863206, 0.1840978127645927, 0.2031357094365258, 0.1919434196656703, 0.1849281086943111, 0.19891400367131062, 0.18270177670656973, 0.21574787797223338, 0.17900200173006142, 0.08360461313327816, 0.08483961787189986, 0.0787439739092799, 0.08480442456842774, 0.08406725133043436, 0.0862253047953474, 0.09421590695033177, 0.10040343801927065, 0.08593658011195782]}, "mutation_prompt": null}
{"id": "0ce8a186-8081-4921-991a-29fe604abc7c", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2\n        self.landscape_info = {'gradient': 0.0, 'diversity': 0.0}\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def update_landscape_info():\n            self.landscape_info['gradient'] = np.mean(np.abs(np.gradient(personal_best_scores)))\n            self.landscape_info['diversity'] = np.mean(np.linalg.norm(swarm - np.mean(swarm, axis=0), axis=1))\n\n        def switch_phase():\n            return self.landscape_info['gradient'] > 1e-3 and self.landscape_info['diversity'] > 1e-3\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase()\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            update_landscape_info()\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with self-adaptive parameter tuning incorporates real-time parameter adjustment based on landscape analysis to improve convergence.", "configspace": "", "generation": 75, "fitness": 0.37982010474035366, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.25.", "error": "", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7665566386584354, 0.7919956889992281, 0.7638550905584737, 0.7953377300182489, 0.7960416955906011, 0.7890020496231043, 0.7820441073238131, 0.7967064100553295, 0.8011392735589269, 0.6211673487428784, 0.6308194061114785, 0.570551516062377, 0.5774174042037075, 0.6002064011432441, 0.5837779876652855, 0.5767334590880626, 0.5850482607706424, 0.5927202130700383, 0.12279842814615038, 0.13832861491465032, 0.41263777721508854, 0.13249110386425889, 0.12587854321147462, 0.12946942200277356, 0.1293431277782714, 0.13131643950771543, 0.14225280094912485, 0.1174884670298405, 0.1351070130300328, 0.115253800092176, 0.12609683784827752, 0.14239858058505506, 0.11091570615774105, 0.12954623736633675, 0.11541689396214894, 0.10451717293007223, 0.9873244908362697, 0.9829959417370899, 0.9883887480116468, 0.9876093078246226, 0.9889791833434818, 0.988829239688828, 0.9882770788353491, 0.9865222299318738, 0.9826323648963718, 0.5464758570013188, 0.5168577269584018, 0.582832454287642, 0.54468085834372, 0.5752627976001274, 0.603113471435783, 0.5498790577046171, 0.5027267968221749, 0.46929146907900454, 0.22103936994558493, 0.7110543265299194, 0.7958662813132127, 0.7464698554771313, 0.21857355352557717, 0.7531939420923376, 0.7265785375888951, 0.7127439499195952, 0.8226650460713714, 0.11100020613260952, 0.5622650096935707, 0.5175644458437758, 0.126763360999808, 0.41762182288764726, 0.29177942265832857, 0.40825852114915384, 0.36301781473200645, 0.41138950683816766, 0.4577858561078527, 0.46154269614804566, 0.40882208675217746, 0.3230866990126732, 0.29474774294428563, 0.3918629574071061, 0.315199485468566, 0.4089913332883256, 0.45492454989109865, 0.2590491979809928, 0.1987362616774313, 0.17216538852087637, 0.08142592105739643, 0.3838193376919118, 0.2979957270546768, 0.4816272687396289, 0.2464164474101489, 0.45769132961991577, 0.4409780275429982, 0.23884277392917896, 0.30885453845085664, 0.45484654795781676, 0.13941871065789224, 0.37488646530425673, 0.5758951359699509, 0.5920972997487024, 0.535048247509909, 0.050169340549717556, 0.09362699724688883, 0.04508034052004517, 0.17456851579559352, 0.27951689258958345, 0.09641962037087126, 0.12678793178858228, 0.11765040149645933, 0.06242688273830155, 0.2576636012249961, 0.2899275931131807, 0.30359743856492283, 0.303040111365243, 0.24500495619745088, 0.262338605965706, 0.18160822284047884, 0.3095649884344971, 0.25440278389232795, 0.6892581811269329, 0.5929768997436571, 0.6312845835326661, 0.581090280814913, 0.5682402483251162, 0.5577971323820182, 0.5872704956228176, 0.7600101046112744, 0.6563218157880649, 0.14134630261269343, 0.11375614875603479, 0.10970722648658682, 0.12068208101149791, 0.10622060921835141, 0.11714900628548697, 0.10174339109823827, 0.23699067926938155, 0.11625211041055572, 0.22988867962928405, 0.35895350715918073, 0.1690834943654378, 0.5152433398537384, 0.48015857644501636, 0.2706796805681905, 0.23322654276017507, 0.20832733794959668, 0.17515365230459223, 0.451778664738951, 0.43384615219805267, 0.45817353059598775, 0.40859964711441255, 0.45130299739965796, 0.47346390910488445, 0.4803510531699553, 0.46291387130470774, 0.45805656543061046, 0.25188005073235764, 0.2901415164029194, 0.30659305090313405, 0.36063880982702257, 0.3125847584086239, 0.35022300836016707, 0.35787902099511737, 0.34995924097324194, 0.30765221030910583, 0.21784849246954352, 0.20226788896877146, 0.17932260015949342, 0.2121188794944251, 0.21952033680403993, 0.21253925648718608, 0.2303651618958905, 0.2021495848051179, 0.21897356204617469, 0.20200949800702817, 0.47656614171196143, 0.21827936043937557, 0.20991905178267323, 0.1902523291900723, 0.20193320723491925, 0.3751085784992739, 0.20446369469326542, 0.21197902594786566, 0.8508733313524587, 0.7660587691828675, 0.16143554829524143, 0.7751223685757697, 0.1982895654466419, 0.16485769520882732, 0.1226215558800593, 0.16945105388402348, 0.15668354228305192, 0.8316485963669277, 0.21084519568122329, 0.7438157127544875, 0.8555184498235213, 0.16865706792740387, 0.781253316103462, 0.211547436036307, 0.7795108257077981, 0.12636573580325217, 0.21128679705035114, 0.18758153347348205, 0.1896323740829734, 0.19315096592309466, 0.19456094983499084, 0.1903452434875328, 0.19057157732740404, 0.1944883847224853, 0.20445720032707582, 0.08056939474797509, 0.0833597081514652, 0.08849161069109845, 0.07541600478955823, 0.08981135994331912, 0.08455708712003995, 0.08464823419990553, 0.08219597305346815, 0.07794068782774555]}, "mutation_prompt": null}
{"id": "06fd5107-f37a-4d82-b4f2-9e5731d99ee8", "solution": "import numpy as np\n\nclass MultiPhaseAdaptivePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49618\n        self.c2 = 1.49618\n        self.w_min = 0.4\n        self.w_max = 0.9\n        self.F_min = 0.5\n        self.F_max = 0.9\n        self.CR_min = 0.8\n        self.CR_max = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.1\n        self.phases = 3  # Three phases\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_max - progress * (self.w_max - self.w_min)\n            F = self.F_min + progress * (self.F_max - self.F_min)\n            CR = self.CR_min + progress * (self.CR_max - self.CR_min)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def current_phase(iteration):\n            phase_duration = self.budget // self.phases\n            return iteration // phase_duration\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            phase = current_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if phase == 0:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = swarm[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                if phase == 2 and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "MultiPhaseAdaptivePSO_DE", "description": "Multi-phase Adaptive PSO-DE combines adaptive inertia weight adjustment, dynamic crossover, and targeted local search in a phase-based evolutionary optimization for improved convergence across diverse landscapes.", "configspace": "", "generation": 76, "fitness": 0.2913294667243505, "feedback": "The algorithm MultiPhaseAdaptivePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.24.", "error": "", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.6586185931371132, 0.6496025772945055, 0.6927239823464053, 0.7078931726664507, 0.711906379626964, 0.38081071208050665, 0.6375073725657785, 0.66197763268219, 0.6783579067450749, 0.49800010397156713, 0.4932622470762842, 0.5105900805201091, 0.4604621298687718, 0.033626309553349665, 9.999999999998899e-05, 0.45984723991701804, 0.5125854999767763, 0.4882712181034562, 0.09766452074628307, 0.11717675454328635, 0.3971739101323002, 0.12729382410676848, 0.12431533283007956, 0.12754960874205612, 0.1000644345115892, 0.1018068519617773, 0.0889410904275264, 0.0828244641576168, 0.10966432856478459, 0.0919067769375822, 0.08839265693989595, 0.08878725814984467, 0.1264945923488514, 0.09925789472748114, 0.09799768640700857, 0.11554504246542652, 0.988055030406815, 0.9868689760107355, 0.9899959323069307, 0.9868797506908628, 0.9871855640962359, 0.9838282978322936, 0.9874627302527518, 0.9874426265280937, 0.9891089816418219, 0.5098777187419385, 0.46038702887949823, 0.16269093908035193, 0.4966687710063544, 0.5060398731393227, 0.4410978655397283, 0.495385852367242, 0.1932810762527195, 0.16119597540654507, 0.6472292532680984, 0.6518119576902642, 0.6555809447646073, 0.20405144292870292, 0.19345065598144706, 0.11704914825472168, 0.23320751623802594, 0.12164020365543005, 0.6118067493494006, 0.3802490719291015, 0.2537131743554748, 0.3939647033998941, 0.24497732535067074, 0.30036441144365367, 0.11334449954403514, 0.36018282922514255, 0.3678481351105234, 0.328073259568025, 0.28564478370510715, 0.08354050033465443, 0.292558619863434, 0.37540344351370303, 0.22010277902154707, 0.41513817571102285, 0.34264420173391263, 0.3331398193029129, 0.4305019231626527, 0.028911519092520765, 0.044531880892696996, 9.999999999998899e-05, 0.0005169779614754288, 0.17079033366243623, 0.10129335832626152, 0.07537265919347425, 0.05959723516136095, 0.07062746025808808, 0.24056610183183336, 0.059808449266674724, 0.27515319105110925, 0.18299218698633068, 0.2405221645891431, 0.017915288379571237, 0.1063629775682452, 0.1008716369413214, 0.09684246578236, 0.03807868765250366, 0.0373773732520738, 0.033258306493316736, 0.12010019562492302, 0.05452017226740358, 0.052013503533552496, 0.08937797859042107, 0.05044308666648323, 0.05006781902282886, 0.17063744958013471, 0.16907046739890175, 0.1833715645420796, 0.19755972631701713, 0.0047543113796501, 0.004726171263415568, 0.15888645994874429, 0.04274472502018012, 0.21154909000081956, 0.5190157332001588, 0.6522921890299136, 0.5813032997971532, 0.5790479241612385, 0.518481205671781, 0.5768793141969855, 0.5346743811433355, 0.5360952355521247, 0.5496657438166758, 0.09484629818874912, 0.13172118712217729, 0.06454016865773415, 0.12007000021260206, 0.10766792707630157, 0.09645611693027945, 0.09181688073658556, 0.09196589270240274, 0.09222069043650394, 0.21214906402241718, 0.17253723991812986, 0.22601630883606294, 0.4923501106037478, 0.18660868456240765, 0.13557536552413185, 0.4095097542331769, 0.4512893286460178, 0.19587894153123764, 0.2336533524926101, 0.3217551577764485, 0.40712006384138966, 0.3825222308291092, 0.3342718909553265, 0.3154812411342466, 0.3240402634678742, 0.4569788543456549, 0.4357677314578984, 0.32742551169409406, 0.2147077007562881, 0.16696535375583865, 0.19756544074880944, 0.28220373639781926, 0.22319690218679045, 0.15686876514440284, 0.26351480365046676, 0.280391006075591, 0.18883076412179167, 0.20415701028211908, 0.193916650099606, 0.19272230786709843, 0.19325839346709017, 0.2091643522839911, 0.1997551464559031, 0.21160116100293724, 0.18949394256444196, 0.17667062113970589, 0.20136419208543976, 0.6067076739825186, 0.19472858181545816, 0.2027202028706626, 0.5886842893853776, 0.17622328129689957, 0.1843722381594829, 0.2131156687408876, 0.7446231812097934, 0.1676270174590696, 0.15245074844999273, 0.7268645078689239, 0.1913339897965377, 0.678406212355565, 0.16019273046231686, 0.16689628839606763, 0.15651042386229364, 0.14777083896119003, 0.2015498760516894, 0.6745833467774052, 0.6613981696490443, 0.3718294808966722, 0.19815616005561898, 0.19986832582265723, 0.20137947728256622, 0.20864902795145657, 0.19700735190735763, 0.19325751594710827, 0.26855085903325593, 0.1849155619654298, 0.19977833993501315, 0.19577074955277118, 0.2068814603882707, 0.19989009514117317, 0.17882115020899014, 0.086171680768379, 0.08931625642818886, 0.08861794854659222, 0.09959769951905417, 0.08674760002383941, 0.08851329323008117, 0.08967292740045774, 0.08340815489732434, 0.07657921249722077]}, "mutation_prompt": null}
{"id": "f5988168-8935-4425-8c0c-f65beb93c8bf", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        def dynamic_grouping():\n            group_size = max(2, self.population_size // 4)\n            np.random.shuffle(swarm)\n            return [swarm[i:i + group_size] for i in range(0, self.population_size, group_size)]\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            subgroups = dynamic_grouping()\n            for group in subgroups:\n                local_best = min(group, key=lambda pos: func(pos))\n\n                for i in range(len(group)):\n                    inertia = w * velocities[i]\n                    cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - group[i])\n                    social = self.c2 * np.random.random(self.dim) * (local_best - group[i])\n                    velocities[i] = inertia + cognitive + social\n                    velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                    group[i] += velocities[i]\n                    group[i] = np.clip(group[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with dynamic subgrouping divides the population into subgroups that balance exploration and exploitation, enabling more adaptive search dynamics.", "configspace": "", "generation": 77, "fitness": 0.25158716850521257, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.21.", "error": "", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.5495234011704445, 0.5520192957011628, 0.5997570896073574, 0.515302481938027, 0.5743966293917383, 0.44047044042344896, 0.550983471211864, 0.541481493039319, 0.4438663382995276, 0.3283141378543687, 0.29234350238961315, 0.22743649273421818, 0.23518074841521563, 0.2941411452745295, 0.1986773290621714, 0.3411360590496523, 0.2557595770152483, 0.2561106685856547, 0.07344351333475774, 0.06830986940479011, 0.08216604269933614, 0.08942071040639199, 0.11852547755047749, 0.07047178427947187, 0.0823076506770869, 0.0802044940961576, 0.07707233607862085, 0.07609863276295559, 0.06863141186442301, 0.07032670116610884, 0.08114240453561283, 0.07270062248113296, 0.07057162232710523, 0.07102987456635601, 0.08531799783600913, 0.0671482111561914, 0.9883200009832632, 0.9523991394658073, 0.9777249732712068, 0.9736226089838131, 0.9690377835418271, 0.9833352076689597, 0.9691621365213259, 0.9783999781660895, 0.9638883009646647, 0.1981952949407313, 0.23003286755993868, 0.2415979922315742, 0.2544767567388828, 0.20202650250586407, 0.23955148179966723, 0.25467087689166434, 0.26856687697674975, 0.11057787427607368, 0.58795162640086, 0.5741915682820644, 0.438420550403257, 0.7039969117082581, 0.5017289665218017, 0.5578852537249808, 0.6225020769756147, 0.6624392741706084, 0.3114231602796085, 0.12371228630764308, 0.16187190516274363, 0.19940303707396556, 0.16886582332882738, 0.1661031534935079, 0.13030197197240012, 0.15103667245400088, 0.12705220925923366, 0.13850983200542288, 0.14550696792135276, 0.19718852022461075, 0.1779192031916984, 0.16888210116445568, 0.18321244354723143, 0.20444729682522134, 0.158435129756206, 0.15419449226371085, 0.22343987863140824, 0.14414384255417068, 0.19742886359063005, 0.13185727927698632, 0.28639949044867274, 0.198065889665635, 0.12504516109444663, 0.1565363581498248, 0.21607874875746225, 0.16658479743116672, 0.3511703232089206, 0.2372473622145077, 0.3357266944284296, 0.12381900017850689, 0.375488427125806, 0.10791773569611274, 0.2707999668969011, 0.22755211921095642, 0.426976046072152, 0.07624870945727891, 0.03628877361604699, 0.04578318264532644, 0.08490904493583817, 0.09959463697200532, 0.06621720643154605, 0.0686115942305574, 0.07628149664996997, 0.04490941385849456, 0.1580017945431167, 0.1874235902877045, 0.13809356239773518, 0.15563668289633392, 0.1800147180335866, 0.12176035485785264, 0.1655122181509474, 0.1738523140887015, 0.07043081383779226, 0.4776783575141115, 0.4954153859712095, 0.48906305706569575, 0.4776297534386751, 0.4875100251747464, 0.4052110102001235, 0.44252754294044927, 0.5223891557382052, 0.5177086366756313, 0.08592661833793758, 0.08207769155779876, 0.09169667001107262, 0.07407669703779207, 0.07685865742128006, 0.08066991371524512, 0.08848780969155401, 0.08044372429253621, 0.07590096365714871, 0.1871996544483414, 0.1320519265116773, 0.15467255361127918, 0.13906446656413096, 0.15746537986833786, 0.1316538208185617, 0.16001510554453258, 0.13638450704003613, 0.14028779168373107, 0.2250870205740676, 0.3054371538317595, 0.2801026692225902, 0.2684943860528506, 0.29755102577581516, 0.2851764190699628, 0.3014207412961514, 0.27492068703220773, 0.28718594212520354, 0.23213143224673094, 0.2288057958696499, 0.21646784780749573, 0.21858100853217377, 0.22356073532346898, 0.23315127663510182, 0.19909108946862297, 0.21741991164382035, 0.23468124529386702, 0.18721584044173467, 0.1829624255935901, 0.1876683204673707, 0.1701344360794974, 0.18741106149810138, 0.1818039607176879, 0.1924431126320042, 0.1914433558724118, 0.177148964354371, 0.17204052929858993, 0.18096512791134767, 0.1875210947338103, 0.16971780199156472, 0.19099792620303968, 0.1760584269684905, 0.1744834823150988, 0.18519796021527035, 0.18839613807434086, 0.19077302038554322, 0.18748553923446476, 0.16261169038443135, 0.18140324306552214, 0.41347441334476986, 0.5796270233067667, 0.3787253170561894, 0.19487296785806096, 0.15679365127682032, 0.16007570449302966, 0.20030039344992512, 0.1976058800023246, 0.4082098982387432, 0.2048526899056201, 0.19671479543721404, 0.12619882725890585, 0.4105263430801499, 0.1864712503562589, 0.1817546541549716, 0.16870330852921345, 0.17411765448700756, 0.18410669654853595, 0.187349444359033, 0.184513690986981, 0.17308113242159484, 0.1785452530040178, 0.19869323461209765, 0.05986553696381858, 0.0703155126136098, 0.07357716339501874, 0.07051830197834463, 0.07260144507297661, 0.08748754405874548, 0.06841356142924737, 0.06381602249277507, 0.0792955233640108]}, "mutation_prompt": null}
{"id": "b9ab6363-2267-481c-a989-b04c74b0ee08", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            elite_index = np.argmin(personal_best_scores)\n            elite_position = personal_best_positions[elite_index]\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n            # Intensify search around the elite solution\n            if not exploration_phase:\n                for _ in range(3):  # limited additional search around elite\n                    if self.num_evals >= self.budget:\n                        break\n                    elite_trial = elite_position + np.random.normal(0, 0.1, self.dim)\n                    elite_trial = np.clip(elite_trial, self.lower_bound, self.upper_bound)\n                    elite_score = func(elite_trial)\n                    self.num_evals += 1\n\n                    if elite_score < global_best_score:\n                        global_best_score = elite_score\n                        global_best_position = elite_trial\n                        elite_position = elite_trial  # update elite position if improved\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive momentum and elite exploitation improves convergence by dynamically adjusting inertia and intensifying search around elite solutions.", "configspace": "", "generation": 78, "fitness": 0.38084687768034325, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.25.", "error": "", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7493436257254484, 0.7645718385950468, 0.7457131891030919, 0.7747054635889724, 0.750770960507165, 0.7846749370121612, 0.7438460593548307, 0.755067228245497, 0.7562905550732612, 0.5486267067661084, 0.549260572137295, 0.5867795642739797, 0.5742493269569179, 0.5899453483477934, 0.6067612423424358, 0.5852761338785906, 0.5930402886006705, 0.5436523716759545, 0.1559683439691546, 0.15379163503178517, 0.14920220384583938, 0.1522816379974471, 0.13826477750307453, 0.15516749196033341, 0.11307178640814275, 0.12240209830283888, 0.1463697472681179, 0.12759133184370441, 0.11855452717933235, 0.11239183879200576, 0.12168187775433525, 0.1259348650436164, 0.11635198826222581, 0.10170787810946769, 0.11473216341198644, 0.11844946645845644, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.5722669789395953, 0.3214373585172934, 0.549426645835659, 0.523924740312569, 0.5760559287707014, 0.36076205433472364, 0.5455400030180662, 0.5228940911329252, 0.5445322706461457, 0.22706765206810653, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.4103398497650461, 0.4278169421175536, 0.3907214457638487, 0.37030236327902244, 0.1271251185589446, 0.4077994182539487, 0.5143605290137662, 0.4156858606873407, 0.3577522740589092, 0.3919179441104763, 0.2455540005562269, 0.2972341313204232, 0.37442966257565813, 0.4504328982920184, 0.39696571018369153, 0.31715884566683294, 0.12787375112450194, 0.42005835439634653, 0.41772060232146535, 0.17565939429083133, 0.08462959074372833, 0.04987469022403601, 0.40159581263031363, 0.07203388062291238, 0.19589457610011374, 0.38970640308030957, 0.5050219553237314, 0.5833188368370696, 0.29384401083661216, 0.5832804465195263, 0.3251483185411683, 0.5138247619755848, 0.33845460461990384, 0.6429653601713504, 0.2473044087379339, 0.4884382707161462, 0.1135832916380416, 0.04043742354492463, 0.06482583020436505, 0.21324158167221208, 0.1835706518115685, 0.29716580147373306, 0.11641380153124714, 0.13418941988631872, 0.1206878096749977, 0.20514669760237547, 0.33076205222399646, 0.30968865716677196, 0.32579646887361036, 0.22408112560536142, 0.23075397492480598, 0.27734933953273455, 0.2770262990812369, 0.2967234569897501, 0.6485779097319351, 0.6624743748517824, 0.6961544817806102, 0.5956504131650942, 0.7137983642610091, 0.695593409331629, 0.6478396883965496, 0.6618389346189797, 0.6505168612054542, 0.08460083984411393, 0.1365309166575739, 0.14096242791505065, 0.10514278880426575, 0.11225361610340368, 0.12323062401978802, 0.11628035446022189, 0.10466104977636792, 0.10037688554139168, 0.22955055384910417, 0.2698131274326183, 0.1665826242007823, 0.21878236823527764, 0.3204570895566974, 0.2542902068137891, 0.22153299121191716, 0.24178578229721204, 0.2793527377098123, 0.4548563374199489, 0.37888237037141814, 0.41967569341054445, 0.41710115547891, 0.4522303373663601, 0.4699199177937311, 0.4539064629074, 0.4438359437725853, 0.46445889790941997, 0.38132224207167587, 0.34714447507764734, 0.29295972664309144, 0.294022907334204, 0.1974708028065344, 0.37320623704377587, 0.347866005166649, 0.3659724385390989, 0.34773203685594367, 0.20958868970969124, 0.19767948000004032, 0.19168281319926772, 0.2143555015485139, 0.20532935589675283, 0.22629546295854175, 0.2173883472468161, 0.19846131793236688, 0.22774327753609724, 0.1943018968577358, 0.5097075685342107, 0.5350939716924257, 0.22018893899178837, 0.23577345961351825, 0.21560350939591444, 0.40535267437564904, 0.21716902401437577, 0.22562917168283125, 0.84120936818493, 0.8246052515524153, 0.15365907878832186, 0.7584287726700076, 0.19773207527937187, 0.19473572432355224, 0.7474784313729328, 0.16991888427697754, 0.8136283511053167, 0.728069673372769, 0.16900123144427215, 0.796306663016825, 0.20612552133334294, 0.7512316653275415, 0.20919714344219154, 0.203188039291468, 0.2113461829323392, 0.21235430767679364, 0.1874663915502789, 0.1841039806614565, 0.20315484701814324, 0.19194262708515275, 0.18110051858579557, 0.19904397307411836, 0.18496826533717148, 0.2717433474323798, 0.1789377517508245, 0.0811217478994053, 0.08777660845382085, 0.07490992736688895, 0.08870661995938989, 0.08313452113298625, 0.08157399557918055, 0.09230278531783276, 0.1015538818165107, 0.0860340734740277]}, "mutation_prompt": null}
{"id": "633a4221-051e-4be2-be69-a4d9a3fe0fc4", "solution": "import numpy as np\n\nclass RefinedHybridPSO_DE_MPLS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_explore = 0.15\n        self.local_search_prob_exploit = 0.25\n        self.intensification_factor = 0.1\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.6 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Multi-phase local search integration\n                local_search_prob = self.local_search_prob_explore if exploration_phase else self.local_search_prob_exploit\n                if np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, self.intensification_factor, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "RefinedHybridPSO_DE_MPLS", "description": "A novel hybrid algorithm combines adaptive PSO and DE with multi-phase local search to enhance exploration and exploitation efficiency.", "configspace": "", "generation": 79, "fitness": 0.3587126288795568, "feedback": "The algorithm RefinedHybridPSO_DE_MPLS got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.24.", "error": "", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7382231657288855, 0.7279198331149064, 0.7280787410952723, 0.7659049550298118, 0.7696018192804648, 0.7659520280059514, 0.7221235411815883, 0.7390047611998576, 0.7727165298052269, 0.555377450139966, 0.5504743151225739, 0.5415234444688641, 0.538562783948595, 0.5595922176252586, 0.5650093386673168, 0.5170653466771924, 0.5176490513713665, 0.5474921734136198, 0.12376408495783542, 0.15843992378190064, 0.1216608350427032, 0.1203170392890397, 0.14378673725855273, 0.13714219720331677, 0.13483806755738403, 0.14167564865629323, 0.13144850070215774, 0.13961343406565774, 0.12281860090817276, 0.09463724266885964, 0.10968200181170962, 0.11878574567254507, 0.1102127787803393, 0.10935201610104339, 0.12085955021466921, 0.11264743947654954, 0.9881791424146602, 0.978445731862864, 0.9872567244508018, 0.9846248900207857, 0.9882271063987963, 0.9762928108992579, 0.9851635486971808, 0.9884712657069499, 0.985339151593883, 0.5212081389548817, 0.4760814970465781, 0.5305577783910131, 0.5554998159423701, 0.5524721486681804, 0.5672317616890179, 0.5290051513629243, 0.5098600545454719, 0.5377391228589845, 0.4795677203273623, 0.7325206055738263, 0.7246432048995708, 0.20622517017316688, 0.20751290428256675, 0.7077580114665725, 0.7453152339745985, 0.7829580272304157, 0.7663801201889995, 0.28984759497331536, 0.3794537003140651, 0.39452628117566557, 0.2607144755914914, 0.32022764171309104, 0.3414264839406672, 0.5595382463580634, 0.44805200735124884, 0.28892445583331683, 0.3730318037098498, 0.11604043000178266, 0.37786406618087154, 0.3461468154821792, 0.326947150773111, 0.41377184085109686, 0.33514776496315746, 0.11470342096965702, 0.2991978869653018, 0.3623649840287728, 0.2561010811593244, 0.21829991580947428, 0.33755243158280923, 0.3094031205370864, 0.2650785381537195, 0.15656715979013514, 0.05405358869746901, 0.4633078807023576, 0.39892806766887023, 0.3117069360635927, 0.5032042850404125, 0.3840091553247609, 0.4600821643458154, 0.49458812800585183, 0.505997418070355, 0.581216845315534, 0.3816930376278056, 0.059294143213742045, 0.13370379143277755, 0.04318645346312966, 0.19379810026870736, 0.17159538602898006, 0.2070781349849039, 0.09492812228367142, 0.06154483157758628, 0.10992956337945903, 0.2609592934298125, 0.27068585491004027, 0.2921251993700281, 0.29661427255649486, 0.291804432851438, 0.3268704753756101, 0.27475828687382486, 0.30629498898002605, 0.29019516702874093, 0.6676963073253905, 0.5602788145505218, 0.5989515085436046, 0.662840252197503, 0.7080686344781368, 0.668240745055517, 0.6621780935857162, 0.6422586634998269, 0.5826556996381483, 0.1345753660788005, 0.11268931313274422, 0.09299648318360054, 0.11698834068845865, 0.15170443401427425, 0.12403039396125004, 0.14724370090871597, 0.0977490844797847, 0.14512288980748467, 0.4846664338677049, 0.14547767841359271, 0.22541400813272716, 0.36072010200796945, 0.19162983141564838, 0.13322239472232145, 0.2178916405710598, 0.42632130061768214, 0.2285549900967625, 0.4336621956345471, 0.4133032112741485, 0.41888622312700385, 0.43709350931057334, 0.3876557160479802, 0.4272213191199089, 0.4190516991327282, 0.4549022512055594, 0.46893404032356734, 0.30501973838589824, 0.34801808888819485, 0.19268751466103817, 0.29787128704996735, 0.3159036863733763, 0.31172860740567754, 0.36334098336834664, 0.3777344792700471, 0.3139195990802641, 0.21902221375627517, 0.2119573283754549, 0.2005602168163234, 0.18368922607387284, 0.20355977936955105, 0.21802745593529194, 0.1896165891083781, 0.2161410405251587, 0.2120843371356783, 0.19519309977328803, 0.185653542897536, 0.4587977337537045, 0.5096774672405078, 0.3956132643341316, 0.2009161203863259, 0.20573710579762816, 0.390749085063294, 0.4395676597450927, 0.8502257941050129, 0.18689274711243475, 0.1722846593842292, 0.779415713490657, 0.20080330036383887, 0.7843571923326279, 0.12225191106520072, 0.1703552100224488, 0.1951880800064434, 0.16572404804580076, 0.16928906571434033, 0.20870978800644757, 0.20558280333813672, 0.166699546736772, 0.21023632625040067, 0.10524587810824759, 0.21069529835018674, 0.2102802455727626, 0.19352137697154947, 0.18845337217767855, 0.1882222313044516, 0.20636190208084848, 0.1930498611999708, 0.22193965110302138, 0.20375422081995076, 0.2064614408201948, 0.19911533847866703, 0.08289626348378876, 0.08061745779914276, 0.09036304901161052, 0.07906976968869128, 0.0819704602583472, 0.09112045756454767, 0.10149877775105398, 0.07751054176715444, 0.0845260542481705]}, "mutation_prompt": null}
{"id": "bb4ec2bc-76c8-4a91-b8bf-ead1e0223f1f", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.6\n        self.F_end = 1.0\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.3  # Increased probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive weight decay and dynamic selective replacement improves both exploration and exploitation by dynamically adjusting particles to balance global and local search.", "configspace": "", "generation": 80, "fitness": 0.354290528409769, "feedback": "The algorithm EnhancedHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.24.", "error": "", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7127167498601741, 0.7231878251049282, 0.7645351901608308, 0.7440996647555231, 0.7507166564035376, 0.7012210406015439, 0.7131130724531727, 0.7317862755575163, 0.7323567767010917, 0.528181683483006, 0.5104788798544518, 0.5303901861394569, 0.5207134898855988, 0.49819721213464796, 0.5289967607971093, 0.5152820022793811, 0.5435020922714927, 0.5245477408035089, 0.1379631447976737, 0.1386149696855582, 0.11477470845580062, 0.09922967962806395, 0.14891369163561596, 0.14793275219358637, 0.13454999406208912, 0.10551065017977856, 0.12085272696658267, 0.11937890170125798, 0.09625264883750262, 0.11312838785014834, 0.10733030928467524, 0.10620602437985982, 0.0930710900117574, 0.12117498375331104, 0.1242343614962017, 0.11160781114017515, 0.9875200061901285, 0.9874067597375192, 0.9888414582665108, 0.9856936870021794, 0.9887245651758062, 0.979883281717522, 0.9843165837014012, 0.9790196741411168, 0.9877154805051879, 0.4918701651084074, 0.509271447097557, 0.49703907418067406, 0.48968701260311587, 0.5117657643223135, 0.317786983945618, 0.5040314901811217, 0.5107243657770736, 0.31849562429152445, 0.7665426613092027, 0.7089491216610251, 0.6804159142231089, 0.7828664532921878, 0.25835466596638346, 0.21440059411886037, 0.7298240920914467, 0.7553635171606027, 0.7297160941510424, 0.26841070980041437, 0.3241270535801958, 0.3116258605880129, 0.32061160565371716, 0.31633140346044597, 0.3653971395219109, 0.37681471106167297, 0.31287267564117616, 0.3230483210081103, 0.28798612348220787, 0.2996526120176817, 0.3452215571167613, 0.34673933236360677, 0.30944062863829935, 0.3501827432905993, 0.3432942235267594, 0.32693654645175607, 0.3743338408954485, 0.22357077782036205, 0.39351724034355795, 0.29656939645296465, 0.06394430532399842, 0.3076339806732633, 0.32221018989800143, 0.23490317910373615, 0.17788755576926651, 0.36961337902856517, 0.4249885032627537, 0.35378891178746874, 0.42826357867266795, 0.35788876482179244, 0.3226974107947945, 0.04920712664122906, 0.37746279295201757, 0.4161419231286071, 0.4111193994253064, 0.07958227484293345, 0.09700954401980977, 0.1317489649361392, 0.12966524879323438, 0.05741082673139841, 0.12870238337659845, 0.08559440526697659, 0.07301181866560369, 0.10458392746991518, 0.040897726951231395, 0.21267777147289557, 0.24919105928412666, 0.281942594320165, 0.2898346001597084, 0.27419460030260223, 0.23867378114132876, 0.2523478310731665, 0.2698886938314663, 0.6112958851843859, 0.6049179201846344, 0.6065717922059927, 0.6341808010882909, 0.5998583312678167, 0.6511309346770546, 0.5762672701354791, 0.6089282459008878, 0.5747559492770112, 0.1173344721815367, 0.09905974586205446, 0.12554699510855172, 0.11714803070008406, 0.1219089939167457, 0.11411213286676825, 0.10451306259784865, 0.1318152451721074, 0.1163704992256116, 0.2896588616193224, 0.3743011906680175, 0.31944790809820744, 0.30913296844819027, 0.18574492026722844, 0.18566907944438837, 0.19711631827903153, 0.19720769492788437, 0.2043421688182373, 0.4422207117893915, 0.42307995356200023, 0.4115760553894079, 0.4011649253178846, 0.3831917058317149, 0.39278755266258414, 0.39244220849833145, 0.4466900392133982, 0.38826287005127136, 0.3059444534045279, 0.28964344887730076, 0.30824393147388063, 0.27171716278921054, 0.2976049749723324, 0.30675441053838115, 0.3532121763078939, 0.3483748151020263, 0.31370991021960304, 0.20446329674304575, 0.219053466761287, 0.2317513181521894, 0.22976259142772504, 0.20322570502720727, 0.18426420359520113, 0.21638266089811298, 0.19012648887494787, 0.20821423797636052, 0.41191353092583327, 0.1903533094449017, 0.20228072002716613, 0.42948455576409506, 0.5019979884125041, 0.23013531181606317, 0.21179698692982907, 0.21522579646334972, 0.2159647037140966, 0.8144095177253907, 0.785810946724475, 0.1520766147184981, 0.7852779782728037, 0.19814171232267308, 0.1962013154894533, 0.15786518168956298, 0.8183878482436227, 0.1940979408540453, 0.73995566539072, 0.20887570309282044, 0.7776467586613067, 0.20885077718186562, 0.7294046234938913, 0.20728193697072106, 0.20501872280236466, 0.2095705112570838, 0.20697087599480823, 0.20135238614790618, 0.20001421344312398, 0.20071706281723067, 0.21834707248604168, 0.20421207477686065, 0.1947010722216076, 0.23461314327106564, 0.24590529764131763, 0.20101517627441712, 0.0868420990935439, 0.08209194673731002, 0.08408141440617511, 0.0835851381359034, 0.08061845979984461, 0.10654540609828977, 0.08974703460529598, 0.08914843629434543, 0.08364624443161506]}, "mutation_prompt": null}
{"id": "6d0d465d-9e80-4194-b918-30c769f86624", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.initial_population_size = 20\n        self.population_size = self.initial_population_size\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.3\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        def adjust_population_size(progress):\n            self.population_size = int(self.initial_population_size * (1.0 - 0.5 * progress))\n\n        while self.num_evals < self.budget:\n            w, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n            adjust_population_size(self.num_evals / self.budget)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_variance = 0.1 * (1 - (self.num_evals / self.budget))\n                    local_trial = trial + np.random.normal(0, local_variance, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "AdaptiveHybridPSO_DE", "description": "AdaptiveHybridPSO_DE incorporates dynamic population resizing and local search variance adjustment based on convergence speed to enhance exploration and exploitation balance.", "configspace": "", "generation": 81, "fitness": 0.3741243276234156, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.26.", "error": "", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7837867419524214, 0.759856576692885, 0.790600951462191, 0.7899805756528594, 0.7936214880457344, 0.7887247070842551, 0.7894857927586716, 0.8036769906389168, 0.7986790243962252, 0.6203834845330609, 0.6085185559543931, 0.5979655721926778, 0.6447657031241472, 0.6078257814871592, 0.6003346507020701, 0.6363476264210466, 0.6236290555986168, 0.6230237196004538, 0.11423924876884217, 0.12101426679849026, 0.10684129436680145, 0.11863796623196798, 0.1485303459080367, 0.14003542334231134, 0.13749351108954766, 0.48921656902130817, 0.12505164461741602, 0.1064272438404763, 0.1271210220464265, 0.13312107486960412, 0.11439073338375472, 0.12239658723767988, 0.10741786620559246, 0.12992152561676684, 0.09060689846763292, 0.12325726926888458, 0.9854888526484314, 0.989134743406661, 0.9888438352167357, 0.9883619597256869, 0.9913336492622947, 0.9747015303760473, 0.9854530998900722, 0.9864648446760236, 0.9854601297959307, 0.5979996157478346, 0.57774702679993, 0.5889972586491073, 0.6017716659438451, 0.6102114788807982, 0.38583981001058365, 0.568521801016289, 0.6257488142746801, 0.6301326593507657, 0.6904811495186968, 0.7214644728463391, 0.7309922305866313, 0.21932173294864477, 0.26666181036123515, 0.7634943913632684, 0.7798711029741192, 0.7880439793490237, 0.7914830203874144, 0.4497926084428977, 0.41305729310741, 0.33914100061488583, 0.39186571176348395, 0.425055159591047, 0.3030760071173567, 0.41304951820718694, 0.3665138973138633, 0.3479566833792259, 0.5118048446358391, 0.11408143605741405, 0.24179104686446196, 0.4260576261145059, 0.3237210234525152, 0.37620945405055695, 0.4358892988526831, 0.11850973787160657, 0.4109018476787323, 0.08756838887887242, 0.03973908243315183, 0.09562178218262829, 0.2130609295164333, 0.08587460396987612, 0.1651864943769097, 0.07360716079516383, 0.5269667867434, 0.10784135866305677, 0.22023754771563175, 0.35147344754247456, 0.5734899432059158, 0.1915494178189553, 0.43071403599539915, 0.2673620408622459, 0.7006023893272447, 0.4752677606743356, 0.22374620430947834, 0.07249418817107034, 0.12552258763388857, 0.14992833591141785, 0.28059357981566346, 0.1978343148190348, 0.12845304247686962, 0.10259809754508675, 0.08466733940167581, 0.08472871018964356, 0.2852936601622995, 0.18474797285972655, 0.35053023309475595, 0.356617595508706, 0.38139830432587274, 0.31773095401638385, 0.2921348139100013, 0.18881050145549338, 0.2553308665689702, 0.6839587098942239, 0.6284293602936963, 0.5608145142778708, 0.6004424654607068, 0.6159194791900586, 0.6919813125891489, 0.6431987876086577, 0.6425943234385768, 0.6552223742953177, 0.09612638372264115, 0.12282455257146263, 0.16755345718485737, 0.10208538089837094, 0.10293477554628827, 0.14191687987667734, 0.11322276999816316, 0.11820973184475947, 0.14147880092250942, 0.17750107600086362, 0.2018250093420787, 0.16670790702720206, 0.4810384267471258, 0.48969893399116304, 0.2573686815334538, 0.5178957141283462, 0.27910183270224675, 0.16543088120896265, 0.5334356909639923, 0.41608057373866414, 0.4429838346598589, 0.45535490833846337, 0.5039236443951224, 0.43131498733098095, 0.4500758133707191, 0.5140077694191996, 0.20873357951392424, 0.384694087315291, 0.3014606142016205, 0.28520532285442035, 0.427948458108074, 0.32147534666362654, 0.2714913927514213, 0.20282969488087288, 0.34109211340673706, 0.3868904844529244, 0.20959945245212985, 0.21751552392927342, 0.19743967755589487, 0.22253053186983973, 0.22639359530547165, 0.24362089809171716, 0.2714219784303642, 0.19450985692277134, 0.2111115568212013, 0.22272717590728763, 0.20822380406711727, 0.2053921591399278, 0.19048117331174785, 0.5777204345801596, 0.540688351207369, 0.48910750028777816, 0.19895171129108136, 0.22436490306059353, 0.8816274739239357, 0.20252352924006822, 0.1536427655186997, 0.8538071025876165, 0.19971243205800648, 0.1979104078051278, 0.12187671817849766, 0.16915134340235072, 0.14735816653436273, 0.8215324488681207, 0.21041153938400936, 0.7062257288247752, 0.20603374634743055, 0.5249278371882813, 0.20978558068959507, 0.2086128848951444, 0.7535414043523595, 0.20688168580262678, 0.23814027338289323, 0.19211821256541506, 0.21150952950247603, 0.1987093369621239, 0.19046180959430326, 0.21410211768567444, 0.20305511782838126, 0.18227771130284265, 0.1820059120635532, 0.09172896455452517, 0.08894548647825906, 0.08282118702388286, 0.08142091291254294, 0.10768379933219241, 0.10879503624269005, 0.0850004719734685, 0.08729726782738523, 0.08418487755124948]}, "mutation_prompt": null}
{"id": "63275b3a-324b-422e-a60c-8fdf17ee062b", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive local search integrates stochastic local search during the exploitation phase to fine-tune solutions, improving convergence.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7484446623911813, 0.7641959616134506, 0.7454935917560436, 0.7739165448992121, 0.7503369513780392, 0.7850689451818347, 0.7441573421917299, 0.757048975842525, 0.7560956547381288, 0.5511217848626917, 0.5534940920845292, 0.5898154743946036, 0.5833014660834138, 0.5864772087377433, 0.6032773373992211, 0.5879284436963637, 0.5852356364220255, 0.5413456665976439, 0.15595470356938457, 0.38611731172949826, 0.14940958434307283, 0.15232885840101662, 0.13809870666113855, 0.15517969717517477, 0.11413971844586901, 0.12245078328049219, 0.14688284767351745, 0.1284512986202797, 0.11876364137337736, 0.11241333395694963, 0.12155039247607347, 0.12681657239112176, 0.12347843940326964, 0.11814245563904291, 0.11475437406818367, 0.1184604231894184, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.574987503643695, 0.36236539684146163, 0.5598280834848447, 0.5333306681833292, 0.5869161621356457, 0.41290135386328375, 0.5647969674564006, 0.5319182427638542, 0.5514831017421311, 0.35166821444125373, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.37616349355184775, 0.44573216332895094, 0.4256645392915912, 0.3755234518841395, 0.12712513770038336, 0.43919414519682776, 0.5323062714079179, 0.4564353894288965, 0.38483607581573354, 0.45654425797354603, 0.24102894690104082, 0.36877841016580637, 0.41202143560433946, 0.4011731964025135, 0.4094292308859071, 0.42515834039424294, 0.12787378640385905, 0.46751618513433024, 0.43931190266616005, 0.11907677004713513, 0.08462963710927363, 0.10296864385537685, 0.5018343580168942, 0.15752583221647598, 0.2043281620453602, 0.4265246341056622, 0.5070397195068126, 0.5550423913750391, 0.15433929385789724, 0.547887014935069, 0.2904022538128461, 0.5022872083750254, 0.25867005411518773, 0.6346643410274144, 0.23639098918948276, 0.5746054984985068, 0.11407980325712597, 0.04520801581034428, 0.0637175041077277, 0.12610842237279962, 0.19267263458538297, 0.26581780370465025, 0.1180591471567537, 0.13238964399108843, 0.13394321409626064, 0.2140676787240372, 0.3048848251704821, 0.3284412347909531, 0.3122908060609827, 0.24029939711003045, 0.29903786809230903, 0.2596462561830435, 0.29887689146203344, 0.20502659201201345, 0.692710933271237, 0.6889920786532941, 0.7101782607910303, 0.6167715725016916, 0.7118263741862114, 0.6591818280749686, 0.6486542541631908, 0.6098766279644814, 0.7108677174038628, 0.08459038225516557, 0.13828841609983644, 0.14089102894867866, 0.10558472212882664, 0.11718958330084828, 0.14205872277450726, 0.11595882493925858, 0.10462779878594208, 0.10027945708054753, 0.21082042329980788, 0.27019449220850855, 0.38780460015415397, 0.21790625764118454, 0.28452531124307456, 0.25447609519107595, 0.22186303474475855, 0.24238543877722207, 0.28227957674727255, 0.42110039637806407, 0.41295421612730265, 0.4348135635977971, 0.4285312717439306, 0.4335960432743873, 0.45737053765074265, 0.4670316987401285, 0.44955115252738787, 0.38956101714044566, 0.35307153811666725, 0.39733578395434, 0.31894459241213546, 0.2848809272189028, 0.19857500046836696, 0.3576677084428712, 0.38640134423118533, 0.3510280292107191, 0.3708795456214532, 0.20609929467634824, 0.19840129074252044, 0.18733417557415732, 0.21420735571712923, 0.20120315219167018, 0.21499467144149997, 0.2261047341666974, 0.19106703129556868, 0.22774327812644335, 0.19431687177135393, 0.5081442142304832, 0.5418807545956155, 0.22045106948895932, 0.23577356850188258, 0.48331630547375315, 0.4295719154123203, 0.21722885110021173, 0.22561090549837426, 0.84120936818493, 0.8246052515524153, 0.15365907878832352, 0.7584287726700076, 0.19773207571633888, 0.19473572510129877, 0.7474784313729328, 0.1699188842761722, 0.8136283511053167, 0.728069673372769, 0.16900123142277734, 0.796306663016825, 0.20612552074207746, 0.7512316653275415, 0.20919714311183368, 0.20312448297505548, 0.21134618292626584, 0.21235430771612906, 0.18744115569601416, 0.18416953756248333, 0.20322798131072473, 0.19195054504461473, 0.18110442905772872, 0.1989409021320092, 0.18592104279289523, 0.26051659353653156, 0.180219359644603, 0.08250401841628008, 0.08472686814662556, 0.07313885569068002, 0.08491506339076893, 0.08164601453501641, 0.07388060604354973, 0.09546596892887449, 0.09662588323739296, 0.08577158806399288]}, "mutation_prompt": null}
{"id": "97ba793a-f804-4849-8ac1-c3b2d487d197", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive local search integrates stochastic local search during the exploitation phase to fine-tune solutions, improving convergence.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7484446623911813, 0.7641959616134506, 0.7454935917560436, 0.7739165448992121, 0.7503369513780392, 0.7850689451818347, 0.7441573421917299, 0.757048975842525, 0.7560956547381288, 0.5511217848626917, 0.5534940920845292, 0.5898154743946036, 0.5833014660834138, 0.5864772087377433, 0.6032773373992211, 0.5879284436963637, 0.5852356364220255, 0.5413456665976439, 0.15595470356938457, 0.38611731172949826, 0.14940958434307283, 0.15232885840101662, 0.13809870666113855, 0.15517969717517477, 0.11413971844586901, 0.12245078328049219, 0.14688284767351745, 0.1284512986202797, 0.11876364137337736, 0.11241333395694963, 0.12155039247607347, 0.12681657239112176, 0.12347843940326964, 0.11814245563904291, 0.11475437406818367, 0.1184604231894184, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.574987503643695, 0.36236539684146163, 0.5598280834848447, 0.5333306681833292, 0.5869161621356457, 0.41290135386328375, 0.5647969674564006, 0.5319182427638542, 0.5514831017421311, 0.35166821444125373, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.37616349355184775, 0.44573216332895094, 0.4256645392915912, 0.3755234518841395, 0.12712513770038336, 0.43919414519682776, 0.5323062714079179, 0.4564353894288965, 0.38483607581573354, 0.45654425797354603, 0.24102894690104082, 0.36877841016580637, 0.41202143560433946, 0.4011731964025135, 0.4094292308859071, 0.42515834039424294, 0.12787378640385905, 0.46751618513433024, 0.43931190266616005, 0.11907677004713513, 0.08462963710927363, 0.10296864385537685, 0.5018343580168942, 0.15752583221647598, 0.2043281620453602, 0.4265246341056622, 0.5070397195068126, 0.5550423913750391, 0.15433929385789724, 0.547887014935069, 0.2904022538128461, 0.5022872083750254, 0.25867005411518773, 0.6346643410274144, 0.23639098918948276, 0.5746054984985068, 0.11407980325712597, 0.04520801581034428, 0.0637175041077277, 0.12610842237279962, 0.19267263458538297, 0.26581780370465025, 0.1180591471567537, 0.13238964399108843, 0.13394321409626064, 0.2140676787240372, 0.3048848251704821, 0.3284412347909531, 0.3122908060609827, 0.24029939711003045, 0.29903786809230903, 0.2596462561830435, 0.29887689146203344, 0.20502659201201345, 0.692710933271237, 0.6889920786532941, 0.7101782607910303, 0.6167715725016916, 0.7118263741862114, 0.6591818280749686, 0.6486542541631908, 0.6098766279644814, 0.7108677174038628, 0.08459038225516557, 0.13828841609983644, 0.14089102894867866, 0.10558472212882664, 0.11718958330084828, 0.14205872277450726, 0.11595882493925858, 0.10462779878594208, 0.10027945708054753, 0.21082042329980788, 0.27019449220850855, 0.38780460015415397, 0.21790625764118454, 0.28452531124307456, 0.25447609519107595, 0.22186303474475855, 0.24238543877722207, 0.28227957674727255, 0.42110039637806407, 0.41295421612730265, 0.4348135635977971, 0.4285312717439306, 0.4335960432743873, 0.45737053765074265, 0.4670316987401285, 0.44955115252738787, 0.38956101714044566, 0.35307153811666725, 0.39733578395434, 0.31894459241213546, 0.2848809272189028, 0.19857500046836696, 0.3576677084428712, 0.38640134423118533, 0.3510280292107191, 0.3708795456214532, 0.20609929467634824, 0.19840129074252044, 0.18733417557415732, 0.21420735571712923, 0.20120315219167018, 0.21499467144149997, 0.2261047341666974, 0.19106703129556868, 0.22774327812644335, 0.19431687177135393, 0.5081442142304832, 0.5418807545956155, 0.22045106948895932, 0.23577356850188258, 0.48331630547375315, 0.4295719154123203, 0.21722885110021173, 0.22561090549837426, 0.84120936818493, 0.8246052515524153, 0.15365907878832352, 0.7584287726700076, 0.19773207571633888, 0.19473572510129877, 0.7474784313729328, 0.1699188842761722, 0.8136283511053167, 0.728069673372769, 0.16900123142277734, 0.796306663016825, 0.20612552074207746, 0.7512316653275415, 0.20919714311183368, 0.20312448297505548, 0.21134618292626584, 0.21235430771612906, 0.18744115569601416, 0.18416953756248333, 0.20322798131072473, 0.19195054504461473, 0.18110442905772872, 0.1989409021320092, 0.18592104279289523, 0.26051659353653156, 0.180219359644603, 0.08250401841628008, 0.08472686814662556, 0.07313885569068002, 0.08491506339076893, 0.08164601453501641, 0.07388060604354973, 0.09546596892887449, 0.09662588323739296, 0.08577158806399288]}, "mutation_prompt": null}
{"id": "15fd2fd7-bada-43b3-992b-c8738d699b00", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive local search integrates stochastic local search during the exploitation phase to fine-tune solutions, improving convergence.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7484446623911813, 0.7641959616134506, 0.7454935917560436, 0.7739165448992121, 0.7503369513780392, 0.7850689451818347, 0.7441573421917299, 0.757048975842525, 0.7560956547381288, 0.5511217848626917, 0.5534940920845292, 0.5898154743946036, 0.5833014660834138, 0.5864772087377433, 0.6032773373992211, 0.5879284436963637, 0.5852356364220255, 0.5413456665976439, 0.15595470356938457, 0.38611731172949826, 0.14940958434307283, 0.15232885840101662, 0.13809870666113855, 0.15517969717517477, 0.11413971844586901, 0.12245078328049219, 0.14688284767351745, 0.1284512986202797, 0.11876364137337736, 0.11241333395694963, 0.12155039247607347, 0.12681657239112176, 0.12347843940326964, 0.11814245563904291, 0.11475437406818367, 0.1184604231894184, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.574987503643695, 0.36236539684146163, 0.5598280834848447, 0.5333306681833292, 0.5869161621356457, 0.41290135386328375, 0.5647969674564006, 0.5319182427638542, 0.5514831017421311, 0.35166821444125373, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.37616349355184775, 0.44573216332895094, 0.4256645392915912, 0.3755234518841395, 0.12712513770038336, 0.43919414519682776, 0.5323062714079179, 0.4564353894288965, 0.38483607581573354, 0.45654425797354603, 0.24102894690104082, 0.36877841016580637, 0.41202143560433946, 0.4011731964025135, 0.4094292308859071, 0.42515834039424294, 0.12787378640385905, 0.46751618513433024, 0.43931190266616005, 0.11907677004713513, 0.08462963710927363, 0.10296864385537685, 0.5018343580168942, 0.15752583221647598, 0.2043281620453602, 0.4265246341056622, 0.5070397195068126, 0.5550423913750391, 0.15433929385789724, 0.547887014935069, 0.2904022538128461, 0.5022872083750254, 0.25867005411518773, 0.6346643410274144, 0.23639098918948276, 0.5746054984985068, 0.11407980325712597, 0.04520801581034428, 0.0637175041077277, 0.12610842237279962, 0.19267263458538297, 0.26581780370465025, 0.1180591471567537, 0.13238964399108843, 0.13394321409626064, 0.2140676787240372, 0.3048848251704821, 0.3284412347909531, 0.3122908060609827, 0.24029939711003045, 0.29903786809230903, 0.2596462561830435, 0.29887689146203344, 0.20502659201201345, 0.692710933271237, 0.6889920786532941, 0.7101782607910303, 0.6167715725016916, 0.7118263741862114, 0.6591818280749686, 0.6486542541631908, 0.6098766279644814, 0.7108677174038628, 0.08459038225516557, 0.13828841609983644, 0.14089102894867866, 0.10558472212882664, 0.11718958330084828, 0.14205872277450726, 0.11595882493925858, 0.10462779878594208, 0.10027945708054753, 0.21082042329980788, 0.27019449220850855, 0.38780460015415397, 0.21790625764118454, 0.28452531124307456, 0.25447609519107595, 0.22186303474475855, 0.24238543877722207, 0.28227957674727255, 0.42110039637806407, 0.41295421612730265, 0.4348135635977971, 0.4285312717439306, 0.4335960432743873, 0.45737053765074265, 0.4670316987401285, 0.44955115252738787, 0.38956101714044566, 0.35307153811666725, 0.39733578395434, 0.31894459241213546, 0.2848809272189028, 0.19857500046836696, 0.3576677084428712, 0.38640134423118533, 0.3510280292107191, 0.3708795456214532, 0.20609929467634824, 0.19840129074252044, 0.18733417557415732, 0.21420735571712923, 0.20120315219167018, 0.21499467144149997, 0.2261047341666974, 0.19106703129556868, 0.22774327812644335, 0.19431687177135393, 0.5081442142304832, 0.5418807545956155, 0.22045106948895932, 0.23577356850188258, 0.48331630547375315, 0.4295719154123203, 0.21722885110021173, 0.22561090549837426, 0.84120936818493, 0.8246052515524153, 0.15365907878832352, 0.7584287726700076, 0.19773207571633888, 0.19473572510129877, 0.7474784313729328, 0.1699188842761722, 0.8136283511053167, 0.728069673372769, 0.16900123142277734, 0.796306663016825, 0.20612552074207746, 0.7512316653275415, 0.20919714311183368, 0.20312448297505548, 0.21134618292626584, 0.21235430771612906, 0.18744115569601416, 0.18416953756248333, 0.20322798131072473, 0.19195054504461473, 0.18110442905772872, 0.1989409021320092, 0.18592104279289523, 0.26051659353653156, 0.180219359644603, 0.08250401841628008, 0.08472686814662556, 0.07313885569068002, 0.08491506339076893, 0.08164601453501641, 0.07388060604354973, 0.09546596892887449, 0.09662588323739296, 0.08577158806399288]}, "mutation_prompt": null}
{"id": "32df3564-e5c6-4ef2-90f4-56b897235b90", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive local search integrates stochastic local search during the exploitation phase to fine-tune solutions, improving convergence.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7484446623911813, 0.7641959616134506, 0.7454935917560436, 0.7739165448992121, 0.7503369513780392, 0.7850689451818347, 0.7441573421917299, 0.757048975842525, 0.7560956547381288, 0.5511217848626917, 0.5534940920845292, 0.5898154743946036, 0.5833014660834138, 0.5864772087377433, 0.6032773373992211, 0.5879284436963637, 0.5852356364220255, 0.5413456665976439, 0.15595470356938457, 0.38611731172949826, 0.14940958434307283, 0.15232885840101662, 0.13809870666113855, 0.15517969717517477, 0.11413971844586901, 0.12245078328049219, 0.14688284767351745, 0.1284512986202797, 0.11876364137337736, 0.11241333395694963, 0.12155039247607347, 0.12681657239112176, 0.12347843940326964, 0.11814245563904291, 0.11475437406818367, 0.1184604231894184, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.574987503643695, 0.36236539684146163, 0.5598280834848447, 0.5333306681833292, 0.5869161621356457, 0.41290135386328375, 0.5647969674564006, 0.5319182427638542, 0.5514831017421311, 0.35166821444125373, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.37616349355184775, 0.44573216332895094, 0.4256645392915912, 0.3755234518841395, 0.12712513770038336, 0.43919414519682776, 0.5323062714079179, 0.4564353894288965, 0.38483607581573354, 0.45654425797354603, 0.24102894690104082, 0.36877841016580637, 0.41202143560433946, 0.4011731964025135, 0.4094292308859071, 0.42515834039424294, 0.12787378640385905, 0.46751618513433024, 0.43931190266616005, 0.11907677004713513, 0.08462963710927363, 0.10296864385537685, 0.5018343580168942, 0.15752583221647598, 0.2043281620453602, 0.4265246341056622, 0.5070397195068126, 0.5550423913750391, 0.15433929385789724, 0.547887014935069, 0.2904022538128461, 0.5022872083750254, 0.25867005411518773, 0.6346643410274144, 0.23639098918948276, 0.5746054984985068, 0.11407980325712597, 0.04520801581034428, 0.0637175041077277, 0.12610842237279962, 0.19267263458538297, 0.26581780370465025, 0.1180591471567537, 0.13238964399108843, 0.13394321409626064, 0.2140676787240372, 0.3048848251704821, 0.3284412347909531, 0.3122908060609827, 0.24029939711003045, 0.29903786809230903, 0.2596462561830435, 0.29887689146203344, 0.20502659201201345, 0.692710933271237, 0.6889920786532941, 0.7101782607910303, 0.6167715725016916, 0.7118263741862114, 0.6591818280749686, 0.6486542541631908, 0.6098766279644814, 0.7108677174038628, 0.08459038225516557, 0.13828841609983644, 0.14089102894867866, 0.10558472212882664, 0.11718958330084828, 0.14205872277450726, 0.11595882493925858, 0.10462779878594208, 0.10027945708054753, 0.21082042329980788, 0.27019449220850855, 0.38780460015415397, 0.21790625764118454, 0.28452531124307456, 0.25447609519107595, 0.22186303474475855, 0.24238543877722207, 0.28227957674727255, 0.42110039637806407, 0.41295421612730265, 0.4348135635977971, 0.4285312717439306, 0.4335960432743873, 0.45737053765074265, 0.4670316987401285, 0.44955115252738787, 0.38956101714044566, 0.35307153811666725, 0.39733578395434, 0.31894459241213546, 0.2848809272189028, 0.19857500046836696, 0.3576677084428712, 0.38640134423118533, 0.3510280292107191, 0.3708795456214532, 0.20609929467634824, 0.19840129074252044, 0.18733417557415732, 0.21420735571712923, 0.20120315219167018, 0.21499467144149997, 0.2261047341666974, 0.19106703129556868, 0.22774327812644335, 0.19431687177135393, 0.5081442142304832, 0.5418807545956155, 0.22045106948895932, 0.23577356850188258, 0.48331630547375315, 0.4295719154123203, 0.21722885110021173, 0.22561090549837426, 0.84120936818493, 0.8246052515524153, 0.15365907878832352, 0.7584287726700076, 0.19773207571633888, 0.19473572510129877, 0.7474784313729328, 0.1699188842761722, 0.8136283511053167, 0.728069673372769, 0.16900123142277734, 0.796306663016825, 0.20612552074207746, 0.7512316653275415, 0.20919714311183368, 0.20312448297505548, 0.21134618292626584, 0.21235430771612906, 0.18744115569601416, 0.18416953756248333, 0.20322798131072473, 0.19195054504461473, 0.18110442905772872, 0.1989409021320092, 0.18592104279289523, 0.26051659353653156, 0.180219359644603, 0.08250401841628008, 0.08472686814662556, 0.07313885569068002, 0.08491506339076893, 0.08164601453501641, 0.07388060604354973, 0.09546596892887449, 0.09662588323739296, 0.08577158806399288]}, "mutation_prompt": null}
{"id": "9d0ffa06-54bb-4568-9835-756e89ec3641", "solution": "import numpy as np\n\nclass EnhancedHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1 = 1.49445\n        self.c2 = 1.49445\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob = 0.2  # Probability for local search during exploitation\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            return w, F, CR\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, F, CR = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = self.c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = self.c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search during the exploitation phase\n                if not exploration_phase and np.random.rand() < self.local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "EnhancedHybridPSO_DE", "description": "EnhancedHybridPSO_DE with adaptive local search integrates stochastic local search during the exploitation phase to fine-tune solutions, improving convergence.", "configspace": "", "generation": 70, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7484446623911813, 0.7641959616134506, 0.7454935917560436, 0.7739165448992121, 0.7503369513780392, 0.7850689451818347, 0.7441573421917299, 0.757048975842525, 0.7560956547381288, 0.5511217848626917, 0.5534940920845292, 0.5898154743946036, 0.5833014660834138, 0.5864772087377433, 0.6032773373992211, 0.5879284436963637, 0.5852356364220255, 0.5413456665976439, 0.15595470356938457, 0.38611731172949826, 0.14940958434307283, 0.15232885840101662, 0.13809870666113855, 0.15517969717517477, 0.11413971844586901, 0.12245078328049219, 0.14688284767351745, 0.1284512986202797, 0.11876364137337736, 0.11241333395694963, 0.12155039247607347, 0.12681657239112176, 0.12347843940326964, 0.11814245563904291, 0.11475437406818367, 0.1184604231894184, 0.9874234129164956, 0.988775963023931, 0.9888377165355734, 0.9856976240702415, 0.9886797943992993, 0.9798248816945794, 0.9843516475449005, 0.9792571516732912, 0.9876278989703595, 0.574987503643695, 0.36236539684146163, 0.5598280834848447, 0.5333306681833292, 0.5869161621356457, 0.41290135386328375, 0.5647969674564006, 0.5319182427638542, 0.5514831017421311, 0.35166821444125373, 0.8088863576262215, 0.7498470625953779, 0.7838167045814698, 0.7335744601675944, 0.8720801345398781, 0.7971077661146184, 0.8136341453912295, 0.7330832549362336, 0.37616349355184775, 0.44573216332895094, 0.4256645392915912, 0.3755234518841395, 0.12712513770038336, 0.43919414519682776, 0.5323062714079179, 0.4564353894288965, 0.38483607581573354, 0.45654425797354603, 0.24102894690104082, 0.36877841016580637, 0.41202143560433946, 0.4011731964025135, 0.4094292308859071, 0.42515834039424294, 0.12787378640385905, 0.46751618513433024, 0.43931190266616005, 0.11907677004713513, 0.08462963710927363, 0.10296864385537685, 0.5018343580168942, 0.15752583221647598, 0.2043281620453602, 0.4265246341056622, 0.5070397195068126, 0.5550423913750391, 0.15433929385789724, 0.547887014935069, 0.2904022538128461, 0.5022872083750254, 0.25867005411518773, 0.6346643410274144, 0.23639098918948276, 0.5746054984985068, 0.11407980325712597, 0.04520801581034428, 0.0637175041077277, 0.12610842237279962, 0.19267263458538297, 0.26581780370465025, 0.1180591471567537, 0.13238964399108843, 0.13394321409626064, 0.2140676787240372, 0.3048848251704821, 0.3284412347909531, 0.3122908060609827, 0.24029939711003045, 0.29903786809230903, 0.2596462561830435, 0.29887689146203344, 0.20502659201201345, 0.692710933271237, 0.6889920786532941, 0.7101782607910303, 0.6167715725016916, 0.7118263741862114, 0.6591818280749686, 0.6486542541631908, 0.6098766279644814, 0.7108677174038628, 0.08459038225516557, 0.13828841609983644, 0.14089102894867866, 0.10558472212882664, 0.11718958330084828, 0.14205872277450726, 0.11595882493925858, 0.10462779878594208, 0.10027945708054753, 0.21082042329980788, 0.27019449220850855, 0.38780460015415397, 0.21790625764118454, 0.28452531124307456, 0.25447609519107595, 0.22186303474475855, 0.24238543877722207, 0.28227957674727255, 0.42110039637806407, 0.41295421612730265, 0.4348135635977971, 0.4285312717439306, 0.4335960432743873, 0.45737053765074265, 0.4670316987401285, 0.44955115252738787, 0.38956101714044566, 0.35307153811666725, 0.39733578395434, 0.31894459241213546, 0.2848809272189028, 0.19857500046836696, 0.3576677084428712, 0.38640134423118533, 0.3510280292107191, 0.3708795456214532, 0.20609929467634824, 0.19840129074252044, 0.18733417557415732, 0.21420735571712923, 0.20120315219167018, 0.21499467144149997, 0.2261047341666974, 0.19106703129556868, 0.22774327812644335, 0.19431687177135393, 0.5081442142304832, 0.5418807545956155, 0.22045106948895932, 0.23577356850188258, 0.48331630547375315, 0.4295719154123203, 0.21722885110021173, 0.22561090549837426, 0.84120936818493, 0.8246052515524153, 0.15365907878832352, 0.7584287726700076, 0.19773207571633888, 0.19473572510129877, 0.7474784313729328, 0.1699188842761722, 0.8136283511053167, 0.728069673372769, 0.16900123142277734, 0.796306663016825, 0.20612552074207746, 0.7512316653275415, 0.20919714311183368, 0.20312448297505548, 0.21134618292626584, 0.21235430771612906, 0.18744115569601416, 0.18416953756248333, 0.20322798131072473, 0.19195054504461473, 0.18110442905772872, 0.1989409021320092, 0.18592104279289523, 0.26051659353653156, 0.180219359644603, 0.08250401841628008, 0.08472686814662556, 0.07313885569068002, 0.08491506339076893, 0.08164601453501641, 0.07388060604354973, 0.09546596892887449, 0.09662588323739296, 0.08577158806399288]}, "mutation_prompt": null}
{"id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "solution": "import numpy as np\n\nclass DynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "DynamicSwarmPSO_DE", "description": "DynamicSwarmPSO_DE introduces feedback-driven parameter adaptation and incorporates a dynamic local search strategy to enhance convergence.", "configspace": "", "generation": 87, "fitness": 0.3900500046041931, "feedback": "The algorithm DynamicSwarmPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.25.", "error": "", "parent_id": "b0899110-29ee-441a-ad2d-6c040148af99", "metadata": {"aucs": [0.7597880341983425, 0.76207986376168, 0.7716661931496172, 0.7555863680086532, 0.761104797711877, 0.7841046162178851, 0.7874114338263496, 0.7726387800174962, 0.7434669592868286, 0.589507878272379, 0.5858687924312704, 0.6069473297293625, 0.6316345684340132, 0.5150471985577125, 0.5980701624516254, 0.5962541029669888, 0.5786796148900804, 0.557387243774261, 0.12319392662122175, 0.134860878374367, 0.14969784198711644, 0.11231961419176384, 0.12033251093326014, 0.12032017107898008, 0.14755872711067464, 0.42732249424162405, 0.12595436366963242, 0.12567971406581802, 0.11023837622149035, 0.11922263963311819, 0.10967891630271154, 0.11288761499340694, 0.12089963785662317, 0.0987485443875954, 0.12256160022891416, 0.1281637071440449, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.567468243420776, 0.3158490834832608, 0.5202059712732018, 0.5719542943672922, 0.6153274526109171, 0.5504971468283502, 0.5722107974778484, 0.5637564004178499, 0.5677624956505721, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21282665737290252, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.42519414746997797, 0.37959969146170724, 0.45254476548793654, 0.48101798521991945, 0.46296822345737176, 0.3706592866045719, 0.4640245163174369, 0.3459515699914565, 0.4743173062746062, 0.5365705918213252, 0.3399823206455459, 0.39287619517658123, 0.4631827835014044, 0.3964162365928964, 0.38382370994907034, 0.3706796595432821, 0.36216279166957477, 0.28148639791847085, 0.0686699243819916, 0.20478749808158414, 0.22368678298583278, 0.42947110872579497, 0.26080956375385156, 0.2437842264866894, 0.26026398343031265, 0.2655245545586655, 0.3039142505566865, 0.4250008778754897, 0.16257077913150575, 0.517153557733049, 0.47531049554167504, 0.38374900762665753, 0.23430340285186602, 0.6000809765031894, 0.5113502925326736, 0.5915360507424003, 0.16049974535981215, 0.21328906162630834, 0.09211519471164242, 0.2938838848811217, 0.18688399719671356, 0.1087191420895286, 0.23273409522291622, 0.20364087424979294, 0.1713851217313721, 0.3076637290491385, 0.2930643161431963, 0.3290061182349753, 0.27510065867483857, 0.3230324435109855, 0.3393580877465191, 0.32240672411191207, 0.33799419607028547, 0.3579397421306796, 0.6825893556558043, 0.642832454744809, 0.6734500887381816, 0.6453832546122819, 0.7152224672246028, 0.6337974487066219, 0.6748727777661232, 0.6692164487112122, 0.687888358012945, 0.1489035472887954, 0.12105900892467125, 0.439699425827646, 0.12840982667387835, 0.12464894344922195, 0.1269710439501468, 0.15051096118138452, 0.14057211944913106, 0.11689216090618904, 0.15261520864660338, 0.28852928949587986, 0.24656631199065338, 0.249141452158549, 0.17093789520736213, 0.17412606699499134, 0.18323616662640108, 0.26756513550939676, 0.1618538476332515, 0.44604229025299824, 0.5209315589738844, 0.3920824621770007, 0.47915228897350237, 0.48350388656427745, 0.4384768199180973, 0.5107606898036997, 0.46593071853954493, 0.45578232494186766, 0.31953052077959077, 0.34358887359053214, 0.2936162626723976, 0.3357753968323587, 0.3704852943575009, 0.3687880276024449, 0.19247626403410745, 0.3797218283192805, 0.37903642908583146, 0.2073857614205593, 0.1972011162009203, 0.21954984677615363, 0.23275347471255958, 0.2041920265325664, 0.21535086189601316, 0.19966016327686065, 0.20606848936720323, 0.24635182945824918, 0.21945428650532983, 0.5276675685435304, 0.2316110506905129, 0.5026734040956584, 0.20281324947457147, 0.19226015745062608, 0.5667067762918259, 0.18625450888098216, 0.22128264509257556, 0.2030229052786875, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.19713128047002015, 0.830319469752175, 0.15011103769935563, 0.6508104704380757, 0.7149845966301969, 0.20484828034828584, 0.20735119441450056, 0.20637329268578364, 0.8383298804401792, 0.1274043755976123, 0.20777856014718976, 0.20981316147643325, 0.1676819331675462, 0.20701157805303916, 0.17732870557464342, 0.22463775899366278, 0.18749639472230262, 0.186293760388357, 0.19608727681215454, 0.19097900728710904, 0.18483933446096457, 0.20374905459528858, 0.20369972523229318, 0.10280324883916203, 0.0848155244494404, 0.08670686178724041, 0.08195585636760994, 0.09674009193932254, 0.10270385986182395, 0.09025212066636612, 0.09863321712267847, 0.09337148246182692]}, "mutation_prompt": null}
{"id": "497847d2-e203-46c0-8d16-43227d2cc923", "solution": "import numpy as np\n\nclass EnhancedDynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n    \n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n        previous_positions = np.copy(swarm)\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n        \n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c) + 0.5 * (a - previous_positions[i])\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n                previous_positions[i] = np.copy(swarm[i])\n\n        return global_best_position", "name": "EnhancedDynamicSwarmPSO_DE", "description": "EnhancedDynamicSwarmPSO_DE employs adaptive multi-phase swarm dynamics with probabilistic local search and memory-based mutation for robust convergence.", "configspace": "", "generation": 88, "fitness": 0.275185142635081, "feedback": "The algorithm EnhancedDynamicSwarmPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.23.", "error": "", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.6308519479791146, 0.6342228673932296, 0.6466262172897768, 0.6785367969685425, 0.678285545784149, 0.7114086860314186, 0.6923570584929376, 0.675859075800717, 0.682011389763994, 0.3227909782627181, 0.3716754820061319, 0.3395065027159917, 0.3150730322011759, 0.36866197399493716, 0.4175538062855535, 0.43629750789771593, 0.3994492973834294, 0.36935836012561285, 0.1248243406224625, 0.11495302296686949, 0.10938355104348063, 0.12412101531679831, 0.12752194672387673, 0.10733845022224409, 0.1160660440033795, 0.12136182247703708, 0.0897410915080381, 0.10451370814733674, 0.09038882205853516, 0.08191114611796912, 0.10743475794102997, 0.12624065043393018, 0.10768236275232534, 0.1087209442463769, 0.09545432245084318, 0.10688313020552487, 0.9805430472736041, 0.9833386647664291, 0.9929918308469065, 0.9780013785671046, 0.9908555613331194, 0.9792599363523025, 0.990147900191, 0.984454997905355, 0.9827422530504344, 0.4431927293873261, 0.46280471592755934, 0.4344178113113336, 0.4574577655764819, 0.4013045440314138, 0.3624662181874926, 0.49390461322997303, 0.29212513589179934, 0.3806193194527474, 0.6925730192840205, 0.5985997231132709, 0.5469440999734311, 0.20363230112271113, 0.5391345277003263, 0.44724788115688197, 0.5657566351625296, 0.5954904232903804, 0.520179693539452, 0.2166937548203608, 0.2950403466558842, 0.22099174327449222, 0.2027277261811068, 0.2023196223130499, 0.20439528054219003, 0.2255771950603479, 0.19871092860328077, 0.18514377610381394, 0.24633656773660262, 0.17775594442815668, 0.20926745503318067, 0.20762036537067985, 0.15847292403704838, 0.1904329348132664, 0.22588893905379026, 0.21334199933651643, 0.12388702420641129, 9.999999999998899e-05, 0.02641745625183134, 9.999999999998899e-05, 0.008159285303052988, 0.01508118633947142, 0.01073996521529752, 0.0005964489642127369, 0.03903442893081088, 0.026321043780299314, 0.13197471010925144, 0.07099930040232871, 0.1057617202945228, 0.09239756674615907, 0.0674973920460703, 0.054804013252874206, 0.12925161313880185, 0.13014394971905896, 0.06977779763256609, 0.081160571588623, 0.10013895831263109, 0.028506558162241125, 0.053031608528525065, 0.06572597192376617, 0.06074623897731812, 0.025189146933364825, 0.0329698675072263, 0.04202847893644557, 0.17911794900280564, 0.11028315039883252, 0.1847237487624871, 0.11744882377782939, 0.1608586099074939, 0.15880073997193522, 0.17344677718253465, 0.10883123316483556, 0.06979772112900795, 0.44687647609535674, 0.496411346860247, 0.4846732847959948, 0.5095323748551571, 0.49206310891031846, 0.4786290572682508, 0.4660080198876001, 0.4982794806417774, 0.4887218452804477, 0.13482509339452864, 0.10462760659695869, 0.09807127460985798, 0.08581902963434207, 0.10172805482381064, 0.08654590859500855, 0.11683548256090415, 0.09645343895824754, 0.11696971805439282, 0.22863924666599988, 0.16125931293958407, 0.16102089177191226, 0.15566912173965497, 0.22357599686744556, 0.18249373055757556, 0.15209667370858682, 0.1934771300880227, 0.14917049864980414, 0.36930185633298573, 0.4010458961075829, 0.3361273785649854, 0.34775243212262696, 0.3285901176330107, 0.37741878718704547, 0.3900418581802134, 0.39435516467646925, 0.40493094761348425, 0.23713615090057916, 0.23481752301165648, 0.2907797053937343, 0.2399417132296855, 0.1801891559953629, 0.25064452325438724, 0.2518797683264875, 0.265818361634074, 0.2509631382031561, 0.20011691276045207, 0.2174356347262154, 0.206909061265954, 0.1882206018415502, 0.20559696919957682, 0.215907405154658, 0.201836336556786, 0.22761102253213072, 0.20824887106673318, 0.2211670622138927, 0.5542898823539406, 0.21179537891419897, 0.243931817992887, 0.19244627597562214, 0.1975172566159289, 0.20470761631013934, 0.19164102466063537, 0.1962943884490551, 0.18257163485257966, 0.17771970465199716, 0.13870480805607144, 0.7724713913180349, 0.19027693487870445, 0.6263516473418678, 0.15703781994364907, 0.6710329175461369, 0.18446511758643924, 0.4846695606215934, 0.1639603962857349, 0.14667124686092647, 0.46800613195364626, 0.12580194795383481, 0.19593329111145708, 0.20436859501057592, 0.20357064968888416, 0.2071365104561823, 0.19362056236076353, 0.20710741103516883, 0.1942520270287481, 0.19071055573671736, 0.19042789217818734, 0.19630824318553708, 0.21593278054724718, 0.1948188051553129, 0.19468229334064668, 0.0820666987493387, 0.07496077210223206, 0.08586070987182504, 0.08036082905711972, 0.08273342942775685, 0.07754482206042834, 0.08902087910414869, 0.08515418983114176, 0.08397345741191453]}, "mutation_prompt": null}
{"id": "fa29e0e6-a290-49c3-868b-465812bf5be8", "solution": "import numpy as np\n\nclass DynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "DynamicSwarmPSO_DE", "description": "DynamicSwarmPSO_DE introduces feedback-driven parameter adaptation and incorporates a dynamic local search strategy to enhance convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7597880341983425, 0.76207986376168, 0.7716661931496172, 0.7555863680086532, 0.761104797711877, 0.7841046162178851, 0.7874114338263496, 0.7726387800174962, 0.7434669592868286, 0.589507878272379, 0.5858687924312704, 0.6069473297293625, 0.6316345684340132, 0.5150471985577125, 0.5980701624516254, 0.5962541029669888, 0.5786796148900804, 0.557387243774261, 0.12319392662122175, 0.134860878374367, 0.14969784198711644, 0.11231961419176384, 0.12033251093326014, 0.12032017107898008, 0.14755872711067464, 0.42732249424162405, 0.12595436366963242, 0.12567971406581802, 0.11023837622149035, 0.11922263963311819, 0.10967891630271154, 0.11288761499340694, 0.12089963785662317, 0.0987485443875954, 0.12256160022891416, 0.1281637071440449, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.567468243420776, 0.3158490834832608, 0.5202059712732018, 0.5719542943672922, 0.6153274526109171, 0.5504971468283502, 0.5722107974778484, 0.5637564004178499, 0.5677624956505721, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21282665737290252, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.42519414746997797, 0.37959969146170724, 0.45254476548793654, 0.48101798521991945, 0.46296822345737176, 0.3706592866045719, 0.4640245163174369, 0.3459515699914565, 0.4743173062746062, 0.5365705918213252, 0.3399823206455459, 0.39287619517658123, 0.4631827835014044, 0.3964162365928964, 0.38382370994907034, 0.3706796595432821, 0.36216279166957477, 0.28148639791847085, 0.0686699243819916, 0.20478749808158414, 0.22368678298583278, 0.42947110872579497, 0.26080956375385156, 0.2437842264866894, 0.26026398343031265, 0.2655245545586655, 0.3039142505566865, 0.4250008778754897, 0.16257077913150575, 0.517153557733049, 0.47531049554167504, 0.38374900762665753, 0.23430340285186602, 0.6000809765031894, 0.5113502925326736, 0.5915360507424003, 0.16049974535981215, 0.21328906162630834, 0.09211519471164242, 0.2938838848811217, 0.18688399719671356, 0.1087191420895286, 0.23273409522291622, 0.20364087424979294, 0.1713851217313721, 0.3076637290491385, 0.2930643161431963, 0.3290061182349753, 0.27510065867483857, 0.3230324435109855, 0.3393580877465191, 0.32240672411191207, 0.33799419607028547, 0.3579397421306796, 0.6825893556558043, 0.642832454744809, 0.6734500887381816, 0.6453832546122819, 0.7152224672246028, 0.6337974487066219, 0.6748727777661232, 0.6692164487112122, 0.687888358012945, 0.1489035472887954, 0.12105900892467125, 0.439699425827646, 0.12840982667387835, 0.12464894344922195, 0.1269710439501468, 0.15051096118138452, 0.14057211944913106, 0.11689216090618904, 0.15261520864660338, 0.28852928949587986, 0.24656631199065338, 0.249141452158549, 0.17093789520736213, 0.17412606699499134, 0.18323616662640108, 0.26756513550939676, 0.1618538476332515, 0.44604229025299824, 0.5209315589738844, 0.3920824621770007, 0.47915228897350237, 0.48350388656427745, 0.4384768199180973, 0.5107606898036997, 0.46593071853954493, 0.45578232494186766, 0.31953052077959077, 0.34358887359053214, 0.2936162626723976, 0.3357753968323587, 0.3704852943575009, 0.3687880276024449, 0.19247626403410745, 0.3797218283192805, 0.37903642908583146, 0.2073857614205593, 0.1972011162009203, 0.21954984677615363, 0.23275347471255958, 0.2041920265325664, 0.21535086189601316, 0.19966016327686065, 0.20606848936720323, 0.24635182945824918, 0.21945428650532983, 0.5276675685435304, 0.2316110506905129, 0.5026734040956584, 0.20281324947457147, 0.19226015745062608, 0.5667067762918259, 0.18625450888098216, 0.22128264509257556, 0.2030229052786875, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.19713128047002015, 0.830319469752175, 0.15011103769935563, 0.6508104704380757, 0.7149845966301969, 0.20484828034828584, 0.20735119441450056, 0.20637329268578364, 0.8383298804401792, 0.1274043755976123, 0.20777856014718976, 0.20981316147643325, 0.1676819331675462, 0.20701157805303916, 0.17732870557464342, 0.22463775899366278, 0.18749639472230262, 0.186293760388357, 0.19608727681215454, 0.19097900728710904, 0.18483933446096457, 0.20374905459528858, 0.20369972523229318, 0.10280324883916203, 0.0848155244494404, 0.08670686178724041, 0.08195585636760994, 0.09674009193932254, 0.10270385986182395, 0.09025212066636612, 0.09863321712267847, 0.09337148246182692]}, "mutation_prompt": null}
{"id": "a28cd004-dc8b-4cf7-9551-de3ae610eed9", "solution": "import numpy as np\n\nclass DynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "DynamicSwarmPSO_DE", "description": "DynamicSwarmPSO_DE introduces feedback-driven parameter adaptation and incorporates a dynamic local search strategy to enhance convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7597880341983425, 0.76207986376168, 0.7716661931496172, 0.7555863680086532, 0.761104797711877, 0.7841046162178851, 0.7874114338263496, 0.7726387800174962, 0.7434669592868286, 0.589507878272379, 0.5858687924312704, 0.6069473297293625, 0.6316345684340132, 0.5150471985577125, 0.5980701624516254, 0.5962541029669888, 0.5786796148900804, 0.557387243774261, 0.12319392662122175, 0.134860878374367, 0.14969784198711644, 0.11231961419176384, 0.12033251093326014, 0.12032017107898008, 0.14755872711067464, 0.42732249424162405, 0.12595436366963242, 0.12567971406581802, 0.11023837622149035, 0.11922263963311819, 0.10967891630271154, 0.11288761499340694, 0.12089963785662317, 0.0987485443875954, 0.12256160022891416, 0.1281637071440449, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.567468243420776, 0.3158490834832608, 0.5202059712732018, 0.5719542943672922, 0.6153274526109171, 0.5504971468283502, 0.5722107974778484, 0.5637564004178499, 0.5677624956505721, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21282665737290252, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.42519414746997797, 0.37959969146170724, 0.45254476548793654, 0.48101798521991945, 0.46296822345737176, 0.3706592866045719, 0.4640245163174369, 0.3459515699914565, 0.4743173062746062, 0.5365705918213252, 0.3399823206455459, 0.39287619517658123, 0.4631827835014044, 0.3964162365928964, 0.38382370994907034, 0.3706796595432821, 0.36216279166957477, 0.28148639791847085, 0.0686699243819916, 0.20478749808158414, 0.22368678298583278, 0.42947110872579497, 0.26080956375385156, 0.2437842264866894, 0.26026398343031265, 0.2655245545586655, 0.3039142505566865, 0.4250008778754897, 0.16257077913150575, 0.517153557733049, 0.47531049554167504, 0.38374900762665753, 0.23430340285186602, 0.6000809765031894, 0.5113502925326736, 0.5915360507424003, 0.16049974535981215, 0.21328906162630834, 0.09211519471164242, 0.2938838848811217, 0.18688399719671356, 0.1087191420895286, 0.23273409522291622, 0.20364087424979294, 0.1713851217313721, 0.3076637290491385, 0.2930643161431963, 0.3290061182349753, 0.27510065867483857, 0.3230324435109855, 0.3393580877465191, 0.32240672411191207, 0.33799419607028547, 0.3579397421306796, 0.6825893556558043, 0.642832454744809, 0.6734500887381816, 0.6453832546122819, 0.7152224672246028, 0.6337974487066219, 0.6748727777661232, 0.6692164487112122, 0.687888358012945, 0.1489035472887954, 0.12105900892467125, 0.439699425827646, 0.12840982667387835, 0.12464894344922195, 0.1269710439501468, 0.15051096118138452, 0.14057211944913106, 0.11689216090618904, 0.15261520864660338, 0.28852928949587986, 0.24656631199065338, 0.249141452158549, 0.17093789520736213, 0.17412606699499134, 0.18323616662640108, 0.26756513550939676, 0.1618538476332515, 0.44604229025299824, 0.5209315589738844, 0.3920824621770007, 0.47915228897350237, 0.48350388656427745, 0.4384768199180973, 0.5107606898036997, 0.46593071853954493, 0.45578232494186766, 0.31953052077959077, 0.34358887359053214, 0.2936162626723976, 0.3357753968323587, 0.3704852943575009, 0.3687880276024449, 0.19247626403410745, 0.3797218283192805, 0.37903642908583146, 0.2073857614205593, 0.1972011162009203, 0.21954984677615363, 0.23275347471255958, 0.2041920265325664, 0.21535086189601316, 0.19966016327686065, 0.20606848936720323, 0.24635182945824918, 0.21945428650532983, 0.5276675685435304, 0.2316110506905129, 0.5026734040956584, 0.20281324947457147, 0.19226015745062608, 0.5667067762918259, 0.18625450888098216, 0.22128264509257556, 0.2030229052786875, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.19713128047002015, 0.830319469752175, 0.15011103769935563, 0.6508104704380757, 0.7149845966301969, 0.20484828034828584, 0.20735119441450056, 0.20637329268578364, 0.8383298804401792, 0.1274043755976123, 0.20777856014718976, 0.20981316147643325, 0.1676819331675462, 0.20701157805303916, 0.17732870557464342, 0.22463775899366278, 0.18749639472230262, 0.186293760388357, 0.19608727681215454, 0.19097900728710904, 0.18483933446096457, 0.20374905459528858, 0.20369972523229318, 0.10280324883916203, 0.0848155244494404, 0.08670686178724041, 0.08195585636760994, 0.09674009193932254, 0.10270385986182395, 0.09025212066636612, 0.09863321712267847, 0.09337148246182692]}, "mutation_prompt": null}
{"id": "c47d0c9e-8622-40fe-8c4f-fac5a570679e", "solution": "import numpy as np\n\nclass DynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "DynamicSwarmPSO_DE", "description": "DynamicSwarmPSO_DE introduces feedback-driven parameter adaptation and incorporates a dynamic local search strategy to enhance convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7597880341983425, 0.76207986376168, 0.7716661931496172, 0.7555863680086532, 0.761104797711877, 0.7841046162178851, 0.7874114338263496, 0.7726387800174962, 0.7434669592868286, 0.589507878272379, 0.5858687924312704, 0.6069473297293625, 0.6316345684340132, 0.5150471985577125, 0.5980701624516254, 0.5962541029669888, 0.5786796148900804, 0.557387243774261, 0.12319392662122175, 0.134860878374367, 0.14969784198711644, 0.11231961419176384, 0.12033251093326014, 0.12032017107898008, 0.14755872711067464, 0.42732249424162405, 0.12595436366963242, 0.12567971406581802, 0.11023837622149035, 0.11922263963311819, 0.10967891630271154, 0.11288761499340694, 0.12089963785662317, 0.0987485443875954, 0.12256160022891416, 0.1281637071440449, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.567468243420776, 0.3158490834832608, 0.5202059712732018, 0.5719542943672922, 0.6153274526109171, 0.5504971468283502, 0.5722107974778484, 0.5637564004178499, 0.5677624956505721, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21282665737290252, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.42519414746997797, 0.37959969146170724, 0.45254476548793654, 0.48101798521991945, 0.46296822345737176, 0.3706592866045719, 0.4640245163174369, 0.3459515699914565, 0.4743173062746062, 0.5365705918213252, 0.3399823206455459, 0.39287619517658123, 0.4631827835014044, 0.3964162365928964, 0.38382370994907034, 0.3706796595432821, 0.36216279166957477, 0.28148639791847085, 0.0686699243819916, 0.20478749808158414, 0.22368678298583278, 0.42947110872579497, 0.26080956375385156, 0.2437842264866894, 0.26026398343031265, 0.2655245545586655, 0.3039142505566865, 0.4250008778754897, 0.16257077913150575, 0.517153557733049, 0.47531049554167504, 0.38374900762665753, 0.23430340285186602, 0.6000809765031894, 0.5113502925326736, 0.5915360507424003, 0.16049974535981215, 0.21328906162630834, 0.09211519471164242, 0.2938838848811217, 0.18688399719671356, 0.1087191420895286, 0.23273409522291622, 0.20364087424979294, 0.1713851217313721, 0.3076637290491385, 0.2930643161431963, 0.3290061182349753, 0.27510065867483857, 0.3230324435109855, 0.3393580877465191, 0.32240672411191207, 0.33799419607028547, 0.3579397421306796, 0.6825893556558043, 0.642832454744809, 0.6734500887381816, 0.6453832546122819, 0.7152224672246028, 0.6337974487066219, 0.6748727777661232, 0.6692164487112122, 0.687888358012945, 0.1489035472887954, 0.12105900892467125, 0.439699425827646, 0.12840982667387835, 0.12464894344922195, 0.1269710439501468, 0.15051096118138452, 0.14057211944913106, 0.11689216090618904, 0.15261520864660338, 0.28852928949587986, 0.24656631199065338, 0.249141452158549, 0.17093789520736213, 0.17412606699499134, 0.18323616662640108, 0.26756513550939676, 0.1618538476332515, 0.44604229025299824, 0.5209315589738844, 0.3920824621770007, 0.47915228897350237, 0.48350388656427745, 0.4384768199180973, 0.5107606898036997, 0.46593071853954493, 0.45578232494186766, 0.31953052077959077, 0.34358887359053214, 0.2936162626723976, 0.3357753968323587, 0.3704852943575009, 0.3687880276024449, 0.19247626403410745, 0.3797218283192805, 0.37903642908583146, 0.2073857614205593, 0.1972011162009203, 0.21954984677615363, 0.23275347471255958, 0.2041920265325664, 0.21535086189601316, 0.19966016327686065, 0.20606848936720323, 0.24635182945824918, 0.21945428650532983, 0.5276675685435304, 0.2316110506905129, 0.5026734040956584, 0.20281324947457147, 0.19226015745062608, 0.5667067762918259, 0.18625450888098216, 0.22128264509257556, 0.2030229052786875, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.19713128047002015, 0.830319469752175, 0.15011103769935563, 0.6508104704380757, 0.7149845966301969, 0.20484828034828584, 0.20735119441450056, 0.20637329268578364, 0.8383298804401792, 0.1274043755976123, 0.20777856014718976, 0.20981316147643325, 0.1676819331675462, 0.20701157805303916, 0.17732870557464342, 0.22463775899366278, 0.18749639472230262, 0.186293760388357, 0.19608727681215454, 0.19097900728710904, 0.18483933446096457, 0.20374905459528858, 0.20369972523229318, 0.10280324883916203, 0.0848155244494404, 0.08670686178724041, 0.08195585636760994, 0.09674009193932254, 0.10270385986182395, 0.09025212066636612, 0.09863321712267847, 0.09337148246182692]}, "mutation_prompt": null}
{"id": "1a1b185d-3a4c-4ec1-9002-66a4e74d0783", "solution": "import numpy as np\n\nclass AdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 25\n        self.c1_start = 2.5\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.5\n        self.w_start = 0.8\n        self.w_end = 0.3\n        self.F_start = 0.4\n        self.F_end = 0.9\n        self.CR_start = 0.7\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.6\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1 + 0.1 * (1 - self.num_evals / self.budget), self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "AdaptiveHybridPSO_DE", "description": "AdaptiveHybridPSO_DE leverages multi-stage adaptation with enhanced local search and strategic crossover to improve convergence across diverse problem landscapes.", "configspace": "", "generation": 92, "fitness": 0.3760084738404455, "feedback": "The algorithm AdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.25.", "error": "", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7453871564876708, 0.7601692557795674, 0.770490281065932, 0.7752038778643401, 0.7755791696989014, 0.7522720657208108, 0.7552182150048831, 0.7631934187462566, 0.7683079690114142, 0.5917837189054346, 0.5956371699773864, 0.5704102370306956, 0.5673830672241678, 0.555952976861868, 0.5645815827890321, 0.5661253626439537, 0.566815595851095, 0.5659592317144027, 0.14934261983894281, 0.14346782915912448, 0.13406068676820304, 0.3855835879775914, 0.15043623569558917, 0.4262947312462324, 0.1541033880459547, 0.12886697446922957, 0.149106887806275, 0.15227214044858395, 0.12078660480366687, 0.10745332906972249, 0.1076476755864898, 0.13405326409034957, 0.12553272191800713, 0.11493779097499446, 0.11558759353930304, 0.15409698854213671, 0.9764685808705882, 0.9839147497909126, 0.9734323084515022, 0.9783021959646533, 0.9759618193644567, 0.9774428304869278, 0.9784397843869381, 0.9765878820417165, 0.9796777705194242, 0.5704507981031172, 0.560587399863264, 0.5470917920790366, 0.5838853028707711, 0.5657977027489347, 0.5850558034270187, 0.5601892301409659, 0.5533400056521756, 0.5467465445394406, 0.7230956423658906, 0.2098507216920189, 0.7722607782506499, 0.736839796562311, 0.2617848306745415, 0.7703708843419523, 0.23503431870283986, 0.23074514358974318, 0.7900342986447235, 0.4519904007185638, 0.3426686037041038, 0.3494758788140784, 0.35815975526649646, 0.4438763207923079, 0.32304291906433313, 0.36474300409759564, 0.30552005132024884, 0.40108848987014367, 0.33584305407720516, 0.2683842803256793, 0.39386738056139015, 0.3316101987855481, 0.29511586517369304, 0.370396769715609, 0.3418048436589831, 0.11188311215328572, 0.4074621306826104, 0.3287003351761446, 0.1941344591912162, 0.31662347777750177, 0.10310341633206244, 0.2525787929543212, 0.1829351419856028, 0.2724545513664709, 0.23287935594908515, 0.24294505946752842, 0.39488046364326845, 0.32681578723115157, 0.5253011326332329, 0.28842670011073457, 0.3025941350393415, 0.14670104898259073, 0.4084781161894524, 0.41964655673102513, 0.47373376359749453, 0.05518906420530234, 0.1535924997784297, 0.13390608136253446, 0.1486067374624236, 0.16662458550395753, 0.07823988439793816, 0.14418212439908207, 0.1471726936550264, 0.0845065899198536, 0.21127862109165108, 0.2890645202432752, 0.2480312754548114, 0.2774674784956286, 0.26879054375218436, 0.27280476868432413, 0.22925905902354682, 0.23848533291088414, 0.1997891256294828, 0.6310518770750859, 0.6481570080160566, 0.6503160920510185, 0.6147732018770409, 0.6444330819547321, 0.6078686134992791, 0.6609569393681478, 0.6475797174926199, 0.6164461420982714, 0.1246890490074154, 0.11791783043564008, 0.13343607191043882, 0.13732534678865682, 0.12267072624075759, 0.12659120957822345, 0.11530722351729161, 0.1469190199371444, 0.12535806416717699, 0.14726349666027094, 0.18928366912860684, 0.27638043985167815, 0.24417463453004895, 0.19960672360134157, 0.32936108428511757, 0.19244267949828942, 0.2949236612611582, 0.23390647430763534, 0.4655141511667872, 0.4538733287444572, 0.4787518805554404, 0.5045840494701188, 0.43580245844783005, 0.4554255482055404, 0.49998724087403934, 0.4785787368620502, 0.4536225291551086, 0.3218981126670122, 0.2690080523034504, 0.33906515021827677, 0.3239296872510804, 0.22709190122305567, 0.3694020580735289, 0.3363714254718587, 0.3245285527749888, 0.3692510447598292, 0.24629416308801033, 0.247213214844752, 0.21967681704562025, 0.20132554069176622, 0.21317898727980233, 0.1977907747556965, 0.22125267822049877, 0.20317581998259715, 0.21816149086770975, 0.2279705467534423, 0.19833221726824568, 0.19064489285757413, 0.2236471618743181, 0.22446120208727416, 0.20107304798712589, 0.23454840889028372, 0.22968695584142373, 0.1882144241696747, 0.7664106089048524, 0.1820371198567594, 0.7203952498308948, 0.8248610068804498, 0.8088835108918508, 0.19879516247754592, 0.5613008237081146, 0.789805034176304, 0.7806302994226763, 0.7609975638254303, 0.19923582128795148, 0.8194321062805011, 0.6850440107277207, 0.760551925027847, 0.21070817361954575, 0.15206625378327754, 0.7241320889883389, 0.21079861053524696, 0.1877184436771876, 0.1803688262706975, 0.1908592845486149, 0.19074228971652296, 0.18665863858536524, 0.1908436194007067, 0.21233399552171894, 0.2080881436259049, 0.19414166388907017, 0.08998222566117253, 0.08304380232253517, 0.09121528468761375, 0.09724080521123757, 0.0825530478369002, 0.08753627559586608, 0.10299438408285277, 0.09244074519834944, 0.0961625150140184]}, "mutation_prompt": null}
{"id": "2a01b726-6752-4285-9b58-a7e63a5b7d42", "solution": "import numpy as np\n\nclass DynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "DynamicSwarmPSO_DE", "description": "DynamicSwarmPSO_DE introduces feedback-driven parameter adaptation and incorporates a dynamic local search strategy to enhance convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7597880341983425, 0.76207986376168, 0.7716661931496172, 0.7555863680086532, 0.761104797711877, 0.7841046162178851, 0.7874114338263496, 0.7726387800174962, 0.7434669592868286, 0.589507878272379, 0.5858687924312704, 0.6069473297293625, 0.6316345684340132, 0.5150471985577125, 0.5980701624516254, 0.5962541029669888, 0.5786796148900804, 0.557387243774261, 0.12319392662122175, 0.134860878374367, 0.14969784198711644, 0.11231961419176384, 0.12033251093326014, 0.12032017107898008, 0.14755872711067464, 0.42732249424162405, 0.12595436366963242, 0.12567971406581802, 0.11023837622149035, 0.11922263963311819, 0.10967891630271154, 0.11288761499340694, 0.12089963785662317, 0.0987485443875954, 0.12256160022891416, 0.1281637071440449, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.567468243420776, 0.3158490834832608, 0.5202059712732018, 0.5719542943672922, 0.6153274526109171, 0.5504971468283502, 0.5722107974778484, 0.5637564004178499, 0.5677624956505721, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21282665737290252, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.42519414746997797, 0.37959969146170724, 0.45254476548793654, 0.48101798521991945, 0.46296822345737176, 0.3706592866045719, 0.4640245163174369, 0.3459515699914565, 0.4743173062746062, 0.5365705918213252, 0.3399823206455459, 0.39287619517658123, 0.4631827835014044, 0.3964162365928964, 0.38382370994907034, 0.3706796595432821, 0.36216279166957477, 0.28148639791847085, 0.0686699243819916, 0.20478749808158414, 0.22368678298583278, 0.42947110872579497, 0.26080956375385156, 0.2437842264866894, 0.26026398343031265, 0.2655245545586655, 0.3039142505566865, 0.4250008778754897, 0.16257077913150575, 0.517153557733049, 0.47531049554167504, 0.38374900762665753, 0.23430340285186602, 0.6000809765031894, 0.5113502925326736, 0.5915360507424003, 0.16049974535981215, 0.21328906162630834, 0.09211519471164242, 0.2938838848811217, 0.18688399719671356, 0.1087191420895286, 0.23273409522291622, 0.20364087424979294, 0.1713851217313721, 0.3076637290491385, 0.2930643161431963, 0.3290061182349753, 0.27510065867483857, 0.3230324435109855, 0.3393580877465191, 0.32240672411191207, 0.33799419607028547, 0.3579397421306796, 0.6825893556558043, 0.642832454744809, 0.6734500887381816, 0.6453832546122819, 0.7152224672246028, 0.6337974487066219, 0.6748727777661232, 0.6692164487112122, 0.687888358012945, 0.1489035472887954, 0.12105900892467125, 0.439699425827646, 0.12840982667387835, 0.12464894344922195, 0.1269710439501468, 0.15051096118138452, 0.14057211944913106, 0.11689216090618904, 0.15261520864660338, 0.28852928949587986, 0.24656631199065338, 0.249141452158549, 0.17093789520736213, 0.17412606699499134, 0.18323616662640108, 0.26756513550939676, 0.1618538476332515, 0.44604229025299824, 0.5209315589738844, 0.3920824621770007, 0.47915228897350237, 0.48350388656427745, 0.4384768199180973, 0.5107606898036997, 0.46593071853954493, 0.45578232494186766, 0.31953052077959077, 0.34358887359053214, 0.2936162626723976, 0.3357753968323587, 0.3704852943575009, 0.3687880276024449, 0.19247626403410745, 0.3797218283192805, 0.37903642908583146, 0.2073857614205593, 0.1972011162009203, 0.21954984677615363, 0.23275347471255958, 0.2041920265325664, 0.21535086189601316, 0.19966016327686065, 0.20606848936720323, 0.24635182945824918, 0.21945428650532983, 0.5276675685435304, 0.2316110506905129, 0.5026734040956584, 0.20281324947457147, 0.19226015745062608, 0.5667067762918259, 0.18625450888098216, 0.22128264509257556, 0.2030229052786875, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.19713128047002015, 0.830319469752175, 0.15011103769935563, 0.6508104704380757, 0.7149845966301969, 0.20484828034828584, 0.20735119441450056, 0.20637329268578364, 0.8383298804401792, 0.1274043755976123, 0.20777856014718976, 0.20981316147643325, 0.1676819331675462, 0.20701157805303916, 0.17732870557464342, 0.22463775899366278, 0.18749639472230262, 0.186293760388357, 0.19608727681215454, 0.19097900728710904, 0.18483933446096457, 0.20374905459528858, 0.20369972523229318, 0.10280324883916203, 0.0848155244494404, 0.08670686178724041, 0.08195585636760994, 0.09674009193932254, 0.10270385986182395, 0.09025212066636612, 0.09863321712267847, 0.09337148246182692]}, "mutation_prompt": null}
{"id": "89029a90-5d80-4461-80a6-9ad6334a645d", "solution": "import numpy as np\n\nclass DynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "DynamicSwarmPSO_DE", "description": "DynamicSwarmPSO_DE introduces feedback-driven parameter adaptation and incorporates a dynamic local search strategy to enhance convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7597880341983425, 0.76207986376168, 0.7716661931496172, 0.7555863680086532, 0.761104797711877, 0.7841046162178851, 0.7874114338263496, 0.7726387800174962, 0.7434669592868286, 0.589507878272379, 0.5858687924312704, 0.6069473297293625, 0.6316345684340132, 0.5150471985577125, 0.5980701624516254, 0.5962541029669888, 0.5786796148900804, 0.557387243774261, 0.12319392662122175, 0.134860878374367, 0.14969784198711644, 0.11231961419176384, 0.12033251093326014, 0.12032017107898008, 0.14755872711067464, 0.42732249424162405, 0.12595436366963242, 0.12567971406581802, 0.11023837622149035, 0.11922263963311819, 0.10967891630271154, 0.11288761499340694, 0.12089963785662317, 0.0987485443875954, 0.12256160022891416, 0.1281637071440449, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.567468243420776, 0.3158490834832608, 0.5202059712732018, 0.5719542943672922, 0.6153274526109171, 0.5504971468283502, 0.5722107974778484, 0.5637564004178499, 0.5677624956505721, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21282665737290252, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.42519414746997797, 0.37959969146170724, 0.45254476548793654, 0.48101798521991945, 0.46296822345737176, 0.3706592866045719, 0.4640245163174369, 0.3459515699914565, 0.4743173062746062, 0.5365705918213252, 0.3399823206455459, 0.39287619517658123, 0.4631827835014044, 0.3964162365928964, 0.38382370994907034, 0.3706796595432821, 0.36216279166957477, 0.28148639791847085, 0.0686699243819916, 0.20478749808158414, 0.22368678298583278, 0.42947110872579497, 0.26080956375385156, 0.2437842264866894, 0.26026398343031265, 0.2655245545586655, 0.3039142505566865, 0.4250008778754897, 0.16257077913150575, 0.517153557733049, 0.47531049554167504, 0.38374900762665753, 0.23430340285186602, 0.6000809765031894, 0.5113502925326736, 0.5915360507424003, 0.16049974535981215, 0.21328906162630834, 0.09211519471164242, 0.2938838848811217, 0.18688399719671356, 0.1087191420895286, 0.23273409522291622, 0.20364087424979294, 0.1713851217313721, 0.3076637290491385, 0.2930643161431963, 0.3290061182349753, 0.27510065867483857, 0.3230324435109855, 0.3393580877465191, 0.32240672411191207, 0.33799419607028547, 0.3579397421306796, 0.6825893556558043, 0.642832454744809, 0.6734500887381816, 0.6453832546122819, 0.7152224672246028, 0.6337974487066219, 0.6748727777661232, 0.6692164487112122, 0.687888358012945, 0.1489035472887954, 0.12105900892467125, 0.439699425827646, 0.12840982667387835, 0.12464894344922195, 0.1269710439501468, 0.15051096118138452, 0.14057211944913106, 0.11689216090618904, 0.15261520864660338, 0.28852928949587986, 0.24656631199065338, 0.249141452158549, 0.17093789520736213, 0.17412606699499134, 0.18323616662640108, 0.26756513550939676, 0.1618538476332515, 0.44604229025299824, 0.5209315589738844, 0.3920824621770007, 0.47915228897350237, 0.48350388656427745, 0.4384768199180973, 0.5107606898036997, 0.46593071853954493, 0.45578232494186766, 0.31953052077959077, 0.34358887359053214, 0.2936162626723976, 0.3357753968323587, 0.3704852943575009, 0.3687880276024449, 0.19247626403410745, 0.3797218283192805, 0.37903642908583146, 0.2073857614205593, 0.1972011162009203, 0.21954984677615363, 0.23275347471255958, 0.2041920265325664, 0.21535086189601316, 0.19966016327686065, 0.20606848936720323, 0.24635182945824918, 0.21945428650532983, 0.5276675685435304, 0.2316110506905129, 0.5026734040956584, 0.20281324947457147, 0.19226015745062608, 0.5667067762918259, 0.18625450888098216, 0.22128264509257556, 0.2030229052786875, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.19713128047002015, 0.830319469752175, 0.15011103769935563, 0.6508104704380757, 0.7149845966301969, 0.20484828034828584, 0.20735119441450056, 0.20637329268578364, 0.8383298804401792, 0.1274043755976123, 0.20777856014718976, 0.20981316147643325, 0.1676819331675462, 0.20701157805303916, 0.17732870557464342, 0.22463775899366278, 0.18749639472230262, 0.186293760388357, 0.19608727681215454, 0.19097900728710904, 0.18483933446096457, 0.20374905459528858, 0.20369972523229318, 0.10280324883916203, 0.0848155244494404, 0.08670686178724041, 0.08195585636760994, 0.09674009193932254, 0.10270385986182395, 0.09025212066636612, 0.09863321712267847, 0.09337148246182692]}, "mutation_prompt": null}
{"id": "a5d61fc8-9f47-4fcb-a2ff-c58eba39d844", "solution": "import numpy as np\n\nclass SelfAdaptiveHybridPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n\n    def __call__(self, func):\n        def random_init_population():\n            return np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n\n        def adapt_parameters(iteration):\n            progress = iteration / self.budget\n            w = 0.9 - progress * (0.9 - 0.4)\n            c1 = 2.5 - progress * (2.5 - 0.5)\n            c2 = 0.5 + progress * (2.0 - 0.5)\n            F = 0.5 + progress * (0.9 - 0.5)\n            CR = 0.8 + progress * (0.95 - 0.8)\n            local_search_prob = 0.1 + progress * (0.5 - 0.1)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = random_init_population()\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n                velocities[i] = np.clip(velocities[i], -clamp, clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                indices = np.random.choice(self.population_size, 3, replace=False)\n                a, b, c = personal_best_positions[indices]\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                if np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "SelfAdaptiveHybridPSO_DE", "description": "The Self-Adaptive Hybrid PSO-DE integrates self-adaptive parameter tuning with hybrid swarm and differential evolution strategies for improved exploration and exploitation.", "configspace": "", "generation": 95, "fitness": 0.361663123663589, "feedback": "The algorithm SelfAdaptiveHybridPSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.24.", "error": "", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7277909671876063, 0.7242489387074211, 0.7305873803151836, 0.7595098831964394, 0.7629852189605122, 0.7447868888111933, 0.7709861010797644, 0.7572010128157309, 0.7445198594471611, 0.5468020466254754, 0.5571393217973215, 0.5144509644886709, 0.5151408510508129, 0.5421157117111787, 0.5475771323351155, 0.527069749221974, 0.530936565080471, 0.504868756546845, 0.13052525628668432, 0.13448046066399366, 0.16144553977326281, 0.12533638719313733, 0.1132592129631359, 0.1346028720113156, 0.14562218566390805, 0.10870140038595766, 0.3362171833659371, 0.10604966672969163, 0.1175622295895482, 0.10306888888400134, 0.11262667740071242, 0.1220389760806897, 0.10867457342262765, 0.09924788379929128, 0.13163264043340261, 0.11919786581147418, 0.986995144982294, 0.9772160166420586, 0.9820537966027741, 0.9791550852112181, 0.9881833792507693, 0.9829038704895768, 0.9812099372088285, 0.9839996637276167, 0.9832361662357504, 0.49552032208816343, 0.47434249452719046, 0.5065010252293022, 0.5189314307164379, 0.47955645667307567, 0.5381521845361739, 0.4743343480410662, 0.5030688400842585, 0.4859794363078208, 0.760094186392144, 0.7521313355039123, 0.6504686209420938, 0.7797662834974521, 0.7295848850155737, 0.6897428696491181, 0.7344049684315718, 0.49980132701295243, 0.7393123211356873, 0.3469913753629016, 0.4768592944334551, 0.23831619015595684, 0.3260771240398266, 0.3203191698051402, 0.3634499933118931, 0.28716653792999147, 0.2642353507212306, 0.45367010034666133, 0.26595160189494693, 0.28725809363567145, 0.26027771064340655, 0.3208069648628682, 0.2497410182251234, 0.2379901835708912, 0.3037470558153309, 0.2570092819776685, 0.3252761906478525, 0.09312661501169883, 0.1921158190312191, 0.2785070165627074, 0.2673909470314464, 0.08424413425533273, 0.17245596030522847, 0.2765296714497142, 0.20304155715520633, 0.3908673083435812, 0.48419604237730074, 0.3825046152753081, 0.3135025852009342, 0.4982464975322818, 0.47968054225109935, 0.3364450591473155, 0.5147379164939797, 0.42226143086026946, 0.35576849847576564, 0.18989473629575104, 0.19903484884227174, 0.07173738624986892, 0.20026965032340616, 0.2520816696809802, 0.1764914701723045, 0.11990379353966796, 0.1370448591110115, 0.07264419317628112, 0.2655430422985199, 0.16244117866317553, 0.26523144109721, 0.2811353720951101, 0.2669999839610817, 0.23463894099575588, 0.2904652929434899, 0.31147128422180426, 0.2563022602226479, 0.6198464441571313, 0.6178289133676742, 0.6311809219454617, 0.6594325169268169, 0.6115794436075512, 0.5278005452776006, 0.6266163958670492, 0.5698506325584285, 0.6055516393372291, 0.1156725241372929, 0.10433223911406853, 0.11137905045393182, 0.11117707454002468, 0.14518571340413977, 0.14345615918541044, 0.12493921777647465, 0.09337279119611996, 0.09857994428372496, 0.275534371762449, 0.18994453172816916, 0.19724879329956335, 0.19394884676191715, 0.15335691231149395, 0.20986281150480712, 0.13742753058203494, 0.1873966396496164, 0.17923950128965238, 0.36979495458239797, 0.4240158079172094, 0.39291311026429854, 0.4139284614576977, 0.41502056000681053, 0.43662119018412504, 0.39199919204560996, 0.45571031910928794, 0.4092604252616955, 0.2994682174349851, 0.3026273140306327, 0.2183005733882062, 0.3104465959130147, 0.27522825723629374, 0.28741515902304726, 0.29458028000479075, 0.3287529649258235, 0.29643272113564245, 0.20927411800724138, 0.2252390907907862, 0.216746017297475, 0.19393877132632664, 0.19186855356844257, 0.20059217063138324, 0.21750531274653695, 0.1995007276811558, 0.21148006886817283, 0.3282805729744914, 0.193616497369552, 0.19469208603860455, 0.21098802690005003, 0.20953666453537523, 0.3874444079873759, 0.20068154608529498, 0.4407454520144224, 0.4385315942742344, 0.18703964404371687, 0.7203118186198008, 0.15398566432073457, 0.7651890328618756, 0.19593303161599673, 0.7916417192115249, 0.7899641451592514, 0.7531505498620842, 0.1732248014800385, 0.7682846575615895, 0.20958040728730365, 0.7062721091955699, 0.2105988355834726, 0.20332299178917046, 0.20290159381190143, 0.6970564107369613, 0.1520880304372384, 0.2090196140060382, 0.19691568767453704, 0.19253905767496848, 0.21377247091581786, 0.18626903437879405, 0.21063265527778907, 0.19038117832370927, 0.19019418411938516, 0.2046202383625888, 0.1896445231813304, 0.08445127392264096, 0.0886377054840779, 0.08133083241886419, 0.08625031074532685, 0.08101906281429727, 0.07698658973721106, 0.07972297263832939, 0.08971608471445758, 0.09191539831842999]}, "mutation_prompt": null}
{"id": "9ac14300-ea44-45a3-a3ab-40d683b1d597", "solution": "import numpy as np\n\nclass DynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "DynamicSwarmPSO_DE", "description": "DynamicSwarmPSO_DE introduces feedback-driven parameter adaptation and incorporates a dynamic local search strategy to enhance convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7597880341983425, 0.76207986376168, 0.7716661931496172, 0.7555863680086532, 0.761104797711877, 0.7841046162178851, 0.7874114338263496, 0.7726387800174962, 0.7434669592868286, 0.589507878272379, 0.5858687924312704, 0.6069473297293625, 0.6316345684340132, 0.5150471985577125, 0.5980701624516254, 0.5962541029669888, 0.5786796148900804, 0.557387243774261, 0.12319392662122175, 0.134860878374367, 0.14969784198711644, 0.11231961419176384, 0.12033251093326014, 0.12032017107898008, 0.14755872711067464, 0.42732249424162405, 0.12595436366963242, 0.12567971406581802, 0.11023837622149035, 0.11922263963311819, 0.10967891630271154, 0.11288761499340694, 0.12089963785662317, 0.0987485443875954, 0.12256160022891416, 0.1281637071440449, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.567468243420776, 0.3158490834832608, 0.5202059712732018, 0.5719542943672922, 0.6153274526109171, 0.5504971468283502, 0.5722107974778484, 0.5637564004178499, 0.5677624956505721, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21282665737290252, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.42519414746997797, 0.37959969146170724, 0.45254476548793654, 0.48101798521991945, 0.46296822345737176, 0.3706592866045719, 0.4640245163174369, 0.3459515699914565, 0.4743173062746062, 0.5365705918213252, 0.3399823206455459, 0.39287619517658123, 0.4631827835014044, 0.3964162365928964, 0.38382370994907034, 0.3706796595432821, 0.36216279166957477, 0.28148639791847085, 0.0686699243819916, 0.20478749808158414, 0.22368678298583278, 0.42947110872579497, 0.26080956375385156, 0.2437842264866894, 0.26026398343031265, 0.2655245545586655, 0.3039142505566865, 0.4250008778754897, 0.16257077913150575, 0.517153557733049, 0.47531049554167504, 0.38374900762665753, 0.23430340285186602, 0.6000809765031894, 0.5113502925326736, 0.5915360507424003, 0.16049974535981215, 0.21328906162630834, 0.09211519471164242, 0.2938838848811217, 0.18688399719671356, 0.1087191420895286, 0.23273409522291622, 0.20364087424979294, 0.1713851217313721, 0.3076637290491385, 0.2930643161431963, 0.3290061182349753, 0.27510065867483857, 0.3230324435109855, 0.3393580877465191, 0.32240672411191207, 0.33799419607028547, 0.3579397421306796, 0.6825893556558043, 0.642832454744809, 0.6734500887381816, 0.6453832546122819, 0.7152224672246028, 0.6337974487066219, 0.6748727777661232, 0.6692164487112122, 0.687888358012945, 0.1489035472887954, 0.12105900892467125, 0.439699425827646, 0.12840982667387835, 0.12464894344922195, 0.1269710439501468, 0.15051096118138452, 0.14057211944913106, 0.11689216090618904, 0.15261520864660338, 0.28852928949587986, 0.24656631199065338, 0.249141452158549, 0.17093789520736213, 0.17412606699499134, 0.18323616662640108, 0.26756513550939676, 0.1618538476332515, 0.44604229025299824, 0.5209315589738844, 0.3920824621770007, 0.47915228897350237, 0.48350388656427745, 0.4384768199180973, 0.5107606898036997, 0.46593071853954493, 0.45578232494186766, 0.31953052077959077, 0.34358887359053214, 0.2936162626723976, 0.3357753968323587, 0.3704852943575009, 0.3687880276024449, 0.19247626403410745, 0.3797218283192805, 0.37903642908583146, 0.2073857614205593, 0.1972011162009203, 0.21954984677615363, 0.23275347471255958, 0.2041920265325664, 0.21535086189601316, 0.19966016327686065, 0.20606848936720323, 0.24635182945824918, 0.21945428650532983, 0.5276675685435304, 0.2316110506905129, 0.5026734040956584, 0.20281324947457147, 0.19226015745062608, 0.5667067762918259, 0.18625450888098216, 0.22128264509257556, 0.2030229052786875, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.19713128047002015, 0.830319469752175, 0.15011103769935563, 0.6508104704380757, 0.7149845966301969, 0.20484828034828584, 0.20735119441450056, 0.20637329268578364, 0.8383298804401792, 0.1274043755976123, 0.20777856014718976, 0.20981316147643325, 0.1676819331675462, 0.20701157805303916, 0.17732870557464342, 0.22463775899366278, 0.18749639472230262, 0.186293760388357, 0.19608727681215454, 0.19097900728710904, 0.18483933446096457, 0.20374905459528858, 0.20369972523229318, 0.10280324883916203, 0.0848155244494404, 0.08670686178724041, 0.08195585636760994, 0.09674009193932254, 0.10270385986182395, 0.09025212066636612, 0.09863321712267847, 0.09337148246182692]}, "mutation_prompt": null}
{"id": "f8de1aad-d14a-4832-9d46-22f60a2c7ca0", "solution": "import numpy as np\n\nclass AdaptiveMultiPhasePSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.6 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "AdaptiveMultiPhasePSO_DE", "description": "AdaptiveMultiPhasePSO_DE integrates an adaptive parameter scheme with multi-phase search and local landscape exploitation to enhance optimization performance.", "configspace": "", "generation": 97, "fitness": 0.3895538842092612, "feedback": "The algorithm AdaptiveMultiPhasePSO_DE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.39 with standard deviation 0.25.", "error": "", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7581164062578969, 0.7614980061294241, 0.7716578924333088, 0.754012265908858, 0.76048699543504, 0.7841046162178851, 0.7874368255475318, 0.7721896434006861, 0.7417199373713974, 0.5804515770788289, 0.5819157639893864, 0.604034631876288, 0.6253525125623471, 0.514265455375799, 0.5989563184874334, 0.5896543102676303, 0.5774354062409904, 0.5488558843712763, 0.12397049004679006, 0.13485468080606533, 0.14982261381997775, 0.1180108189794209, 0.12033183909118739, 0.12765175592855504, 0.14705447012410966, 0.4079758437363097, 0.36765795695675096, 0.1256677966946691, 0.12281558932725278, 0.12627468765473382, 0.10969522247391383, 0.11870625694989523, 0.1283114998421515, 0.11400922705489192, 0.12261638242141837, 0.12816337994811478, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.5628942734683458, 0.22549880590074933, 0.5107888948215977, 0.5528620922727236, 0.602299839290665, 0.5523977618462192, 0.5679046576898243, 0.5594335490966673, 0.5654437944193933, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21275923586900847, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.39192994946544135, 0.39253303316983745, 0.4429126350465672, 0.4359165528760587, 0.39419766731908534, 0.3917471870662861, 0.4397780518593699, 0.329843814524562, 0.4721902487269133, 0.508293326710463, 0.3073764069906474, 0.3483668868481752, 0.4304350757674914, 0.3948524746686636, 0.34854874019129256, 0.36698394102441056, 0.36148169355865445, 0.2347189958247181, 0.06894627776605089, 0.2510232458915126, 0.13977022544488937, 0.3121752174690309, 0.3243810954152664, 0.22614968311298922, 0.20444773227482782, 0.32420760163965867, 0.3710120831052124, 0.4685838618151732, 0.1965333605520071, 0.4914840717788126, 0.5446736035836954, 0.40086124960458, 0.22320165629043687, 0.5632912672799224, 0.5783622987148723, 0.5852094013343498, 0.16929379062890837, 0.218402955647514, 0.09929044690980715, 0.2594559562991344, 0.17132299746979607, 0.10785781889426993, 0.2486999901508694, 0.24516809100537118, 0.18570730810428016, 0.3210506213915084, 0.33035619162853336, 0.2897857433353491, 0.28347725984142214, 0.31585253585348105, 0.32559387017467745, 0.32747222274123455, 0.33407946024492396, 0.33805822771114735, 0.6807906481394761, 0.6644777484712361, 0.6759101049497105, 0.6784145736854209, 0.7239025355636572, 0.6675990106168157, 0.6431400556975281, 0.6604257903275239, 0.6852828031234022, 0.14889442963512434, 0.12059200762776168, 0.41880262222802955, 0.1288263438855669, 0.12659792157672967, 0.12695933875081533, 0.15049624829651254, 0.14333997012197508, 0.11653291403655475, 0.21625414639208762, 0.4166976609813301, 0.24377070136462164, 0.23354447198219375, 0.1733859381134054, 0.16487507580789573, 0.17027927422846245, 0.27667287773630955, 0.17381919498420284, 0.43255973307831064, 0.49711033243317027, 0.4628589654980929, 0.4369980604608137, 0.4531198343842733, 0.4849376655075811, 0.4520230648524336, 0.48413639561156874, 0.42572377338530987, 0.33763437909455984, 0.3341543562991075, 0.3159951573445112, 0.32861105244120514, 0.31353608678573863, 0.3273803000112726, 0.19233497002312305, 0.3746403161297892, 0.3507241103542267, 0.2053498857341669, 0.21373817068338075, 0.2192439179017407, 0.23250870777759824, 0.20114958344565226, 0.22099220224029237, 0.19882740061818904, 0.22332972501314652, 0.25363079295679103, 0.21953124442971816, 0.5251298528061386, 0.23160670898921254, 0.4910520179142487, 0.20281240229175124, 0.1922601495622146, 0.5525276641855734, 0.19475764919796035, 0.2202710771372841, 0.203022902186337, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.1971312803151295, 0.830319469752175, 0.15011103740013765, 0.6507931765071465, 0.7149845966301969, 0.20484827911000936, 0.2073511944397468, 0.2063732915890445, 0.8383298804401792, 0.12740437509994917, 0.20777856098678094, 0.2094447617125681, 0.16768193309459223, 0.2059875954023661, 0.1782304542808395, 0.2126807052996904, 0.1868282231882672, 0.18623235471653166, 0.19609532390202866, 0.19088878440902723, 0.18453762825840436, 0.20369009045960862, 0.20342492699305903, 0.10132918719921657, 0.08341403747491716, 0.09473065612226206, 0.08045301901663404, 0.09646029156927383, 0.1056275787963552, 0.09614656745686645, 0.099282405438469, 0.08973926562503987]}, "mutation_prompt": null}
{"id": "e1f71bf4-a632-4628-b301-709438b210a9", "solution": "import numpy as np\n\nclass DynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "DynamicSwarmPSO_DE", "description": "DynamicSwarmPSO_DE introduces feedback-driven parameter adaptation and incorporates a dynamic local search strategy to enhance convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7597880341983425, 0.76207986376168, 0.7716661931496172, 0.7555863680086532, 0.761104797711877, 0.7841046162178851, 0.7874114338263496, 0.7726387800174962, 0.7434669592868286, 0.589507878272379, 0.5858687924312704, 0.6069473297293625, 0.6316345684340132, 0.5150471985577125, 0.5980701624516254, 0.5962541029669888, 0.5786796148900804, 0.557387243774261, 0.12319392662122175, 0.134860878374367, 0.14969784198711644, 0.11231961419176384, 0.12033251093326014, 0.12032017107898008, 0.14755872711067464, 0.42732249424162405, 0.12595436366963242, 0.12567971406581802, 0.11023837622149035, 0.11922263963311819, 0.10967891630271154, 0.11288761499340694, 0.12089963785662317, 0.0987485443875954, 0.12256160022891416, 0.1281637071440449, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.567468243420776, 0.3158490834832608, 0.5202059712732018, 0.5719542943672922, 0.6153274526109171, 0.5504971468283502, 0.5722107974778484, 0.5637564004178499, 0.5677624956505721, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21282665737290252, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.42519414746997797, 0.37959969146170724, 0.45254476548793654, 0.48101798521991945, 0.46296822345737176, 0.3706592866045719, 0.4640245163174369, 0.3459515699914565, 0.4743173062746062, 0.5365705918213252, 0.3399823206455459, 0.39287619517658123, 0.4631827835014044, 0.3964162365928964, 0.38382370994907034, 0.3706796595432821, 0.36216279166957477, 0.28148639791847085, 0.0686699243819916, 0.20478749808158414, 0.22368678298583278, 0.42947110872579497, 0.26080956375385156, 0.2437842264866894, 0.26026398343031265, 0.2655245545586655, 0.3039142505566865, 0.4250008778754897, 0.16257077913150575, 0.517153557733049, 0.47531049554167504, 0.38374900762665753, 0.23430340285186602, 0.6000809765031894, 0.5113502925326736, 0.5915360507424003, 0.16049974535981215, 0.21328906162630834, 0.09211519471164242, 0.2938838848811217, 0.18688399719671356, 0.1087191420895286, 0.23273409522291622, 0.20364087424979294, 0.1713851217313721, 0.3076637290491385, 0.2930643161431963, 0.3290061182349753, 0.27510065867483857, 0.3230324435109855, 0.3393580877465191, 0.32240672411191207, 0.33799419607028547, 0.3579397421306796, 0.6825893556558043, 0.642832454744809, 0.6734500887381816, 0.6453832546122819, 0.7152224672246028, 0.6337974487066219, 0.6748727777661232, 0.6692164487112122, 0.687888358012945, 0.1489035472887954, 0.12105900892467125, 0.439699425827646, 0.12840982667387835, 0.12464894344922195, 0.1269710439501468, 0.15051096118138452, 0.14057211944913106, 0.11689216090618904, 0.15261520864660338, 0.28852928949587986, 0.24656631199065338, 0.249141452158549, 0.17093789520736213, 0.17412606699499134, 0.18323616662640108, 0.26756513550939676, 0.1618538476332515, 0.44604229025299824, 0.5209315589738844, 0.3920824621770007, 0.47915228897350237, 0.48350388656427745, 0.4384768199180973, 0.5107606898036997, 0.46593071853954493, 0.45578232494186766, 0.31953052077959077, 0.34358887359053214, 0.2936162626723976, 0.3357753968323587, 0.3704852943575009, 0.3687880276024449, 0.19247626403410745, 0.3797218283192805, 0.37903642908583146, 0.2073857614205593, 0.1972011162009203, 0.21954984677615363, 0.23275347471255958, 0.2041920265325664, 0.21535086189601316, 0.19966016327686065, 0.20606848936720323, 0.24635182945824918, 0.21945428650532983, 0.5276675685435304, 0.2316110506905129, 0.5026734040956584, 0.20281324947457147, 0.19226015745062608, 0.5667067762918259, 0.18625450888098216, 0.22128264509257556, 0.2030229052786875, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.19713128047002015, 0.830319469752175, 0.15011103769935563, 0.6508104704380757, 0.7149845966301969, 0.20484828034828584, 0.20735119441450056, 0.20637329268578364, 0.8383298804401792, 0.1274043755976123, 0.20777856014718976, 0.20981316147643325, 0.1676819331675462, 0.20701157805303916, 0.17732870557464342, 0.22463775899366278, 0.18749639472230262, 0.186293760388357, 0.19608727681215454, 0.19097900728710904, 0.18483933446096457, 0.20374905459528858, 0.20369972523229318, 0.10280324883916203, 0.0848155244494404, 0.08670686178724041, 0.08195585636760994, 0.09674009193932254, 0.10270385986182395, 0.09025212066636612, 0.09863321712267847, 0.09337148246182692]}, "mutation_prompt": null}
{"id": "3320a17b-e588-49a9-a246-43c64ce1231a", "solution": "import numpy as np\n\nclass DynamicSwarmPSO_DE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 20\n        self.c1_start = 2.0\n        self.c1_end = 0.5\n        self.c2_start = 0.5\n        self.c2_end = 2.0\n        self.w_start = 0.9\n        self.w_end = 0.4\n        self.F_start = 0.5\n        self.F_end = 0.9\n        self.CR_start = 0.8\n        self.CR_end = 0.95\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.num_evals = 0\n        self.local_search_prob_start = 0.1\n        self.local_search_prob_end = 0.5\n\n    def __call__(self, func):\n        def adapt_parameters():\n            progress = self.num_evals / self.budget\n            w = self.w_start - progress * (self.w_start - self.w_end)\n            c1 = self.c1_start - progress * (self.c1_start - self.c1_end)\n            c2 = self.c2_start + progress * (self.c2_end - self.c2_start)\n            F = self.F_start + progress * (self.F_end - self.F_start)\n            CR = self.CR_start + progress * (self.CR_end - self.CR_start)\n            local_search_prob = self.local_search_prob_start + progress * (self.local_search_prob_end - self.local_search_prob_start)\n            return w, c1, c2, F, CR, local_search_prob\n\n        swarm = np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(swarm)\n        personal_best_scores = np.full(self.population_size, np.inf)\n        global_best_position = None\n        global_best_score = np.inf\n\n        initial_velocity_clamp = (self.upper_bound - self.lower_bound) / 2.0\n\n        def switch_phase(iteration):\n            return (iteration < 0.5 * self.budget)\n\n        while self.num_evals < self.budget:\n            w, c1, c2, F, CR, local_search_prob = adapt_parameters()\n            velocity_clamp = initial_velocity_clamp * (1 - self.num_evals / self.budget)\n            exploration_phase = switch_phase(self.num_evals)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                score = func(swarm[i])\n                self.num_evals += 1\n\n                if score < personal_best_scores[i]:\n                    personal_best_scores[i] = score\n                    personal_best_positions[i] = swarm[i]\n\n                if score < global_best_score:\n                    global_best_score = score\n                    global_best_position = swarm[i]\n\n            for i in range(self.population_size):\n                inertia = w * velocities[i]\n                cognitive = c1 * np.random.random(self.dim) * (personal_best_positions[i] - swarm[i])\n                social = c2 * np.random.random(self.dim) * (global_best_position - swarm[i])\n                velocities[i] = inertia + cognitive + social\n                velocities[i] = np.clip(velocities[i], -velocity_clamp, velocity_clamp)\n\n                swarm[i] += velocities[i]\n                swarm[i] = np.clip(swarm[i], self.lower_bound, self.upper_bound)\n\n            for i in range(self.population_size):\n                if self.num_evals >= self.budget:\n                    break\n                if exploration_phase:\n                    indices = np.random.choice(self.population_size, 3, replace=False)\n                    a, b, c = personal_best_positions[indices]\n                else:\n                    candidates = np.random.choice(self.population_size, 5, replace=False)\n                    best_candidate = min(candidates, key=lambda idx: personal_best_scores[idx])\n                    a, b, c = personal_best_positions[[best_candidate] + list(np.random.choice(candidates, 2, replace=False))]\n\n                mutant = a + F * (b - c)\n                mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n\n                trial = np.copy(swarm[i])\n                for j in range(self.dim):\n                    if np.random.rand() < CR or j == np.random.randint(0, self.dim):\n                        trial[j] = mutant[j]\n\n                trial_score = func(trial)\n                self.num_evals += 1\n\n                if trial_score < personal_best_scores[i]:\n                    personal_best_scores[i] = trial_score\n                    personal_best_positions[i] = trial\n                    if trial_score < global_best_score:\n                        global_best_score = trial_score\n                        global_best_position = trial\n\n                # Integrate stochastic local search with increasing probability\n                if not exploration_phase and np.random.rand() < local_search_prob:\n                    local_trial = trial + np.random.normal(0, 0.1, self.dim)\n                    local_trial = np.clip(local_trial, self.lower_bound, self.upper_bound)\n                    local_trial_score = func(local_trial)\n                    self.num_evals += 1\n\n                    if local_trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = local_trial_score\n                        personal_best_positions[i] = local_trial\n                        if local_trial_score < global_best_score:\n                            global_best_score = local_trial_score\n                            global_best_position = local_trial\n\n        return global_best_position", "name": "DynamicSwarmPSO_DE", "description": "DynamicSwarmPSO_DE introduces feedback-driven parameter adaptation and incorporates a dynamic local search strategy to enhance convergence.", "configspace": "", "generation": 88, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "c68843a5-f39a-4479-ab43-eb718e3b7375", "metadata": {"aucs": [0.7597880341983425, 0.76207986376168, 0.7716661931496172, 0.7555863680086532, 0.761104797711877, 0.7841046162178851, 0.7874114338263496, 0.7726387800174962, 0.7434669592868286, 0.589507878272379, 0.5858687924312704, 0.6069473297293625, 0.6316345684340132, 0.5150471985577125, 0.5980701624516254, 0.5962541029669888, 0.5786796148900804, 0.557387243774261, 0.12319392662122175, 0.134860878374367, 0.14969784198711644, 0.11231961419176384, 0.12033251093326014, 0.12032017107898008, 0.14755872711067464, 0.42732249424162405, 0.12595436366963242, 0.12567971406581802, 0.11023837622149035, 0.11922263963311819, 0.10967891630271154, 0.11288761499340694, 0.12089963785662317, 0.0987485443875954, 0.12256160022891416, 0.1281637071440449, 0.9819309450732159, 0.9846472006143109, 0.9849168076304363, 0.9741971527906278, 0.9882042478347765, 0.9765121630056518, 0.982727450708655, 0.9803898702349207, 0.9823552548464048, 0.567468243420776, 0.3158490834832608, 0.5202059712732018, 0.5719542943672922, 0.6153274526109171, 0.5504971468283502, 0.5722107974778484, 0.5637564004178499, 0.5677624956505721, 0.7686167687293557, 0.7522026924452159, 0.6954809031309888, 0.7538399898831326, 0.21282665737290252, 0.8086797742077865, 0.7342339622929098, 0.7743992591731002, 0.8226666247331633, 0.42519414746997797, 0.37959969146170724, 0.45254476548793654, 0.48101798521991945, 0.46296822345737176, 0.3706592866045719, 0.4640245163174369, 0.3459515699914565, 0.4743173062746062, 0.5365705918213252, 0.3399823206455459, 0.39287619517658123, 0.4631827835014044, 0.3964162365928964, 0.38382370994907034, 0.3706796595432821, 0.36216279166957477, 0.28148639791847085, 0.0686699243819916, 0.20478749808158414, 0.22368678298583278, 0.42947110872579497, 0.26080956375385156, 0.2437842264866894, 0.26026398343031265, 0.2655245545586655, 0.3039142505566865, 0.4250008778754897, 0.16257077913150575, 0.517153557733049, 0.47531049554167504, 0.38374900762665753, 0.23430340285186602, 0.6000809765031894, 0.5113502925326736, 0.5915360507424003, 0.16049974535981215, 0.21328906162630834, 0.09211519471164242, 0.2938838848811217, 0.18688399719671356, 0.1087191420895286, 0.23273409522291622, 0.20364087424979294, 0.1713851217313721, 0.3076637290491385, 0.2930643161431963, 0.3290061182349753, 0.27510065867483857, 0.3230324435109855, 0.3393580877465191, 0.32240672411191207, 0.33799419607028547, 0.3579397421306796, 0.6825893556558043, 0.642832454744809, 0.6734500887381816, 0.6453832546122819, 0.7152224672246028, 0.6337974487066219, 0.6748727777661232, 0.6692164487112122, 0.687888358012945, 0.1489035472887954, 0.12105900892467125, 0.439699425827646, 0.12840982667387835, 0.12464894344922195, 0.1269710439501468, 0.15051096118138452, 0.14057211944913106, 0.11689216090618904, 0.15261520864660338, 0.28852928949587986, 0.24656631199065338, 0.249141452158549, 0.17093789520736213, 0.17412606699499134, 0.18323616662640108, 0.26756513550939676, 0.1618538476332515, 0.44604229025299824, 0.5209315589738844, 0.3920824621770007, 0.47915228897350237, 0.48350388656427745, 0.4384768199180973, 0.5107606898036997, 0.46593071853954493, 0.45578232494186766, 0.31953052077959077, 0.34358887359053214, 0.2936162626723976, 0.3357753968323587, 0.3704852943575009, 0.3687880276024449, 0.19247626403410745, 0.3797218283192805, 0.37903642908583146, 0.2073857614205593, 0.1972011162009203, 0.21954984677615363, 0.23275347471255958, 0.2041920265325664, 0.21535086189601316, 0.19966016327686065, 0.20606848936720323, 0.24635182945824918, 0.21945428650532983, 0.5276675685435304, 0.2316110506905129, 0.5026734040956584, 0.20281324947457147, 0.19226015745062608, 0.5667067762918259, 0.18625450888098216, 0.22128264509257556, 0.2030229052786875, 0.839774923163952, 0.7658059675768085, 0.7918571131200813, 0.19713128047002015, 0.830319469752175, 0.15011103769935563, 0.6508104704380757, 0.7149845966301969, 0.20484828034828584, 0.20735119441450056, 0.20637329268578364, 0.8383298804401792, 0.1274043755976123, 0.20777856014718976, 0.20981316147643325, 0.1676819331675462, 0.20701157805303916, 0.17732870557464342, 0.22463775899366278, 0.18749639472230262, 0.186293760388357, 0.19608727681215454, 0.19097900728710904, 0.18483933446096457, 0.20374905459528858, 0.20369972523229318, 0.10280324883916203, 0.0848155244494404, 0.08670686178724041, 0.08195585636760994, 0.09674009193932254, 0.10270385986182395, 0.09025212066636612, 0.09863321712267847, 0.09337148246182692]}, "mutation_prompt": null}

{"id": "0ab7f42a-03b4-46b7-a316-a59bd6fda49d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-0.1, 0.1, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining Differential Evolution with a Greedy Local Search for efficient exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.2214752309115933, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.18.", "error": "", "parent_id": null, "metadata": {"aucs": [0.5012607712123999, 0.5025474385763762, 0.5039210154367295, 0.5290123234015023, 0.5567864439460872, 0.5040047360415534, 0.47345316604390153, 0.5075416580958774, 0.5043770432193142, 0.13805947401673935, 0.18432200858719194, 0.17372784336194014, 0.17276303336570076, 0.17407907173392956, 0.16240312165675463, 0.17741000056156442, 0.1663303178717146, 0.14383511687604933, 0.09171758490536375, 0.12742960832229, 0.10176890431413921, 0.08947334150412645, 0.09520720788830639, 0.10415465550962144, 0.10750657269815478, 0.09956108060570368, 0.09750411525809555, 0.07919707158627898, 0.07816368233629178, 0.08955520103015169, 0.08646840841522152, 0.06525503987021475, 0.07593382095649326, 0.09175696315580639, 0.07963773600536328, 0.08970478340308596, 0.8568224135559782, 0.839731446860924, 0.8794370502875176, 0.7065580532352236, 0.8520714813035487, 0.9307076815530314, 0.8483468083193741, 0.8610942163509939, 0.9406712434071245, 0.22922301647748122, 0.21975449662053148, 0.22649759085354393, 0.24780006955301148, 0.25649211558327933, 0.26590780837450656, 0.22469234891056644, 0.23133670727061362, 0.20896433144497406, 0.2547908948870842, 0.3669748846863451, 0.3921111248998467, 0.3575011015344105, 0.41181479167605617, 0.37095808020932486, 0.396446070517423, 0.4873977642673242, 0.23624834931169325, 0.18727563109998602, 0.13452135534771237, 0.16772790406613125, 0.16726385140307942, 0.11057440357994197, 0.15539518340851177, 0.1616250885549887, 0.17233853115732456, 0.15684778933621746, 0.10899725765073509, 0.1906461617610654, 0.12557660582264163, 0.15156417166453917, 0.15227747065929675, 0.16642508056298333, 0.10318535097293191, 0.21310523524283964, 0.20641230120414666, 0.07774437265326173, 0.06597683321331238, 0.095620558723987, 0.11162415931953162, 0.06711403660156134, 0.08242755359428444, 0.06438105620437362, 0.07847567507843778, 0.08839217009981659, 0.1825444482476285, 0.17152164340184395, 0.16804648915869036, 0.20758629760178182, 0.20147456323893598, 0.20798728197559135, 0.21391651832908942, 0.21796809379941395, 0.18137076372232663, 0.011251165989058287, 0.009395997808982592, 0.014629237560305541, 0.030526367243620345, 0.006928077903142871, 0.019017762235606694, 0.04265197057415904, 0.007358049605674433, 0.029955699113555, 0.11492564781773795, 0.10302828434882172, 0.12037551129901825, 0.11894536520281163, 0.14350937148961407, 0.12427728986096032, 0.12840081366317646, 0.11962076610430339, 0.13964553027266502, 0.37361890508727313, 0.40080206172051913, 0.40930982197759347, 0.4150320194071142, 0.4624152745614992, 0.43861607316134155, 0.41610798292885043, 0.394225004776965, 0.40447275025003904, 0.08199860522277191, 0.09793500623928686, 0.11936207563641787, 0.1018460419920757, 0.10442693131764613, 0.08254180967247426, 0.1196269430742648, 0.10734056210471576, 0.10109583259387778, 0.15817320488390774, 0.17732705704316343, 0.16960421412311955, 0.14899243388085137, 0.17833484826056434, 0.17745430421956843, 0.16067001694691174, 0.16831613856635141, 0.17468257846395296, 0.17843579698509016, 0.2121232382468261, 0.20336828431399323, 0.25792453290405093, 0.218893294248947, 0.1870331734771017, 0.217711690883034, 0.23384307754316702, 0.22918032462747362, 0.15975975681276833, 0.1869550565651632, 0.11978801030616737, 0.13752103691725848, 0.12755614539089255, 0.15308552174725698, 0.19874801065097658, 0.18977207164921428, 0.1949699471963826, 0.17751386017268866, 0.1895812655117054, 0.16291771822344836, 0.17418996888303395, 0.18651445640150732, 0.19047341429904296, 0.19079498406979278, 0.16449338396736735, 0.203747175172161, 0.1659199460691425, 0.18415689492202525, 0.2206497098559026, 0.20033517377998988, 0.16594295832534245, 0.17188369796249225, 0.1886948270333717, 0.17897049704298262, 0.19443206723182438, 0.19124389165018152, 0.1467428949496461, 0.5682001778674299, 0.164192878662351, 0.31329607769159196, 0.17843831795534992, 0.11817034616497257, 0.1624406522929226, 0.4412463916336272, 0.18688838674655395, 0.5282600734263503, 0.3078126684278636, 0.40496345916701804, 0.5519818253324749, 0.4452662835863592, 0.12009167507465901, 0.1956239761833931, 0.20200444363727188, 0.1794122252357354, 0.1774283700627508, 0.17659305311386908, 0.17335020675693846, 0.20964710232790484, 0.17960456312146977, 0.19119846253877215, 0.2057352657669369, 0.17614914811210092, 0.0729120800685299, 0.06415789982563425, 0.08593916586551054, 0.06977826198704462, 0.07513840450118059, 0.07990536956721805, 0.07230800809281701, 0.0697626292273249, 0.06399867250577151]}, "mutation_prompt": null}
{"id": "496b6116-b6ef-43ac-ad15-904a42ab9716", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-0.1, 0.1, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "A hybrid metaheuristic combining Differential Evolution with a Greedy Local Search for efficient exploration and exploitation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "0ab7f42a-03b4-46b7-a316-a59bd6fda49d", "metadata": {"aucs": [0.5012607712123999, 0.5025474385763762, 0.5039210154367295, 0.5290123234015023, 0.5567864439460872, 0.5040047360415534, 0.47345316604390153, 0.5075416580958774, 0.5043770432193142, 0.13805947401673935, 0.18432200858719194, 0.17372784336194014, 0.17276303336570076, 0.17407907173392956, 0.16240312165675463, 0.17741000056156442, 0.1663303178717146, 0.14383511687604933, 0.09171758490536375, 0.12742960832229, 0.10176890431413921, 0.08947334150412645, 0.09520720788830639, 0.10415465550962144, 0.10750657269815478, 0.09956108060570368, 0.09750411525809555, 0.07919707158627898, 0.07816368233629178, 0.08955520103015169, 0.08646840841522152, 0.06525503987021475, 0.07593382095649326, 0.09175696315580639, 0.07963773600536328, 0.08970478340308596, 0.8568224135559782, 0.839731446860924, 0.8794370502875176, 0.7065580532352236, 0.8520714813035487, 0.9307076815530314, 0.8483468083193741, 0.8610942163509939, 0.9406712434071245, 0.22922301647748122, 0.21975449662053148, 0.22649759085354393, 0.24780006955301148, 0.25649211558327933, 0.26590780837450656, 0.22469234891056644, 0.23133670727061362, 0.20896433144497406, 0.2547908948870842, 0.3669748846863451, 0.3921111248998467, 0.3575011015344105, 0.41181479167605617, 0.37095808020932486, 0.396446070517423, 0.4873977642673242, 0.23624834931169325, 0.18727563109998602, 0.13452135534771237, 0.16772790406613125, 0.16726385140307942, 0.11057440357994197, 0.15539518340851177, 0.1616250885549887, 0.17233853115732456, 0.15684778933621746, 0.10899725765073509, 0.1906461617610654, 0.12557660582264163, 0.15156417166453917, 0.15227747065929675, 0.16642508056298333, 0.10318535097293191, 0.21310523524283964, 0.20641230120414666, 0.07774437265326173, 0.06597683321331238, 0.095620558723987, 0.11162415931953162, 0.06711403660156134, 0.08242755359428444, 0.06438105620437362, 0.07847567507843778, 0.08839217009981659, 0.1825444482476285, 0.17152164340184395, 0.16804648915869036, 0.20758629760178182, 0.20147456323893598, 0.20798728197559135, 0.21391651832908942, 0.21796809379941395, 0.18137076372232663, 0.011251165989058287, 0.009395997808982592, 0.014629237560305541, 0.030526367243620345, 0.006928077903142871, 0.019017762235606694, 0.04265197057415904, 0.007358049605674433, 0.029955699113555, 0.11492564781773795, 0.10302828434882172, 0.12037551129901825, 0.11894536520281163, 0.14350937148961407, 0.12427728986096032, 0.12840081366317646, 0.11962076610430339, 0.13964553027266502, 0.37361890508727313, 0.40080206172051913, 0.40930982197759347, 0.4150320194071142, 0.4624152745614992, 0.43861607316134155, 0.41610798292885043, 0.394225004776965, 0.40447275025003904, 0.08199860522277191, 0.09793500623928686, 0.11936207563641787, 0.1018460419920757, 0.10442693131764613, 0.08254180967247426, 0.1196269430742648, 0.10734056210471576, 0.10109583259387778, 0.15817320488390774, 0.17732705704316343, 0.16960421412311955, 0.14899243388085137, 0.17833484826056434, 0.17745430421956843, 0.16067001694691174, 0.16831613856635141, 0.17468257846395296, 0.17843579698509016, 0.2121232382468261, 0.20336828431399323, 0.25792453290405093, 0.218893294248947, 0.1870331734771017, 0.217711690883034, 0.23384307754316702, 0.22918032462747362, 0.15975975681276833, 0.1869550565651632, 0.11978801030616737, 0.13752103691725848, 0.12755614539089255, 0.15308552174725698, 0.19874801065097658, 0.18977207164921428, 0.1949699471963826, 0.17751386017268866, 0.1895812655117054, 0.16291771822344836, 0.17418996888303395, 0.18651445640150732, 0.19047341429904296, 0.19079498406979278, 0.16449338396736735, 0.203747175172161, 0.1659199460691425, 0.18415689492202525, 0.2206497098559026, 0.20033517377998988, 0.16594295832534245, 0.17188369796249225, 0.1886948270333717, 0.17897049704298262, 0.19443206723182438, 0.19124389165018152, 0.1467428949496461, 0.5682001778674299, 0.164192878662351, 0.31329607769159196, 0.17843831795534992, 0.11817034616497257, 0.1624406522929226, 0.4412463916336272, 0.18688838674655395, 0.5282600734263503, 0.3078126684278636, 0.40496345916701804, 0.5519818253324749, 0.4452662835863592, 0.12009167507465901, 0.1956239761833931, 0.20200444363727188, 0.1794122252357354, 0.1774283700627508, 0.17659305311386908, 0.17335020675693846, 0.20964710232790484, 0.17960456312146977, 0.19119846253877215, 0.2057352657669369, 0.17614914811210092, 0.0729120800685299, 0.06415789982563425, 0.08593916586551054, 0.06977826198704462, 0.07513840450118059, 0.07990536956721805, 0.07230800809281701, 0.0697626292273249, 0.06399867250577151]}, "mutation_prompt": null}
{"id": "ae47f58f-b010-4494-9c01-56a9e390840e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                self.f = 0.5 + 0.5 * (self.evaluations / self.budget)  # Adaptive tuning line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-0.1, 0.1, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive parameter tuning in the Differential Evolution phase to balance exploration and exploitation dynamically.", "configspace": "", "generation": 2, "fitness": 0.23914472400366277, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.18.", "error": "", "parent_id": "0ab7f42a-03b4-46b7-a316-a59bd6fda49d", "metadata": {"aucs": [0.5088559309319338, 0.560293347283969, 0.5768866293116941, 0.5797152372984868, 0.6109198279622499, 0.535188788045627, 0.5933506287254589, 0.5229274812052351, 0.5643910883221142, 0.21191448247112643, 0.17048998604407917, 0.2522883489411317, 0.21178095609863445, 0.20638731224351914, 0.2734888043598639, 0.25848302013205127, 0.2041308443356159, 0.2257231154687046, 0.10899768384348041, 0.11232778385987352, 0.12180985403825362, 0.11849550670074482, 0.09864283296365506, 0.11871755136131013, 0.09985020985691007, 0.13905449581895668, 0.10108845721687942, 0.047432853100511374, 0.10614371142748147, 0.11793059968363484, 0.08269002927291169, 0.10381811431681509, 0.08069238435150472, 0.11650721435626965, 0.10863533140719084, 0.08340460453143372, 0.7875423079579007, 0.8163850664801942, 0.7832749641859198, 0.6853877321638187, 0.8382600258089713, 0.9436700112260672, 0.8807524279257652, 0.8495641024786301, 0.8880579601474228, 0.2406380731077007, 0.2244233489509565, 0.27155536746490005, 0.29085491387449414, 0.2539788326126853, 0.3078727573801694, 0.24005144021603353, 0.22771659396976995, 0.275551779077855, 0.35492069707751417, 0.4074606050349113, 0.47528894320780735, 0.38606896729340257, 0.19268834849511574, 0.5240224271234619, 0.3322466233857645, 0.42070693865751696, 0.38637026335638947, 0.1358835069089933, 0.22240825252905538, 0.23221457154503622, 0.11924717992928269, 0.14658907251528708, 0.2260030170447781, 0.19957463724869584, 0.18315968562562868, 0.19589495701241566, 0.11287487292424303, 0.17058536302107075, 0.2211919964113872, 0.17205195292857167, 0.20270052359385182, 0.13067058779716012, 0.16972604091980048, 0.2168369421236901, 0.17223043816773753, 0.07432568613313939, 0.22155362024733016, 0.0853467240810254, 0.1485878521718771, 0.10889322542203239, 0.10266464280408705, 0.10357225780214285, 0.15436033033253438, 0.14014648515244643, 0.11567115881965562, 0.23256971691924122, 0.22949288209925445, 0.19825301887120395, 0.24284152827263605, 0.22158854458238741, 0.1447785460241484, 0.25817395154822564, 0.16205196323806648, 0.03403265194528704, 0.016563964796296737, 0.03070280795853053, 0.024465668635033078, 0.0535867788961647, 0.052963019421018775, 0.037029363258280545, 0.08647960699571922, 0.02190212370269251, 0.1692069151596043, 0.18542523203365924, 0.1568813408537817, 0.1664982194313681, 0.1665716849190827, 0.1698980258031505, 0.13528379972308213, 0.13221143431223448, 0.1261050498009315, 0.4649612675791014, 0.4962453305870055, 0.4566741118174463, 0.45400767544399356, 0.44205357111246335, 0.4549924271503424, 0.46267938892806904, 0.439456382618838, 0.43806882362983635, 0.10678962956639482, 0.06553518308218587, 0.08939617634945285, 0.11565932847465266, 0.1057037039887857, 0.10529521373069306, 0.12270204623201475, 0.14587103610849372, 0.14805773811355105, 0.16753038485173788, 0.20432925219672537, 0.2420558264481435, 0.2223938623390893, 0.2587009486995069, 0.1808397734479983, 0.1702890393599764, 0.3009491334496589, 0.17407129422015044, 0.22681670887230465, 0.2561468765676669, 0.20814910434483513, 0.20766637251202602, 0.2593162807059254, 0.23977677498737082, 0.2613047424897671, 0.24529301454393293, 0.2272761434679249, 0.1825148822819056, 0.1746954609240724, 0.17287053834300536, 0.23039890013381836, 0.20780420038113545, 0.17759102198386623, 0.17529186788212392, 0.22371913983016334, 0.19329190049109612, 0.20085147770335243, 0.1928785055662755, 0.2002696691310636, 0.1940913585684576, 0.1909231108855982, 0.2020215279630061, 0.18536863245121193, 0.21697876577716224, 0.18842082947441607, 0.19449813345375455, 0.21523297931604157, 0.19714295638743995, 0.1830139884595594, 0.20346484978719392, 0.1976559311366627, 0.19374790717446955, 0.20464200784823328, 0.17775042070465008, 0.17294607461230693, 0.14909718598220678, 0.14956780851580265, 0.16967631746205025, 0.19777613219516288, 0.17205153026605113, 0.15491440563812453, 0.1621521947884248, 0.7839041774062612, 0.19566128604139665, 0.19778331410266559, 0.2511137034039804, 0.19813992953575432, 0.4164744684149795, 0.6555990494763799, 0.3181716907781955, 0.15289514930722303, 0.1476229055991014, 0.1862686222422626, 0.18975614722045142, 0.17681956349163608, 0.19705529208136086, 0.20025176487562868, 0.18526699503345256, 0.19746008984778618, 0.18487886520534136, 0.1852514853136229, 0.07356375085230193, 0.09437076168759428, 0.08474597492727332, 0.07050402743938555, 0.07539213051163318, 0.07885540821581982, 0.06835611414328091, 0.08422444708031196, 0.0732161026736603]}, "mutation_prompt": null}
{"id": "29ed934e-563b-446f-924f-9d179b78e540", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                self.f = 0.5 + 0.5 * (self.evaluations / self.budget)  # Adaptive tuning line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-0.1, 0.1, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive parameter tuning in the Differential Evolution phase to balance exploration and exploitation dynamically.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae47f58f-b010-4494-9c01-56a9e390840e", "metadata": {"aucs": [0.5088559309319338, 0.560293347283969, 0.5768866293116941, 0.5797152372984868, 0.6109198279622499, 0.535188788045627, 0.5933506287254589, 0.5229274812052351, 0.5643910883221142, 0.21191448247112643, 0.17048998604407917, 0.2522883489411317, 0.21178095609863445, 0.20638731224351914, 0.2734888043598639, 0.25848302013205127, 0.2041308443356159, 0.2257231154687046, 0.10899768384348041, 0.11232778385987352, 0.12180985403825362, 0.11849550670074482, 0.09864283296365506, 0.11871755136131013, 0.09985020985691007, 0.13905449581895668, 0.10108845721687942, 0.047432853100511374, 0.10614371142748147, 0.11793059968363484, 0.08269002927291169, 0.10381811431681509, 0.08069238435150472, 0.11650721435626965, 0.10863533140719084, 0.08340460453143372, 0.7875423079579007, 0.8163850664801942, 0.7832749641859198, 0.6853877321638187, 0.8382600258089713, 0.9436700112260672, 0.8807524279257652, 0.8495641024786301, 0.8880579601474228, 0.2406380731077007, 0.2244233489509565, 0.27155536746490005, 0.29085491387449414, 0.2539788326126853, 0.3078727573801694, 0.24005144021603353, 0.22771659396976995, 0.275551779077855, 0.35492069707751417, 0.4074606050349113, 0.47528894320780735, 0.38606896729340257, 0.19268834849511574, 0.5240224271234619, 0.3322466233857645, 0.42070693865751696, 0.38637026335638947, 0.1358835069089933, 0.22240825252905538, 0.23221457154503622, 0.11924717992928269, 0.14658907251528708, 0.2260030170447781, 0.19957463724869584, 0.18315968562562868, 0.19589495701241566, 0.11287487292424303, 0.17058536302107075, 0.2211919964113872, 0.17205195292857167, 0.20270052359385182, 0.13067058779716012, 0.16972604091980048, 0.2168369421236901, 0.17223043816773753, 0.07432568613313939, 0.22155362024733016, 0.0853467240810254, 0.1485878521718771, 0.10889322542203239, 0.10266464280408705, 0.10357225780214285, 0.15436033033253438, 0.14014648515244643, 0.11567115881965562, 0.23256971691924122, 0.22949288209925445, 0.19825301887120395, 0.24284152827263605, 0.22158854458238741, 0.1447785460241484, 0.25817395154822564, 0.16205196323806648, 0.03403265194528704, 0.016563964796296737, 0.03070280795853053, 0.024465668635033078, 0.0535867788961647, 0.052963019421018775, 0.037029363258280545, 0.08647960699571922, 0.02190212370269251, 0.1692069151596043, 0.18542523203365924, 0.1568813408537817, 0.1664982194313681, 0.1665716849190827, 0.1698980258031505, 0.13528379972308213, 0.13221143431223448, 0.1261050498009315, 0.4649612675791014, 0.4962453305870055, 0.4566741118174463, 0.45400767544399356, 0.44205357111246335, 0.4549924271503424, 0.46267938892806904, 0.439456382618838, 0.43806882362983635, 0.10678962956639482, 0.06553518308218587, 0.08939617634945285, 0.11565932847465266, 0.1057037039887857, 0.10529521373069306, 0.12270204623201475, 0.14587103610849372, 0.14805773811355105, 0.16753038485173788, 0.20432925219672537, 0.2420558264481435, 0.2223938623390893, 0.2587009486995069, 0.1808397734479983, 0.1702890393599764, 0.3009491334496589, 0.17407129422015044, 0.22681670887230465, 0.2561468765676669, 0.20814910434483513, 0.20766637251202602, 0.2593162807059254, 0.23977677498737082, 0.2613047424897671, 0.24529301454393293, 0.2272761434679249, 0.1825148822819056, 0.1746954609240724, 0.17287053834300536, 0.23039890013381836, 0.20780420038113545, 0.17759102198386623, 0.17529186788212392, 0.22371913983016334, 0.19329190049109612, 0.20085147770335243, 0.1928785055662755, 0.2002696691310636, 0.1940913585684576, 0.1909231108855982, 0.2020215279630061, 0.18536863245121193, 0.21697876577716224, 0.18842082947441607, 0.19449813345375455, 0.21523297931604157, 0.19714295638743995, 0.1830139884595594, 0.20346484978719392, 0.1976559311366627, 0.19374790717446955, 0.20464200784823328, 0.17775042070465008, 0.17294607461230693, 0.14909718598220678, 0.14956780851580265, 0.16967631746205025, 0.19777613219516288, 0.17205153026605113, 0.15491440563812453, 0.1621521947884248, 0.7839041774062612, 0.19566128604139665, 0.19778331410266559, 0.2511137034039804, 0.19813992953575432, 0.4164744684149795, 0.6555990494763799, 0.3181716907781955, 0.15289514930722303, 0.1476229055991014, 0.1862686222422626, 0.18975614722045142, 0.17681956349163608, 0.19705529208136086, 0.20025176487562868, 0.18526699503345256, 0.19746008984778618, 0.18487886520534136, 0.1852514853136229, 0.07356375085230193, 0.09437076168759428, 0.08474597492727332, 0.07050402743938555, 0.07539213051163318, 0.07885540821581982, 0.06835611414328091, 0.08422444708031196, 0.0732161026736603]}, "mutation_prompt": null}
{"id": "845dbaac-41d9-445b-abd4-7a92714605ea", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                self.f = 0.5 + 0.5 * (self.evaluations / self.budget)  # Adaptive tuning line 2\n            if self.evaluations > self.budget / 2:  # New line 1\n                self.cr = 0.5  # New line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-0.1, 0.1, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance exploration by introducing temporary lower crossover rate for diversity when evaluations exceed half the budget.", "configspace": "", "generation": 4, "fitness": 0.2304945412436879, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.18.", "error": "", "parent_id": "ae47f58f-b010-4494-9c01-56a9e390840e", "metadata": {"aucs": [0.5153830821215095, 0.5624759291596599, 0.587744615412036, 0.5973011242222326, 0.6160661253692469, 0.5435168050800327, 0.6012069289003463, 0.5546361058013018, 0.5575718559721391, 0.23469430734592078, 0.17569794240927727, 0.25653183682330005, 0.21449411062243218, 0.2018428857675172, 0.284454701830655, 0.24243354393518157, 0.2127111356017798, 0.2415803974345806, 0.11162657415888355, 0.12256268557484307, 0.12487813320525343, 0.12623212777954418, 0.10051277094823163, 0.12113477331991107, 0.11149202254882495, 0.14329875393363312, 0.11423284574753434, 0.05507575519673935, 0.11099678880490704, 0.1179975112657794, 0.0910035567764984, 0.10628960628983619, 0.08563176827140528, 0.11654456862577356, 0.11179155333097479, 0.09634755570811049, 0.7875423079579007, 0.8163850664801942, 0.7832749641859198, 0.6853877321638187, 0.8382600258089713, 0.9436700112260672, 0.8807524279257652, 0.8495641024786301, 0.8880579601474228, 0.2301605674213436, 0.2226371565009413, 0.26758074192346915, 0.2941395963659532, 0.2513182258909741, 0.30089998457175826, 0.2357070062815282, 0.23547648827109202, 0.2688070936469583, 0.30736946647062136, 0.4074606050349113, 0.2938081261517489, 0.3460639833780107, 0.1926450737800539, 0.5240224271234619, 0.3196580409075743, 0.27637728500553516, 0.21335256995428076, 0.11487908862066509, 0.20643692901455257, 0.21035705472987964, 0.11305890114420869, 0.13442549581963503, 0.23370330713484122, 0.18599405065155616, 0.1736646022932815, 0.1808715271935194, 0.11196832685875857, 0.1501803338681661, 0.2046637542475077, 0.1648641362203882, 0.1862019571932063, 0.12248990898104839, 0.1541161888632825, 0.18010085916714547, 0.17262294563859637, 0.05516774130371527, 0.14826667475826183, 0.05987356071375993, 0.11313911273903554, 0.07810553729090863, 0.06762141658057008, 0.06959784605288166, 0.119762324471542, 0.12900493240024824, 0.07952862013621653, 0.21728289251498478, 0.19828183967290758, 0.1857669113152116, 0.2271339019436891, 0.21152875054979003, 0.10851351877206794, 0.22655067998658673, 0.12346417990914615, 0.012397994614030683, 0.008264256891212796, 0.001303795705603128, 0.006640439879599391, 0.0013268303328035636, 0.03490500282685238, 0.021161499215178625, 0.03980545064405161, 0.010412902083594244, 0.1506210049545067, 0.15653115994449218, 0.14797715557524482, 0.15675858562920075, 0.15192994013393113, 0.1503828069630948, 0.11471311152493324, 0.11908594913502313, 0.12329326222882231, 0.4401500372621292, 0.48080318867261573, 0.44815618507582056, 0.4434083023168376, 0.42412799887056896, 0.42365776502488894, 0.44446180829812487, 0.45411568138085046, 0.41053641629411486, 0.10678962956639482, 0.06521736460896188, 0.08939617634945285, 0.11565932847465266, 0.10686315621645459, 0.10305567105236246, 0.12270204623201475, 0.14587103610849372, 0.14805773811355105, 0.16675538326576844, 0.19794811845683302, 0.2420558264481435, 0.2223938623390893, 0.2587009486995069, 0.1808397734479983, 0.1702890393599764, 0.3009491334496589, 0.17407129422015044, 0.22681670887230465, 0.2561281413200974, 0.21837972613702983, 0.20180821363222945, 0.25647582939155367, 0.2443219390172271, 0.2605842918250898, 0.24093771380798956, 0.22713708727780557, 0.1825148822819056, 0.17132309106311405, 0.17101465015704198, 0.23249654469733938, 0.2074983404910351, 0.1728573210303841, 0.1723362415402636, 0.22469369838219755, 0.18841970116413642, 0.2006169041951532, 0.1928785055662755, 0.2002696691310636, 0.19491086888408515, 0.1909011569235134, 0.2020215279630061, 0.18536863245121193, 0.21697876577716224, 0.18842082947441607, 0.19463793311017186, 0.21523297931604157, 0.1980694787252799, 0.19131027089761177, 0.2010206643058713, 0.19796461595922799, 0.19374790717446955, 0.20464200784823328, 0.17979608891693966, 0.1729475960233704, 0.14909713830150428, 0.14956767213100153, 0.16967528839167245, 0.19777266459589193, 0.17203411406771052, 0.15491380344632, 0.1621528684329815, 0.7859351425972295, 0.1956591562885005, 0.19778626922544207, 0.2014441631644901, 0.19813899511827127, 0.35770575838097995, 0.6076042653943181, 0.2665232935894043, 0.1528934587100097, 0.14762300015458274, 0.1862686222422626, 0.18975614722045142, 0.17595447784916163, 0.19705529208136086, 0.20025176487562868, 0.18526699503345256, 0.19746008984778618, 0.18487886520534136, 0.1852514853136229, 0.07356375085230193, 0.09437076168759428, 0.08474597492727332, 0.07050402743938555, 0.07471852148857638, 0.07916948691965175, 0.06697768769715406, 0.08129758956966904, 0.0732161026736603]}, "mutation_prompt": null}
{"id": "f6e16794-0ef6-453d-a845-728142bd2552", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                self.f = 0.5 + 0.5 * (self.evaluations / self.budget)  # Adaptive tuning line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-0.1, 0.1, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive parameter tuning in the Differential Evolution phase to balance exploration and exploitation dynamically.", "configspace": "", "generation": 3, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ae47f58f-b010-4494-9c01-56a9e390840e", "metadata": {"aucs": [0.5088559309319338, 0.560293347283969, 0.5768866293116941, 0.5797152372984868, 0.6109198279622499, 0.535188788045627, 0.5933506287254589, 0.5229274812052351, 0.5643910883221142, 0.21191448247112643, 0.17048998604407917, 0.2522883489411317, 0.21178095609863445, 0.20638731224351914, 0.2734888043598639, 0.25848302013205127, 0.2041308443356159, 0.2257231154687046, 0.10899768384348041, 0.11232778385987352, 0.12180985403825362, 0.11849550670074482, 0.09864283296365506, 0.11871755136131013, 0.09985020985691007, 0.13905449581895668, 0.10108845721687942, 0.047432853100511374, 0.10614371142748147, 0.11793059968363484, 0.08269002927291169, 0.10381811431681509, 0.08069238435150472, 0.11650721435626965, 0.10863533140719084, 0.08340460453143372, 0.7875423079579007, 0.8163850664801942, 0.7832749641859198, 0.6853877321638187, 0.8382600258089713, 0.9436700112260672, 0.8807524279257652, 0.8495641024786301, 0.8880579601474228, 0.2406380731077007, 0.2244233489509565, 0.27155536746490005, 0.29085491387449414, 0.2539788326126853, 0.3078727573801694, 0.24005144021603353, 0.22771659396976995, 0.275551779077855, 0.35492069707751417, 0.4074606050349113, 0.47528894320780735, 0.38606896729340257, 0.19268834849511574, 0.5240224271234619, 0.3322466233857645, 0.42070693865751696, 0.38637026335638947, 0.1358835069089933, 0.22240825252905538, 0.23221457154503622, 0.11924717992928269, 0.14658907251528708, 0.2260030170447781, 0.19957463724869584, 0.18315968562562868, 0.19589495701241566, 0.11287487292424303, 0.17058536302107075, 0.2211919964113872, 0.17205195292857167, 0.20270052359385182, 0.13067058779716012, 0.16972604091980048, 0.2168369421236901, 0.17223043816773753, 0.07432568613313939, 0.22155362024733016, 0.0853467240810254, 0.1485878521718771, 0.10889322542203239, 0.10266464280408705, 0.10357225780214285, 0.15436033033253438, 0.14014648515244643, 0.11567115881965562, 0.23256971691924122, 0.22949288209925445, 0.19825301887120395, 0.24284152827263605, 0.22158854458238741, 0.1447785460241484, 0.25817395154822564, 0.16205196323806648, 0.03403265194528704, 0.016563964796296737, 0.03070280795853053, 0.024465668635033078, 0.0535867788961647, 0.052963019421018775, 0.037029363258280545, 0.08647960699571922, 0.02190212370269251, 0.1692069151596043, 0.18542523203365924, 0.1568813408537817, 0.1664982194313681, 0.1665716849190827, 0.1698980258031505, 0.13528379972308213, 0.13221143431223448, 0.1261050498009315, 0.4649612675791014, 0.4962453305870055, 0.4566741118174463, 0.45400767544399356, 0.44205357111246335, 0.4549924271503424, 0.46267938892806904, 0.439456382618838, 0.43806882362983635, 0.10678962956639482, 0.06553518308218587, 0.08939617634945285, 0.11565932847465266, 0.1057037039887857, 0.10529521373069306, 0.12270204623201475, 0.14587103610849372, 0.14805773811355105, 0.16753038485173788, 0.20432925219672537, 0.2420558264481435, 0.2223938623390893, 0.2587009486995069, 0.1808397734479983, 0.1702890393599764, 0.3009491334496589, 0.17407129422015044, 0.22681670887230465, 0.2561468765676669, 0.20814910434483513, 0.20766637251202602, 0.2593162807059254, 0.23977677498737082, 0.2613047424897671, 0.24529301454393293, 0.2272761434679249, 0.1825148822819056, 0.1746954609240724, 0.17287053834300536, 0.23039890013381836, 0.20780420038113545, 0.17759102198386623, 0.17529186788212392, 0.22371913983016334, 0.19329190049109612, 0.20085147770335243, 0.1928785055662755, 0.2002696691310636, 0.1940913585684576, 0.1909231108855982, 0.2020215279630061, 0.18536863245121193, 0.21697876577716224, 0.18842082947441607, 0.19449813345375455, 0.21523297931604157, 0.19714295638743995, 0.1830139884595594, 0.20346484978719392, 0.1976559311366627, 0.19374790717446955, 0.20464200784823328, 0.17775042070465008, 0.17294607461230693, 0.14909718598220678, 0.14956780851580265, 0.16967631746205025, 0.19777613219516288, 0.17205153026605113, 0.15491440563812453, 0.1621521947884248, 0.7839041774062612, 0.19566128604139665, 0.19778331410266559, 0.2511137034039804, 0.19813992953575432, 0.4164744684149795, 0.6555990494763799, 0.3181716907781955, 0.15289514930722303, 0.1476229055991014, 0.1862686222422626, 0.18975614722045142, 0.17681956349163608, 0.19705529208136086, 0.20025176487562868, 0.18526699503345256, 0.19746008984778618, 0.18487886520534136, 0.1852514853136229, 0.07356375085230193, 0.09437076168759428, 0.08474597492727332, 0.07050402743938555, 0.07539213051163318, 0.07885540821581982, 0.06835611414328091, 0.08422444708031196, 0.0732161026736603]}, "mutation_prompt": null}
{"id": "8fe93cf6-caaf-4c9e-8b88-9430d0a76b9a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                self.f = 0.5 + 0.5 * (self.evaluations / self.budget)  # Adaptive tuning line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.1 * (1 - self.evaluations / self.budget)  # Line modified 1\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce a dynamic adjustment of the local search perturbation range based on the current evaluation progress to enhance exploration capabilities.", "configspace": "", "generation": 6, "fitness": 0.2493040410862061, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.18.", "error": "", "parent_id": "ae47f58f-b010-4494-9c01-56a9e390840e", "metadata": {"aucs": [0.5197493395316035, 0.6066208903017691, 0.5840671755369911, 0.5750526370873248, 0.5567868242237857, 0.570341484032515, 0.5866672278420937, 0.5585019751244649, 0.5932388975593734, 0.17947094131085572, 0.1989563521614356, 0.2315259501257365, 0.21124389492027273, 0.20555855912047005, 0.2556563279529155, 0.21244471608020354, 0.21973512750573976, 0.24007288311940256, 0.12309875771087442, 0.12972648358728633, 0.10250642792708675, 0.09639718907808015, 0.1162108365786153, 0.11695999628715403, 0.11006018238103554, 0.108108430780269, 0.11919724876172766, 0.05451219378949357, 0.10687571394130302, 0.07726270312490124, 0.08840495483927424, 0.11487399757251482, 0.09186461380772104, 0.08669053774499846, 0.13010723151071757, 0.08227752524893672, 0.791581354952071, 0.8269343893377699, 0.7741856716776774, 0.5901195372866839, 0.8460246683184811, 0.9436697046123049, 0.8616118785233586, 0.8470403666274922, 0.8868665541554784, 0.264894744782983, 0.2507401164798716, 0.3167549761523424, 0.3188884298705178, 0.27468711338856855, 0.33481504167427545, 0.21288585274259053, 0.24268803561022056, 0.29529425413967525, 0.4064458502725872, 0.5894465211657258, 0.5429058056617884, 0.51049785975854, 0.15668923917414124, 0.6491547029261918, 0.6620969541652557, 0.2837317273197898, 0.58033988254401, 0.0772179242415979, 0.2842751206611267, 0.2024615876860023, 0.10928722556014403, 0.22394502579946152, 0.19831730625086053, 0.2502700656776188, 0.1634243850779531, 0.20599330660618198, 0.15119099340820452, 0.20386093783750714, 0.24705361533324754, 0.23043770371659222, 0.25582022041754415, 0.14955411276714492, 0.19502556892550338, 0.15962637958268877, 0.1908495038586958, 0.11593035053799283, 0.13816970289027142, 0.09301923626356934, 0.17046801337714823, 0.15410515313106166, 0.1267925510895851, 0.14225995097883848, 0.20086037270515522, 0.14851279055600775, 0.19042852805675625, 0.24829066045790826, 0.28367844355451477, 0.270610448681908, 0.2253414387967949, 0.22134648180410366, 0.112709920614664, 0.2277496788208122, 0.19792291407500262, 0.04934091004486019, 0.05687943260050399, 0.05361362585685869, 0.05671684890834783, 0.040015026070469695, 0.06775735862385479, 0.049955356786582694, 0.048269422006683604, 0.05815276481976106, 0.1681878018658921, 0.15308862269015666, 0.16910799076728034, 0.15856213501362637, 0.18239292165587506, 0.17155635667991342, 0.1331351713920731, 0.16458810735858276, 0.1467638357108051, 0.4431868130041575, 0.4797407531243363, 0.4744265341141012, 0.46498975451377167, 0.4729326742098786, 0.47171387370764395, 0.47379337597620974, 0.44366173002174714, 0.4603223067599601, 0.13585651505040786, 0.08104986720320118, 0.09928034711141787, 0.13391154996740684, 0.11046266079667477, 0.12799007266282847, 0.09036875374972586, 0.14980393463458297, 0.13589768314851625, 0.1789536978281545, 0.17845040299622672, 0.25488824828651446, 0.1629143719306405, 0.3042058052409775, 0.17119373178885655, 0.16956484666456184, 0.1944709330068869, 0.1757060178456128, 0.24719024766091802, 0.25637673305396413, 0.20988218218049037, 0.18895953468566706, 0.24275259984289232, 0.23943794520052608, 0.29633422561043987, 0.23524757737085322, 0.2952260652642106, 0.16490060585051236, 0.1968754426797612, 0.16820615834759278, 0.20667276760361053, 0.21569232131052818, 0.20182207949929487, 0.19486146773407775, 0.1546859577880657, 0.18892972800685992, 0.18850790724535538, 0.24794807425157506, 0.186840391416353, 0.22993735466756327, 0.21619695355613155, 0.1836765355132698, 0.17333256284052245, 0.2090865508481844, 0.2114462879622534, 0.19901193180516696, 0.18649534198949236, 0.18267020860151828, 0.19149279936422203, 0.1914831187056193, 0.18830323339105604, 0.20376410877945694, 0.21134440142155342, 0.1783886554646693, 0.17524401024531266, 0.14946353747725427, 0.1494775476309842, 0.17017556417499602, 0.19991188896389522, 0.16731987951023453, 0.15280038379464245, 0.16533440420845713, 0.7961929842728466, 0.19541983040131505, 0.1949781810793214, 0.17729608103825722, 0.1984310813064014, 0.33654025392888975, 0.6882483576319249, 0.4131911690607192, 0.15025414060241038, 0.371824421093072, 0.19435336641347956, 0.19538722093247096, 0.2232632056816003, 0.19603724469901584, 0.21307972934660258, 0.19671376064588286, 0.21095325587014946, 0.19322131033250267, 0.19029054612399476, 0.08231023812830685, 0.07406463001171015, 0.09364628074867942, 0.08375370549556593, 0.07970176657034722, 0.08494968547751525, 0.08259062810341744, 0.0888940965498014, 0.07393240402768209]}, "mutation_prompt": null}
{"id": "cc353dcb-f884-4ac8-b162-26283ae8e8fd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                self.f = 0.5 + 0.5 * (self.evaluations / self.budget)  # Adaptive tuning line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.1 * (1 - self.evaluations / self.budget)  # Line modified 1\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce a dynamic adjustment of the local search perturbation range based on the current evaluation progress to enhance exploration capabilities.", "configspace": "", "generation": 7, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "8fe93cf6-caaf-4c9e-8b88-9430d0a76b9a", "metadata": {"aucs": [0.5197493395316035, 0.6066208903017691, 0.5840671755369911, 0.5750526370873248, 0.5567868242237857, 0.570341484032515, 0.5866672278420937, 0.5585019751244649, 0.5932388975593734, 0.17947094131085572, 0.1989563521614356, 0.2315259501257365, 0.21124389492027273, 0.20555855912047005, 0.2556563279529155, 0.21244471608020354, 0.21973512750573976, 0.24007288311940256, 0.12309875771087442, 0.12972648358728633, 0.10250642792708675, 0.09639718907808015, 0.1162108365786153, 0.11695999628715403, 0.11006018238103554, 0.108108430780269, 0.11919724876172766, 0.05451219378949357, 0.10687571394130302, 0.07726270312490124, 0.08840495483927424, 0.11487399757251482, 0.09186461380772104, 0.08669053774499846, 0.13010723151071757, 0.08227752524893672, 0.791581354952071, 0.8269343893377699, 0.7741856716776774, 0.5901195372866839, 0.8460246683184811, 0.9436697046123049, 0.8616118785233586, 0.8470403666274922, 0.8868665541554784, 0.264894744782983, 0.2507401164798716, 0.3167549761523424, 0.3188884298705178, 0.27468711338856855, 0.33481504167427545, 0.21288585274259053, 0.24268803561022056, 0.29529425413967525, 0.4064458502725872, 0.5894465211657258, 0.5429058056617884, 0.51049785975854, 0.15668923917414124, 0.6491547029261918, 0.6620969541652557, 0.2837317273197898, 0.58033988254401, 0.0772179242415979, 0.2842751206611267, 0.2024615876860023, 0.10928722556014403, 0.22394502579946152, 0.19831730625086053, 0.2502700656776188, 0.1634243850779531, 0.20599330660618198, 0.15119099340820452, 0.20386093783750714, 0.24705361533324754, 0.23043770371659222, 0.25582022041754415, 0.14955411276714492, 0.19502556892550338, 0.15962637958268877, 0.1908495038586958, 0.11593035053799283, 0.13816970289027142, 0.09301923626356934, 0.17046801337714823, 0.15410515313106166, 0.1267925510895851, 0.14225995097883848, 0.20086037270515522, 0.14851279055600775, 0.19042852805675625, 0.24829066045790826, 0.28367844355451477, 0.270610448681908, 0.2253414387967949, 0.22134648180410366, 0.112709920614664, 0.2277496788208122, 0.19792291407500262, 0.04934091004486019, 0.05687943260050399, 0.05361362585685869, 0.05671684890834783, 0.040015026070469695, 0.06775735862385479, 0.049955356786582694, 0.048269422006683604, 0.05815276481976106, 0.1681878018658921, 0.15308862269015666, 0.16910799076728034, 0.15856213501362637, 0.18239292165587506, 0.17155635667991342, 0.1331351713920731, 0.16458810735858276, 0.1467638357108051, 0.4431868130041575, 0.4797407531243363, 0.4744265341141012, 0.46498975451377167, 0.4729326742098786, 0.47171387370764395, 0.47379337597620974, 0.44366173002174714, 0.4603223067599601, 0.13585651505040786, 0.08104986720320118, 0.09928034711141787, 0.13391154996740684, 0.11046266079667477, 0.12799007266282847, 0.09036875374972586, 0.14980393463458297, 0.13589768314851625, 0.1789536978281545, 0.17845040299622672, 0.25488824828651446, 0.1629143719306405, 0.3042058052409775, 0.17119373178885655, 0.16956484666456184, 0.1944709330068869, 0.1757060178456128, 0.24719024766091802, 0.25637673305396413, 0.20988218218049037, 0.18895953468566706, 0.24275259984289232, 0.23943794520052608, 0.29633422561043987, 0.23524757737085322, 0.2952260652642106, 0.16490060585051236, 0.1968754426797612, 0.16820615834759278, 0.20667276760361053, 0.21569232131052818, 0.20182207949929487, 0.19486146773407775, 0.1546859577880657, 0.18892972800685992, 0.18850790724535538, 0.24794807425157506, 0.186840391416353, 0.22993735466756327, 0.21619695355613155, 0.1836765355132698, 0.17333256284052245, 0.2090865508481844, 0.2114462879622534, 0.19901193180516696, 0.18649534198949236, 0.18267020860151828, 0.19149279936422203, 0.1914831187056193, 0.18830323339105604, 0.20376410877945694, 0.21134440142155342, 0.1783886554646693, 0.17524401024531266, 0.14946353747725427, 0.1494775476309842, 0.17017556417499602, 0.19991188896389522, 0.16731987951023453, 0.15280038379464245, 0.16533440420845713, 0.7961929842728466, 0.19541983040131505, 0.1949781810793214, 0.17729608103825722, 0.1984310813064014, 0.33654025392888975, 0.6882483576319249, 0.4131911690607192, 0.15025414060241038, 0.371824421093072, 0.19435336641347956, 0.19538722093247096, 0.2232632056816003, 0.19603724469901584, 0.21307972934660258, 0.19671376064588286, 0.21095325587014946, 0.19322131033250267, 0.19029054612399476, 0.08231023812830685, 0.07406463001171015, 0.09364628074867942, 0.08375370549556593, 0.07970176657034722, 0.08494968547751525, 0.08259062810341744, 0.0888940965498014, 0.07393240402768209]}, "mutation_prompt": null}
{"id": "89e4c101-c7f9-443a-a7be-23287e52782d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.1 * (1 - self.evaluations / self.budget)  # Line modified 1\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance adaptive tuning by incorporating feedback from population diversity to optimize search dynamics.", "configspace": "", "generation": 8, "fitness": 0.25952884675093907, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.20.", "error": "", "parent_id": "8fe93cf6-caaf-4c9e-8b88-9430d0a76b9a", "metadata": {"aucs": [0.625000140216615, 0.6718080000499898, 0.6801302352466905, 0.7000200974937987, 0.689149219777551, 0.6741987872165884, 0.6421756267200388, 0.6885961941664795, 0.6697863409389064, 0.09141946583193516, 0.3134858025993048, 0.2930065519344751, 0.28287957221782223, 0.3550054630996978, 0.33339608519377995, 0.3329861421617447, 0.32656785831760526, 0.08740678605668273, 0.141397407065179, 0.15623036726871165, 0.11207487298175711, 0.14417659217447376, 0.12674952203997158, 0.112053418300737, 0.09249588968878275, 0.11982601758147993, 0.12645136125342793, 0.08692003875131937, 0.09919712075846487, 0.12607736730919916, 0.08257455947021641, 0.11180618294171185, 0.10304130563448088, 0.0906011459953544, 0.09078801708372752, 0.1032659271881835, 0.7785479939358658, 0.8582142789701123, 0.789039072060107, 0.4813358364159602, 0.868992166831551, 0.9437108924544674, 0.8718197477209719, 0.8186657682503218, 0.8874192832755424, 0.3127843638773712, 0.27992193148551725, 0.3235640773374098, 0.3042450067676695, 0.33381470687179793, 0.3073059362929472, 0.13739861370956807, 0.2525300037153031, 0.31920384535145696, 0.5130789733554182, 0.4407303485068743, 0.20253432431097118, 0.6272272656545339, 0.14258244349711235, 0.5579718906370059, 0.7173997907802642, 0.205444402589245, 0.6400796784145939, 0.08075726021658014, 0.34715902762106465, 0.22478557986738834, 0.13437198611945445, 0.1767149716876425, 0.22724730502561175, 0.1535424612020021, 0.13298770169458551, 0.1481496062587312, 0.11124869920559499, 0.11690154177705558, 0.23372207624493457, 0.20587322112390893, 0.30221699999021634, 0.20371827102209683, 0.10657981055916521, 0.16934142882081737, 0.24796838132841792, 0.12034269834481948, 0.14292613179820768, 0.20143868545197663, 0.14657452867432452, 0.16117547457875314, 0.025029591935231466, 0.11959557380067487, 0.17616869612693076, 0.15586792235466584, 0.09081629266976743, 0.29783557757211254, 0.29725694198092, 0.32111695939097695, 0.22835449187908408, 0.24510268094127552, 0.06640167734677782, 0.20253255520401325, 0.21371224319487836, 0.04775437526975279, 0.08523072725583625, 0.04780950352790714, 0.11033155124059357, 0.11963039695813293, 0.057879289370858844, 0.1086946557708226, 0.057015382060969566, 0.050896971194366425, 0.14945574626723646, 0.18316707565588874, 0.19045211805566786, 0.17766751184295881, 0.19817092318472262, 0.19174782515832156, 0.1501099955355225, 0.18285989145392623, 0.21783815450475974, 0.5472533748501072, 0.5577860739819618, 0.5243919867921063, 0.5564495237740466, 0.5131469413845628, 0.5616936715488705, 0.4672996235523732, 0.548903921761527, 0.49407707945749, 0.09526852628054727, 0.06330948275654846, 0.11715143017591545, 0.10492579836207916, 0.13407294596893193, 0.11774456458300608, 0.10316696745248721, 0.1505647559321358, 0.1841529213247155, 0.24895497054365046, 0.19678354931141329, 0.1665813348661701, 0.16192779294720216, 0.2665560622465054, 0.20923583756327813, 0.2152432035294205, 0.22031936150736087, 0.18443724002223982, 0.23244309145421627, 0.22232373321946375, 0.21746715127957417, 0.21944614558833553, 0.25014584497106596, 0.24049492118694116, 0.29504234462931866, 0.22725499434586394, 0.23495970139670663, 0.17774272259732082, 0.20621795936760423, 0.13845788978589857, 0.1742537937221994, 0.19124262011593085, 0.22607262405679618, 0.1410088052527262, 0.1967733247269482, 0.19417004995927167, 0.18473884102922844, 0.1894546827310667, 0.18908069824107465, 0.18697016745971973, 0.2248257610751474, 0.19663664451986196, 0.19692677528143054, 0.21712258557274833, 0.1922152374631244, 0.19190199708835987, 0.20013518103189476, 0.1860441619483103, 0.2004416796430215, 0.19545387391468172, 0.1843328227631411, 0.18651690286603306, 0.18433036295286842, 0.19054666101396878, 0.14755078361443374, 0.14817196413477962, 0.148813145060671, 0.1683088444508105, 0.1964842056285958, 0.1656076491995616, 0.15843990880328984, 0.5226242900424674, 0.8063193362388624, 0.19369664249077212, 0.1974244139244361, 0.26759639351872466, 0.19857171356415215, 0.5596980771026121, 0.6202878558849441, 0.11748267416908587, 0.12042110966555342, 0.49007428823955035, 0.198834541639213, 0.19863067912071497, 0.1902711435029405, 0.21023467438996535, 0.1999327729977115, 0.19679881383306208, 0.1984510253269054, 0.19756577410941334, 0.20138186353344412, 0.10270118434262154, 0.08941095025915524, 0.08746607382035987, 0.07277518041249276, 0.09240054111743867, 0.09329984086758325, 0.0877576584680384, 0.08075535099122677, 0.07684256389299116]}, "mutation_prompt": null}
{"id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Utilize a dynamic perturbation range in local search to enhance exploration adaptively.", "configspace": "", "generation": 9, "fitness": 0.26673396074567723, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.20.", "error": "", "parent_id": "89e4c101-c7f9-443a-a7be-23287e52782d", "metadata": {"aucs": [0.6464660238591508, 0.692353448884776, 0.6744836638337468, 0.645867695047444, 0.6888882078079962, 0.6075547663342649, 0.699296990465918, 0.6528076275116812, 0.6402221109898869, 0.33266425597356597, 0.24882385882729718, 0.22347740871740374, 0.3186355632964196, 0.31977446272041143, 0.2998260504700392, 0.35435332685944054, 0.09056589132876447, 0.27097171622455696, 0.11459267033782994, 0.12326552833271942, 0.12828746117743017, 0.10485913515046108, 0.11894798044884225, 0.09318262517877918, 0.11836453336848662, 0.1281919131388808, 0.12008078903975328, 0.09241752923181845, 0.10194612829514482, 0.10286844888282498, 0.07258483976763364, 0.11245988970809229, 0.11648834023025834, 0.07203644438043522, 0.08446980430651296, 0.10376726659332636, 0.8163861974745478, 0.8474122374411639, 0.7699259053051883, 0.1143513196368533, 0.8427053523481973, 0.8518027545976079, 0.9159877764174582, 0.865030950106848, 0.9145098819516947, 0.27309154232464394, 0.3034707932685148, 0.32780508805006503, 0.3237645775834682, 0.3330199897461158, 0.3132400046552851, 0.27004612770840564, 0.35747466707027886, 0.29990028444342964, 0.5296293076805101, 0.6412668155080758, 0.6485531410121972, 0.5309792638150209, 0.6303341428722671, 0.436033709118849, 0.7442901996885684, 0.2140278000565622, 0.3685761173408826, 0.2161402363371291, 0.1623146839415991, 0.23468980499876946, 0.11377094154957834, 0.21482859246558816, 0.18363697139995538, 0.17670734085829098, 0.19844924009564924, 0.18273284065960815, 0.14438850102924083, 0.18417977458726376, 0.21998667312807185, 0.21940520982644784, 0.24577916229207653, 0.21914835321547066, 0.15237551938618832, 0.1933469355727322, 0.29551852231146847, 0.11869159217678804, 0.18756403094985252, 0.14206353660226234, 0.11109181319003747, 0.12491774901171926, 0.02284271157516482, 0.10747458178416669, 0.14189115309180633, 0.15962585721255895, 0.1564401871141936, 0.28660199716682777, 0.23845376624504533, 0.2905581240012338, 0.30686874052905455, 0.22552631987201555, 0.16472168787410502, 0.14930123253620708, 0.11608082835906475, 0.10084042189764952, 0.1177945378964328, 0.0325033173895779, 0.051730889108697165, 0.07698113069121204, 0.06215706386905495, 0.11945794289480416, 0.0939830209100122, 0.06592758703554269, 0.2191118699937148, 0.22013252610951273, 0.1625919797783989, 0.1924313197003763, 0.18836111483014917, 0.19470303628768726, 0.16813223443772163, 0.15945581007407217, 0.18196868894950702, 0.5629419712797245, 0.5375440153028057, 0.532708811387517, 0.5354595216972282, 0.45792768953664853, 0.5401921079960457, 0.49414806433254643, 0.4972107007426556, 0.4704945867559689, 0.08503212289307016, 0.08462872675037247, 0.11922433534974264, 0.11715974494714176, 0.10846819641332639, 0.10295365232780929, 0.09874355372485899, 0.14063695237587126, 0.13542571849045815, 0.19082858121159474, 0.22894426077889085, 0.17747196020723133, 0.21848877115022092, 0.24561530249450048, 0.26137639582468475, 0.2158115607910741, 0.2233306523778985, 0.1951422635290294, 0.297502445563384, 0.28173145980579994, 0.24827779828189378, 0.2701472467729703, 0.27028169170586247, 0.19456199982332145, 0.2548212261385707, 0.2935933077485583, 0.2711195015742157, 0.1629327270025056, 0.17888571817558496, 0.17792796576666337, 0.16612457900014665, 0.17738099336012914, 0.15309666839268177, 0.15343721955611056, 0.1534964835290089, 0.1967755305530372, 0.17985559378859906, 0.2052496870926831, 0.18783925683001135, 0.20070186833893078, 0.21712706088799805, 0.20027994758740697, 0.1598625405282471, 0.20283026864090803, 0.18624052243926592, 0.21940282366832498, 0.21526749614581842, 0.18007927331181295, 0.2064301141660343, 0.19708689452127448, 0.17868730542746203, 0.19995247289719031, 0.22370302521499474, 0.19406536105710714, 0.14815268705040763, 0.15076979846493466, 0.1498313517810539, 0.17154569450222856, 0.5889565592502912, 0.5828068851193432, 0.1551608187643646, 0.5701332227056678, 0.7785861924230445, 0.19920871183904765, 0.19951177187305436, 0.4584224526432932, 0.20174930786206402, 0.5431365257937668, 0.6629999759974777, 0.1408554140006607, 0.16368274606944, 0.5010036812486964, 0.1852866372614297, 0.17956083446732352, 0.18173471488206827, 0.19306467976293762, 0.19569627627752084, 0.18271976300338588, 0.18958656510157357, 0.1831874982860633, 0.18742474078263593, 0.08451950970086386, 0.08003379407593092, 0.07492734876508489, 0.07158723100455067, 0.08358947393808636, 0.08179483078008687, 0.08992412592816568, 0.07529622028413374, 0.07758113466611649]}, "mutation_prompt": null}
{"id": "2f5a87e6-1039-485a-a560-bd9548110a60", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutation_strength = np.random.rand() * (b - c)  # Modified line\n            mutant = np.clip(a + self.f * mutation_strength, self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce stochastic scaling in mutation for better diversity management.", "configspace": "", "generation": 10, "fitness": 0.2133995503020805, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.17.", "error": "", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.5645579237625873, 0.6166629794887776, 0.5405720896641278, 0.5653984999809335, 0.5899485183773692, 0.48126626684284834, 0.5634965650675875, 0.5764982533007694, 0.492135721158071, 0.07692807343515529, 0.03536679931972708, 0.004258018617179782, 0.06937515325632415, 0.007435390048139978, 0.045919262253814486, 0.005038619087500584, 0.029317959955612594, 0.031555605839390766, 0.10966250048053228, 0.11064714366720385, 0.10345845793080222, 0.12006825697241386, 0.14720106548591083, 0.14374919828752042, 0.15974750861013653, 0.15357601508847818, 0.1319263730245721, 0.04909910092382197, 0.05272509797135139, 0.08084450679619115, 0.02968283399044136, 0.03938344738415145, 0.10540845056798775, 9.999999999998899e-05, 0.08070676091852202, 0.10166777260809468, 0.16256786966190262, 0.12126204293170051, 0.6141503284081631, 0.10814406923231323, 0.8892613426786997, 0.4285298320089228, 0.8109489587339648, 0.36288092680456574, 0.8082459849767261, 0.280257251704248, 0.2338106127674089, 0.310865300234339, 0.2650041975230988, 0.15338614354315305, 0.2912681909940861, 0.33186512882849206, 0.1295037264869674, 0.3343342545714477, 0.6602539115132218, 0.11300783220586019, 0.25585873126184655, 0.25826395212628295, 0.68813809366599, 0.6622450843329414, 0.17352149918860704, 0.09176805665867815, 0.17039705425590068, 0.1390956556734695, 0.1181389320175027, 0.10713870312060958, 0.17936896720332973, 0.17304995370315934, 0.1948200185435891, 0.21770210287296332, 0.11797147863622792, 0.2652426223348967, 0.16408669910094564, 0.20309721366397626, 0.26372376849937473, 0.32113371938037816, 0.16989872797504835, 0.18429608316785306, 0.22641410147684504, 0.12004932728426887, 0.1315125472214368, 9.999999999998899e-05, 0.06100467129757092, 0.07276042999921761, 0.013384429013249433, 0.06659868951640913, 0.02663749048964925, 0.10815872963934559, 0.13681026042841005, 0.06835721596122435, 0.1150141170741521, 0.07542173108546302, 0.1641350517161403, 0.2978926006500131, 0.09006838293810016, 0.04183491577354892, 0.1448510803956926, 0.08149554160810002, 0.07691767797293103, 0.12662224726876503, 0.08018944415482443, 0.07268583983612587, 0.05149716591228348, 0.06882672568409653, 0.06424385857589765, 0.11806625520180225, 0.06019452512477996, 0.0513563768958325, 0.229668434718464, 0.12280571679350594, 0.09086144096179927, 0.17744538129938248, 0.141411887821966, 0.03692946168380917, 0.10201843705060931, 0.1361492186549067, 0.12060472173115944, 0.4837167636131591, 0.44390223880788504, 0.5287218788831682, 0.4068726548745192, 0.44861096625116037, 0.46987241639060995, 0.47182838457374787, 0.46283202062795314, 0.48082929156832677, 0.09445345615804579, 0.12275581286223003, 0.036032259133825795, 0.10044846184577749, 0.08201241977325424, 0.050041181762669695, 0.09766321470645578, 0.09053849011395199, 0.07313421058855563, 0.29440270236187804, 0.17321310470383855, 0.46655185483921746, 0.36444773937034114, 0.325148404902316, 0.30813764589205717, 0.20243576051128032, 0.33203269106742794, 0.2332942531767932, 0.22252074390300636, 0.29472072310112085, 0.21449746778520717, 0.36806122947541775, 0.3810299772129583, 0.24080007024934202, 0.24109552605289486, 0.3589312259486894, 0.1376673230195804, 0.1925506717380855, 0.17846886458216626, 0.1858225085160795, 0.2667708235798716, 0.28512401726086234, 0.194818945050378, 0.2144555997856038, 0.21120946102472293, 0.08633388165235178, 0.20670249596913337, 0.19120055011171466, 0.24151402456420967, 0.20795435298137976, 0.18271812512473073, 0.2335161330928659, 0.19982231611169277, 0.18638670695808568, 0.189493815435689, 0.18876185688095604, 0.18228961098229512, 0.18791393532350498, 0.18857620502408867, 0.19157544935651405, 0.17953267477910506, 0.182727737488098, 0.18548257276300828, 0.15763433465130106, 0.18622295305626735, 0.1874269327780842, 0.1622603068266033, 0.15350277052821804, 0.15515662437375655, 0.17254199532835723, 0.6229833918420269, 0.15444904952607774, 0.10593117576995825, 0.16338005435148173, 0.21032834357994512, 0.2575242595009337, 0.4395600301995187, 0.159651318746733, 0.5036914239959966, 0.3230851072116657, 0.15349021980120903, 0.6412389728895633, 0.17843978176252873, 0.18099887038284246, 0.18149469625323755, 0.20354783026399215, 0.18444095123365256, 0.18141392318021354, 0.19275247281020058, 0.1837089057782999, 0.19851491056767712, 0.08908678260495162, 0.0789532187377745, 0.07951404359358927, 0.07428541556523882, 0.07458935453222804, 0.07733086876605377, 0.09022754772651809, 0.09329963166847666, 0.08177914834968103]}, "mutation_prompt": null}
{"id": "de0e2b28-2616-48e1-be15-3ef38c720f7e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            self.local_search_iter = int(5 + 10 * np.mean(np.std(self.population, axis=0)))  # Changed line\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Adaptively adjust the local search iteration count based on population diversity to improve convergence.", "configspace": "", "generation": 11, "fitness": 0.12244751772681424, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.13.", "error": "", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.2848299488499427, 0.4283778199485201, 0.3435505001510969, 0.5263930932802954, 0.4383203439500325, 0.5469474477659191, 0.4249968214081501, 0.2931223264339714, 0.3518892087775063, 0.08973488002969043, 9.999999999998899e-05, 0.03876217543321958, 9.999999999998899e-05, 0.002381912222366389, 0.046146285597171266, 0.03324980178562742, 9.999999999998899e-05, 0.005646454339844786, 0.057962471562226336, 0.06361712362334404, 0.040511224156937864, 0.05809798201465255, 0.04501152254512275, 0.05097407008010635, 0.05144547858198201, 0.07718947739324444, 0.06673730619341645, 0.022029447921322887, 0.03066585088846241, 0.014402194280730307, 0.0472623773829155, 0.03847759564549813, 0.0488188164286113, 0.0341178262230063, 0.03675911659160391, 0.048614818519639114, 0.47318164483584946, 0.3537936210535352, 0.5702614685731953, 0.46510953865174676, 0.5021260121733135, 0.5698631113089457, 0.5146803108461756, 0.6025141977876203, 0.5543520675484351, 0.03500676858465235, 0.05843789999776161, 0.062261850345179615, 0.12394372497405148, 0.08350187264778963, 0.015538610779806894, 0.05687933766342934, 0.020186361451301815, 0.1005205321702275, 0.05673461296848892, 0.0506367053609883, 0.1403961724376087, 0.06967249850924984, 0.059560131717926734, 0.10545001305127866, 0.11445547517333887, 0.06381643225902478, 0.10553409791552948, 0.005548036022848701, 0.08127030329569074, 0.033614213950872385, 0.04142207269566767, 0.030303644903107996, 0.06346610889312487, 9.999999999998899e-05, 0.08958576314938616, 0.12198382672444552, 0.011663782690931823, 0.011304900039926569, 0.020956532964235386, 0.011396175151648147, 9.999999999998899e-05, 0.11413707002399365, 9.999999999998899e-05, 0.04967724128045048, 0.0040392995672080545, 9.999999999998899e-05, 0.0030993410502676566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03625732898133849, 9.999999999998899e-05, 0.014988872263651087, 0.05412638059226793, 0.08299186795185742, 0.08602706010471106, 0.057478756817322396, 0.04874897882858931, 0.054119636436766094, 0.070038218861739, 0.05188180745586646, 0.05780722419816997, 0.008258488986790491, 0.0079686400810417, 9.999999999998899e-05, 0.0033642146343998425, 0.014132269571880185, 9.999999999998899e-05, 0.028399408852810892, 9.999999999998899e-05, 0.009003954788196045, 0.002860841359387578, 0.017857217408181025, 9.999999999998899e-05, 0.027877431846474066, 0.030620618329510574, 0.0685772371847424, 0.02748256475603028, 0.023049103537526983, 0.08207883824587192, 0.16328087752160303, 0.17571673467219973, 0.36038495932669434, 0.34842688567206703, 0.34320233088708063, 0.3553592545977443, 0.2509136902049329, 0.24357088810721528, 0.16447567640861183, 0.032330646273242336, 0.032318344936810184, 0.09839658360788017, 0.04654944068854405, 0.05191171878401424, 0.046293228563074496, 0.057181866695321104, 0.05660464695062872, 0.044046178847122475, 0.18864326180912183, 0.19707508464637724, 0.15816839480751954, 0.1430175887310957, 0.23359213902233456, 0.19540243497488796, 0.18261596555007387, 0.1576741945374306, 0.1710281179192109, 0.13460975687045684, 0.1449419061757461, 0.14432430833927068, 0.1550992855162716, 0.19230561826018677, 0.13709150994709884, 0.1553370449835202, 0.15240153790237787, 0.14752557253381327, 0.07437277121152508, 0.10607151508545942, 0.11030311310126162, 0.10953608956758887, 0.08732804455661358, 0.09373115191898651, 0.12856856198583955, 0.08744835714395849, 0.10998082344571025, 0.15586493275153002, 0.16036379787411936, 0.17509519293230402, 0.16741270048066037, 0.15107354853301835, 0.2011760165704395, 0.15083589978988643, 0.1773654607078513, 0.1601592582515976, 0.1484493130703156, 0.12583328797055782, 0.1650836278106368, 0.1422431808601755, 0.17449980022634248, 0.14754853832338688, 0.12218190356168002, 0.09486098853908465, 0.10153437210668603, 0.1264378628738616, 0.1055412517870351, 0.1288597899491688, 0.12923298055468313, 0.11944744670747465, 0.1392319790002441, 0.14512337502229433, 0.15619336499235814, 0.1460476994359351, 0.07943130814502619, 0.15340327188308078, 0.09513468636588007, 0.22672398582367503, 0.2557562020986922, 0.10770354089482004, 0.1454372474648038, 0.09779811995404164, 0.1174966340325394, 0.1783470792564218, 0.17958738294299526, 0.1873089624841151, 0.1894174027984612, 0.18536282392496772, 0.20415896583195192, 0.19187081278086782, 0.18869001688262832, 0.18943385877579855, 0.04111422123974684, 0.046102487281921234, 0.0622878208955604, 0.07459061871895267, 0.057871914582198425, 0.06531077719313272, 0.05864607139240885, 0.050932200370437775, 0.05536567573333995]}, "mutation_prompt": null}
{"id": "d41ead16-82ef-4c5d-a285-4a9693476685", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Utilize a dynamic perturbation range in local search to enhance exploration adaptively.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.6464660238591508, 0.692353448884776, 0.6744836638337468, 0.645867695047444, 0.6888882078079962, 0.6075547663342649, 0.699296990465918, 0.6528076275116812, 0.6402221109898869, 0.33266425597356597, 0.24882385882729718, 0.22347740871740374, 0.3186355632964196, 0.31977446272041143, 0.2998260504700392, 0.35435332685944054, 0.09056589132876447, 0.27097171622455696, 0.11459267033782994, 0.12326552833271942, 0.12828746117743017, 0.10485913515046108, 0.11894798044884225, 0.09318262517877918, 0.11836453336848662, 0.1281919131388808, 0.12008078903975328, 0.09241752923181845, 0.10194612829514482, 0.10286844888282498, 0.07258483976763364, 0.11245988970809229, 0.11648834023025834, 0.07203644438043522, 0.08446980430651296, 0.10376726659332636, 0.8163861974745478, 0.8474122374411639, 0.7699259053051883, 0.1143513196368533, 0.8427053523481973, 0.8518027545976079, 0.9159877764174582, 0.865030950106848, 0.9145098819516947, 0.27309154232464394, 0.3034707932685148, 0.32780508805006503, 0.3237645775834682, 0.3330199897461158, 0.3132400046552851, 0.27004612770840564, 0.35747466707027886, 0.29990028444342964, 0.5296293076805101, 0.6412668155080758, 0.6485531410121972, 0.5309792638150209, 0.6303341428722671, 0.436033709118849, 0.7442901996885684, 0.2140278000565622, 0.3685761173408826, 0.2161402363371291, 0.1623146839415991, 0.23468980499876946, 0.11377094154957834, 0.21482859246558816, 0.18363697139995538, 0.17670734085829098, 0.19844924009564924, 0.18273284065960815, 0.14438850102924083, 0.18417977458726376, 0.21998667312807185, 0.21940520982644784, 0.24577916229207653, 0.21914835321547066, 0.15237551938618832, 0.1933469355727322, 0.29551852231146847, 0.11869159217678804, 0.18756403094985252, 0.14206353660226234, 0.11109181319003747, 0.12491774901171926, 0.02284271157516482, 0.10747458178416669, 0.14189115309180633, 0.15962585721255895, 0.1564401871141936, 0.28660199716682777, 0.23845376624504533, 0.2905581240012338, 0.30686874052905455, 0.22552631987201555, 0.16472168787410502, 0.14930123253620708, 0.11608082835906475, 0.10084042189764952, 0.1177945378964328, 0.0325033173895779, 0.051730889108697165, 0.07698113069121204, 0.06215706386905495, 0.11945794289480416, 0.0939830209100122, 0.06592758703554269, 0.2191118699937148, 0.22013252610951273, 0.1625919797783989, 0.1924313197003763, 0.18836111483014917, 0.19470303628768726, 0.16813223443772163, 0.15945581007407217, 0.18196868894950702, 0.5629419712797245, 0.5375440153028057, 0.532708811387517, 0.5354595216972282, 0.45792768953664853, 0.5401921079960457, 0.49414806433254643, 0.4972107007426556, 0.4704945867559689, 0.08503212289307016, 0.08462872675037247, 0.11922433534974264, 0.11715974494714176, 0.10846819641332639, 0.10295365232780929, 0.09874355372485899, 0.14063695237587126, 0.13542571849045815, 0.19082858121159474, 0.22894426077889085, 0.17747196020723133, 0.21848877115022092, 0.24561530249450048, 0.26137639582468475, 0.2158115607910741, 0.2233306523778985, 0.1951422635290294, 0.297502445563384, 0.28173145980579994, 0.24827779828189378, 0.2701472467729703, 0.27028169170586247, 0.19456199982332145, 0.2548212261385707, 0.2935933077485583, 0.2711195015742157, 0.1629327270025056, 0.17888571817558496, 0.17792796576666337, 0.16612457900014665, 0.17738099336012914, 0.15309666839268177, 0.15343721955611056, 0.1534964835290089, 0.1967755305530372, 0.17985559378859906, 0.2052496870926831, 0.18783925683001135, 0.20070186833893078, 0.21712706088799805, 0.20027994758740697, 0.1598625405282471, 0.20283026864090803, 0.18624052243926592, 0.21940282366832498, 0.21526749614581842, 0.18007927331181295, 0.2064301141660343, 0.19708689452127448, 0.17868730542746203, 0.19995247289719031, 0.22370302521499474, 0.19406536105710714, 0.14815268705040763, 0.15076979846493466, 0.1498313517810539, 0.17154569450222856, 0.5889565592502912, 0.5828068851193432, 0.1551608187643646, 0.5701332227056678, 0.7785861924230445, 0.19920871183904765, 0.19951177187305436, 0.4584224526432932, 0.20174930786206402, 0.5431365257937668, 0.6629999759974777, 0.1408554140006607, 0.16368274606944, 0.5010036812486964, 0.1852866372614297, 0.17956083446732352, 0.18173471488206827, 0.19306467976293762, 0.19569627627752084, 0.18271976300338588, 0.18958656510157357, 0.1831874982860633, 0.18742474078263593, 0.08451950970086386, 0.08003379407593092, 0.07492734876508489, 0.07158723100455067, 0.08358947393808636, 0.08179483078008687, 0.08992412592816568, 0.07529622028413374, 0.07758113466611649]}, "mutation_prompt": null}
{"id": "139d9e96-668f-4183-9e65-e8268b36f7f7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Utilize a dynamic perturbation range in local search to enhance exploration adaptively.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.6464660238591508, 0.692353448884776, 0.6744836638337468, 0.645867695047444, 0.6888882078079962, 0.6075547663342649, 0.699296990465918, 0.6528076275116812, 0.6402221109898869, 0.33266425597356597, 0.24882385882729718, 0.22347740871740374, 0.3186355632964196, 0.31977446272041143, 0.2998260504700392, 0.35435332685944054, 0.09056589132876447, 0.27097171622455696, 0.11459267033782994, 0.12326552833271942, 0.12828746117743017, 0.10485913515046108, 0.11894798044884225, 0.09318262517877918, 0.11836453336848662, 0.1281919131388808, 0.12008078903975328, 0.09241752923181845, 0.10194612829514482, 0.10286844888282498, 0.07258483976763364, 0.11245988970809229, 0.11648834023025834, 0.07203644438043522, 0.08446980430651296, 0.10376726659332636, 0.8163861974745478, 0.8474122374411639, 0.7699259053051883, 0.1143513196368533, 0.8427053523481973, 0.8518027545976079, 0.9159877764174582, 0.865030950106848, 0.9145098819516947, 0.27309154232464394, 0.3034707932685148, 0.32780508805006503, 0.3237645775834682, 0.3330199897461158, 0.3132400046552851, 0.27004612770840564, 0.35747466707027886, 0.29990028444342964, 0.5296293076805101, 0.6412668155080758, 0.6485531410121972, 0.5309792638150209, 0.6303341428722671, 0.436033709118849, 0.7442901996885684, 0.2140278000565622, 0.3685761173408826, 0.2161402363371291, 0.1623146839415991, 0.23468980499876946, 0.11377094154957834, 0.21482859246558816, 0.18363697139995538, 0.17670734085829098, 0.19844924009564924, 0.18273284065960815, 0.14438850102924083, 0.18417977458726376, 0.21998667312807185, 0.21940520982644784, 0.24577916229207653, 0.21914835321547066, 0.15237551938618832, 0.1933469355727322, 0.29551852231146847, 0.11869159217678804, 0.18756403094985252, 0.14206353660226234, 0.11109181319003747, 0.12491774901171926, 0.02284271157516482, 0.10747458178416669, 0.14189115309180633, 0.15962585721255895, 0.1564401871141936, 0.28660199716682777, 0.23845376624504533, 0.2905581240012338, 0.30686874052905455, 0.22552631987201555, 0.16472168787410502, 0.14930123253620708, 0.11608082835906475, 0.10084042189764952, 0.1177945378964328, 0.0325033173895779, 0.051730889108697165, 0.07698113069121204, 0.06215706386905495, 0.11945794289480416, 0.0939830209100122, 0.06592758703554269, 0.2191118699937148, 0.22013252610951273, 0.1625919797783989, 0.1924313197003763, 0.18836111483014917, 0.19470303628768726, 0.16813223443772163, 0.15945581007407217, 0.18196868894950702, 0.5629419712797245, 0.5375440153028057, 0.532708811387517, 0.5354595216972282, 0.45792768953664853, 0.5401921079960457, 0.49414806433254643, 0.4972107007426556, 0.4704945867559689, 0.08503212289307016, 0.08462872675037247, 0.11922433534974264, 0.11715974494714176, 0.10846819641332639, 0.10295365232780929, 0.09874355372485899, 0.14063695237587126, 0.13542571849045815, 0.19082858121159474, 0.22894426077889085, 0.17747196020723133, 0.21848877115022092, 0.24561530249450048, 0.26137639582468475, 0.2158115607910741, 0.2233306523778985, 0.1951422635290294, 0.297502445563384, 0.28173145980579994, 0.24827779828189378, 0.2701472467729703, 0.27028169170586247, 0.19456199982332145, 0.2548212261385707, 0.2935933077485583, 0.2711195015742157, 0.1629327270025056, 0.17888571817558496, 0.17792796576666337, 0.16612457900014665, 0.17738099336012914, 0.15309666839268177, 0.15343721955611056, 0.1534964835290089, 0.1967755305530372, 0.17985559378859906, 0.2052496870926831, 0.18783925683001135, 0.20070186833893078, 0.21712706088799805, 0.20027994758740697, 0.1598625405282471, 0.20283026864090803, 0.18624052243926592, 0.21940282366832498, 0.21526749614581842, 0.18007927331181295, 0.2064301141660343, 0.19708689452127448, 0.17868730542746203, 0.19995247289719031, 0.22370302521499474, 0.19406536105710714, 0.14815268705040763, 0.15076979846493466, 0.1498313517810539, 0.17154569450222856, 0.5889565592502912, 0.5828068851193432, 0.1551608187643646, 0.5701332227056678, 0.7785861924230445, 0.19920871183904765, 0.19951177187305436, 0.4584224526432932, 0.20174930786206402, 0.5431365257937668, 0.6629999759974777, 0.1408554140006607, 0.16368274606944, 0.5010036812486964, 0.1852866372614297, 0.17956083446732352, 0.18173471488206827, 0.19306467976293762, 0.19569627627752084, 0.18271976300338588, 0.18958656510157357, 0.1831874982860633, 0.18742474078263593, 0.08451950970086386, 0.08003379407593092, 0.07492734876508489, 0.07158723100455067, 0.08358947393808636, 0.08179483078008687, 0.08992412592816568, 0.07529622028413374, 0.07758113466611649]}, "mutation_prompt": null}
{"id": "b483f206-c5e3-4a8f-8d2e-60c0b8848a82", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Utilize a dynamic perturbation range in local search to enhance exploration adaptively.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.6464660238591508, 0.692353448884776, 0.6744836638337468, 0.645867695047444, 0.6888882078079962, 0.6075547663342649, 0.699296990465918, 0.6528076275116812, 0.6402221109898869, 0.33266425597356597, 0.24882385882729718, 0.22347740871740374, 0.3186355632964196, 0.31977446272041143, 0.2998260504700392, 0.35435332685944054, 0.09056589132876447, 0.27097171622455696, 0.11459267033782994, 0.12326552833271942, 0.12828746117743017, 0.10485913515046108, 0.11894798044884225, 0.09318262517877918, 0.11836453336848662, 0.1281919131388808, 0.12008078903975328, 0.09241752923181845, 0.10194612829514482, 0.10286844888282498, 0.07258483976763364, 0.11245988970809229, 0.11648834023025834, 0.07203644438043522, 0.08446980430651296, 0.10376726659332636, 0.8163861974745478, 0.8474122374411639, 0.7699259053051883, 0.1143513196368533, 0.8427053523481973, 0.8518027545976079, 0.9159877764174582, 0.865030950106848, 0.9145098819516947, 0.27309154232464394, 0.3034707932685148, 0.32780508805006503, 0.3237645775834682, 0.3330199897461158, 0.3132400046552851, 0.27004612770840564, 0.35747466707027886, 0.29990028444342964, 0.5296293076805101, 0.6412668155080758, 0.6485531410121972, 0.5309792638150209, 0.6303341428722671, 0.436033709118849, 0.7442901996885684, 0.2140278000565622, 0.3685761173408826, 0.2161402363371291, 0.1623146839415991, 0.23468980499876946, 0.11377094154957834, 0.21482859246558816, 0.18363697139995538, 0.17670734085829098, 0.19844924009564924, 0.18273284065960815, 0.14438850102924083, 0.18417977458726376, 0.21998667312807185, 0.21940520982644784, 0.24577916229207653, 0.21914835321547066, 0.15237551938618832, 0.1933469355727322, 0.29551852231146847, 0.11869159217678804, 0.18756403094985252, 0.14206353660226234, 0.11109181319003747, 0.12491774901171926, 0.02284271157516482, 0.10747458178416669, 0.14189115309180633, 0.15962585721255895, 0.1564401871141936, 0.28660199716682777, 0.23845376624504533, 0.2905581240012338, 0.30686874052905455, 0.22552631987201555, 0.16472168787410502, 0.14930123253620708, 0.11608082835906475, 0.10084042189764952, 0.1177945378964328, 0.0325033173895779, 0.051730889108697165, 0.07698113069121204, 0.06215706386905495, 0.11945794289480416, 0.0939830209100122, 0.06592758703554269, 0.2191118699937148, 0.22013252610951273, 0.1625919797783989, 0.1924313197003763, 0.18836111483014917, 0.19470303628768726, 0.16813223443772163, 0.15945581007407217, 0.18196868894950702, 0.5629419712797245, 0.5375440153028057, 0.532708811387517, 0.5354595216972282, 0.45792768953664853, 0.5401921079960457, 0.49414806433254643, 0.4972107007426556, 0.4704945867559689, 0.08503212289307016, 0.08462872675037247, 0.11922433534974264, 0.11715974494714176, 0.10846819641332639, 0.10295365232780929, 0.09874355372485899, 0.14063695237587126, 0.13542571849045815, 0.19082858121159474, 0.22894426077889085, 0.17747196020723133, 0.21848877115022092, 0.24561530249450048, 0.26137639582468475, 0.2158115607910741, 0.2233306523778985, 0.1951422635290294, 0.297502445563384, 0.28173145980579994, 0.24827779828189378, 0.2701472467729703, 0.27028169170586247, 0.19456199982332145, 0.2548212261385707, 0.2935933077485583, 0.2711195015742157, 0.1629327270025056, 0.17888571817558496, 0.17792796576666337, 0.16612457900014665, 0.17738099336012914, 0.15309666839268177, 0.15343721955611056, 0.1534964835290089, 0.1967755305530372, 0.17985559378859906, 0.2052496870926831, 0.18783925683001135, 0.20070186833893078, 0.21712706088799805, 0.20027994758740697, 0.1598625405282471, 0.20283026864090803, 0.18624052243926592, 0.21940282366832498, 0.21526749614581842, 0.18007927331181295, 0.2064301141660343, 0.19708689452127448, 0.17868730542746203, 0.19995247289719031, 0.22370302521499474, 0.19406536105710714, 0.14815268705040763, 0.15076979846493466, 0.1498313517810539, 0.17154569450222856, 0.5889565592502912, 0.5828068851193432, 0.1551608187643646, 0.5701332227056678, 0.7785861924230445, 0.19920871183904765, 0.19951177187305436, 0.4584224526432932, 0.20174930786206402, 0.5431365257937668, 0.6629999759974777, 0.1408554140006607, 0.16368274606944, 0.5010036812486964, 0.1852866372614297, 0.17956083446732352, 0.18173471488206827, 0.19306467976293762, 0.19569627627752084, 0.18271976300338588, 0.18958656510157357, 0.1831874982860633, 0.18742474078263593, 0.08451950970086386, 0.08003379407593092, 0.07492734876508489, 0.07158723100455067, 0.08358947393808636, 0.08179483078008687, 0.08992412592816568, 0.07529622028413374, 0.07758113466611649]}, "mutation_prompt": null}
{"id": "edb5861e-11dd-44eb-afcf-71dfd40298ae", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            fitness_variance = np.var(self.fitness) / np.var(self.fitness + 1e-10)  # Changed line\n            perturbation_range = 0.2 * (1 - fitness_variance)  # Changed line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce diversity in the local search by dynamically adjusting perturbation based on fitness variance.", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: OverflowError('Range exceeds valid bounds').", "error": "OverflowError('Range exceeds valid bounds')", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {}, "mutation_prompt": null}
{"id": "12b5a3fc-37f9-4b0c-9bc6-e5e8d4b45b12", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Utilize a dynamic perturbation range in local search to enhance exploration adaptively.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.6464660238591508, 0.692353448884776, 0.6744836638337468, 0.645867695047444, 0.6888882078079962, 0.6075547663342649, 0.699296990465918, 0.6528076275116812, 0.6402221109898869, 0.33266425597356597, 0.24882385882729718, 0.22347740871740374, 0.3186355632964196, 0.31977446272041143, 0.2998260504700392, 0.35435332685944054, 0.09056589132876447, 0.27097171622455696, 0.11459267033782994, 0.12326552833271942, 0.12828746117743017, 0.10485913515046108, 0.11894798044884225, 0.09318262517877918, 0.11836453336848662, 0.1281919131388808, 0.12008078903975328, 0.09241752923181845, 0.10194612829514482, 0.10286844888282498, 0.07258483976763364, 0.11245988970809229, 0.11648834023025834, 0.07203644438043522, 0.08446980430651296, 0.10376726659332636, 0.8163861974745478, 0.8474122374411639, 0.7699259053051883, 0.1143513196368533, 0.8427053523481973, 0.8518027545976079, 0.9159877764174582, 0.865030950106848, 0.9145098819516947, 0.27309154232464394, 0.3034707932685148, 0.32780508805006503, 0.3237645775834682, 0.3330199897461158, 0.3132400046552851, 0.27004612770840564, 0.35747466707027886, 0.29990028444342964, 0.5296293076805101, 0.6412668155080758, 0.6485531410121972, 0.5309792638150209, 0.6303341428722671, 0.436033709118849, 0.7442901996885684, 0.2140278000565622, 0.3685761173408826, 0.2161402363371291, 0.1623146839415991, 0.23468980499876946, 0.11377094154957834, 0.21482859246558816, 0.18363697139995538, 0.17670734085829098, 0.19844924009564924, 0.18273284065960815, 0.14438850102924083, 0.18417977458726376, 0.21998667312807185, 0.21940520982644784, 0.24577916229207653, 0.21914835321547066, 0.15237551938618832, 0.1933469355727322, 0.29551852231146847, 0.11869159217678804, 0.18756403094985252, 0.14206353660226234, 0.11109181319003747, 0.12491774901171926, 0.02284271157516482, 0.10747458178416669, 0.14189115309180633, 0.15962585721255895, 0.1564401871141936, 0.28660199716682777, 0.23845376624504533, 0.2905581240012338, 0.30686874052905455, 0.22552631987201555, 0.16472168787410502, 0.14930123253620708, 0.11608082835906475, 0.10084042189764952, 0.1177945378964328, 0.0325033173895779, 0.051730889108697165, 0.07698113069121204, 0.06215706386905495, 0.11945794289480416, 0.0939830209100122, 0.06592758703554269, 0.2191118699937148, 0.22013252610951273, 0.1625919797783989, 0.1924313197003763, 0.18836111483014917, 0.19470303628768726, 0.16813223443772163, 0.15945581007407217, 0.18196868894950702, 0.5629419712797245, 0.5375440153028057, 0.532708811387517, 0.5354595216972282, 0.45792768953664853, 0.5401921079960457, 0.49414806433254643, 0.4972107007426556, 0.4704945867559689, 0.08503212289307016, 0.08462872675037247, 0.11922433534974264, 0.11715974494714176, 0.10846819641332639, 0.10295365232780929, 0.09874355372485899, 0.14063695237587126, 0.13542571849045815, 0.19082858121159474, 0.22894426077889085, 0.17747196020723133, 0.21848877115022092, 0.24561530249450048, 0.26137639582468475, 0.2158115607910741, 0.2233306523778985, 0.1951422635290294, 0.297502445563384, 0.28173145980579994, 0.24827779828189378, 0.2701472467729703, 0.27028169170586247, 0.19456199982332145, 0.2548212261385707, 0.2935933077485583, 0.2711195015742157, 0.1629327270025056, 0.17888571817558496, 0.17792796576666337, 0.16612457900014665, 0.17738099336012914, 0.15309666839268177, 0.15343721955611056, 0.1534964835290089, 0.1967755305530372, 0.17985559378859906, 0.2052496870926831, 0.18783925683001135, 0.20070186833893078, 0.21712706088799805, 0.20027994758740697, 0.1598625405282471, 0.20283026864090803, 0.18624052243926592, 0.21940282366832498, 0.21526749614581842, 0.18007927331181295, 0.2064301141660343, 0.19708689452127448, 0.17868730542746203, 0.19995247289719031, 0.22370302521499474, 0.19406536105710714, 0.14815268705040763, 0.15076979846493466, 0.1498313517810539, 0.17154569450222856, 0.5889565592502912, 0.5828068851193432, 0.1551608187643646, 0.5701332227056678, 0.7785861924230445, 0.19920871183904765, 0.19951177187305436, 0.4584224526432932, 0.20174930786206402, 0.5431365257937668, 0.6629999759974777, 0.1408554140006607, 0.16368274606944, 0.5010036812486964, 0.1852866372614297, 0.17956083446732352, 0.18173471488206827, 0.19306467976293762, 0.19569627627752084, 0.18271976300338588, 0.18958656510157357, 0.1831874982860633, 0.18742474078263593, 0.08451950970086386, 0.08003379407593092, 0.07492734876508489, 0.07158723100455067, 0.08358947393808636, 0.08179483078008687, 0.08992412592816568, 0.07529622028413374, 0.07758113466611649]}, "mutation_prompt": null}
{"id": "454634d7-7412-450f-b25b-c43bf36dbba5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Utilize a dynamic perturbation range in local search to enhance exploration adaptively.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.6464660238591508, 0.692353448884776, 0.6744836638337468, 0.645867695047444, 0.6888882078079962, 0.6075547663342649, 0.699296990465918, 0.6528076275116812, 0.6402221109898869, 0.33266425597356597, 0.24882385882729718, 0.22347740871740374, 0.3186355632964196, 0.31977446272041143, 0.2998260504700392, 0.35435332685944054, 0.09056589132876447, 0.27097171622455696, 0.11459267033782994, 0.12326552833271942, 0.12828746117743017, 0.10485913515046108, 0.11894798044884225, 0.09318262517877918, 0.11836453336848662, 0.1281919131388808, 0.12008078903975328, 0.09241752923181845, 0.10194612829514482, 0.10286844888282498, 0.07258483976763364, 0.11245988970809229, 0.11648834023025834, 0.07203644438043522, 0.08446980430651296, 0.10376726659332636, 0.8163861974745478, 0.8474122374411639, 0.7699259053051883, 0.1143513196368533, 0.8427053523481973, 0.8518027545976079, 0.9159877764174582, 0.865030950106848, 0.9145098819516947, 0.27309154232464394, 0.3034707932685148, 0.32780508805006503, 0.3237645775834682, 0.3330199897461158, 0.3132400046552851, 0.27004612770840564, 0.35747466707027886, 0.29990028444342964, 0.5296293076805101, 0.6412668155080758, 0.6485531410121972, 0.5309792638150209, 0.6303341428722671, 0.436033709118849, 0.7442901996885684, 0.2140278000565622, 0.3685761173408826, 0.2161402363371291, 0.1623146839415991, 0.23468980499876946, 0.11377094154957834, 0.21482859246558816, 0.18363697139995538, 0.17670734085829098, 0.19844924009564924, 0.18273284065960815, 0.14438850102924083, 0.18417977458726376, 0.21998667312807185, 0.21940520982644784, 0.24577916229207653, 0.21914835321547066, 0.15237551938618832, 0.1933469355727322, 0.29551852231146847, 0.11869159217678804, 0.18756403094985252, 0.14206353660226234, 0.11109181319003747, 0.12491774901171926, 0.02284271157516482, 0.10747458178416669, 0.14189115309180633, 0.15962585721255895, 0.1564401871141936, 0.28660199716682777, 0.23845376624504533, 0.2905581240012338, 0.30686874052905455, 0.22552631987201555, 0.16472168787410502, 0.14930123253620708, 0.11608082835906475, 0.10084042189764952, 0.1177945378964328, 0.0325033173895779, 0.051730889108697165, 0.07698113069121204, 0.06215706386905495, 0.11945794289480416, 0.0939830209100122, 0.06592758703554269, 0.2191118699937148, 0.22013252610951273, 0.1625919797783989, 0.1924313197003763, 0.18836111483014917, 0.19470303628768726, 0.16813223443772163, 0.15945581007407217, 0.18196868894950702, 0.5629419712797245, 0.5375440153028057, 0.532708811387517, 0.5354595216972282, 0.45792768953664853, 0.5401921079960457, 0.49414806433254643, 0.4972107007426556, 0.4704945867559689, 0.08503212289307016, 0.08462872675037247, 0.11922433534974264, 0.11715974494714176, 0.10846819641332639, 0.10295365232780929, 0.09874355372485899, 0.14063695237587126, 0.13542571849045815, 0.19082858121159474, 0.22894426077889085, 0.17747196020723133, 0.21848877115022092, 0.24561530249450048, 0.26137639582468475, 0.2158115607910741, 0.2233306523778985, 0.1951422635290294, 0.297502445563384, 0.28173145980579994, 0.24827779828189378, 0.2701472467729703, 0.27028169170586247, 0.19456199982332145, 0.2548212261385707, 0.2935933077485583, 0.2711195015742157, 0.1629327270025056, 0.17888571817558496, 0.17792796576666337, 0.16612457900014665, 0.17738099336012914, 0.15309666839268177, 0.15343721955611056, 0.1534964835290089, 0.1967755305530372, 0.17985559378859906, 0.2052496870926831, 0.18783925683001135, 0.20070186833893078, 0.21712706088799805, 0.20027994758740697, 0.1598625405282471, 0.20283026864090803, 0.18624052243926592, 0.21940282366832498, 0.21526749614581842, 0.18007927331181295, 0.2064301141660343, 0.19708689452127448, 0.17868730542746203, 0.19995247289719031, 0.22370302521499474, 0.19406536105710714, 0.14815268705040763, 0.15076979846493466, 0.1498313517810539, 0.17154569450222856, 0.5889565592502912, 0.5828068851193432, 0.1551608187643646, 0.5701332227056678, 0.7785861924230445, 0.19920871183904765, 0.19951177187305436, 0.4584224526432932, 0.20174930786206402, 0.5431365257937668, 0.6629999759974777, 0.1408554140006607, 0.16368274606944, 0.5010036812486964, 0.1852866372614297, 0.17956083446732352, 0.18173471488206827, 0.19306467976293762, 0.19569627627752084, 0.18271976300338588, 0.18958656510157357, 0.1831874982860633, 0.18742474078263593, 0.08451950970086386, 0.08003379407593092, 0.07492734876508489, 0.07158723100455067, 0.08358947393808636, 0.08179483078008687, 0.08992412592816568, 0.07529622028413374, 0.07758113466611649]}, "mutation_prompt": null}
{"id": "e08aa35a-add2-4661-844e-1ac6e1d4dd09", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (np.std(self.fitness) / self.fitness[i])  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance exploration by adjusting perturbation range based on function fitness variance.", "configspace": "", "generation": 18, "fitness": 0.2396982534644444, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.17.", "error": "", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.5394289511578564, 0.44567472068933744, 0.5163970733906997, 0.5610133726717697, 0.40761153336221123, 0.5480909554362133, 0.441428249652861, 0.5803451380961542, 0.5725975807722139, 0.3580018939169225, 0.4479940367337384, 0.30275761851269267, 0.3770645155773513, 0.39082569730320127, 0.3062739145609671, 0.33588661177571955, 0.4326554712757342, 0.27244836942370476, 0.08656849985255921, 0.0803199895676302, 0.08541053024586709, 0.11644398371118403, 0.14858099485210274, 0.1198395129845019, 0.08536408727562117, 0.14583057264353394, 0.098015626727046, 0.0736728315300641, 0.11910464565965628, 0.08050189618544046, 0.07449682980415673, 0.0947021821729519, 0.12345278491460943, 0.08944466209326152, 0.11088305922012465, 0.07916939927317568, 0.8523888898832824, 0.9248598439460243, 0.6929039010440479, 0.12947974314124544, 0.7121767751862214, 0.869980706759018, 0.6550228892777505, 0.7583395801480961, 0.879242319608696, 0.19110766158938963, 0.23704262670331022, 0.2407468572375352, 0.1859412817280629, 0.13592896812922683, 0.19269310198683787, 0.13616096991264204, 0.213473172298688, 0.19018047825497852, 0.12546632318424888, 0.3010763978035408, 0.27717134421856493, 0.2192177635691276, 0.47558085428420793, 0.4231568822726325, 0.5889596527011881, 0.273439411867868, 0.32898360901863066, 0.31059756371721325, 0.13995906883984444, 0.1735848286657209, 0.19064040896560952, 0.1587619246456885, 0.11348404069480234, 0.28586025024624895, 0.13300477340137618, 0.32447838416177766, 0.13808038890384178, 0.16934566325622435, 0.1655712233304394, 0.19312444372839488, 0.13049001755157463, 0.3220974961317119, 0.1590487622125354, 0.14002139252654522, 0.42740620777783644, 0.10774401070554795, 0.2925575375818006, 0.14139575433483897, 0.12434228856757068, 0.2074693332673747, 0.13371771577986924, 0.2250070113200512, 0.2438058047146704, 0.11940171589145743, 0.2805235565306432, 0.33899477235281317, 0.23856591589291065, 0.21727697634817622, 0.22351347916184872, 0.2272856163007343, 0.07834157760853255, 0.2556576687263943, 0.0772947147991252, 0.03794383591935935, 0.0992387195295743, 0.0634697454132509, 0.10519923826172894, 0.06278963419362804, 0.12970422817765526, 0.08046947048996167, 0.04860294615068872, 0.10244783256015377, 0.3343949024761601, 0.3265837006055611, 0.3285205957905615, 0.3095005896128251, 0.3508471043216964, 0.3897101033863043, 0.13165006791985523, 0.1756107501574279, 0.226554797219222, 0.458721229824261, 0.3322343637944315, 0.44346069660165854, 0.4971049972898812, 0.4037921326027625, 0.41867206287023295, 0.42935768505310457, 0.41369903167486777, 0.3960856236820537, 0.06734344575289686, 0.07577694539538193, 0.08563869977740102, 0.09602876166606167, 0.10744105264019599, 0.10645045480670956, 0.1354971871403774, 0.11763369953777347, 0.10580940468190236, 0.17902605518521508, 0.1626716509122822, 0.14565431150826202, 0.15437493468462848, 0.11996180067036899, 0.1432094302922987, 0.12356008538532592, 0.1522057683505491, 0.15485367500860814, 0.23072278145517777, 0.24480810885806437, 0.25956885752233216, 0.23866539065805925, 0.20581750569363577, 0.2542270690433718, 0.2820094222412377, 0.27243149733449623, 0.26598048252512274, 0.1458288460158712, 0.2253338286532024, 0.17136881872140297, 0.12359110145148955, 0.18606875561599012, 0.14766254713131743, 0.2020302721092878, 0.1105034614249889, 0.13754394338547848, 0.2566898384468046, 0.2049411914933379, 0.21553604020149164, 0.2291553712354093, 0.23138917977141904, 0.1971289736240237, 0.2115073069845288, 0.27340411964543077, 0.28923731267398656, 0.17452616018615208, 0.1858026197886039, 0.17497873916147233, 0.18827893827464104, 0.18034358648704696, 0.16523933353672493, 0.17223285970779922, 0.16774803039494668, 0.1690469842975879, 0.16548456523778565, 0.14719629658774336, 0.15573758680317917, 0.17078852849654413, 0.20075391957912947, 0.6137545307034098, 0.12418779892920107, 0.09274555907772752, 0.4823215402598877, 0.18144646614502957, 0.4568096370960708, 0.15835207004966467, 0.1953275111407874, 0.16172666551049586, 0.5436491361031529, 0.19192146593685733, 0.12181791752121585, 0.19497006873112155, 0.20077671987611845, 0.22119749699009372, 0.20650751698399128, 0.19734420989989498, 0.1931953904193815, 0.1959998223745547, 0.2177706033315343, 0.2190571522462441, 0.2322019421623871, 0.12497447103303805, 0.06564174700649072, 0.08764051009553131, 0.07876775808035563, 0.08001693581161218, 0.08119650775433729, 0.0598807550421252, 0.08336711966234489, 0.08197001349426514]}, "mutation_prompt": null}
{"id": "2579a4c4-dc42-41c9-a5fa-2dd7a529360b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            adaptive_local_search_iter = int(self.local_search_iter * (1 + np.mean(np.std(self.population, axis=0))))  # Modified line 3\n            for _ in range(adaptive_local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive local search steps based on population diversity to balance exploration and exploitation.", "configspace": "", "generation": 19, "fitness": 0.17477207708031028, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.16.", "error": "", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.41443891632282215, 0.5106535895564436, 0.5737780893570628, 0.6418318770751542, 0.5872888290295233, 0.6325055796419347, 0.5760090646988912, 0.552250329202651, 0.5243415710048074, 0.08254609838378402, 0.07630782971421046, 0.12302866918999822, 0.11141933910267432, 0.18593526588006437, 0.1223503011148398, 0.15052091725497718, 0.1605089424241507, 0.07419217523240407, 0.08602364181490807, 0.0842848264716658, 0.08412442590349822, 0.09670274036780468, 0.08907942972194127, 0.07793770072605533, 0.06724086812457042, 0.06365224798686797, 0.09511699809704055, 0.07563454581668427, 0.061817949949888096, 0.0596274127952825, 0.06685115812369635, 0.07039929812324774, 0.0804142892522508, 0.042727552047230666, 0.06893815397442726, 0.0662479416322852, 0.6003585048233638, 0.49775771906453015, 0.6302511805414794, 0.7223207212436509, 0.5981189670142425, 0.7005836708311125, 0.8337398547935088, 0.6223924196069824, 0.811027056161303, 0.10253376307697015, 0.12645057634531154, 0.19923228210708266, 0.09067634563626092, 0.18397798205357563, 0.17553573385423438, 0.1492061712243018, 0.200542134416144, 0.23120111740405458, 0.17474235902329605, 0.12340173536857313, 0.191094097931641, 0.1723718349976463, 0.08303520491772431, 0.11563873645822054, 0.11305072213644884, 0.1597941730335095, 0.08614888310415614, 0.0983696284533393, 0.1373747033376278, 0.09609703873292985, 0.1768071782462063, 0.15966430663069353, 0.11129133617271292, 0.16046903555222958, 0.16923549048043018, 0.1996611892222543, 0.0904260962611283, 0.12690623115547428, 0.11273165043758249, 0.09174326792644516, 0.0981366406106623, 0.1254376504154734, 0.1039910468182561, 0.1282643187166852, 0.0959942321721472, 0.03687673163393956, 0.03514338523994043, 0.030172688434506933, 0.006581426290786618, 0.02913016336607488, 0.034183703434614965, 0.001377416932675235, 0.051942362482743754, 9.999999999998899e-05, 0.08672107482978131, 0.09091373481257137, 0.08084534143088917, 0.11066406637205362, 0.05652962671421302, 0.10018083307037429, 0.05235102690032967, 0.11249691472865675, 0.08919463803575767, 0.006906864829024251, 0.021493622456994488, 0.025532026245848827, 0.00956416860593523, 0.01926431931268302, 0.011989903540926217, 0.12244209194487954, 0.02832787319988106, 0.011410892238309156, 0.07725002870599362, 0.11895864558265623, 0.0998242957045431, 0.06964472302665203, 0.11886139548418484, 0.16468610727242483, 0.10568068908709571, 0.12413044855342503, 0.13149295398402316, 0.332922657024619, 0.32984104098437295, 0.43258959459722857, 0.4004325854467423, 0.3865119250401685, 0.49312304974887056, 0.31820344598891726, 0.4278554089237666, 0.35306048298887005, 0.07510578731931106, 0.06123042490720654, 0.06870783659951651, 0.06253119136683905, 0.08902153199022234, 0.1058371491175365, 0.06698918578376323, 0.12429063349038261, 0.10284225454056117, 0.17424271957461768, 0.21273998695570673, 0.168729169362567, 0.23186501604243548, 0.2648474259210284, 0.18735371381681443, 0.21096071567641816, 0.15123932044538724, 0.16393088855618787, 0.1611804979223036, 0.1455495052744793, 0.19703774365333948, 0.15344322119574605, 0.27028351833249575, 0.16422566915377923, 0.17483307591866037, 0.17090126048531018, 0.18812316754917457, 0.11655029444668419, 0.09254232616327318, 0.14016873203056235, 0.11806593993033188, 0.10512430514007998, 0.09113942413026632, 0.11219620609855896, 0.11603020537892639, 0.11629849800280678, 0.17919099540935368, 0.18840323845287532, 0.19871543896086974, 0.17082271538419536, 0.1939656330990378, 0.17557500735753306, 0.1714807311909311, 0.20916640834338052, 0.15829785170510735, 0.14518768889596412, 0.15998728361150794, 0.16544690357539327, 0.1677267255847371, 0.174164550515432, 0.15348594994921128, 0.17473984450400404, 0.15654451654625923, 0.14570624274706245, 0.15043198649744594, 0.14904382974932884, 0.1904539403170339, 0.1530042059678215, 0.17010210766513956, 0.1503474958757972, 0.1262766555077165, 0.33716161687043633, 0.22550775607561113, 0.1625744981769216, 0.16917653051121617, 0.11495138703548347, 0.15582014618151352, 0.13984556659526348, 0.1406250406675832, 0.23510757969215623, 0.1302967498862787, 0.19305395422890037, 0.1849153470270457, 0.18865853594335136, 0.18766874956388724, 0.19383497029844798, 0.1848448225332625, 0.18262634375834153, 0.17619367439551514, 0.1747787563473706, 0.18459456644985583, 0.05653244608953423, 0.07733358866577456, 0.0717266270609005, 0.06514597651260279, 0.06839085497983377, 0.07190848479926748, 0.0537585700374017, 0.05936109600159034, 0.068027994418969]}, "mutation_prompt": null}
{"id": "e9149a38-9d83-47ba-8c57-65c65097c2dd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:  # Adaptive tuning line 1\n                diversity = np.mean(np.std(self.population, axis=0))  # Change line 1\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)  # Change line 2\n\n    def run_greedy_local_search(self, func):\n        for i in range(self.population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)  # Modified line\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)  # Line modified 2\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Utilize a dynamic perturbation range in local search to enhance exploration adaptively.", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.6464660238591508, 0.692353448884776, 0.6744836638337468, 0.645867695047444, 0.6888882078079962, 0.6075547663342649, 0.699296990465918, 0.6528076275116812, 0.6402221109898869, 0.33266425597356597, 0.24882385882729718, 0.22347740871740374, 0.3186355632964196, 0.31977446272041143, 0.2998260504700392, 0.35435332685944054, 0.09056589132876447, 0.27097171622455696, 0.11459267033782994, 0.12326552833271942, 0.12828746117743017, 0.10485913515046108, 0.11894798044884225, 0.09318262517877918, 0.11836453336848662, 0.1281919131388808, 0.12008078903975328, 0.09241752923181845, 0.10194612829514482, 0.10286844888282498, 0.07258483976763364, 0.11245988970809229, 0.11648834023025834, 0.07203644438043522, 0.08446980430651296, 0.10376726659332636, 0.8163861974745478, 0.8474122374411639, 0.7699259053051883, 0.1143513196368533, 0.8427053523481973, 0.8518027545976079, 0.9159877764174582, 0.865030950106848, 0.9145098819516947, 0.27309154232464394, 0.3034707932685148, 0.32780508805006503, 0.3237645775834682, 0.3330199897461158, 0.3132400046552851, 0.27004612770840564, 0.35747466707027886, 0.29990028444342964, 0.5296293076805101, 0.6412668155080758, 0.6485531410121972, 0.5309792638150209, 0.6303341428722671, 0.436033709118849, 0.7442901996885684, 0.2140278000565622, 0.3685761173408826, 0.2161402363371291, 0.1623146839415991, 0.23468980499876946, 0.11377094154957834, 0.21482859246558816, 0.18363697139995538, 0.17670734085829098, 0.19844924009564924, 0.18273284065960815, 0.14438850102924083, 0.18417977458726376, 0.21998667312807185, 0.21940520982644784, 0.24577916229207653, 0.21914835321547066, 0.15237551938618832, 0.1933469355727322, 0.29551852231146847, 0.11869159217678804, 0.18756403094985252, 0.14206353660226234, 0.11109181319003747, 0.12491774901171926, 0.02284271157516482, 0.10747458178416669, 0.14189115309180633, 0.15962585721255895, 0.1564401871141936, 0.28660199716682777, 0.23845376624504533, 0.2905581240012338, 0.30686874052905455, 0.22552631987201555, 0.16472168787410502, 0.14930123253620708, 0.11608082835906475, 0.10084042189764952, 0.1177945378964328, 0.0325033173895779, 0.051730889108697165, 0.07698113069121204, 0.06215706386905495, 0.11945794289480416, 0.0939830209100122, 0.06592758703554269, 0.2191118699937148, 0.22013252610951273, 0.1625919797783989, 0.1924313197003763, 0.18836111483014917, 0.19470303628768726, 0.16813223443772163, 0.15945581007407217, 0.18196868894950702, 0.5629419712797245, 0.5375440153028057, 0.532708811387517, 0.5354595216972282, 0.45792768953664853, 0.5401921079960457, 0.49414806433254643, 0.4972107007426556, 0.4704945867559689, 0.08503212289307016, 0.08462872675037247, 0.11922433534974264, 0.11715974494714176, 0.10846819641332639, 0.10295365232780929, 0.09874355372485899, 0.14063695237587126, 0.13542571849045815, 0.19082858121159474, 0.22894426077889085, 0.17747196020723133, 0.21848877115022092, 0.24561530249450048, 0.26137639582468475, 0.2158115607910741, 0.2233306523778985, 0.1951422635290294, 0.297502445563384, 0.28173145980579994, 0.24827779828189378, 0.2701472467729703, 0.27028169170586247, 0.19456199982332145, 0.2548212261385707, 0.2935933077485583, 0.2711195015742157, 0.1629327270025056, 0.17888571817558496, 0.17792796576666337, 0.16612457900014665, 0.17738099336012914, 0.15309666839268177, 0.15343721955611056, 0.1534964835290089, 0.1967755305530372, 0.17985559378859906, 0.2052496870926831, 0.18783925683001135, 0.20070186833893078, 0.21712706088799805, 0.20027994758740697, 0.1598625405282471, 0.20283026864090803, 0.18624052243926592, 0.21940282366832498, 0.21526749614581842, 0.18007927331181295, 0.2064301141660343, 0.19708689452127448, 0.17868730542746203, 0.19995247289719031, 0.22370302521499474, 0.19406536105710714, 0.14815268705040763, 0.15076979846493466, 0.1498313517810539, 0.17154569450222856, 0.5889565592502912, 0.5828068851193432, 0.1551608187643646, 0.5701332227056678, 0.7785861924230445, 0.19920871183904765, 0.19951177187305436, 0.4584224526432932, 0.20174930786206402, 0.5431365257937668, 0.6629999759974777, 0.1408554140006607, 0.16368274606944, 0.5010036812486964, 0.1852866372614297, 0.17956083446732352, 0.18173471488206827, 0.19306467976293762, 0.19569627627752084, 0.18271976300338588, 0.18958656510157357, 0.1831874982860633, 0.18742474078263593, 0.08451950970086386, 0.08003379407593092, 0.07492734876508489, 0.07158723100455067, 0.08358947393808636, 0.08179483078008687, 0.08992412592816568, 0.07529622028413374, 0.07758113466611649]}, "mutation_prompt": null}
{"id": "e0ef0979-88f2-488f-b812-286b178560ff", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  # Line changed\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive population size adjustment based on evaluations to improve convergence.", "configspace": "", "generation": 21, "fitness": 0.2976275421858201, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.22.", "error": "", "parent_id": "21318747-0aba-4d18-8d9d-0b6b966fc8e8", "metadata": {"aucs": [0.6940418612747186, 0.7592226582909436, 0.7289639678176736, 0.7388305937858344, 0.721759268782757, 0.7502734137790892, 0.7550252238571383, 0.7091226761554033, 0.7483462256276983, 0.22417251583071052, 0.38613195085302654, 0.04345966900624865, 0.4637434850239581, 0.5154063061733638, 0.4796947624978317, 0.5285299820212078, 0.4838223332343575, 0.04193935504930979, 0.10835476244508069, 0.11424602955377816, 0.13497477141109593, 0.10185687998009108, 0.11225147821549508, 0.1004486090986344, 0.11897127255055162, 0.1070583578042118, 0.13585106128860713, 0.09193255519581611, 0.11111724682543223, 0.11207201371769882, 0.07182218649199223, 0.09611861496425012, 0.1070452480590608, 0.08793067557579448, 0.08518721140804464, 0.11001701047072654, 0.8694963170854244, 0.8306622559397504, 0.7032194587028664, 0.8656114203206206, 0.7287641867278725, 0.8806272107505876, 0.8886346969678509, 0.9041474097639645, 0.874018530297335, 0.3271499977702804, 0.37815561827439803, 0.3197321804896571, 0.39873836079160596, 0.37749943466983227, 0.3559008319097312, 0.33899663020951243, 0.4000798448898639, 0.3369037212965328, 0.5998778425870182, 0.6380563885255307, 0.7666191586858513, 0.16599561124997708, 0.6294102352401544, 0.4383611475603021, 0.4762129750002514, 0.6253432106786876, 0.5925039970358937, 0.13764055873534564, 0.1847582528788545, 0.1601160226439624, 0.1168994299901569, 0.19617984017444656, 0.19912214451845267, 0.21767371138563307, 0.11208485095260734, 0.23325515456816548, 0.24310232241997176, 0.18981034859794177, 0.16784545689467045, 0.20367913230782397, 0.25697969840587986, 0.17631370887737907, 0.09628804007168523, 0.17926612383153462, 0.16623151627464738, 0.21238322438987622, 0.2802420809887781, 0.20652563541600732, 0.19141460077734118, 0.18114227604545918, 0.17493062811228666, 0.1685248322256866, 0.22059196573440887, 0.19802791629254624, 0.3476701535069243, 0.25070198800794297, 0.3169391270643911, 0.31197426594750355, 0.3173019790435003, 0.2296211722379793, 0.34175227239141637, 0.20431306893138634, 0.2711085473443501, 0.06734793488037816, 0.18867919451266435, 0.08061776972336299, 0.0987689202118468, 0.11308887435120563, 0.05884283670303225, 0.08714810134554796, 0.1184039541323576, 0.14494808466834597, 0.25869942727752826, 0.24095840865748952, 0.1765580807584627, 0.22418792289786815, 0.18897001182085138, 0.2404116456398656, 0.07800288158489244, 0.18283481018240633, 0.22221331642962927, 0.6023449048206291, 0.6120569632176913, 0.5323300997191508, 0.5210615774090648, 0.6310086086178421, 0.600137211716884, 0.4992054778844015, 0.5811653684870712, 0.5603279462676873, 0.1099437590011737, 0.10062663707171382, 0.10188484114089025, 0.11381200680138048, 0.15034264169113432, 0.12077575526363293, 0.1013016235739389, 0.09641699942187865, 0.11555003682036136, 0.24197924598606846, 0.22691804029084783, 0.19226250863549033, 0.22361361560435877, 0.2663817427486933, 0.2417878183637323, 0.21299406595044879, 0.1824404760852255, 0.17698594651175792, 0.3337679964326966, 0.3494777231432754, 0.32613055503618094, 0.2939767788855917, 0.3081064548428454, 0.31279662821455534, 0.3767570978398942, 0.3402900079006157, 0.3160114422219341, 0.20115324116234978, 0.20565065509624025, 0.2893779420901351, 0.1980113131842135, 0.24890739226413994, 0.15825474463681344, 0.2845976817443252, 0.24118697457550498, 0.24231560027301124, 0.18370593938492485, 0.20261723074063653, 0.2129916036744418, 0.1544592604051348, 0.19544084836617037, 0.18370300834812447, 0.1828919019947658, 0.17764058458403065, 0.2023850125839265, 0.19969133222029545, 0.18805838994452428, 0.18741910523224115, 0.2327947159769782, 0.19612701113628117, 0.17029416535359765, 0.19249864937372752, 0.18462679509532276, 0.3257177043328655, 0.19096270215308409, 0.16114802989663768, 0.5970583805480778, 0.5515355324514138, 0.6158102436918973, 0.5904714979104257, 0.19414240002599925, 0.7793662738877019, 0.17014557608550074, 0.1949265013516832, 0.7317185335750698, 0.5484441640417472, 0.19425429248306014, 0.28890118400056075, 0.6061198898490687, 0.15886995274542737, 0.1514350901065653, 0.624020563799579, 0.18535223485427843, 0.18025108565703563, 0.18418285651547894, 0.1883322108971921, 0.19830520810817887, 0.1878324446716143, 0.2058895307986559, 0.20737982827360324, 0.186051973194579, 0.07167356137733094, 0.0892449470203297, 0.07670038516890076, 0.0732406019397347, 0.07302326784446855, 0.07472731164037472, 0.07118368942202646, 0.06699690055914342, 0.0788057268915785]}, "mutation_prompt": null}
{"id": "00031c26-598a-40f6-a307-52b729ec5a4e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  # Line changed\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive population size adjustment based on evaluations to improve convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.6940418612747186, 0.7592226582909436, 0.7289639678176736, 0.7388305937858344, 0.721759268782757, 0.7502734137790892, 0.7550252238571383, 0.7091226761554033, 0.7483462256276983, 0.22417251583071052, 0.38613195085302654, 0.04345966900624865, 0.4637434850239581, 0.5154063061733638, 0.4796947624978317, 0.5285299820212078, 0.4838223332343575, 0.04193935504930979, 0.10835476244508069, 0.11424602955377816, 0.13497477141109593, 0.10185687998009108, 0.11225147821549508, 0.1004486090986344, 0.11897127255055162, 0.1070583578042118, 0.13585106128860713, 0.09193255519581611, 0.11111724682543223, 0.11207201371769882, 0.07182218649199223, 0.09611861496425012, 0.1070452480590608, 0.08793067557579448, 0.08518721140804464, 0.11001701047072654, 0.8694963170854244, 0.8306622559397504, 0.7032194587028664, 0.8656114203206206, 0.7287641867278725, 0.8806272107505876, 0.8886346969678509, 0.9041474097639645, 0.874018530297335, 0.3271499977702804, 0.37815561827439803, 0.3197321804896571, 0.39873836079160596, 0.37749943466983227, 0.3559008319097312, 0.33899663020951243, 0.4000798448898639, 0.3369037212965328, 0.5998778425870182, 0.6380563885255307, 0.7666191586858513, 0.16599561124997708, 0.6294102352401544, 0.4383611475603021, 0.4762129750002514, 0.6253432106786876, 0.5925039970358937, 0.13764055873534564, 0.1847582528788545, 0.1601160226439624, 0.1168994299901569, 0.19617984017444656, 0.19912214451845267, 0.21767371138563307, 0.11208485095260734, 0.23325515456816548, 0.24310232241997176, 0.18981034859794177, 0.16784545689467045, 0.20367913230782397, 0.25697969840587986, 0.17631370887737907, 0.09628804007168523, 0.17926612383153462, 0.16623151627464738, 0.21238322438987622, 0.2802420809887781, 0.20652563541600732, 0.19141460077734118, 0.18114227604545918, 0.17493062811228666, 0.1685248322256866, 0.22059196573440887, 0.19802791629254624, 0.3476701535069243, 0.25070198800794297, 0.3169391270643911, 0.31197426594750355, 0.3173019790435003, 0.2296211722379793, 0.34175227239141637, 0.20431306893138634, 0.2711085473443501, 0.06734793488037816, 0.18867919451266435, 0.08061776972336299, 0.0987689202118468, 0.11308887435120563, 0.05884283670303225, 0.08714810134554796, 0.1184039541323576, 0.14494808466834597, 0.25869942727752826, 0.24095840865748952, 0.1765580807584627, 0.22418792289786815, 0.18897001182085138, 0.2404116456398656, 0.07800288158489244, 0.18283481018240633, 0.22221331642962927, 0.6023449048206291, 0.6120569632176913, 0.5323300997191508, 0.5210615774090648, 0.6310086086178421, 0.600137211716884, 0.4992054778844015, 0.5811653684870712, 0.5603279462676873, 0.1099437590011737, 0.10062663707171382, 0.10188484114089025, 0.11381200680138048, 0.15034264169113432, 0.12077575526363293, 0.1013016235739389, 0.09641699942187865, 0.11555003682036136, 0.24197924598606846, 0.22691804029084783, 0.19226250863549033, 0.22361361560435877, 0.2663817427486933, 0.2417878183637323, 0.21299406595044879, 0.1824404760852255, 0.17698594651175792, 0.3337679964326966, 0.3494777231432754, 0.32613055503618094, 0.2939767788855917, 0.3081064548428454, 0.31279662821455534, 0.3767570978398942, 0.3402900079006157, 0.3160114422219341, 0.20115324116234978, 0.20565065509624025, 0.2893779420901351, 0.1980113131842135, 0.24890739226413994, 0.15825474463681344, 0.2845976817443252, 0.24118697457550498, 0.24231560027301124, 0.18370593938492485, 0.20261723074063653, 0.2129916036744418, 0.1544592604051348, 0.19544084836617037, 0.18370300834812447, 0.1828919019947658, 0.17764058458403065, 0.2023850125839265, 0.19969133222029545, 0.18805838994452428, 0.18741910523224115, 0.2327947159769782, 0.19612701113628117, 0.17029416535359765, 0.19249864937372752, 0.18462679509532276, 0.3257177043328655, 0.19096270215308409, 0.16114802989663768, 0.5970583805480778, 0.5515355324514138, 0.6158102436918973, 0.5904714979104257, 0.19414240002599925, 0.7793662738877019, 0.17014557608550074, 0.1949265013516832, 0.7317185335750698, 0.5484441640417472, 0.19425429248306014, 0.28890118400056075, 0.6061198898490687, 0.15886995274542737, 0.1514350901065653, 0.624020563799579, 0.18535223485427843, 0.18025108565703563, 0.18418285651547894, 0.1883322108971921, 0.19830520810817887, 0.1878324446716143, 0.2058895307986559, 0.20737982827360324, 0.186051973194579, 0.07167356137733094, 0.0892449470203297, 0.07670038516890076, 0.0732406019397347, 0.07302326784446855, 0.07472731164037472, 0.07118368942202646, 0.06699690055914342, 0.0788057268915785]}, "mutation_prompt": null}
{"id": "8478e713-3936-48a4-a44c-8319a87f424a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  # Line changed\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive population size adjustment based on evaluations to improve convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.6940418612747186, 0.7592226582909436, 0.7289639678176736, 0.7388305937858344, 0.721759268782757, 0.7502734137790892, 0.7550252238571383, 0.7091226761554033, 0.7483462256276983, 0.22417251583071052, 0.38613195085302654, 0.04345966900624865, 0.4637434850239581, 0.5154063061733638, 0.4796947624978317, 0.5285299820212078, 0.4838223332343575, 0.04193935504930979, 0.10835476244508069, 0.11424602955377816, 0.13497477141109593, 0.10185687998009108, 0.11225147821549508, 0.1004486090986344, 0.11897127255055162, 0.1070583578042118, 0.13585106128860713, 0.09193255519581611, 0.11111724682543223, 0.11207201371769882, 0.07182218649199223, 0.09611861496425012, 0.1070452480590608, 0.08793067557579448, 0.08518721140804464, 0.11001701047072654, 0.8694963170854244, 0.8306622559397504, 0.7032194587028664, 0.8656114203206206, 0.7287641867278725, 0.8806272107505876, 0.8886346969678509, 0.9041474097639645, 0.874018530297335, 0.3271499977702804, 0.37815561827439803, 0.3197321804896571, 0.39873836079160596, 0.37749943466983227, 0.3559008319097312, 0.33899663020951243, 0.4000798448898639, 0.3369037212965328, 0.5998778425870182, 0.6380563885255307, 0.7666191586858513, 0.16599561124997708, 0.6294102352401544, 0.4383611475603021, 0.4762129750002514, 0.6253432106786876, 0.5925039970358937, 0.13764055873534564, 0.1847582528788545, 0.1601160226439624, 0.1168994299901569, 0.19617984017444656, 0.19912214451845267, 0.21767371138563307, 0.11208485095260734, 0.23325515456816548, 0.24310232241997176, 0.18981034859794177, 0.16784545689467045, 0.20367913230782397, 0.25697969840587986, 0.17631370887737907, 0.09628804007168523, 0.17926612383153462, 0.16623151627464738, 0.21238322438987622, 0.2802420809887781, 0.20652563541600732, 0.19141460077734118, 0.18114227604545918, 0.17493062811228666, 0.1685248322256866, 0.22059196573440887, 0.19802791629254624, 0.3476701535069243, 0.25070198800794297, 0.3169391270643911, 0.31197426594750355, 0.3173019790435003, 0.2296211722379793, 0.34175227239141637, 0.20431306893138634, 0.2711085473443501, 0.06734793488037816, 0.18867919451266435, 0.08061776972336299, 0.0987689202118468, 0.11308887435120563, 0.05884283670303225, 0.08714810134554796, 0.1184039541323576, 0.14494808466834597, 0.25869942727752826, 0.24095840865748952, 0.1765580807584627, 0.22418792289786815, 0.18897001182085138, 0.2404116456398656, 0.07800288158489244, 0.18283481018240633, 0.22221331642962927, 0.6023449048206291, 0.6120569632176913, 0.5323300997191508, 0.5210615774090648, 0.6310086086178421, 0.600137211716884, 0.4992054778844015, 0.5811653684870712, 0.5603279462676873, 0.1099437590011737, 0.10062663707171382, 0.10188484114089025, 0.11381200680138048, 0.15034264169113432, 0.12077575526363293, 0.1013016235739389, 0.09641699942187865, 0.11555003682036136, 0.24197924598606846, 0.22691804029084783, 0.19226250863549033, 0.22361361560435877, 0.2663817427486933, 0.2417878183637323, 0.21299406595044879, 0.1824404760852255, 0.17698594651175792, 0.3337679964326966, 0.3494777231432754, 0.32613055503618094, 0.2939767788855917, 0.3081064548428454, 0.31279662821455534, 0.3767570978398942, 0.3402900079006157, 0.3160114422219341, 0.20115324116234978, 0.20565065509624025, 0.2893779420901351, 0.1980113131842135, 0.24890739226413994, 0.15825474463681344, 0.2845976817443252, 0.24118697457550498, 0.24231560027301124, 0.18370593938492485, 0.20261723074063653, 0.2129916036744418, 0.1544592604051348, 0.19544084836617037, 0.18370300834812447, 0.1828919019947658, 0.17764058458403065, 0.2023850125839265, 0.19969133222029545, 0.18805838994452428, 0.18741910523224115, 0.2327947159769782, 0.19612701113628117, 0.17029416535359765, 0.19249864937372752, 0.18462679509532276, 0.3257177043328655, 0.19096270215308409, 0.16114802989663768, 0.5970583805480778, 0.5515355324514138, 0.6158102436918973, 0.5904714979104257, 0.19414240002599925, 0.7793662738877019, 0.17014557608550074, 0.1949265013516832, 0.7317185335750698, 0.5484441640417472, 0.19425429248306014, 0.28890118400056075, 0.6061198898490687, 0.15886995274542737, 0.1514350901065653, 0.624020563799579, 0.18535223485427843, 0.18025108565703563, 0.18418285651547894, 0.1883322108971921, 0.19830520810817887, 0.1878324446716143, 0.2058895307986559, 0.20737982827360324, 0.186051973194579, 0.07167356137733094, 0.0892449470203297, 0.07670038516890076, 0.0732406019397347, 0.07302326784446855, 0.07472731164037472, 0.07118368942202646, 0.06699690055914342, 0.0788057268915785]}, "mutation_prompt": null}
{"id": "ad725ae4-dd01-4534-aca6-63e3098881ca", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  # Line changed\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive population size adjustment based on evaluations to improve convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.6940418612747186, 0.7592226582909436, 0.7289639678176736, 0.7388305937858344, 0.721759268782757, 0.7502734137790892, 0.7550252238571383, 0.7091226761554033, 0.7483462256276983, 0.22417251583071052, 0.38613195085302654, 0.04345966900624865, 0.4637434850239581, 0.5154063061733638, 0.4796947624978317, 0.5285299820212078, 0.4838223332343575, 0.04193935504930979, 0.10835476244508069, 0.11424602955377816, 0.13497477141109593, 0.10185687998009108, 0.11225147821549508, 0.1004486090986344, 0.11897127255055162, 0.1070583578042118, 0.13585106128860713, 0.09193255519581611, 0.11111724682543223, 0.11207201371769882, 0.07182218649199223, 0.09611861496425012, 0.1070452480590608, 0.08793067557579448, 0.08518721140804464, 0.11001701047072654, 0.8694963170854244, 0.8306622559397504, 0.7032194587028664, 0.8656114203206206, 0.7287641867278725, 0.8806272107505876, 0.8886346969678509, 0.9041474097639645, 0.874018530297335, 0.3271499977702804, 0.37815561827439803, 0.3197321804896571, 0.39873836079160596, 0.37749943466983227, 0.3559008319097312, 0.33899663020951243, 0.4000798448898639, 0.3369037212965328, 0.5998778425870182, 0.6380563885255307, 0.7666191586858513, 0.16599561124997708, 0.6294102352401544, 0.4383611475603021, 0.4762129750002514, 0.6253432106786876, 0.5925039970358937, 0.13764055873534564, 0.1847582528788545, 0.1601160226439624, 0.1168994299901569, 0.19617984017444656, 0.19912214451845267, 0.21767371138563307, 0.11208485095260734, 0.23325515456816548, 0.24310232241997176, 0.18981034859794177, 0.16784545689467045, 0.20367913230782397, 0.25697969840587986, 0.17631370887737907, 0.09628804007168523, 0.17926612383153462, 0.16623151627464738, 0.21238322438987622, 0.2802420809887781, 0.20652563541600732, 0.19141460077734118, 0.18114227604545918, 0.17493062811228666, 0.1685248322256866, 0.22059196573440887, 0.19802791629254624, 0.3476701535069243, 0.25070198800794297, 0.3169391270643911, 0.31197426594750355, 0.3173019790435003, 0.2296211722379793, 0.34175227239141637, 0.20431306893138634, 0.2711085473443501, 0.06734793488037816, 0.18867919451266435, 0.08061776972336299, 0.0987689202118468, 0.11308887435120563, 0.05884283670303225, 0.08714810134554796, 0.1184039541323576, 0.14494808466834597, 0.25869942727752826, 0.24095840865748952, 0.1765580807584627, 0.22418792289786815, 0.18897001182085138, 0.2404116456398656, 0.07800288158489244, 0.18283481018240633, 0.22221331642962927, 0.6023449048206291, 0.6120569632176913, 0.5323300997191508, 0.5210615774090648, 0.6310086086178421, 0.600137211716884, 0.4992054778844015, 0.5811653684870712, 0.5603279462676873, 0.1099437590011737, 0.10062663707171382, 0.10188484114089025, 0.11381200680138048, 0.15034264169113432, 0.12077575526363293, 0.1013016235739389, 0.09641699942187865, 0.11555003682036136, 0.24197924598606846, 0.22691804029084783, 0.19226250863549033, 0.22361361560435877, 0.2663817427486933, 0.2417878183637323, 0.21299406595044879, 0.1824404760852255, 0.17698594651175792, 0.3337679964326966, 0.3494777231432754, 0.32613055503618094, 0.2939767788855917, 0.3081064548428454, 0.31279662821455534, 0.3767570978398942, 0.3402900079006157, 0.3160114422219341, 0.20115324116234978, 0.20565065509624025, 0.2893779420901351, 0.1980113131842135, 0.24890739226413994, 0.15825474463681344, 0.2845976817443252, 0.24118697457550498, 0.24231560027301124, 0.18370593938492485, 0.20261723074063653, 0.2129916036744418, 0.1544592604051348, 0.19544084836617037, 0.18370300834812447, 0.1828919019947658, 0.17764058458403065, 0.2023850125839265, 0.19969133222029545, 0.18805838994452428, 0.18741910523224115, 0.2327947159769782, 0.19612701113628117, 0.17029416535359765, 0.19249864937372752, 0.18462679509532276, 0.3257177043328655, 0.19096270215308409, 0.16114802989663768, 0.5970583805480778, 0.5515355324514138, 0.6158102436918973, 0.5904714979104257, 0.19414240002599925, 0.7793662738877019, 0.17014557608550074, 0.1949265013516832, 0.7317185335750698, 0.5484441640417472, 0.19425429248306014, 0.28890118400056075, 0.6061198898490687, 0.15886995274542737, 0.1514350901065653, 0.624020563799579, 0.18535223485427843, 0.18025108565703563, 0.18418285651547894, 0.1883322108971921, 0.19830520810817887, 0.1878324446716143, 0.2058895307986559, 0.20737982827360324, 0.186051973194579, 0.07167356137733094, 0.0892449470203297, 0.07670038516890076, 0.0732406019397347, 0.07302326784446855, 0.07472731164037472, 0.07118368942202646, 0.06699690055914342, 0.0788057268915785]}, "mutation_prompt": null}
{"id": "56a07f06-3510-4da6-baa3-f9d6a50cd59e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * (diversity / (1 + self.evaluations / self.budget))  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic mutation factor scaling based on population diversity to enhance exploration and exploitation.", "configspace": "", "generation": 25, "fitness": 0.22627057752950555, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.6153543937498385, 0.6013373230017749, 0.5394393230676922, 0.6948873635906667, 0.6753075103745325, 0.7042629568796119, 0.6185144315180207, 0.6860474722184267, 0.6500643536532711, 0.058306753584609794, 0.03902863741737783, 0.30088567449623127, 0.32593623171100594, 0.26023420194387004, 0.290166605911811, 0.2667987667664554, 0.38579930151755426, 0.3289136037423589, 0.06679071702970174, 0.09090867867521069, 0.06773721932848642, 0.09310023815441015, 0.11623393317861896, 0.087645590532891, 0.08654547612404262, 0.07972369410423674, 0.10175651770854532, 0.047067005511229554, 0.07543683910331145, 0.06327331746214837, 0.06469985079994656, 0.06550245114300246, 0.08231605994983404, 0.06851579602916569, 0.06841331322229471, 0.07408411362803868, 0.9784087753404093, 0.9285686708742185, 0.8913892222902551, 0.8471558273521218, 0.9987553801862883, 0.8930371134366233, 0.9395264569446357, 0.9397420941679224, 0.9678458397813782, 0.3030071301239552, 0.3090880341408019, 0.25017098933592485, 0.28141896352021545, 0.32390627692341045, 0.2946031495404783, 0.3845776806474419, 0.2538524470956831, 0.3018793882988029, 0.18322884909417303, 0.1891724779600269, 0.38245919167238795, 0.15465516451474082, 0.13438782051819964, 0.40258714702552945, 0.3028051820393769, 0.5380805902290469, 0.4514908229400907, 0.12179363715555414, 0.15173870117211263, 0.1275985940061608, 0.18391369818374048, 0.14609395106162792, 0.1445091220906186, 0.18324803725612104, 0.15625027514924872, 0.21337422271294781, 0.10863576942676156, 0.11372330653576135, 0.11263141632364548, 0.07815721533649445, 0.12690592241653886, 0.17119954497529088, 0.16077304915666768, 0.1593110601337423, 0.16944649452224514, 0.05125941283159807, 0.05158274884517522, 0.14807363407716834, 0.17675799098612766, 0.09075052618603585, 0.04137434903059023, 9.999999999998899e-05, 0.08820156338564134, 0.07587074924337578, 0.04877044029030164, 0.17815138979728995, 0.18189108876951743, 0.17649242694628642, 0.0946063484455828, 0.13947897973053425, 0.10832558421870764, 0.10389409142677175, 0.2205772838288501, 0.0321280671908577, 0.030719406412148764, 0.02347066967961786, 0.10308714301854438, 0.0626581150113068, 0.084751364948502, 0.10345897478285204, 0.05235093411681935, 0.07196002206387131, 0.19808590681403893, 0.21655803206212243, 0.15853700756849354, 0.23210905499555923, 0.19572944441911355, 0.1962491349077734, 0.20968629166620745, 0.20504935266067958, 0.22892547962818166, 0.38279912015912054, 0.5043731175049824, 0.5187605333862422, 0.4817472037021151, 0.4444994562677307, 0.46997702036102906, 0.42348899400767337, 0.4994272346674956, 0.4968540267973707, 0.1017985744309351, 0.0799874150070431, 0.08702362122635565, 0.05945047020903971, 0.08300526931083663, 0.09484788729446081, 0.06683729789354198, 0.08092926240254694, 0.05924213826835456, 0.24235354844157364, 0.17649880842995225, 0.15480904167388077, 0.30965887272533466, 0.2662739066200349, 0.2564904892836526, 0.17734305631459868, 0.19677496090962965, 0.193231068411284, 0.14584748063386177, 0.17392845464369677, 0.1511198938067746, 0.15608203647714036, 0.14423902474947603, 0.1552107086471255, 0.2516795126254905, 0.2609766197823108, 0.2865442331633612, 0.11816606387715534, 0.11751204910928703, 0.13030412836614214, 0.1152527011009864, 0.08019268752659536, 0.15886370053830035, 0.11721500480941427, 0.13358669595082595, 0.08943804578189918, 0.16107554044264616, 0.16038545020128003, 0.16459336757782894, 0.15869830518516814, 0.17281031304606453, 0.15344045393314554, 0.17167900915195278, 0.15570257661697218, 0.1924183563481603, 0.16845474361747037, 0.14485347373960944, 0.16077622084145493, 0.15459279212038746, 0.1813594200318569, 0.1636161336089237, 0.14596898432976335, 0.12907084276903846, 0.1507842603494659, 0.1618509647893095, 0.12915093963110758, 0.16418756852232652, 0.19671969570465775, 0.5466854124075595, 0.17031606640447738, 0.1699228958104304, 0.174258548615274, 0.17733770840008578, 0.1804095804045941, 0.15532397179937762, 0.40575406471634146, 0.17818915784739497, 0.1550903403347973, 0.16190683676921802, 0.19909036556648252, 0.1994736722459215, 0.1754935697997131, 0.17706605003520237, 0.19407932498502556, 0.2208036881428176, 0.18899646125847724, 0.20441566006826106, 0.1826196267066167, 0.19125970091965627, 0.20098559916236047, 0.20275738398711052, 0.05424577993262247, 0.05461589608168993, 0.061584903353513076, 0.07003213506531014, 0.06447414563201814, 0.05346560964349445, 0.0668363616947718, 0.054006402512650875, 0.06830354578879527]}, "mutation_prompt": null}
{"id": "e7639da6-354c-468b-8ffc-711d64e1e9a9", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (np.std(self.fitness) / np.mean(self.fitness))  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  \n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance adaptive parameter tuning by incorporating population fitness diversity to improve convergence speed.", "configspace": "", "generation": 26, "fitness": 0.13603322015768948, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.14 with standard deviation 0.13.", "error": "", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.44358165631814794, 0.49640160950123535, 0.4981015961649431, 0.4551408372988447, 0.5186696566589644, 0.4823934600461799, 0.45906800642403645, 0.46445748580375057, 0.42160280871558975, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.004847807280238703, 0.027357310397913115, 0.03317817850755023, 0.02025646361859801, 0.03380957407645768, 0.03511095895255334, 0.0068614313684817185, 0.0135832187742575, 0.03785984399685438, 0.009762693949814438, 0.014993409048250417, 0.03721930762367065, 0.05987417335896428, 0.024473210673573886, 0.03345667792342444, 0.03188507806958096, 0.018016220970467067, 0.021161537290675603, 0.061539530603214154, 0.07745105842383493, 0.04639883569825287, 0.07979281199400556, 0.1080279704147441, 0.11474244189209182, 0.09270770405629702, 0.10392446349160744, 0.1887993443852507, 0.17060907210339105, 0.15612594835134896, 0.04806784634866401, 0.3077494402893943, 0.21647495437188535, 0.2812548842638658, 0.11488397063974387, 0.2946640348274595, 0.15737451647374978, 0.14505909483932755, 0.07533040728356322, 0.047903913077483984, 0.022205070695525686, 0.04132335442665713, 0.009085724671618167, 0.0708438680796486, 0.10200560363189048, 0.17405150733608865, 0.11071785287358438, 0.132896795772248, 0.07977206846784979, 0.11642786797710492, 0.12147856755847186, 0.0776494140618017, 0.1325717449252699, 0.12477792122085118, 0.16439718854252583, 0.1541595792135788, 0.1113292167310812, 0.19546434098729637, 0.11368132907032957, 0.12384582130150268, 0.1939629697313544, 0.13843976033362704, 0.10627432509015744, 0.15570653535718282, 0.030733700888382787, 0.0, 0.0, 0.005419238972153129, 0.0, 0.0, 0.0, 0.0, 0.008007262939878634, 0.084906861183499, 0.09231246365496848, 0.07480511647054522, 0.13235912667990546, 0.06709601233285922, 0.11583506476967309, 0.06902960545522308, 0.06726429544914203, 0.07914000468267457, 0.04453538398995338, 0.04731972318219235, 0.05842924125894566, 0.06682847566402994, 0.028717595376177796, 0.0, 0.05105956490584418, 0.046181710342214854, 0.05095424532245163, 0.04756213187516556, 0.0644991595775094, 0.12473291190161362, 0.06482423096739132, 0.04577302559927898, 0.08055127109415494, 0.0659216104741428, 0.11048123898065931, 0.06682264939006655, 0.39460658505143753, 0.4225283061251074, 0.4511637536683464, 0.3396202657426821, 0.3408289600152803, 0.3584285397504964, 0.3535956487875874, 0.3489399949258212, 0.3724250098720673, 0.019777702869489655, 0.0, 0.0, 0.021015215451804403, 0.010548878475706958, 0.04633964507451516, 0.014832290178006247, 0.018518905457885704, 0.023784779958486824, 0.16259923427096024, 0.1904819325951329, 0.18830687688372416, 0.3017888073427194, 0.20391800861150444, 0.2175620610238017, 0.1680382789366871, 0.11938603914638402, 0.15434801489346095, 0.11496910226783441, 0.1395040842130335, 0.1259647759848973, 0.13013148832366328, 0.13347124464089644, 0.13194064612691814, 0.12210598629954039, 0.17250556345845547, 0.10648533504241864, 0.055547125444309176, 0.06824905862073505, 0.07752852886379702, 0.07184747795230229, 0.07348267850214685, 0.07302818704000347, 0.07549766080916798, 0.13775050047532333, 0.05253698212906566, 0.1245986719395894, 0.12573401298667997, 0.16515856615211777, 0.14577686986644878, 0.12664333056275268, 0.15436718090966095, 0.13117709644637598, 0.12593624813461624, 0.14413887700025718, 0.1804995285258516, 0.18055312217345532, 0.17531315511929058, 0.22210820305831402, 0.17338996490120895, 0.15617077383039102, 0.16684541348359472, 0.16853601430338405, 0.1708231204318036, 0.36192856484360747, 0.16921132801202932, 0.6398311901667839, 0.1802959952091231, 0.6376372176954199, 0.3350147150953803, 0.16442624604396883, 0.1733122402212306, 0.5609842373867039, 0.21709242825886454, 0.18975119005119845, 0.3102700265547014, 0.18762174927728414, 0.1541051184049287, 0.16986669642148555, 0.15703977954306503, 0.14482899258948023, 0.19633466423861168, 0.21689384457045358, 0.20563349719819057, 0.23045412825683387, 0.19967553351828937, 0.20119155514494547, 0.20099651105022476, 0.2050829594318454, 0.21143363162174322, 0.19471467023828204, 0.02822859470238759, 0.03919066509998281, 0.05155144911182685, 0.03970106654695105, 0.045641814579587825, 0.04523432107787506, 0.039256710610426904, 0.04110093113335567, 0.03676317094432502]}, "mutation_prompt": null}
{"id": "51518bd9-2b8a-4489-b5e2-011a183f6787", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            # The line changed below: Adjusting crossover probability based on diversity\n            self.cr = 0.5 + 0.4 * (self.evaluations / self.budget)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Fine-tune crossover probability based on diversity to balance exploration and exploitation effectively.", "configspace": "", "generation": 27, "fitness": 0.264941472742188, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.21.", "error": "", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.7198680375513575, 0.6950939904111819, 0.7028090578579966, 0.7086699161548254, 0.716031150592657, 0.6971802811932741, 0.7210372030252297, 0.7058353638281205, 0.7250219070539776, 0.4504325960364185, 0.45755410320903134, 0.47274710711774715, 0.4433177995919907, 0.4191527183759187, 0.4810009761944365, 0.44943800505681464, 0.4264468908954042, 0.48024564158603167, 0.14293287234329255, 0.12469985062347555, 0.14782990775196392, 0.12375915682531613, 0.12324669641813979, 0.14225352303148808, 0.129069861738219, 0.11482584312778965, 0.10923302577490046, 0.1093573338344197, 0.10933408498578123, 0.10475094440257404, 0.11075960610118252, 0.10794504887132517, 0.11857407604637771, 0.11546250501745325, 0.1132119912543339, 0.13100101556901877, 0.8114546512435946, 0.9158956761035433, 0.8165988005027047, 0.8521641994928032, 0.8693798278044299, 0.8860387463116326, 0.8545057259931226, 0.8532241429753309, 0.85451887831898, 0.3466491177559128, 0.31627219203110035, 0.294842434162936, 0.34918751061830566, 0.3288874643964246, 0.28924732163608446, 0.28353404622944756, 0.3392800296405475, 0.32233247042345614, 0.26501014640201603, 0.40551067189376644, 0.2727277383492659, 0.45067997379269464, 0.468468180946392, 0.4778044198437579, 0.1872384653027137, 0.3289285375998512, 0.40676728916613925, 0.15903633006040507, 0.21002094559390583, 0.21647517709304442, 0.22306528235519663, 0.25266778655470634, 0.11093760211821735, 0.2161037389213667, 0.20222551224904506, 0.17469287269613254, 0.2171584049082651, 0.24713800177356404, 0.18351071385470197, 0.19663745156861667, 0.18168448194880593, 0.1742231760385754, 0.23668291337078395, 0.15971160764041548, 0.17568810520247624, 0.04453031476352154, 0.028354881425498357, 0.0651788073227173, 0.07838240365330895, 0.035536311322889924, 0.027523820602332494, 0.04553419761991462, 0.03978897699158024, 0.06368545905945777, 0.1762405236094764, 0.11897528404262703, 0.10979090079771792, 0.06648183169507116, 0.13048799062693417, 0.05926190805993625, 0.12956313627245053, 0.12505678653312757, 0.13710850442745992, 0.027975993242224884, 0.05063503260649671, 0.022688254188599433, 0.03044559859990681, 0.028796152398403274, 0.02520587509415617, 0.048872995749217996, 0.019710591176495984, 0.035064597954674204, 0.1660502029466716, 0.13150709203386501, 0.13736010195132253, 0.16176647588665927, 0.1738496343163748, 0.161508113046956, 0.1580892814714775, 0.14896837165683297, 0.14279369478334736, 0.48666157359265994, 0.5098586449350284, 0.49731531271568186, 0.5231852615067868, 0.4938978161507688, 0.4949181199807966, 0.49821716332032795, 0.4665839149200297, 0.48402701461794473, 0.106850088243999, 0.09006461264183285, 0.08350725662492464, 0.08202393310957701, 0.0778836777021592, 0.0800152056756368, 0.13371195147547565, 0.12079294607926072, 0.09299062747535791, 0.24641917138263247, 0.18560789441646708, 0.17359889406426698, 0.18921497419573374, 0.1678618576755755, 0.17069320742412908, 0.2461268337438829, 0.17463968483496173, 0.20347752847694855, 0.22104373852751602, 0.2028813585033712, 0.21512249501508462, 0.18505801656734067, 0.2329934206851122, 0.18191171935684347, 0.2468329918610097, 0.25352627501823655, 0.23291843944471247, 0.14429767587587428, 0.17213257091567336, 0.1382753940259709, 0.14555279849115155, 0.16367102484058704, 0.17389152813599795, 0.19994519705580993, 0.19699159571266445, 0.09405965392964444, 0.1830430350261929, 0.1908480204776829, 0.18069438200540444, 0.18362438899858746, 0.18522516509314457, 0.21173014608184992, 0.19183775230520084, 0.19155182428383244, 0.1914270339522487, 0.1830561836518243, 0.2634197909548769, 0.19144656178782626, 0.2078377223925556, 0.20626272137411183, 0.16676847310109422, 0.20916372265657424, 0.2153955106195411, 0.18307182398650768, 0.6002782687987294, 0.6528518650810164, 0.6245983830236527, 0.20177789210340003, 0.634037834523898, 0.17206686411980132, 0.1991723519029277, 0.713366338259947, 0.5492019630603919, 0.47459597224987915, 0.4484720372103953, 0.29808282376782214, 0.2988951737585539, 0.31203473147073735, 0.33220396662088714, 0.3730864772478235, 0.29528506512230457, 0.4502599037821029, 0.1994128397436301, 0.18995487267952116, 0.1884684386681138, 0.18267104729200867, 0.1933193756410595, 0.1951414556569544, 0.20522218791442481, 0.21087579775184884, 0.17696801419851815, 0.07220669199003771, 0.06752973795927208, 0.06702693646075641, 0.07683286519148991, 0.07884357701541611, 0.07118792658329931, 0.08103416151668041, 0.07551222689411607, 0.059517777092337965]}, "mutation_prompt": null}
{"id": "105983ec-16d8-4d00-bf7f-3529f9aa863b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                self.cr = 0.7 + 0.3 * (1 - diversity)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic crossover probability based on diversity to enhance exploration.", "configspace": "", "generation": 28, "fitness": 0.22874748369197864, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.5377519090158576, 0.5965238806297706, 0.6645719996257041, 0.5795496123881886, 0.5845308672217038, 0.517959479978459, 0.5892777698457563, 0.5478085993802453, 0.6984817939103144, 0.24841118705613519, 0.3281513680253867, 0.2597222865645852, 0.3042837254142323, 0.18510195303821309, 0.27740902615039753, 0.34820085297499626, 0.3047446522997962, 0.2617977847533499, 0.11688462493415352, 0.11439706916977588, 0.1101752173132412, 0.1197359139626758, 0.1265594353031021, 0.11671560700986394, 0.11422305499774321, 0.1159024246869409, 0.11866313488047531, 0.09763727553749246, 0.11115146576520818, 0.095156131777975, 0.11182337813322485, 0.10438079522648602, 0.09014732891507315, 0.10163083515107374, 0.10570453711535333, 0.10700799670816596, 0.842029744543179, 0.8264381955285132, 0.8374913601625043, 0.8203317631007854, 0.7703307937370121, 0.8271292085832739, 0.8045996262841537, 0.7949494018353381, 0.8466596363571366, 0.3195044537449775, 0.2776257771264119, 0.24841093755464283, 0.29363003747243477, 0.253067510264229, 0.3125490386950688, 0.271641891292131, 0.2995412995501032, 0.32075060824705015, 0.13616115604346402, 0.15891238317637923, 0.3430821682171793, 0.30607001749980345, 0.294267075230913, 0.2656427881366401, 0.12377288985992085, 0.280911841768548, 0.29276717391675877, 0.28974444921417464, 0.20378119021096475, 0.18523241720939654, 0.19418359904146587, 0.16339967281257728, 0.27652531885999887, 0.15993130883559148, 0.2584738901468221, 0.18836134804206017, 0.1739474840121813, 0.20764264218616102, 0.16307656466144838, 0.16076065458121613, 0.16519455747312073, 0.2017125646029353, 0.11116719493486782, 0.1519888539368378, 0.12289931874232429, 9.999999999998899e-05, 0.01507201220889598, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012658551197847756, 9.999999999998899e-05, 0.0026279844207798275, 0.0816167919800157, 0.08219912758102543, 0.08131786864707413, 0.14200900353108203, 0.11132939701206357, 0.0805214019594176, 0.09576385320543346, 0.09514163263308806, 0.06133156306164678, 0.013855904110655293, 0.03527830120542619, 0.014148749514267145, 0.09753161960775047, 0.02762615190740414, 0.023892284212942427, 0.1064701414223147, 0.08583650290858258, 0.1184432007212739, 0.11612695192575917, 0.10703565814763838, 0.16515093299818706, 0.14684616351776802, 0.2563109206633617, 0.23446583370287977, 0.178247437689791, 0.15984149704899142, 0.15478961161126958, 0.5761308223891793, 0.45919419066413536, 0.49914875821099536, 0.50856185462317, 0.5402230654992668, 0.5865088696095379, 0.454280351481848, 0.40700079318059856, 0.574326161049244, 0.0977721784037594, 0.10614900769560587, 0.09469309918614421, 0.09292666759612234, 0.05889978863266021, 0.11184671724224116, 0.09683868935166373, 0.09981751392166405, 0.09476928773697235, 0.17591708781139803, 0.17930869389484594, 0.19904005984870055, 0.25004176911023, 0.19136789551488032, 0.18698377148719403, 0.20993766108159329, 0.2362295775668758, 0.20111222920875793, 0.14309330060816117, 0.18122382915342927, 0.1435913646001814, 0.17215180738505498, 0.21814915309036542, 0.1505520536776741, 0.15700236962500147, 0.2131880219568899, 0.14172410666129087, 0.11187210385997659, 0.10206885782960506, 0.11740430801995805, 0.10903186054657721, 0.09979800782448855, 0.1485665442143782, 0.09424666285811256, 0.1522297997276041, 0.10111395499622466, 0.18164488955510416, 0.1784417888556763, 0.20711505166301902, 0.1864209318334702, 0.19077916112805904, 0.21109707818518375, 0.1847197634751062, 0.18260244089245248, 0.17502378334316104, 0.20252844327269381, 0.2070453960232217, 0.20363362577376143, 0.18986174205576423, 0.17866700217457, 0.2081331804975991, 0.24496016679761123, 0.18774070521600839, 0.17676677229415783, 0.4893376967939028, 0.2069256991150159, 0.5147487234611055, 0.19093903954795732, 0.5989714375551443, 0.2380694603015554, 0.17183805895341775, 0.5783377052433225, 0.20760282095103466, 0.30441964619387074, 0.3251852196965671, 0.24343052264909548, 0.2582986012731431, 0.34175779603763856, 0.2076635768348637, 0.22756356351241946, 0.2004269023787837, 0.18785517495869175, 0.18507225441914554, 0.1871496623396417, 0.2214655930066577, 0.18687849678427415, 0.18230749487724995, 0.18582723150572023, 0.20076698569873308, 0.18902741786895672, 0.18415627673132762, 0.05849504838974684, 0.08164895707793107, 0.07262325900274991, 0.0570146246731823, 0.07219525310614172, 0.05053589903833511, 0.07728510866022642, 0.06126205637493398, 0.05660278813558417]}, "mutation_prompt": null}
{"id": "e65a4fe9-c330-436d-8b1f-6b7b83291f68", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                self.f *= 1.2  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Integrate an adaptive mutation strategy into differential evolution to enhance exploration.", "configspace": "", "generation": 29, "fitness": 0.29204802631704085, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.21.", "error": "", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.6587006989720974, 0.7239669990570009, 0.6884434535276518, 0.7412450073170423, 0.6877539420870236, 0.6955358912130838, 0.6864072565154439, 0.7129303980181928, 0.7038791316159774, 0.3653821700202562, 0.3873851672091623, 0.3865332169376591, 0.394698022413732, 0.4600401905530479, 0.34486753436926676, 0.3812826545569762, 0.39910655606268, 0.3756866279981901, 0.13450311828094563, 0.11531669588484961, 0.11624450620603821, 0.12092969747436855, 0.11406823368287766, 0.10778267200858205, 0.12530383195054962, 0.1470725570706689, 0.11731116416118437, 0.09178332583070004, 0.10372135113148362, 0.10012825190864183, 0.09987149176744115, 0.08486078763147742, 0.09640932333924723, 0.1110202828639354, 0.09148683424416248, 0.10035112749356723, 0.9473762951067406, 0.8044328322492876, 0.8565981515116481, 0.8669817554391325, 0.8719449440007249, 0.888842397640253, 0.9360651720255394, 0.9017277940453552, 0.8328456225093959, 0.38648292588075406, 0.32117701794339826, 0.38297419474878225, 0.38482859186443497, 0.36239268225584576, 0.3398549201057093, 0.33220600638035225, 0.35964232019433495, 0.38825290351411446, 0.5464760510713746, 0.595921298662422, 0.5742612492954186, 0.57021659353748, 0.5744933728813058, 0.4777434641188725, 0.5607680251421703, 0.5028912366208222, 0.5403110027464735, 0.3525342244986398, 0.2892128081281943, 0.1813907639814215, 0.16275997721677138, 0.2336801083410881, 0.27645298947940944, 0.17693237832764386, 0.24978870153642252, 0.19529808791699577, 0.34907221249671927, 0.20181023603378556, 0.20977645612897167, 0.2619707754989429, 0.2149159550191302, 0.27622020802994396, 0.14636904588800792, 0.26071809924980505, 0.33378577606103177, 0.120217871959868, 0.1699328087799844, 0.167255348766833, 0.12692903558937996, 0.10672344376127818, 0.09951547722723408, 0.13256241739358843, 0.15343163226294532, 0.12375748455527924, 0.22639216697049902, 0.2863729505906265, 0.23999546590382792, 0.35000725884144945, 0.22646917986946757, 0.14533203185389376, 0.3426461932364858, 0.3204658004323945, 0.18760283781519915, 0.07425967147566748, 0.055281089513464776, 0.03682787136900989, 0.09748532002733501, 0.0800967377395706, 0.07182851022297654, 0.07321779481775537, 0.14554865207520595, 0.06750301992072605, 0.20837366733746332, 0.19232869338942704, 0.20571248674660958, 0.2456052185089619, 0.24772514377688393, 0.21689983723911954, 0.19278043113175258, 0.23724645679015177, 0.2013644269088818, 0.5421189211537172, 0.6260194421669032, 0.6018278193333539, 0.4662921660545323, 0.5800321671270179, 0.5911967153047775, 0.48502192710545056, 0.57483404851324, 0.48540312224303284, 0.12734832068620328, 0.0950804682549462, 0.11924322553938016, 0.10849554437993525, 0.09195461634796542, 0.08757087639401995, 0.135597634386589, 0.10489503993266736, 0.12251110863476355, 0.2020129276999756, 0.19139339907367725, 0.17881582162812792, 0.2572024463987701, 0.20412807552457757, 0.27372744216071465, 0.18990437777687674, 0.1830950301172013, 0.18694521949778886, 0.28470271228718413, 0.26233740155206164, 0.2564569801670922, 0.20968364984532117, 0.21411348749529435, 0.18616271348741087, 0.2876403607227913, 0.21054768611613495, 0.341152130736629, 0.16072324891017464, 0.1364671433938187, 0.19921287163291213, 0.21951771138551524, 0.15348643822319774, 0.1308770174622912, 0.16817660326876738, 0.2243664974102373, 0.21393271343814657, 0.18888565776394672, 0.19425035325181605, 0.21444207174875718, 0.18935654516538358, 0.21433593652214233, 0.16558566766931127, 0.18549838953084408, 0.1816912478216698, 0.1916779296983394, 0.20169851255482907, 0.18274039033346812, 0.1825117281542119, 0.21755438610064826, 0.18660575048585348, 0.18376591286396682, 0.21312121308439258, 0.2039015714582647, 0.199533179706193, 0.15726029375687522, 0.16532757634010464, 0.5585636044158165, 0.672234860713447, 0.6457192349422801, 0.16020365146415438, 0.16311522455698635, 0.7083424512227245, 0.7066928804866872, 0.1934787313965094, 0.19791543760611763, 0.548795262140087, 0.15714481501216138, 0.6333592591808106, 0.533182946931797, 0.2022999346542722, 0.1208057101871356, 0.5621101076233068, 0.1834876562219695, 0.18208359229437598, 0.19960358428634206, 0.1947048910524215, 0.1916909138809365, 0.19431869583110728, 0.2084349859723671, 0.19568869693943602, 0.18638559694101886, 0.06418516663257579, 0.07405861008650716, 0.0729905945602557, 0.08152835311488449, 0.08171417872165998, 0.07088626271289067, 0.06838185477949921, 0.07453406782823058, 0.07366005360637684]}, "mutation_prompt": null}
{"id": "14927fe8-b336-4017-8dd9-79e4c244a4e1", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * np.exp(-5 * self.evaluations / self.budget)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Adjust cooling schedule in local search to adaptively enhance exploration during early evaluations.", "configspace": "", "generation": 30, "fitness": 0.28881554533066467, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.21.", "error": "", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.7263028378136241, 0.7585146840866324, 0.7422405601092601, 0.7401514621464536, 0.7519727204895681, 0.7428581658920879, 0.7398813381406202, 0.7373858837440903, 0.7546420542771982, 0.5152921804509554, 0.48987511906001013, 0.41141974762121736, 0.483951492419338, 0.4921493269818944, 0.5026805600609764, 0.49961633237178216, 0.5094028006030171, 0.3449570671917912, 0.1191661489040482, 0.10614776991453567, 0.12230269806074867, 0.13031370568383083, 0.12753865456757518, 0.12127474099115099, 0.1261555991686637, 0.14126780974681463, 0.14896213218592458, 0.06749120576805456, 0.10139771127599184, 0.11378493503950304, 0.07201418890975297, 0.1237975565883751, 0.06539871906988215, 0.08146785749941188, 0.1080171636332472, 0.07850656225204478, 0.8435575564370907, 0.7704561817319922, 0.7642331233159549, 0.8750655369377404, 0.7451042155115715, 0.8767202009338637, 0.7994417253348429, 0.892929459392764, 0.8591245080068968, 0.3581085610637287, 0.36137418823173306, 0.3690225196835334, 0.39020899637808015, 0.4264955826781224, 0.3772770453917923, 0.40279514732061483, 0.4211927498322099, 0.40100600644040507, 0.37825313749129286, 0.6213310296396942, 0.7504878878262784, 0.14861269645516528, 0.12595180554080432, 0.19198513344916457, 0.3124808378505808, 0.6537664223041927, 0.21398860499317074, 0.11568507024045682, 0.1562761210218534, 0.12675234733351992, 0.11707571723506083, 0.2393944824264469, 0.2876163711434393, 0.19072492610248382, 0.11850675406191513, 0.1922144030692421, 0.46873568965734247, 0.27466956399213516, 0.2082109854207863, 0.14662279250518728, 0.16813412190968535, 0.25028153154431865, 0.09878434912546341, 0.19974577861588227, 0.15719381881314254, 0.1396508843431833, 0.17646751241560776, 0.2723520767453008, 0.2541470196985086, 0.10849633471140441, 0.06462604232616664, 0.24633219439145215, 0.10225457221415857, 0.2616621930771851, 0.435825405811774, 0.26629517999845, 0.390969172841787, 0.2711861283324878, 0.3269806359456615, 0.22353202842945663, 0.09933112382283782, 0.13859372951465154, 0.18492295328021624, 0.14945110100846815, 0.10113735297207405, 0.09344518079304165, 0.09960227526384569, 0.130046685003108, 0.19431353195293233, 0.13101726426519034, 0.1744488895648093, 0.09799729530265555, 0.22754488730418565, 0.21256336328666325, 0.22184993178570445, 0.23704015869190576, 0.2224902472441579, 0.24111995436529898, 0.08439848438262998, 0.21748066443812764, 0.21356618781826653, 0.5594430904426368, 0.5803740476746513, 0.6486536443599815, 0.5871428858414003, 0.5635396272713822, 0.5274714026994907, 0.5345246980932998, 0.5682371416292068, 0.5646816788973202, 0.11711089066598157, 0.11256946407889079, 0.0988546808288866, 0.1387470819749187, 0.11452189856197126, 0.1502059986417842, 0.10792906300828031, 0.1295046648618181, 0.11302901201260829, 0.1660057328931578, 0.2435013337354156, 0.19724297790655276, 0.18331801976785067, 0.24313013222776092, 0.2263622935608206, 0.2629006658837749, 0.16337366855533197, 0.2856215854991778, 0.2903717241808448, 0.3274608851809879, 0.31603877646684564, 0.26797062754271406, 0.263555579165342, 0.3915933147586592, 0.2610143765252383, 0.28818575348512376, 0.24798914281056783, 0.1756687783053612, 0.143470553778843, 0.2520975036374913, 0.1505047473819071, 0.18865816734115448, 0.22902362449374403, 0.23026405811907769, 0.17770476061862772, 0.18651799733841135, 0.18826256826843946, 0.19159062496065082, 0.19120363110922112, 0.20234553989382664, 0.20007898183344652, 0.20735618931818256, 0.21078702201594657, 0.2058253425474581, 0.23601146952804164, 0.19336259617215812, 0.20760275773587877, 0.18567222628983482, 0.24418313204857167, 0.1820288676579569, 0.17540010654551175, 0.31805583030960416, 0.2029996915653839, 0.4556083340230943, 0.17867698540465704, 0.15527520615911194, 0.14528694494839833, 0.2878338632387034, 0.4680718758457153, 0.6765621098288461, 0.15265046709880847, 0.6663428933511325, 0.16726060299307333, 0.19032680563212223, 0.20158106184524227, 0.12299653076319261, 0.1669401019651543, 0.21767960114926632, 0.1923710264992574, 0.1587790305278921, 0.543327791588248, 0.5913995339552582, 0.22251133516213717, 0.23934018908493204, 0.20633975962491857, 0.23311060781898263, 0.21485873166541003, 0.23856290345007292, 0.22735926494414815, 0.20311561200416062, 0.21582756215473586, 0.09675064656264354, 0.08963509806297021, 0.07755684575531197, 0.0848386060204499, 0.08532214473148725, 0.08148849978405304, 0.08278724205372634, 0.08348259272885972, 0.0844112320369188]}, "mutation_prompt": null}
{"id": "6970c20f-def1-4017-8487-38e51e8d4bc3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  # Line changed\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive population size adjustment based on evaluations to improve convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.6940418612747186, 0.7592226582909436, 0.7289639678176736, 0.7388305937858344, 0.721759268782757, 0.7502734137790892, 0.7550252238571383, 0.7091226761554033, 0.7483462256276983, 0.22417251583071052, 0.38613195085302654, 0.04345966900624865, 0.4637434850239581, 0.5154063061733638, 0.4796947624978317, 0.5285299820212078, 0.4838223332343575, 0.04193935504930979, 0.10835476244508069, 0.11424602955377816, 0.13497477141109593, 0.10185687998009108, 0.11225147821549508, 0.1004486090986344, 0.11897127255055162, 0.1070583578042118, 0.13585106128860713, 0.09193255519581611, 0.11111724682543223, 0.11207201371769882, 0.07182218649199223, 0.09611861496425012, 0.1070452480590608, 0.08793067557579448, 0.08518721140804464, 0.11001701047072654, 0.8694963170854244, 0.8306622559397504, 0.7032194587028664, 0.8656114203206206, 0.7287641867278725, 0.8806272107505876, 0.8886346969678509, 0.9041474097639645, 0.874018530297335, 0.3271499977702804, 0.37815561827439803, 0.3197321804896571, 0.39873836079160596, 0.37749943466983227, 0.3559008319097312, 0.33899663020951243, 0.4000798448898639, 0.3369037212965328, 0.5998778425870182, 0.6380563885255307, 0.7666191586858513, 0.16599561124997708, 0.6294102352401544, 0.4383611475603021, 0.4762129750002514, 0.6253432106786876, 0.5925039970358937, 0.13764055873534564, 0.1847582528788545, 0.1601160226439624, 0.1168994299901569, 0.19617984017444656, 0.19912214451845267, 0.21767371138563307, 0.11208485095260734, 0.23325515456816548, 0.24310232241997176, 0.18981034859794177, 0.16784545689467045, 0.20367913230782397, 0.25697969840587986, 0.17631370887737907, 0.09628804007168523, 0.17926612383153462, 0.16623151627464738, 0.21238322438987622, 0.2802420809887781, 0.20652563541600732, 0.19141460077734118, 0.18114227604545918, 0.17493062811228666, 0.1685248322256866, 0.22059196573440887, 0.19802791629254624, 0.3476701535069243, 0.25070198800794297, 0.3169391270643911, 0.31197426594750355, 0.3173019790435003, 0.2296211722379793, 0.34175227239141637, 0.20431306893138634, 0.2711085473443501, 0.06734793488037816, 0.18867919451266435, 0.08061776972336299, 0.0987689202118468, 0.11308887435120563, 0.05884283670303225, 0.08714810134554796, 0.1184039541323576, 0.14494808466834597, 0.25869942727752826, 0.24095840865748952, 0.1765580807584627, 0.22418792289786815, 0.18897001182085138, 0.2404116456398656, 0.07800288158489244, 0.18283481018240633, 0.22221331642962927, 0.6023449048206291, 0.6120569632176913, 0.5323300997191508, 0.5210615774090648, 0.6310086086178421, 0.600137211716884, 0.4992054778844015, 0.5811653684870712, 0.5603279462676873, 0.1099437590011737, 0.10062663707171382, 0.10188484114089025, 0.11381200680138048, 0.15034264169113432, 0.12077575526363293, 0.1013016235739389, 0.09641699942187865, 0.11555003682036136, 0.24197924598606846, 0.22691804029084783, 0.19226250863549033, 0.22361361560435877, 0.2663817427486933, 0.2417878183637323, 0.21299406595044879, 0.1824404760852255, 0.17698594651175792, 0.3337679964326966, 0.3494777231432754, 0.32613055503618094, 0.2939767788855917, 0.3081064548428454, 0.31279662821455534, 0.3767570978398942, 0.3402900079006157, 0.3160114422219341, 0.20115324116234978, 0.20565065509624025, 0.2893779420901351, 0.1980113131842135, 0.24890739226413994, 0.15825474463681344, 0.2845976817443252, 0.24118697457550498, 0.24231560027301124, 0.18370593938492485, 0.20261723074063653, 0.2129916036744418, 0.1544592604051348, 0.19544084836617037, 0.18370300834812447, 0.1828919019947658, 0.17764058458403065, 0.2023850125839265, 0.19969133222029545, 0.18805838994452428, 0.18741910523224115, 0.2327947159769782, 0.19612701113628117, 0.17029416535359765, 0.19249864937372752, 0.18462679509532276, 0.3257177043328655, 0.19096270215308409, 0.16114802989663768, 0.5970583805480778, 0.5515355324514138, 0.6158102436918973, 0.5904714979104257, 0.19414240002599925, 0.7793662738877019, 0.17014557608550074, 0.1949265013516832, 0.7317185335750698, 0.5484441640417472, 0.19425429248306014, 0.28890118400056075, 0.6061198898490687, 0.15886995274542737, 0.1514350901065653, 0.624020563799579, 0.18535223485427843, 0.18025108565703563, 0.18418285651547894, 0.1883322108971921, 0.19830520810817887, 0.1878324446716143, 0.2058895307986559, 0.20737982827360324, 0.186051973194579, 0.07167356137733094, 0.0892449470203297, 0.07670038516890076, 0.0732406019397347, 0.07302326784446855, 0.07472731164037472, 0.07118368942202646, 0.06699690055914342, 0.0788057268915785]}, "mutation_prompt": null}
{"id": "ebb2acd1-6526-49fb-9950-65b757115651", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  # Line changed\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive population size adjustment based on evaluations to improve convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.6940418612747186, 0.7592226582909436, 0.7289639678176736, 0.7388305937858344, 0.721759268782757, 0.7502734137790892, 0.7550252238571383, 0.7091226761554033, 0.7483462256276983, 0.22417251583071052, 0.38613195085302654, 0.04345966900624865, 0.4637434850239581, 0.5154063061733638, 0.4796947624978317, 0.5285299820212078, 0.4838223332343575, 0.04193935504930979, 0.10835476244508069, 0.11424602955377816, 0.13497477141109593, 0.10185687998009108, 0.11225147821549508, 0.1004486090986344, 0.11897127255055162, 0.1070583578042118, 0.13585106128860713, 0.09193255519581611, 0.11111724682543223, 0.11207201371769882, 0.07182218649199223, 0.09611861496425012, 0.1070452480590608, 0.08793067557579448, 0.08518721140804464, 0.11001701047072654, 0.8694963170854244, 0.8306622559397504, 0.7032194587028664, 0.8656114203206206, 0.7287641867278725, 0.8806272107505876, 0.8886346969678509, 0.9041474097639645, 0.874018530297335, 0.3271499977702804, 0.37815561827439803, 0.3197321804896571, 0.39873836079160596, 0.37749943466983227, 0.3559008319097312, 0.33899663020951243, 0.4000798448898639, 0.3369037212965328, 0.5998778425870182, 0.6380563885255307, 0.7666191586858513, 0.16599561124997708, 0.6294102352401544, 0.4383611475603021, 0.4762129750002514, 0.6253432106786876, 0.5925039970358937, 0.13764055873534564, 0.1847582528788545, 0.1601160226439624, 0.1168994299901569, 0.19617984017444656, 0.19912214451845267, 0.21767371138563307, 0.11208485095260734, 0.23325515456816548, 0.24310232241997176, 0.18981034859794177, 0.16784545689467045, 0.20367913230782397, 0.25697969840587986, 0.17631370887737907, 0.09628804007168523, 0.17926612383153462, 0.16623151627464738, 0.21238322438987622, 0.2802420809887781, 0.20652563541600732, 0.19141460077734118, 0.18114227604545918, 0.17493062811228666, 0.1685248322256866, 0.22059196573440887, 0.19802791629254624, 0.3476701535069243, 0.25070198800794297, 0.3169391270643911, 0.31197426594750355, 0.3173019790435003, 0.2296211722379793, 0.34175227239141637, 0.20431306893138634, 0.2711085473443501, 0.06734793488037816, 0.18867919451266435, 0.08061776972336299, 0.0987689202118468, 0.11308887435120563, 0.05884283670303225, 0.08714810134554796, 0.1184039541323576, 0.14494808466834597, 0.25869942727752826, 0.24095840865748952, 0.1765580807584627, 0.22418792289786815, 0.18897001182085138, 0.2404116456398656, 0.07800288158489244, 0.18283481018240633, 0.22221331642962927, 0.6023449048206291, 0.6120569632176913, 0.5323300997191508, 0.5210615774090648, 0.6310086086178421, 0.600137211716884, 0.4992054778844015, 0.5811653684870712, 0.5603279462676873, 0.1099437590011737, 0.10062663707171382, 0.10188484114089025, 0.11381200680138048, 0.15034264169113432, 0.12077575526363293, 0.1013016235739389, 0.09641699942187865, 0.11555003682036136, 0.24197924598606846, 0.22691804029084783, 0.19226250863549033, 0.22361361560435877, 0.2663817427486933, 0.2417878183637323, 0.21299406595044879, 0.1824404760852255, 0.17698594651175792, 0.3337679964326966, 0.3494777231432754, 0.32613055503618094, 0.2939767788855917, 0.3081064548428454, 0.31279662821455534, 0.3767570978398942, 0.3402900079006157, 0.3160114422219341, 0.20115324116234978, 0.20565065509624025, 0.2893779420901351, 0.1980113131842135, 0.24890739226413994, 0.15825474463681344, 0.2845976817443252, 0.24118697457550498, 0.24231560027301124, 0.18370593938492485, 0.20261723074063653, 0.2129916036744418, 0.1544592604051348, 0.19544084836617037, 0.18370300834812447, 0.1828919019947658, 0.17764058458403065, 0.2023850125839265, 0.19969133222029545, 0.18805838994452428, 0.18741910523224115, 0.2327947159769782, 0.19612701113628117, 0.17029416535359765, 0.19249864937372752, 0.18462679509532276, 0.3257177043328655, 0.19096270215308409, 0.16114802989663768, 0.5970583805480778, 0.5515355324514138, 0.6158102436918973, 0.5904714979104257, 0.19414240002599925, 0.7793662738877019, 0.17014557608550074, 0.1949265013516832, 0.7317185335750698, 0.5484441640417472, 0.19425429248306014, 0.28890118400056075, 0.6061198898490687, 0.15886995274542737, 0.1514350901065653, 0.624020563799579, 0.18535223485427843, 0.18025108565703563, 0.18418285651547894, 0.1883322108971921, 0.19830520810817887, 0.1878324446716143, 0.2058895307986559, 0.20737982827360324, 0.186051973194579, 0.07167356137733094, 0.0892449470203297, 0.07670038516890076, 0.0732406019397347, 0.07302326784446855, 0.07472731164037472, 0.07118368942202646, 0.06699690055914342, 0.0788057268915785]}, "mutation_prompt": null}
{"id": "62e26b59-f416-40be-9aeb-56c21c8cdd15", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))  # Line changed\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive population size adjustment based on evaluations to improve convergence.", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.6940418612747186, 0.7592226582909436, 0.7289639678176736, 0.7388305937858344, 0.721759268782757, 0.7502734137790892, 0.7550252238571383, 0.7091226761554033, 0.7483462256276983, 0.22417251583071052, 0.38613195085302654, 0.04345966900624865, 0.4637434850239581, 0.5154063061733638, 0.4796947624978317, 0.5285299820212078, 0.4838223332343575, 0.04193935504930979, 0.10835476244508069, 0.11424602955377816, 0.13497477141109593, 0.10185687998009108, 0.11225147821549508, 0.1004486090986344, 0.11897127255055162, 0.1070583578042118, 0.13585106128860713, 0.09193255519581611, 0.11111724682543223, 0.11207201371769882, 0.07182218649199223, 0.09611861496425012, 0.1070452480590608, 0.08793067557579448, 0.08518721140804464, 0.11001701047072654, 0.8694963170854244, 0.8306622559397504, 0.7032194587028664, 0.8656114203206206, 0.7287641867278725, 0.8806272107505876, 0.8886346969678509, 0.9041474097639645, 0.874018530297335, 0.3271499977702804, 0.37815561827439803, 0.3197321804896571, 0.39873836079160596, 0.37749943466983227, 0.3559008319097312, 0.33899663020951243, 0.4000798448898639, 0.3369037212965328, 0.5998778425870182, 0.6380563885255307, 0.7666191586858513, 0.16599561124997708, 0.6294102352401544, 0.4383611475603021, 0.4762129750002514, 0.6253432106786876, 0.5925039970358937, 0.13764055873534564, 0.1847582528788545, 0.1601160226439624, 0.1168994299901569, 0.19617984017444656, 0.19912214451845267, 0.21767371138563307, 0.11208485095260734, 0.23325515456816548, 0.24310232241997176, 0.18981034859794177, 0.16784545689467045, 0.20367913230782397, 0.25697969840587986, 0.17631370887737907, 0.09628804007168523, 0.17926612383153462, 0.16623151627464738, 0.21238322438987622, 0.2802420809887781, 0.20652563541600732, 0.19141460077734118, 0.18114227604545918, 0.17493062811228666, 0.1685248322256866, 0.22059196573440887, 0.19802791629254624, 0.3476701535069243, 0.25070198800794297, 0.3169391270643911, 0.31197426594750355, 0.3173019790435003, 0.2296211722379793, 0.34175227239141637, 0.20431306893138634, 0.2711085473443501, 0.06734793488037816, 0.18867919451266435, 0.08061776972336299, 0.0987689202118468, 0.11308887435120563, 0.05884283670303225, 0.08714810134554796, 0.1184039541323576, 0.14494808466834597, 0.25869942727752826, 0.24095840865748952, 0.1765580807584627, 0.22418792289786815, 0.18897001182085138, 0.2404116456398656, 0.07800288158489244, 0.18283481018240633, 0.22221331642962927, 0.6023449048206291, 0.6120569632176913, 0.5323300997191508, 0.5210615774090648, 0.6310086086178421, 0.600137211716884, 0.4992054778844015, 0.5811653684870712, 0.5603279462676873, 0.1099437590011737, 0.10062663707171382, 0.10188484114089025, 0.11381200680138048, 0.15034264169113432, 0.12077575526363293, 0.1013016235739389, 0.09641699942187865, 0.11555003682036136, 0.24197924598606846, 0.22691804029084783, 0.19226250863549033, 0.22361361560435877, 0.2663817427486933, 0.2417878183637323, 0.21299406595044879, 0.1824404760852255, 0.17698594651175792, 0.3337679964326966, 0.3494777231432754, 0.32613055503618094, 0.2939767788855917, 0.3081064548428454, 0.31279662821455534, 0.3767570978398942, 0.3402900079006157, 0.3160114422219341, 0.20115324116234978, 0.20565065509624025, 0.2893779420901351, 0.1980113131842135, 0.24890739226413994, 0.15825474463681344, 0.2845976817443252, 0.24118697457550498, 0.24231560027301124, 0.18370593938492485, 0.20261723074063653, 0.2129916036744418, 0.1544592604051348, 0.19544084836617037, 0.18370300834812447, 0.1828919019947658, 0.17764058458403065, 0.2023850125839265, 0.19969133222029545, 0.18805838994452428, 0.18741910523224115, 0.2327947159769782, 0.19612701113628117, 0.17029416535359765, 0.19249864937372752, 0.18462679509532276, 0.3257177043328655, 0.19096270215308409, 0.16114802989663768, 0.5970583805480778, 0.5515355324514138, 0.6158102436918973, 0.5904714979104257, 0.19414240002599925, 0.7793662738877019, 0.17014557608550074, 0.1949265013516832, 0.7317185335750698, 0.5484441640417472, 0.19425429248306014, 0.28890118400056075, 0.6061198898490687, 0.15886995274542737, 0.1514350901065653, 0.624020563799579, 0.18535223485427843, 0.18025108565703563, 0.18418285651547894, 0.1883322108971921, 0.19830520810817887, 0.1878324446716143, 0.2058895307986559, 0.20737982827360324, 0.186051973194579, 0.07167356137733094, 0.0892449470203297, 0.07670038516890076, 0.0732406019397347, 0.07302326784446855, 0.07472731164037472, 0.07118368942202646, 0.06699690055914342, 0.0788057268915785]}, "mutation_prompt": null}
{"id": "4db5889b-3726-4544-9696-76e70aeebcee", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance local search efficacy by dynamically adjusting perturbation range based on current diversity.", "configspace": "", "generation": 34, "fitness": 0.3187944776271166, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.23.", "error": "", "parent_id": "e0ef0979-88f2-488f-b812-286b178560ff", "metadata": {"aucs": [0.7109907146435755, 0.7491827025033557, 0.7536247985245653, 0.7613471294740257, 0.770450987136383, 0.7713968523131269, 0.7399818922134859, 0.7160643092220165, 0.7689999495101987, 0.49827369016192347, 0.46418720044596007, 0.24338868353165788, 0.49421937483230194, 0.5176091833543226, 0.5122178804891997, 0.40442925220937354, 0.4743813883298771, 0.47038839077976635, 0.09730796888742099, 0.11868218213987924, 0.1299201618987823, 0.09826485914827976, 0.1134033431189635, 0.10171572936963036, 0.11488239426450964, 0.12982740548873462, 0.12966128201834493, 0.08764723145335052, 0.08796328789291985, 0.08753550710643665, 0.09042753481148935, 0.09714223948294698, 0.10222214276981723, 0.09020888772480706, 0.09346617992900441, 0.09953399029422183, 0.9473287825984831, 0.8416245695090718, 0.894032675502264, 0.8714361365044148, 0.8956423276465709, 0.8885469028271118, 0.8613101653212107, 0.8728393404064587, 0.865883883132017, 0.3149273204720655, 0.3959204776481836, 0.42043250644517527, 0.33737730208942474, 0.4739753674737547, 0.42016434439934824, 0.35627746821559547, 0.36292407489361933, 0.3500743216439848, 0.672668127937555, 0.696855350977736, 0.7000812091843864, 0.660688350162701, 0.6541804787597694, 0.7536334144590695, 0.6612143352282878, 0.6063585815738578, 0.7172517479004048, 0.16944384574418747, 0.2681118315690577, 0.2758227901462543, 0.1936238202813969, 0.2063608911359991, 0.19892439986031785, 0.19313198536165654, 0.2299066426860581, 0.20954775606616471, 0.18082246276034608, 0.20419181940466447, 0.17200418276299, 0.17872864767350494, 0.20803082171466314, 0.23721444439793848, 0.1535647385460157, 0.1774263429065499, 0.18053995154207692, 0.18495003121399123, 0.23491853431543785, 0.10795620910644388, 0.19585799110922708, 0.19853593382299506, 0.07935645265260705, 0.20217785609934869, 0.21965824940456546, 0.2475632012212836, 0.24523087987926784, 0.35106407249147564, 0.2636198279251327, 0.4208582888428829, 0.27143398802718677, 0.13558600750626115, 0.2702087713327044, 0.480791687753354, 0.08306249510694375, 0.09003962588152603, 0.0755477291096508, 0.10715347269092379, 0.12997504538211757, 0.07636892477314938, 0.0743264306732182, 0.13542899700093336, 0.09542907617683627, 0.09928472307885872, 0.2030026977991538, 0.23958307195532447, 0.2071314744963969, 0.264247117512297, 0.25395469175979546, 0.24988689304238554, 0.14873665502733835, 0.21439055847552757, 0.23297814498454805, 0.6561532404611267, 0.636100870898002, 0.4708972140725557, 0.5133621529799683, 0.5668792283373996, 0.6358775245968582, 0.5343143705984384, 0.520050294893871, 0.5299782030588369, 0.10263212025208035, 0.1142104641632764, 0.10364670140437116, 0.10664833647407301, 0.10037129976518011, 0.12295883147079145, 0.12390403458948351, 0.11821990748021616, 0.08098216086771115, 0.20425448070201013, 0.18858606658440435, 0.20983549303543048, 0.2014788105295795, 0.20910377842661276, 0.1982507469065854, 0.17559709572257942, 0.21011939630943932, 0.19638637633538958, 0.33225753097656774, 0.34723350451294566, 0.3456232939410552, 0.31256287820446227, 0.3273431375248672, 0.3445039742385233, 0.3779061881040069, 0.4034887559590694, 0.37403448382004667, 0.28939670269903606, 0.2580641244551791, 0.22830313060197105, 0.25417222876318923, 0.2597533487739314, 0.23870234292534664, 0.3098797702387276, 0.30585020425472154, 0.29721124297349255, 0.20262287212334162, 0.22361827265979184, 0.1838231675466001, 0.18397922854184534, 0.21179579917578262, 0.19818115591926222, 0.22645183142302572, 0.19568815153238261, 0.21877286670205232, 0.21950635429981125, 0.22339162985949212, 0.1843779066183795, 0.3411468062421764, 0.20852556298396874, 0.17393846618169861, 0.23937061960435846, 0.1919353472056331, 0.18047085163878074, 0.20588490823388716, 0.1811290844597674, 0.805528575362443, 0.17521440273639077, 0.6957331032723452, 0.6723087586961611, 0.198302162567226, 0.6526442198096826, 0.7560786090557581, 0.20331999919789245, 0.20917020354169613, 0.7299920523013037, 0.497715604079912, 0.6368120741025609, 0.737474448852891, 0.15344176646263386, 0.7242300415106782, 0.10756521514443684, 0.18585062677099518, 0.18412590878468926, 0.17489903349546543, 0.1836719884049668, 0.1807510753095941, 0.18385510530467464, 0.19057070129569142, 0.1806598624575938, 0.17833827575463002, 0.07260106556412116, 0.08229887852451956, 0.07459068537939129, 0.07213395133250633, 0.09264582148432088, 0.0914207924565168, 0.0775215499275449, 0.0744000414307755, 0.0797541876716179]}, "mutation_prompt": null}
{"id": "251586b3-3f71-4269-bb6d-44cabf1a1644", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            diversity = np.mean(np.std(self.population, axis=0))  # New line added for dynamic cr\n            self.cr = 0.5 + 0.5 * diversity  # Line changed for dynamic crossover rate adjustment\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce a dynamic crossover rate adjustment based on diversity to balance exploration and exploitation.", "configspace": "", "generation": 35, "fitness": 0.28392859966268885, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.22.", "error": "", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.7216629752399897, 0.7268157176512824, 0.7287538416184672, 0.7440031688641423, 0.7401441562180691, 0.7501386701646783, 0.7222969756369204, 0.7361695780566402, 0.6935281946152239, 0.47141986091838717, 0.47350795748696095, 0.38964605743467495, 0.4482453227329357, 0.4920094938339622, 0.45912240055840425, 0.4214199288917485, 0.45729206832752545, 0.33307749349737814, 0.12201480574313539, 0.1008012051455971, 0.10827357624794443, 0.12316156321629168, 0.12374826443254738, 0.13795790526668772, 0.11853297426944531, 0.12694476570404478, 0.0797081745983671, 0.09154684392968215, 0.086607993372666, 0.11407649171625267, 0.1071626019217512, 0.12254225463076762, 0.10395635225902167, 0.09316776969274199, 0.10426691557192447, 0.12262889208582495, 0.789262183078445, 0.8470646320282051, 0.49276998046397325, 0.8147010286742931, 0.8732528717485692, 0.8223840259399406, 0.9010489646715812, 0.7661353620038324, 0.8738555144621709, 0.35227747092150363, 0.36422659155216597, 0.3113127818289215, 0.3209157904170279, 0.4009500250975673, 0.3586601127827609, 0.30556861432439797, 0.3422013055573897, 0.34581186221608695, 0.7493766887487343, 0.5619243766824223, 0.7058155566160644, 0.6999741495710396, 0.598768766343744, 0.1656647938498862, 0.557826558892154, 0.5432234435167618, 0.591920115046221, 0.16496184282248827, 0.16507021919491838, 0.18437368943434695, 0.1473226983532926, 0.16031666627462304, 0.1917968882164861, 0.20402211025783712, 0.23386775148497163, 0.20389732186021314, 0.1713833166819051, 0.19151949511807587, 0.18398589294750978, 0.15894706554647509, 0.1890414142110881, 0.2055842059936518, 0.2031688925912819, 0.20520853151483387, 0.1533401031042958, 0.14684226705873082, 0.11530578035486871, 0.1011129917508089, 0.1757586935676103, 0.18171957920216608, 0.05915280802737111, 0.13959962629995903, 0.12098787572101477, 0.08653562724736708, 0.272114805521424, 0.2188737574774825, 0.25312144650367885, 0.0947699152766387, 0.2332453856781992, 0.13024981483771914, 0.2362669203452319, 0.2803456692175813, 0.07340775712960546, 0.032640791463037, 0.01797323902043968, 0.010583315180166752, 0.021228447775893056, 0.02025595276859493, 0.01627998466205971, 0.044903510162634164, 0.015834659868710688, 0.013967249872133491, 0.13659410335033884, 0.052481626258698455, 0.12740648538740096, 0.13056744223300398, 0.1441606048429891, 0.13231311674000312, 0.11118973649635222, 0.1313489407978533, 0.1303222569782203, 0.4686213930409263, 0.46499314297403593, 0.48192412985597577, 0.4480872740998595, 0.45874389718912456, 0.455026904891224, 0.4684006613487889, 0.45448773208144444, 0.47514180982532594, 0.09029449353675723, 0.09791647210034571, 0.09698893417235577, 0.09667854584380964, 0.08262954809255885, 0.07950953481779344, 0.08963388019716656, 0.09430518381709174, 0.1564496880763041, 0.18243316574304724, 0.19776363293733712, 0.21856971628468913, 0.2157524700003054, 0.2092398516444075, 0.17257172772509688, 0.20469888650016455, 0.21649311712873975, 0.22211560145275044, 0.23104384841101477, 0.3319823414443136, 0.27939429756330525, 0.30053606885655093, 0.3119956274896949, 0.3274949227027619, 0.29853228199800574, 0.20575482424930802, 0.34313083243059894, 0.21490278838031696, 0.2304805261296733, 0.19078640377339506, 0.2465279887198033, 0.23213143391464264, 0.22789214916356537, 0.22852962880598426, 0.22713496502543595, 0.21708574187105267, 0.19691254127960411, 0.18744629087782116, 0.21044038042016966, 0.1903166413727797, 0.20226255131604676, 0.2119667535045855, 0.19356066368834224, 0.1966300165581084, 0.21019794729638897, 0.1963265908589884, 0.22033601098764655, 0.18238540635235045, 0.2023909760358349, 0.19174619857800568, 0.18809383358765686, 0.1916755741135906, 0.1861979782551927, 0.19083083726921446, 0.17925356607577903, 0.7499286098091833, 0.7479320099383291, 0.17535262181550493, 0.6973949429674715, 0.7264429346071539, 0.15993329825038616, 0.7428437142086047, 0.7761161716490979, 0.20419696123931141, 0.20499603639102948, 0.6004754645116619, 0.6149854449720795, 0.16769380636694098, 0.6455592288514739, 0.6617425948207365, 0.20234327038811395, 0.16177005064947847, 0.18089052444731146, 0.17631934073681843, 0.19850695949410113, 0.18859509807772057, 0.1814741184502976, 0.18336602225579646, 0.18462231179105715, 0.1783445700981935, 0.17828898021502027, 0.06422263089350344, 0.06722928109307558, 0.0814563627770214, 0.08261586990226388, 0.08371357056662476, 0.08139941024913766, 0.06596011221923237, 0.07769801777606478, 0.0798712906538045]}, "mutation_prompt": null}
{"id": "f07dfa48-3d35-4ccc-a9c5-15fd0507e17b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                self.cr = 0.7 + 0.2 * diversity * (1 - self.evaluations / self.budget)  # Changed line\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce a gradual adjustment to the crossover probability based on the budget utilization and diversity to enhance exploration.", "configspace": "", "generation": 36, "fitness": 0.30219947689075716, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.23.", "error": "", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.6922509336591689, 0.7458116900748055, 0.7487603224188484, 0.7329397861804818, 0.7446305903636958, 0.7476474170735465, 0.7413575278445715, 0.7253855659533106, 0.7154474673160811, 0.5078764230803543, 0.48779667581914676, 0.4122055325732007, 0.4695793381554957, 0.5064912871251698, 0.413686069098796, 0.5268265012215878, 0.48990704485555503, 0.3626316531319983, 0.12397353279088552, 0.10493391623038806, 0.13100161599090154, 0.10130995487955496, 0.11933582985021496, 0.08143612834438974, 0.13211669207120336, 0.13388020567944037, 0.11298076118580247, 0.10214216663147546, 0.11966414942633097, 0.11419128762869879, 0.11500634398948328, 0.10724244583254439, 0.10669625924115334, 0.14328668229812502, 0.10711480799611495, 0.11633125275550116, 0.7851601126526502, 0.882071470673237, 0.7966272726132506, 0.8622093002661465, 0.9098964726840388, 0.8077873708183022, 0.9210654134308586, 0.914397234497943, 0.9089078184938649, 0.3151329542946374, 0.3785882113858765, 0.37525412680245607, 0.3695684246442116, 0.41626913019647005, 0.40529376980468235, 0.33211218091533623, 0.37828474377559784, 0.41902998463708585, 0.497602793154319, 0.6292592870872742, 0.6238838479534863, 0.6018115914969169, 0.6192871262205899, 0.19514296222430683, 0.6220605473512129, 0.5822733680758783, 0.6138471196836864, 0.21741546194580919, 0.1978178838668867, 0.21428270046133857, 0.18170189046770413, 0.155841380608854, 0.22537483258140845, 0.23640098354071537, 0.17051831814677065, 0.20700632701355037, 0.10931845798718298, 0.178220921310405, 0.17906021342505452, 0.17418390116245996, 0.23439916930480043, 0.2648652193458122, 0.21352235961524024, 0.22294783196975554, 0.16129943262683044, 0.13504974118636837, 0.1599985359595989, 0.11678221948520806, 0.10903634765618375, 0.12188484346938289, 0.034454064934356765, 0.11991712187925352, 0.12858676553573223, 0.10674520656009956, 0.20945809977187468, 0.24667854729779415, 0.27415890549806077, 0.23792145653323304, 0.25115165739286205, 0.17649310509965832, 0.28828853605959237, 0.20953127642677827, 0.22250161751239272, 0.0266552375349427, 0.03348688700179303, 0.050001724022769145, 0.055859004454696715, 0.07844586568432588, 0.043853890520064276, 0.0727301081269981, 0.033229472355867595, 0.06374705943824299, 0.1548588535379708, 0.1674844415205693, 0.15601808782833904, 0.15717659900874092, 0.1721604756793753, 0.1419603529970095, 0.13752385625594798, 0.1366743661132943, 0.15493262463095703, 0.5242362408987964, 0.503330702694718, 0.529867310143127, 0.5094992070267, 0.5064959934189066, 0.4984479864259139, 0.4910881706053706, 0.5151561623366795, 0.5044615525008995, 0.11061147273439309, 0.08386113017170771, 0.09913865872280403, 0.12055083732987937, 0.10197908145824242, 0.09258397191037349, 0.09329471127719702, 0.10513827872530657, 0.0978590927220725, 0.22050288042437616, 0.20237207642207555, 0.21056240750687316, 0.201481630700992, 0.1973155788346046, 0.17643864474631632, 0.2334936162648743, 0.209705085345808, 0.1972176210222577, 0.28492352814345645, 0.31279566956599403, 0.28503643787538324, 0.29779607958641996, 0.33346697229914, 0.28932962364626624, 0.3393535377506134, 0.3466391914705613, 0.38463568245405577, 0.2138956201117056, 0.23906598351081232, 0.17597956984610597, 0.18779919213697327, 0.20896530207084418, 0.25870802844860363, 0.2609909610135507, 0.23990519401599464, 0.2269412468404255, 0.20190354693711576, 0.2034565742054505, 0.18294909560774508, 0.19487001170786056, 0.21671689801967153, 0.19522357752673603, 0.18604584424492232, 0.17804494658187264, 0.20301262013571952, 0.21191082775115566, 0.1855650311965994, 0.18621720962254695, 0.18368338585166255, 0.19840782407125213, 0.20022866671981587, 0.17822098913056905, 0.19032804685988913, 0.19382228473306984, 0.2090338155237753, 0.18432549755002015, 0.788396810843073, 0.19477087419076344, 0.6766193416108778, 0.7643537831799617, 0.1642782733438105, 0.7676029551427086, 0.7669189758513689, 0.19685295402349845, 0.6653587518899582, 0.6222378470412725, 0.6763278126403929, 0.6947451312807654, 0.6515779026793982, 0.7159666810427283, 0.6546604459595908, 0.20696117261517388, 0.1925266941244438, 0.1784167551610406, 0.1896734621127495, 0.18275791346074644, 0.209691780214612, 0.19781500245347083, 0.17513028171202005, 0.1797420213186557, 0.2043282082764395, 0.07923839022601864, 0.07674627200739648, 0.07458855740597281, 0.07439286950933621, 0.08072835593466876, 0.08991913669780427, 0.07625939122368286, 0.07214785259715117, 0.09015499854310638]}, "mutation_prompt": null}
{"id": "030df40a-b24a-48c0-a7a6-88ec3bf24faa", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance local search efficacy by dynamically adjusting perturbation range based on current diversity.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.7109907146435755, 0.7491827025033557, 0.7536247985245653, 0.7613471294740257, 0.770450987136383, 0.7713968523131269, 0.7399818922134859, 0.7160643092220165, 0.7689999495101987, 0.49827369016192347, 0.46418720044596007, 0.24338868353165788, 0.49421937483230194, 0.5176091833543226, 0.5122178804891997, 0.40442925220937354, 0.4743813883298771, 0.47038839077976635, 0.09730796888742099, 0.11868218213987924, 0.1299201618987823, 0.09826485914827976, 0.1134033431189635, 0.10171572936963036, 0.11488239426450964, 0.12982740548873462, 0.12966128201834493, 0.08764723145335052, 0.08796328789291985, 0.08753550710643665, 0.09042753481148935, 0.09714223948294698, 0.10222214276981723, 0.09020888772480706, 0.09346617992900441, 0.09953399029422183, 0.9473287825984831, 0.8416245695090718, 0.894032675502264, 0.8714361365044148, 0.8956423276465709, 0.8885469028271118, 0.8613101653212107, 0.8728393404064587, 0.865883883132017, 0.3149273204720655, 0.3959204776481836, 0.42043250644517527, 0.33737730208942474, 0.4739753674737547, 0.42016434439934824, 0.35627746821559547, 0.36292407489361933, 0.3500743216439848, 0.672668127937555, 0.696855350977736, 0.7000812091843864, 0.660688350162701, 0.6541804787597694, 0.7536334144590695, 0.6612143352282878, 0.6063585815738578, 0.7172517479004048, 0.16944384574418747, 0.2681118315690577, 0.2758227901462543, 0.1936238202813969, 0.2063608911359991, 0.19892439986031785, 0.19313198536165654, 0.2299066426860581, 0.20954775606616471, 0.18082246276034608, 0.20419181940466447, 0.17200418276299, 0.17872864767350494, 0.20803082171466314, 0.23721444439793848, 0.1535647385460157, 0.1774263429065499, 0.18053995154207692, 0.18495003121399123, 0.23491853431543785, 0.10795620910644388, 0.19585799110922708, 0.19853593382299506, 0.07935645265260705, 0.20217785609934869, 0.21965824940456546, 0.2475632012212836, 0.24523087987926784, 0.35106407249147564, 0.2636198279251327, 0.4208582888428829, 0.27143398802718677, 0.13558600750626115, 0.2702087713327044, 0.480791687753354, 0.08306249510694375, 0.09003962588152603, 0.0755477291096508, 0.10715347269092379, 0.12997504538211757, 0.07636892477314938, 0.0743264306732182, 0.13542899700093336, 0.09542907617683627, 0.09928472307885872, 0.2030026977991538, 0.23958307195532447, 0.2071314744963969, 0.264247117512297, 0.25395469175979546, 0.24988689304238554, 0.14873665502733835, 0.21439055847552757, 0.23297814498454805, 0.6561532404611267, 0.636100870898002, 0.4708972140725557, 0.5133621529799683, 0.5668792283373996, 0.6358775245968582, 0.5343143705984384, 0.520050294893871, 0.5299782030588369, 0.10263212025208035, 0.1142104641632764, 0.10364670140437116, 0.10664833647407301, 0.10037129976518011, 0.12295883147079145, 0.12390403458948351, 0.11821990748021616, 0.08098216086771115, 0.20425448070201013, 0.18858606658440435, 0.20983549303543048, 0.2014788105295795, 0.20910377842661276, 0.1982507469065854, 0.17559709572257942, 0.21011939630943932, 0.19638637633538958, 0.33225753097656774, 0.34723350451294566, 0.3456232939410552, 0.31256287820446227, 0.3273431375248672, 0.3445039742385233, 0.3779061881040069, 0.4034887559590694, 0.37403448382004667, 0.28939670269903606, 0.2580641244551791, 0.22830313060197105, 0.25417222876318923, 0.2597533487739314, 0.23870234292534664, 0.3098797702387276, 0.30585020425472154, 0.29721124297349255, 0.20262287212334162, 0.22361827265979184, 0.1838231675466001, 0.18397922854184534, 0.21179579917578262, 0.19818115591926222, 0.22645183142302572, 0.19568815153238261, 0.21877286670205232, 0.21950635429981125, 0.22339162985949212, 0.1843779066183795, 0.3411468062421764, 0.20852556298396874, 0.17393846618169861, 0.23937061960435846, 0.1919353472056331, 0.18047085163878074, 0.20588490823388716, 0.1811290844597674, 0.805528575362443, 0.17521440273639077, 0.6957331032723452, 0.6723087586961611, 0.198302162567226, 0.6526442198096826, 0.7560786090557581, 0.20331999919789245, 0.20917020354169613, 0.7299920523013037, 0.497715604079912, 0.6368120741025609, 0.737474448852891, 0.15344176646263386, 0.7242300415106782, 0.10756521514443684, 0.18585062677099518, 0.18412590878468926, 0.17489903349546543, 0.1836719884049668, 0.1807510753095941, 0.18385510530467464, 0.19057070129569142, 0.1806598624575938, 0.17833827575463002, 0.07260106556412116, 0.08229887852451956, 0.07459068537939129, 0.07213395133250633, 0.09264582148432088, 0.0914207924565168, 0.0775215499275449, 0.0744000414307755, 0.0797541876716179]}, "mutation_prompt": null}
{"id": "3062742b-e629-4774-b241-1c4929eddc9f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance local search efficacy by dynamically adjusting perturbation range based on current diversity.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.7109907146435755, 0.7491827025033557, 0.7536247985245653, 0.7613471294740257, 0.770450987136383, 0.7713968523131269, 0.7399818922134859, 0.7160643092220165, 0.7689999495101987, 0.49827369016192347, 0.46418720044596007, 0.24338868353165788, 0.49421937483230194, 0.5176091833543226, 0.5122178804891997, 0.40442925220937354, 0.4743813883298771, 0.47038839077976635, 0.09730796888742099, 0.11868218213987924, 0.1299201618987823, 0.09826485914827976, 0.1134033431189635, 0.10171572936963036, 0.11488239426450964, 0.12982740548873462, 0.12966128201834493, 0.08764723145335052, 0.08796328789291985, 0.08753550710643665, 0.09042753481148935, 0.09714223948294698, 0.10222214276981723, 0.09020888772480706, 0.09346617992900441, 0.09953399029422183, 0.9473287825984831, 0.8416245695090718, 0.894032675502264, 0.8714361365044148, 0.8956423276465709, 0.8885469028271118, 0.8613101653212107, 0.8728393404064587, 0.865883883132017, 0.3149273204720655, 0.3959204776481836, 0.42043250644517527, 0.33737730208942474, 0.4739753674737547, 0.42016434439934824, 0.35627746821559547, 0.36292407489361933, 0.3500743216439848, 0.672668127937555, 0.696855350977736, 0.7000812091843864, 0.660688350162701, 0.6541804787597694, 0.7536334144590695, 0.6612143352282878, 0.6063585815738578, 0.7172517479004048, 0.16944384574418747, 0.2681118315690577, 0.2758227901462543, 0.1936238202813969, 0.2063608911359991, 0.19892439986031785, 0.19313198536165654, 0.2299066426860581, 0.20954775606616471, 0.18082246276034608, 0.20419181940466447, 0.17200418276299, 0.17872864767350494, 0.20803082171466314, 0.23721444439793848, 0.1535647385460157, 0.1774263429065499, 0.18053995154207692, 0.18495003121399123, 0.23491853431543785, 0.10795620910644388, 0.19585799110922708, 0.19853593382299506, 0.07935645265260705, 0.20217785609934869, 0.21965824940456546, 0.2475632012212836, 0.24523087987926784, 0.35106407249147564, 0.2636198279251327, 0.4208582888428829, 0.27143398802718677, 0.13558600750626115, 0.2702087713327044, 0.480791687753354, 0.08306249510694375, 0.09003962588152603, 0.0755477291096508, 0.10715347269092379, 0.12997504538211757, 0.07636892477314938, 0.0743264306732182, 0.13542899700093336, 0.09542907617683627, 0.09928472307885872, 0.2030026977991538, 0.23958307195532447, 0.2071314744963969, 0.264247117512297, 0.25395469175979546, 0.24988689304238554, 0.14873665502733835, 0.21439055847552757, 0.23297814498454805, 0.6561532404611267, 0.636100870898002, 0.4708972140725557, 0.5133621529799683, 0.5668792283373996, 0.6358775245968582, 0.5343143705984384, 0.520050294893871, 0.5299782030588369, 0.10263212025208035, 0.1142104641632764, 0.10364670140437116, 0.10664833647407301, 0.10037129976518011, 0.12295883147079145, 0.12390403458948351, 0.11821990748021616, 0.08098216086771115, 0.20425448070201013, 0.18858606658440435, 0.20983549303543048, 0.2014788105295795, 0.20910377842661276, 0.1982507469065854, 0.17559709572257942, 0.21011939630943932, 0.19638637633538958, 0.33225753097656774, 0.34723350451294566, 0.3456232939410552, 0.31256287820446227, 0.3273431375248672, 0.3445039742385233, 0.3779061881040069, 0.4034887559590694, 0.37403448382004667, 0.28939670269903606, 0.2580641244551791, 0.22830313060197105, 0.25417222876318923, 0.2597533487739314, 0.23870234292534664, 0.3098797702387276, 0.30585020425472154, 0.29721124297349255, 0.20262287212334162, 0.22361827265979184, 0.1838231675466001, 0.18397922854184534, 0.21179579917578262, 0.19818115591926222, 0.22645183142302572, 0.19568815153238261, 0.21877286670205232, 0.21950635429981125, 0.22339162985949212, 0.1843779066183795, 0.3411468062421764, 0.20852556298396874, 0.17393846618169861, 0.23937061960435846, 0.1919353472056331, 0.18047085163878074, 0.20588490823388716, 0.1811290844597674, 0.805528575362443, 0.17521440273639077, 0.6957331032723452, 0.6723087586961611, 0.198302162567226, 0.6526442198096826, 0.7560786090557581, 0.20331999919789245, 0.20917020354169613, 0.7299920523013037, 0.497715604079912, 0.6368120741025609, 0.737474448852891, 0.15344176646263386, 0.7242300415106782, 0.10756521514443684, 0.18585062677099518, 0.18412590878468926, 0.17489903349546543, 0.1836719884049668, 0.1807510753095941, 0.18385510530467464, 0.19057070129569142, 0.1806598624575938, 0.17833827575463002, 0.07260106556412116, 0.08229887852451956, 0.07459068537939129, 0.07213395133250633, 0.09264582148432088, 0.0914207924565168, 0.0775215499275449, 0.0744000414307755, 0.0797541876716179]}, "mutation_prompt": null}
{"id": "a7895794-258e-459b-98ff-a3416a5690bd", "solution": "import numpy as np\n\nclass EnhancedHybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9\n        self.f = 0.8\n        self.local_search_iter = 5\n        self.adaptive_mut = True  # New line for adaptive mutation\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.3 * diversity * (self.evaluations / self.budget)  # Changed weight to 0.3\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.1 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Changed factor to 0.1\n            for _ in range(self.local_search_iter + 2):  # Increased local search iterations\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "EnhancedHybridMetaheuristic", "description": "Integrate adaptive mutation strategies and enhanced local exploitation to optimize search efficiency across varying landscapes.", "configspace": "", "generation": 39, "fitness": 0.29200074682014865, "feedback": "The algorithm EnhancedHybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.29 with standard deviation 0.21.", "error": "", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.6954147915972679, 0.6991020197799862, 0.6904412051121929, 0.7203457962546658, 0.7181508729492683, 0.7154121336105705, 0.6933336648711399, 0.7134633670606338, 0.6866936109940485, 0.1353365670386656, 0.4934350391537501, 0.3809802576441813, 0.4398385056965908, 0.42119665411200446, 0.44323508932633926, 0.3866850239155132, 0.37646463155877263, 0.3910832248488135, 0.08736162250556623, 0.12657764375511782, 0.11877086224878453, 0.11624664160034459, 0.10053201036125792, 0.14029006892542728, 0.09217762202608992, 0.09425346984544991, 0.11500656913436047, 0.08445357217748628, 0.09914316594885009, 0.09052257544687259, 0.10006121432533277, 0.12399660079322261, 0.08908646077437421, 0.09116898668443629, 0.07423712978830355, 0.1168235292265214, 0.7417852756637098, 0.6644103328872331, 0.8047234737855964, 0.8288366982239681, 0.8357629019537263, 0.803651795574592, 0.7903025177848223, 0.8359189359720866, 0.9149989732861019, 0.34356327493628924, 0.3558596663806427, 0.3255089043048791, 0.34279169526914366, 0.3523377913732316, 0.32386148440993634, 0.34502032750908873, 0.302805479320025, 0.3552512161938871, 0.5178353793541006, 0.6329118071525186, 0.5296849533514447, 0.6117118389822442, 0.6708993590991951, 0.6557425376164475, 0.15663144991027367, 0.6102587337978206, 0.44884515176531536, 0.12273641239204003, 0.1894505863227941, 0.33430448995069606, 0.21948092184260437, 0.1351163533713079, 0.30625930171399374, 0.315163839066922, 0.17141266998286597, 0.2426472398674666, 0.19539157878170443, 0.1835581556645568, 0.27138433752452873, 0.19432986753441006, 0.1995993768193396, 0.22532109960624958, 0.17868834814400725, 0.11505578557216067, 0.29148267094959857, 0.24751543250095187, 0.19830794800660145, 0.18196952851663906, 0.2501630294991646, 0.19870384471393499, 0.016955953108604982, 0.07877852026526011, 0.19285525637558043, 0.17308971285263264, 0.31497978955125683, 0.2847012349279828, 0.3352535219863112, 0.2185872914023992, 0.19066444120750137, 0.33453283695832525, 0.09543102524198532, 0.11381971737658791, 0.3401473690873309, 0.07393070082608488, 0.0699439637249647, 0.03708293077619984, 0.10366903570573982, 0.0507801484410596, 0.16276776781201463, 0.13407768756172278, 0.10277324383460895, 0.04354916034327927, 0.181343254421939, 0.22132498060102668, 0.17301099521728192, 0.20664177652134286, 0.24316904704899966, 0.23332897307868794, 0.19001212706462345, 0.15700325676395654, 0.22174660121285272, 0.5270847368307476, 0.4907850103785316, 0.560858940145878, 0.5181223698137291, 0.5810402687407881, 0.5279418236522673, 0.5237089140117662, 0.4956944093529905, 0.49603089606730055, 0.10152617375496553, 0.11346947306571187, 0.11114442899746735, 0.11336760606063256, 0.08955868430219993, 0.09220563365158796, 0.1172732729578374, 0.11725079667069316, 0.10520242766721699, 0.2614766856219273, 0.20541435078808346, 0.22810499755454605, 0.24622645010541133, 0.21987614127774813, 0.21486310472428571, 0.21983596674557293, 0.23806562795915964, 0.24679999441364342, 0.20973526254087138, 0.3424791719455885, 0.2817969400867115, 0.236671069888998, 0.2689361519868364, 0.2977352599435331, 0.2552076371770987, 0.31856671759901545, 0.26792450193596473, 0.1689280911634865, 0.2632568467931826, 0.2332303162446182, 0.22883056560726367, 0.14025795231635352, 0.15212071185229015, 0.2273700147719685, 0.15312115943422377, 0.2487271930731405, 0.18408442698019967, 0.22303524306790523, 0.1876157297788279, 0.1898960719323206, 0.18958245476971058, 0.1859491977697868, 0.18875995557777292, 0.2352422723159634, 0.19409067585942963, 0.19218332423894957, 0.1882820320282228, 0.19146599136651843, 0.20541522733743167, 0.2792593915849372, 0.1821926222872967, 0.20828714116754043, 0.1744974778153615, 0.20845301957553497, 0.5594765685546758, 0.17914022389866202, 0.7232169670069409, 0.19184602958295272, 0.7317686950923346, 0.5299361251448858, 0.19431393415081988, 0.7609570409359478, 0.7313969707020245, 0.1943899194087887, 0.20122178071924224, 0.6596584409234861, 0.20187394664008385, 0.6323042360401772, 0.5082770664407641, 0.1536819757001171, 0.6105539632728985, 0.2012001033669023, 0.20980547643206282, 0.20559017358133114, 0.18696997069886967, 0.17982278822707798, 0.1812997192358614, 0.19900617321733616, 0.19399688394210202, 0.18631053401283892, 0.18967716645487354, 0.07828940807302354, 0.07161510376431035, 0.07941693566995522, 0.08491197573317566, 0.0662496505735517, 0.07321149699653429, 0.07322348807664836, 0.0815527920011131, 0.07265128715899083]}, "mutation_prompt": null}
{"id": "da938d61-d3dd-4a30-8f35-26a04947faa9", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        fitness_improvement = np.mean(self.fitness) - np.min(self.fitness)  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim) * (0.5 + 0.5 * fitness_improvement)  # Line changed\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance perturbation strategy by incorporating adaptive scaling based on current fitness improvement rate.", "configspace": "", "generation": 40, "fitness": 0.28029390889658, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.28 with standard deviation 0.24.", "error": "", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.7616507098539624, 0.7657237366143939, 0.771534734591014, 0.7790352943247199, 0.7977649879107681, 0.783430787964366, 0.7597964074973605, 0.7848145045792096, 0.7970177739098878, 0.3560238806391486, 0.43483995659231256, 0.4109824047867291, 0.3844220816314641, 0.47741358873785145, 0.46373583868058166, 0.388671339915469, 0.11212325736539519, 0.3953656213153447, 0.09675652754804487, 0.11109591071863689, 0.10121921586556659, 0.08260868316904157, 0.08816487200466983, 0.08213735290167534, 0.08921732598273613, 0.0975870278911094, 0.08425482854890853, 0.0785694479074377, 0.08295253729043284, 0.06922650163124855, 0.08824588780883746, 0.07784899681723068, 0.07693795760603739, 0.06964229063290517, 0.07488028007595315, 0.07692268820341053, 0.9979466302694048, 0.9958988638207046, 0.9967212895891887, 0.9978846866155139, 0.9589581281513658, 0.9977403427451135, 0.9958302560780034, 0.9902763546651385, 0.9976765497010075, 0.4104594330284246, 0.3587542430735633, 0.4088245018781469, 0.3107619032174419, 0.37031940653517326, 0.36208262688699133, 0.33284511369370207, 0.37943568249064197, 0.3974426307825163, 0.21111328087148817, 0.6430690829982337, 0.6627266249160013, 0.7218758492785281, 0.7345582984821509, 0.7346079325115464, 0.592539069927944, 0.6189759948625679, 0.6502474167714863, 0.16389365914990028, 0.26112260110216534, 0.2018001428104943, 0.16336584137072985, 0.15865912974804908, 0.08853735900370396, 0.17134428928996714, 0.24601551395630183, 0.1817889297987626, 0.15160281634582318, 0.20205137974480591, 0.15879527807869886, 0.14812445902975124, 0.2474187879852121, 0.15955973616596453, 0.14679179155408673, 0.1506279840767416, 0.17387799096767464, 9.999999999998899e-05, 0.07412850147225836, 0.004274717210799306, 0.1068300950560983, 0.09734342181346534, 0.031065492131038486, 0.14250124235940553, 0.042747223656090294, 0.06645937531959056, 0.1798776739026644, 0.11115979157297695, 0.32744813766018444, 0.1031967188797438, 0.06649511696624755, 0.1475723715601298, 0.19810206549467047, 0.07548714074125096, 0.12515464291175105, 0.029047183628945428, 0.02359184259467506, 0.028966702890253715, 0.07698544063139756, 0.10779026656981228, 0.05480577304213807, 0.0681397395643959, 0.08272500381647219, 0.0841527590742901, 0.1877340524187272, 0.16421286245459177, 0.21411940760171977, 0.22909511434560492, 0.22919209629126824, 0.10391429658670004, 0.127394498692456, 0.050977189451265614, 0.07724839847652853, 0.5720714909579436, 0.5586743059578174, 0.5723168425457033, 0.6252486146379923, 0.5754546030989847, 0.529504172423712, 0.5438405293022147, 0.544830703309306, 0.5863968816076386, 0.08537984560994338, 0.08554554576823026, 0.09153426653474395, 0.08321337338672641, 0.08162659553170726, 0.0706968631479753, 0.08547643571622521, 0.078072105665148, 0.08981904915105388, 0.21083402866320133, 0.2359303432787001, 0.20338265428718882, 0.147414529191914, 0.17355634045336032, 0.19941602765923883, 0.15694297707859517, 0.15977580527873492, 0.16687624989742367, 0.38110079093922444, 0.3738187990243875, 0.3912484107693669, 0.32840003131742523, 0.40391279511522804, 0.37379351645741, 0.3735233481253747, 0.34875734244493084, 0.3839229476060243, 0.253562682868957, 0.24022753632955252, 0.25968982644976035, 0.23745375524494305, 0.2547812325587724, 0.22317960405064774, 0.293922321155322, 0.27903286896723667, 0.2842097631621786, 0.21317780069698455, 0.20482632618136432, 0.21709934603821313, 0.18667552176027424, 0.17542991976042954, 0.18758853832353628, 0.2067790179372253, 0.18716770794844928, 0.20857014368229532, 0.1812707230975471, 0.18730759899650984, 0.18192101334312993, 0.20813569822745115, 0.17564645809562973, 0.17376376562050244, 0.1651226453395308, 0.19124975383661702, 0.19937137617057532, 0.16149773363260134, 0.18911588416581815, 0.1890820983989886, 0.17685285359855574, 0.19960832242875748, 0.17749061545633105, 0.18161476659907483, 0.6769517288858281, 0.1749190885547205, 0.4057059166672915, 0.1898810981044421, 0.28798257117497084, 0.4405985561038762, 0.3936431698856202, 0.32235347804722303, 0.20427568911184213, 0.20542251500518327, 0.20098904059841316, 0.1990880105734909, 0.18670070712966036, 0.17905083552431333, 0.1750392701310548, 0.19266750300536828, 0.1959176987786545, 0.17478290053747791, 0.20648577411059543, 0.19070679523299527, 0.06897532227311276, 0.06600543730657538, 0.0706283430821244, 0.06639103519742673, 0.062355603792327186, 0.06932693480234742, 0.07311315915460836, 0.07389489445680264, 0.06729538199409157]}, "mutation_prompt": null}
{"id": "dadb26ec-07ec-4459-ac4d-ee0fdd325e8b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget) * (1 - np.min(self.fitness) / self.fitness[i])\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Adjust mutation strategy by integrating adaptive differential weight based on convergence rate.", "configspace": "", "generation": 41, "fitness": 0.31851990430454, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.23.", "error": "", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.5821911748339117, 0.7437804893739695, 0.7531674546750499, 0.7548176409809334, 0.761267897413632, 0.7164784555856576, 0.7638415692000557, 0.7232662652965018, 0.7398175666537055, 0.43653733896036917, 0.47585626821103544, 0.05468586184414159, 0.4794981047188458, 0.5149627971387987, 0.46059287003005245, 0.4703379059605052, 0.5154305845325358, 9.999999999998899e-05, 0.120225484916618, 0.1016612110480215, 0.1178049666882669, 0.12485060651480473, 0.1716842129425291, 0.14840507924633983, 0.11674691959580219, 0.11380631377185035, 0.10035603204701715, 0.10469477825887608, 0.10849434044940776, 0.09854747717674817, 0.07210170081846268, 0.08513105524015141, 0.11740959843173171, 0.09161542861520244, 0.08498266744852101, 0.10795032579801722, 0.9470471337356334, 0.8087755425904443, 0.8922545653286794, 0.8768173874726103, 0.9022949236211302, 0.9017280499487335, 0.865861725363825, 0.8626957054513471, 0.8851812049010739, 0.4201961019851219, 0.338282538169709, 0.40765526717298495, 0.46475437342739057, 0.4513168547031935, 0.33992063201288514, 0.32269090957953084, 0.34166674745217296, 0.47767863914152475, 0.6395525177472554, 0.7258751006546866, 0.7494177274094801, 0.684628936513215, 0.6888522258762848, 0.6999303997189443, 0.6495895602105356, 0.6879335593091945, 0.6983266476708866, 0.14592577091912606, 0.20017256539847472, 0.4768042436443932, 0.18101289000179488, 0.39924647715563255, 0.19337430734172156, 0.23100370780945056, 0.17715484919943847, 0.21687158118927907, 0.18618830742780124, 0.1748583856061121, 0.18673627263417736, 0.19005186253628104, 0.18664763285500718, 0.23566343571040071, 0.13530056193843465, 0.1744220562753015, 0.19793073658192184, 0.1895134129264613, 0.1751557697076188, 0.2525446033043006, 0.259513639824243, 0.12413263587139223, 0.06145942792774328, 0.1841956113847697, 0.03162666352130927, 0.23226427500818048, 0.25588990833295233, 0.27104923959029936, 0.407574877447233, 0.27095769331192565, 0.08869987205267138, 0.23545146130568295, 0.27362010557543137, 0.25652599859278047, 0.36168836150961037, 0.11361366372491577, 0.1103754841147544, 0.14932793612217787, 0.08367201185389572, 0.12091901682973238, 0.05804274276634935, 0.07119399757133305, 0.1843519918486035, 0.07336268456158468, 0.2671022784702063, 0.19156413338106748, 0.24949869430686122, 0.23673637304105433, 0.26468157268645387, 0.16870714765299122, 0.0840627524816926, 0.22886497668953987, 0.23140735585969274, 0.5590970012330121, 0.5459072165821575, 0.5502761313195756, 0.6201216065631612, 0.5780312495803523, 0.5836785613158076, 0.5812945643408467, 0.5897153771758309, 0.5581236791204234, 0.08349138844835602, 0.0992020494991881, 0.0923744790802351, 0.10346398037744586, 0.09197126506445552, 0.10817156834798602, 0.09019733512926409, 0.112073095659466, 0.11348431871667108, 0.21003476633772555, 0.2527192034922239, 0.1990362940400623, 0.23005732383311084, 0.20008267739130636, 0.2215010503112691, 0.183931094038715, 0.2082580174468046, 0.23139508851533286, 0.3305593142902923, 0.3702173189887501, 0.3486149654683831, 0.36942025637340814, 0.3633117039860123, 0.3819360103688516, 0.3654635661493879, 0.39604884150938124, 0.3679465669763152, 0.2514096501043531, 0.3268521561348091, 0.21129738024521327, 0.27781219981987415, 0.25618650298307744, 0.24924284548726527, 0.3000331013246985, 0.30196009815539127, 0.28464179161337055, 0.18206112749913517, 0.19454184749943815, 0.20156233592058903, 0.1944845479321703, 0.20391344680569334, 0.2087440812374246, 0.20005108775832814, 0.1743211605080467, 0.184499605531114, 0.20003133423180264, 0.3158150085563427, 0.1895176500035528, 0.29315076990938016, 0.25477926520864624, 0.18532118401936182, 0.20623181968623883, 0.2014457107374099, 0.18548729815365372, 0.2053122157613242, 0.18127686621915629, 0.800391583312116, 0.17592705464878222, 0.47434493518405696, 0.6919863973652499, 0.13105120615071042, 0.62259623030646, 0.777701012582052, 0.20155665089636987, 0.7428108082115485, 0.7009828877057842, 0.4951097079452408, 0.7073145095722164, 0.6989773739912866, 0.16357547675978334, 0.1606889793914219, 0.5823309550744571, 0.17305284667562904, 0.18803189264060638, 0.17792862206563953, 0.1756289319010177, 0.19436338033664646, 0.20089640882397175, 0.184091730942486, 0.18223952752673045, 0.1771396939126063, 0.08626022515606946, 0.0741768515913136, 0.07804661776218291, 0.08447552604823982, 0.0813813306636566, 0.08391110770837062, 0.08375997062229235, 0.08397558595659771, 0.077662857261806]}, "mutation_prompt": null}
{"id": "efc50d0d-f3f8-417c-b272-439c34f3701c", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)\n            self.local_search_iter = max(1, int(5 * (1 + diversity)))  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive local search iterations to balance exploration and exploitation throughout the budget.", "configspace": "", "generation": 42, "fitness": 0.2545231307269552, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.20.", "error": "", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.6658946387743834, 0.6881324570761833, 0.6907241695440128, 0.7252385430308759, 0.6907962611415728, 0.7178744728631572, 0.6939650238695059, 0.6984408570549085, 0.6382407820743525, 0.3736074287099026, 0.3675649633727124, 0.31323846831990876, 0.3802054921115098, 0.29143995961600044, 0.43366716780425496, 0.3925549155626604, 0.28591144467588525, 0.33645624899434645, 0.10818623888473389, 0.07518831261225334, 0.09727295424433546, 0.0758421779405235, 0.09959978828741334, 0.1028206314716068, 0.0801857478057103, 0.08628451607888199, 0.10466048066863454, 0.06243904367388109, 0.08283658258688742, 0.0772599914295371, 0.07060924482655428, 0.09619631073258716, 0.07312475048588096, 0.07115411625556045, 0.0745513822775753, 0.0875544398110849, 0.7570804360405531, 0.7301885938802051, 0.6931875208783556, 0.7842609859474434, 0.8625948966578721, 0.7774630704535785, 0.8071295003643368, 0.7969597964580092, 0.8610344242239305, 0.30141006197506937, 0.30744364790732415, 0.3127286600287371, 0.34609097947477796, 0.29203766392670716, 0.30441901912329794, 0.23917320971966938, 0.28212623537782, 0.2901219819007612, 0.43566914426181025, 0.5896046605501888, 0.5628059448773435, 0.5790121985618415, 0.633887751110715, 0.5572547674740664, 0.6287306937354911, 0.5430039093617387, 0.46223962240588334, 0.1884998978411806, 0.1971146183769822, 0.21444112730705522, 0.1611616511242866, 0.16912498726404068, 0.2327042571520801, 0.16793925055348513, 0.1582256913033252, 0.1731182080870165, 0.15661681866874222, 0.17353581494228731, 0.15129038928752958, 0.1513566326174508, 0.36078794483554044, 0.15840905795063442, 0.21946951896700861, 0.20497795751187964, 0.15924021087039486, 0.05857574278214639, 0.11594257813412912, 0.047989027359439884, 0.006385046727378163, 0.05242121411466416, 0.01563924949299178, 0.008025216448138917, 0.03073507503347428, 0.08741018385598076, 0.10990634974012647, 0.11774028201988063, 0.14675940049064462, 0.1462867138480617, 0.1315982565117041, 0.08613971017902144, 0.15731751244821135, 0.15152681758286524, 0.1054224121521089, 0.03598331461851578, 0.0694925139450463, 0.08498370335406857, 0.07381994692048377, 0.05433971282039274, 0.08519981652509612, 0.05472266304788609, 0.08382476804606653, 0.12428023901611396, 0.18804637768124166, 0.21954946901089956, 0.2003198564623565, 0.20235874222927364, 0.19474578788045682, 0.19313673557572852, 0.1822009715625239, 0.16911835529151908, 0.20530109370230043, 0.5496927142401073, 0.5275645869295269, 0.5631163352922828, 0.45290361189286454, 0.4842371103748533, 0.5026878188255686, 0.49072366437912196, 0.516923513553283, 0.5627297501747327, 0.08211765158702289, 0.08937912607125731, 0.09051567198120758, 0.0855486968948106, 0.07597804394930008, 0.08984021916441143, 0.08582314510817013, 0.08420281963451326, 0.10991733680987781, 0.18565982898274247, 0.21077917601194063, 0.1997134096438341, 0.1934039849876954, 0.19560467533468906, 0.2119044890216547, 0.19446623419832265, 0.18646301179752423, 0.19264823964883604, 0.20018482383106306, 0.21821031299725469, 0.23255574109422228, 0.21312735960403462, 0.2625649089980372, 0.20726955199061903, 0.20877228544018067, 0.2906524019716663, 0.23014341216642065, 0.1015721379840665, 0.16713520958346528, 0.14395643822287874, 0.1437777401103485, 0.17198956533886944, 0.17946642030131066, 0.20174773773990484, 0.20126504561020486, 0.19110161339992382, 0.16804864283977183, 0.1894319194046331, 0.18160027650290578, 0.18703321182730137, 0.16572130628808823, 0.19066001859078752, 0.15937901404393906, 0.19758900486844944, 0.2092939590341697, 0.18381110729618444, 0.1738440170910226, 0.17528612383164344, 0.1881022768038011, 0.21029756920638953, 0.16266508117595535, 0.22165545020466992, 0.18017333189689455, 0.18759947312022007, 0.19269711910629084, 0.16995960573228241, 0.5149801559325868, 0.18668954065965604, 0.47493789151201304, 0.19340886116922051, 0.16107411122740267, 0.5534316368966781, 0.44726010215507617, 0.18976622664341936, 0.45827417291197226, 0.35471228393331156, 0.42859523764129914, 0.40629478673518327, 0.2225502370212007, 0.17056521145844494, 0.15331147647937793, 0.18749124054321586, 0.18371417031328796, 0.1890090039302842, 0.19245593471159206, 0.19880028103480285, 0.1961724840124538, 0.19744749597734101, 0.18417958694862324, 0.1894336055032867, 0.1881106710776551, 0.0661720534552378, 0.06991252021723471, 0.06870232012527688, 0.06984717753125536, 0.07511128160855696, 0.08343588398813029, 0.06661563095474099, 0.07282751247219987, 0.06418109588112197]}, "mutation_prompt": null}
{"id": "1fea08db-ff3d-4af9-ae70-8499834ee970", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance local search efficacy by dynamically adjusting perturbation range based on current diversity.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.7109907146435755, 0.7491827025033557, 0.7536247985245653, 0.7613471294740257, 0.770450987136383, 0.7713968523131269, 0.7399818922134859, 0.7160643092220165, 0.7689999495101987, 0.49827369016192347, 0.46418720044596007, 0.24338868353165788, 0.49421937483230194, 0.5176091833543226, 0.5122178804891997, 0.40442925220937354, 0.4743813883298771, 0.47038839077976635, 0.09730796888742099, 0.11868218213987924, 0.1299201618987823, 0.09826485914827976, 0.1134033431189635, 0.10171572936963036, 0.11488239426450964, 0.12982740548873462, 0.12966128201834493, 0.08764723145335052, 0.08796328789291985, 0.08753550710643665, 0.09042753481148935, 0.09714223948294698, 0.10222214276981723, 0.09020888772480706, 0.09346617992900441, 0.09953399029422183, 0.9473287825984831, 0.8416245695090718, 0.894032675502264, 0.8714361365044148, 0.8956423276465709, 0.8885469028271118, 0.8613101653212107, 0.8728393404064587, 0.865883883132017, 0.3149273204720655, 0.3959204776481836, 0.42043250644517527, 0.33737730208942474, 0.4739753674737547, 0.42016434439934824, 0.35627746821559547, 0.36292407489361933, 0.3500743216439848, 0.672668127937555, 0.696855350977736, 0.7000812091843864, 0.660688350162701, 0.6541804787597694, 0.7536334144590695, 0.6612143352282878, 0.6063585815738578, 0.7172517479004048, 0.16944384574418747, 0.2681118315690577, 0.2758227901462543, 0.1936238202813969, 0.2063608911359991, 0.19892439986031785, 0.19313198536165654, 0.2299066426860581, 0.20954775606616471, 0.18082246276034608, 0.20419181940466447, 0.17200418276299, 0.17872864767350494, 0.20803082171466314, 0.23721444439793848, 0.1535647385460157, 0.1774263429065499, 0.18053995154207692, 0.18495003121399123, 0.23491853431543785, 0.10795620910644388, 0.19585799110922708, 0.19853593382299506, 0.07935645265260705, 0.20217785609934869, 0.21965824940456546, 0.2475632012212836, 0.24523087987926784, 0.35106407249147564, 0.2636198279251327, 0.4208582888428829, 0.27143398802718677, 0.13558600750626115, 0.2702087713327044, 0.480791687753354, 0.08306249510694375, 0.09003962588152603, 0.0755477291096508, 0.10715347269092379, 0.12997504538211757, 0.07636892477314938, 0.0743264306732182, 0.13542899700093336, 0.09542907617683627, 0.09928472307885872, 0.2030026977991538, 0.23958307195532447, 0.2071314744963969, 0.264247117512297, 0.25395469175979546, 0.24988689304238554, 0.14873665502733835, 0.21439055847552757, 0.23297814498454805, 0.6561532404611267, 0.636100870898002, 0.4708972140725557, 0.5133621529799683, 0.5668792283373996, 0.6358775245968582, 0.5343143705984384, 0.520050294893871, 0.5299782030588369, 0.10263212025208035, 0.1142104641632764, 0.10364670140437116, 0.10664833647407301, 0.10037129976518011, 0.12295883147079145, 0.12390403458948351, 0.11821990748021616, 0.08098216086771115, 0.20425448070201013, 0.18858606658440435, 0.20983549303543048, 0.2014788105295795, 0.20910377842661276, 0.1982507469065854, 0.17559709572257942, 0.21011939630943932, 0.19638637633538958, 0.33225753097656774, 0.34723350451294566, 0.3456232939410552, 0.31256287820446227, 0.3273431375248672, 0.3445039742385233, 0.3779061881040069, 0.4034887559590694, 0.37403448382004667, 0.28939670269903606, 0.2580641244551791, 0.22830313060197105, 0.25417222876318923, 0.2597533487739314, 0.23870234292534664, 0.3098797702387276, 0.30585020425472154, 0.29721124297349255, 0.20262287212334162, 0.22361827265979184, 0.1838231675466001, 0.18397922854184534, 0.21179579917578262, 0.19818115591926222, 0.22645183142302572, 0.19568815153238261, 0.21877286670205232, 0.21950635429981125, 0.22339162985949212, 0.1843779066183795, 0.3411468062421764, 0.20852556298396874, 0.17393846618169861, 0.23937061960435846, 0.1919353472056331, 0.18047085163878074, 0.20588490823388716, 0.1811290844597674, 0.805528575362443, 0.17521440273639077, 0.6957331032723452, 0.6723087586961611, 0.198302162567226, 0.6526442198096826, 0.7560786090557581, 0.20331999919789245, 0.20917020354169613, 0.7299920523013037, 0.497715604079912, 0.6368120741025609, 0.737474448852891, 0.15344176646263386, 0.7242300415106782, 0.10756521514443684, 0.18585062677099518, 0.18412590878468926, 0.17489903349546543, 0.1836719884049668, 0.1807510753095941, 0.18385510530467464, 0.19057070129569142, 0.1806598624575938, 0.17833827575463002, 0.07260106556412116, 0.08229887852451956, 0.07459068537939129, 0.07213395133250633, 0.09264582148432088, 0.0914207924565168, 0.0775215499275449, 0.0744000414307755, 0.0797541876716179]}, "mutation_prompt": null}
{"id": "627891ce-37c2-4f94-a6cb-c6a32d1bc40a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance local search efficacy by dynamically adjusting perturbation range based on current diversity.", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.7109907146435755, 0.7491827025033557, 0.7536247985245653, 0.7613471294740257, 0.770450987136383, 0.7713968523131269, 0.7399818922134859, 0.7160643092220165, 0.7689999495101987, 0.49827369016192347, 0.46418720044596007, 0.24338868353165788, 0.49421937483230194, 0.5176091833543226, 0.5122178804891997, 0.40442925220937354, 0.4743813883298771, 0.47038839077976635, 0.09730796888742099, 0.11868218213987924, 0.1299201618987823, 0.09826485914827976, 0.1134033431189635, 0.10171572936963036, 0.11488239426450964, 0.12982740548873462, 0.12966128201834493, 0.08764723145335052, 0.08796328789291985, 0.08753550710643665, 0.09042753481148935, 0.09714223948294698, 0.10222214276981723, 0.09020888772480706, 0.09346617992900441, 0.09953399029422183, 0.9473287825984831, 0.8416245695090718, 0.894032675502264, 0.8714361365044148, 0.8956423276465709, 0.8885469028271118, 0.8613101653212107, 0.8728393404064587, 0.865883883132017, 0.3149273204720655, 0.3959204776481836, 0.42043250644517527, 0.33737730208942474, 0.4739753674737547, 0.42016434439934824, 0.35627746821559547, 0.36292407489361933, 0.3500743216439848, 0.672668127937555, 0.696855350977736, 0.7000812091843864, 0.660688350162701, 0.6541804787597694, 0.7536334144590695, 0.6612143352282878, 0.6063585815738578, 0.7172517479004048, 0.16944384574418747, 0.2681118315690577, 0.2758227901462543, 0.1936238202813969, 0.2063608911359991, 0.19892439986031785, 0.19313198536165654, 0.2299066426860581, 0.20954775606616471, 0.18082246276034608, 0.20419181940466447, 0.17200418276299, 0.17872864767350494, 0.20803082171466314, 0.23721444439793848, 0.1535647385460157, 0.1774263429065499, 0.18053995154207692, 0.18495003121399123, 0.23491853431543785, 0.10795620910644388, 0.19585799110922708, 0.19853593382299506, 0.07935645265260705, 0.20217785609934869, 0.21965824940456546, 0.2475632012212836, 0.24523087987926784, 0.35106407249147564, 0.2636198279251327, 0.4208582888428829, 0.27143398802718677, 0.13558600750626115, 0.2702087713327044, 0.480791687753354, 0.08306249510694375, 0.09003962588152603, 0.0755477291096508, 0.10715347269092379, 0.12997504538211757, 0.07636892477314938, 0.0743264306732182, 0.13542899700093336, 0.09542907617683627, 0.09928472307885872, 0.2030026977991538, 0.23958307195532447, 0.2071314744963969, 0.264247117512297, 0.25395469175979546, 0.24988689304238554, 0.14873665502733835, 0.21439055847552757, 0.23297814498454805, 0.6561532404611267, 0.636100870898002, 0.4708972140725557, 0.5133621529799683, 0.5668792283373996, 0.6358775245968582, 0.5343143705984384, 0.520050294893871, 0.5299782030588369, 0.10263212025208035, 0.1142104641632764, 0.10364670140437116, 0.10664833647407301, 0.10037129976518011, 0.12295883147079145, 0.12390403458948351, 0.11821990748021616, 0.08098216086771115, 0.20425448070201013, 0.18858606658440435, 0.20983549303543048, 0.2014788105295795, 0.20910377842661276, 0.1982507469065854, 0.17559709572257942, 0.21011939630943932, 0.19638637633538958, 0.33225753097656774, 0.34723350451294566, 0.3456232939410552, 0.31256287820446227, 0.3273431375248672, 0.3445039742385233, 0.3779061881040069, 0.4034887559590694, 0.37403448382004667, 0.28939670269903606, 0.2580641244551791, 0.22830313060197105, 0.25417222876318923, 0.2597533487739314, 0.23870234292534664, 0.3098797702387276, 0.30585020425472154, 0.29721124297349255, 0.20262287212334162, 0.22361827265979184, 0.1838231675466001, 0.18397922854184534, 0.21179579917578262, 0.19818115591926222, 0.22645183142302572, 0.19568815153238261, 0.21877286670205232, 0.21950635429981125, 0.22339162985949212, 0.1843779066183795, 0.3411468062421764, 0.20852556298396874, 0.17393846618169861, 0.23937061960435846, 0.1919353472056331, 0.18047085163878074, 0.20588490823388716, 0.1811290844597674, 0.805528575362443, 0.17521440273639077, 0.6957331032723452, 0.6723087586961611, 0.198302162567226, 0.6526442198096826, 0.7560786090557581, 0.20331999919789245, 0.20917020354169613, 0.7299920523013037, 0.497715604079912, 0.6368120741025609, 0.737474448852891, 0.15344176646263386, 0.7242300415106782, 0.10756521514443684, 0.18585062677099518, 0.18412590878468926, 0.17489903349546543, 0.1836719884049668, 0.1807510753095941, 0.18385510530467464, 0.19057070129569142, 0.1806598624575938, 0.17833827575463002, 0.07260106556412116, 0.08229887852451956, 0.07459068537939129, 0.07213395133250633, 0.09264582148432088, 0.0914207924565168, 0.0775215499275449, 0.0744000414307755, 0.0797541876716179]}, "mutation_prompt": null}
{"id": "64164990-c978-40c1-8225-ed8e1684d86e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            # Introduce decay factor in perturbation range adjustment\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity * (self.evaluations / self.budget))\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce a decay factor in perturbation range adjustment to enhance local exploitation as evaluations increase.", "configspace": "", "generation": 45, "fitness": 0.297295061075442, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.22.", "error": "", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.7298082524257177, 0.7524765150434882, 0.7380769135767484, 0.7341112004119457, 0.7051882846285957, 0.7407811424546773, 0.7489235688269915, 0.7385216017915096, 0.7422978896160732, 0.5011919764819296, 0.5074491048574874, 0.398067131268526, 0.4787088973716277, 0.4580344606117598, 0.42846131470030346, 0.5064028058411536, 0.4647932381138047, 0.4746313124246976, 0.13030479173977305, 0.18662147736044177, 0.1184694751980736, 0.10290318706949764, 0.09639008747343525, 0.10656879506631467, 0.11549853062807691, 0.13529216839296698, 0.12863261492111255, 0.08455911202302746, 0.11506833498606162, 0.08153077621075266, 0.0785521342886294, 0.08492844869921079, 0.09542365650293849, 0.08298511287201893, 0.09713726730717931, 0.09348357225918313, 0.8875857345241582, 0.8379791232398883, 0.14930676862297476, 0.8655195009010956, 0.6751467130883981, 0.875984869922311, 0.8884538920975731, 0.9045530925601242, 0.8472167783947507, 0.3305393220818058, 0.3789877700980797, 0.3606803918007818, 0.3217904206590785, 0.37468090212226324, 0.3136677572874753, 0.33903531439452483, 0.37937444733083925, 0.32825718907856694, 0.6685000278987852, 0.6755050912277121, 0.6681639630216067, 0.19359805539036057, 0.657099591133822, 0.18566751609813192, 0.7360887319770653, 0.6392084103345924, 0.670436578656441, 0.11784133057311796, 0.18867397375447936, 0.23639818276089508, 0.17497097674853634, 0.20174149827722299, 0.2161930521537413, 0.24903557155431943, 0.17716189650291814, 0.1880626412446994, 0.15174266515955004, 0.18529903777212775, 0.35545334569021714, 0.16256588966611996, 0.18707231837238458, 0.1757135520356331, 0.0891221211250871, 0.19373584912067698, 0.17702418024904965, 0.16115774673059313, 0.32249230905540593, 0.13248022677451676, 0.1614949561865736, 0.16964709110415055, 0.030334427063100744, 0.24443722014011238, 0.10576868765124325, 0.20430490565815096, 0.29496471493197385, 0.34081642795088507, 0.3849040866855016, 0.2892399296540217, 0.23668392334800614, 0.11030085231748854, 0.07802292021745583, 0.3292686857438897, 0.3635436122646334, 0.06427949293157564, 0.1171926134566309, 0.04333505843084473, 0.12161341820540306, 0.09314959708337267, 0.17534862132844353, 0.08598967288235049, 0.08480176394481109, 0.12206729022501528, 0.22447427127706654, 0.24711492964947712, 0.18330715862764058, 0.23770830599541792, 0.1396794791371978, 0.23292122274274674, 0.08794917287787196, 0.23323012616157446, 0.20538649440814694, 0.507587580405133, 0.5212027224298718, 0.6240501871458517, 0.6023104634495442, 0.5886655618326608, 0.47209665944360935, 0.46936997502991185, 0.5308856897270591, 0.5020697369009373, 0.11426872411759037, 0.11678354896299081, 0.12536887516726059, 0.09260107900506531, 0.11886011875776326, 0.11543151124602713, 0.08892106731742877, 0.10842377243151713, 0.11708765070868599, 0.21388100317439296, 0.17931782265945806, 0.19091882330907806, 0.3020454777778495, 0.20006548698801685, 0.21566780796292162, 0.22291556855342964, 0.190211513407875, 0.17254582533462814, 0.3293663342241222, 0.30835613269195383, 0.3116817168595295, 0.38894678081279077, 0.26034393015594337, 0.3239083071360467, 0.3325057458351687, 0.33013065611156833, 0.34109779248960104, 0.22862044922958746, 0.1806873785053269, 0.1971291707910635, 0.20166627063771758, 0.22930576415366333, 0.22976741498452447, 0.2991408110524808, 0.19831012874215637, 0.23144988370569386, 0.21043108460180038, 0.1851111869292501, 0.19693760817294503, 0.19281039925932586, 0.20421129266969984, 0.18167846870710802, 0.17674459735473813, 0.20099359997073862, 0.2084160832666252, 0.19276261886465196, 0.2714619670659941, 0.18603302679267364, 0.2881447423967688, 0.1939075409231511, 0.18113907715178967, 0.33896987294195746, 0.17984666234396895, 0.26844494852295675, 0.19534950050013233, 0.1807039854558523, 0.7093139206404271, 0.16713802318211424, 0.7172202711682417, 0.6535740961403622, 0.19540870814433364, 0.7123445864147192, 0.1844075585533752, 0.19633221373562537, 0.7036231997250803, 0.5958544087111378, 0.1909920114783784, 0.46804820136278513, 0.5260930538840809, 0.15955522535456912, 0.5465502796942656, 0.3412449272666941, 0.19010125956627755, 0.1859268120520554, 0.18494743821599158, 0.1837348676989209, 0.1847641639083929, 0.1776814366990529, 0.17811401620993383, 0.18163044772680625, 0.17853592611713487, 0.06054206999428857, 0.07294094939459006, 0.06744034717706204, 0.0744981737127518, 0.06423010565762632, 0.0701535099304108, 0.06670293978118902, 0.07448113624947783, 0.06901711849668968]}, "mutation_prompt": null}
{"id": "65ee22db-6af0-47e1-beb2-ea0c7352a9be", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance solution diversity by applying perturbation in the global search process.", "configspace": "", "generation": 46, "fitness": 0.32010286510029523, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.23.", "error": "", "parent_id": "4db5889b-3726-4544-9696-76e70aeebcee", "metadata": {"aucs": [0.7607967017081234, 0.7519548315545355, 0.7007003834369634, 0.7441584399988928, 0.7729798970499207, 0.765451783615243, 0.7532637211014249, 0.7407305727950579, 0.7555785807516087, 0.4800752198025262, 0.489457758643717, 0.486952022450557, 0.5037921618842655, 0.48855140155163235, 0.5053785935075861, 0.4849393647161905, 0.4688929523513261, 0.4964498157138115, 0.09762685926842218, 0.10348748794405638, 0.11664356279167643, 0.10878146769209274, 0.10721687673595737, 0.09288086627235048, 0.12081382548181863, 0.11560724766710628, 0.12558651861333747, 0.0954126704737146, 0.10010429962020428, 0.07865035496053518, 0.10331926355192123, 0.10011974176647054, 0.10115693027094153, 0.08778916660401714, 0.09075183434793266, 0.09473864039553481, 0.8436856458406987, 0.8524742325802663, 0.8303730894092345, 0.9303275109576592, 0.9199442754012144, 0.8798031098136095, 0.9577589313331976, 0.8237674660691194, 0.9010965609048908, 0.40323854245171054, 0.3493812950400186, 0.3453647221151037, 0.4134729824050617, 0.36381483774890744, 0.36684309651440206, 0.35571566654481035, 0.37806900883187256, 0.40918386403555296, 0.7485332508948819, 0.7265109858189072, 0.7084729235152172, 0.6713183428282523, 0.7221131586890583, 0.2753714952776256, 0.7003153283821015, 0.718421942426746, 0.701609642615175, 0.17887635699793258, 0.2021231929183136, 0.20122187532773916, 0.5206360346969492, 0.22314694377035005, 0.20600715493230648, 0.28572989203331145, 0.22655122156406116, 0.1752106838230003, 0.17614610441076384, 0.19609793735404557, 0.19638380805484068, 0.1980782344968155, 0.24970912159250802, 0.1994140056324929, 0.1985255518735699, 0.20669893051401, 0.2130018377127717, 0.10476128906055071, 0.27509785347802596, 0.1807064744998803, 0.1262103236438361, 0.2657380270171469, 0.06943766188023415, 0.18159577580995778, 0.15813075860501535, 0.2166248805361045, 0.28646219687304686, 0.4000523213945735, 0.37854702276147345, 0.2656247642558396, 0.20257596354244833, 0.0750880367168909, 0.2790064163217869, 0.2816075822606213, 0.318779685530554, 0.1703656927857624, 0.06765578818261653, 0.09104522662696857, 0.08326477596464033, 0.18620505523847464, 0.10433423808948805, 0.11433431502589575, 0.1759335347559562, 0.09045851556891538, 0.22159324522375645, 0.24032708972785144, 0.25397243505517764, 0.2157415555265919, 0.18987517686264255, 0.243078769607446, 0.20536761929496883, 0.18460030897300417, 0.19140316095224175, 0.5528035915600908, 0.6413768328463679, 0.5721042481389762, 0.5988513597660479, 0.5341514075916016, 0.5662033494169015, 0.5825212887200591, 0.5256953897987886, 0.6504431832598583, 0.10698451237877615, 0.09693261198063596, 0.09348492403861597, 0.09504745783053492, 0.0813818636926621, 0.08444138392917044, 0.09716589029225309, 0.11711303316415234, 0.1114240481160621, 0.19693244823294953, 0.1786687723545316, 0.19937711130934466, 0.18946668528621358, 0.23021156552362054, 0.18495286151232526, 0.1965263399726317, 0.20461538988127614, 0.20310767865493895, 0.33937624907561936, 0.29660414729252227, 0.37634868729801696, 0.3179255850589596, 0.30578073713372256, 0.37843639386677563, 0.3543371385334828, 0.3786696499465535, 0.3667011359111032, 0.26679300361108926, 0.2262505527861285, 0.26199916505295817, 0.2600672849779406, 0.18620664581149782, 0.26283071034222405, 0.3058948210742507, 0.30868794665401433, 0.2880330243748709, 0.19038674184159954, 0.21362245837572058, 0.2290514153355102, 0.19636973171433814, 0.1920554983431706, 0.19413977429560259, 0.18224887052948935, 0.19490500874220207, 0.23815449417247114, 0.2112333904472221, 0.19769377043992709, 0.267052528755929, 0.1900435436449538, 0.20377019621385672, 0.19118776338819654, 0.25827528724443694, 0.19979996839170244, 0.19731348640050317, 0.6790868800562377, 0.19304962959505223, 0.7571786863831931, 0.5900588263409743, 0.6123646537771106, 0.5403087781891753, 0.18432449549012886, 0.16433263566150857, 0.6704970233611031, 0.20059775820238124, 0.728758186581556, 0.6518943739823779, 0.5401372219108633, 0.6453198162170132, 0.16389933088236974, 0.20208483216933115, 0.4217734638671091, 0.20512808235701752, 0.1970753470579204, 0.18588432026935853, 0.18595592450085874, 0.2023871204690353, 0.18244308078128446, 0.21655067933106542, 0.18563587396466863, 0.19446826557702213, 0.18469727742295594, 0.0759154433966196, 0.07762434049414058, 0.07123058247654246, 0.07230727239474488, 0.08247562258113061, 0.08703454873689498, 0.07567520178896414, 0.0824248677261521, 0.07447023044901924]}, "mutation_prompt": null}
{"id": "9b886a8b-e16e-40c6-b028-de62b9204fb5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance solution diversity by applying perturbation in the global search process.", "configspace": "", "generation": 47, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "65ee22db-6af0-47e1-beb2-ea0c7352a9be", "metadata": {"aucs": [0.7607967017081234, 0.7519548315545355, 0.7007003834369634, 0.7441584399988928, 0.7729798970499207, 0.765451783615243, 0.7532637211014249, 0.7407305727950579, 0.7555785807516087, 0.4800752198025262, 0.489457758643717, 0.486952022450557, 0.5037921618842655, 0.48855140155163235, 0.5053785935075861, 0.4849393647161905, 0.4688929523513261, 0.4964498157138115, 0.09762685926842218, 0.10348748794405638, 0.11664356279167643, 0.10878146769209274, 0.10721687673595737, 0.09288086627235048, 0.12081382548181863, 0.11560724766710628, 0.12558651861333747, 0.0954126704737146, 0.10010429962020428, 0.07865035496053518, 0.10331926355192123, 0.10011974176647054, 0.10115693027094153, 0.08778916660401714, 0.09075183434793266, 0.09473864039553481, 0.8436856458406987, 0.8524742325802663, 0.8303730894092345, 0.9303275109576592, 0.9199442754012144, 0.8798031098136095, 0.9577589313331976, 0.8237674660691194, 0.9010965609048908, 0.40323854245171054, 0.3493812950400186, 0.3453647221151037, 0.4134729824050617, 0.36381483774890744, 0.36684309651440206, 0.35571566654481035, 0.37806900883187256, 0.40918386403555296, 0.7485332508948819, 0.7265109858189072, 0.7084729235152172, 0.6713183428282523, 0.7221131586890583, 0.2753714952776256, 0.7003153283821015, 0.718421942426746, 0.701609642615175, 0.17887635699793258, 0.2021231929183136, 0.20122187532773916, 0.5206360346969492, 0.22314694377035005, 0.20600715493230648, 0.28572989203331145, 0.22655122156406116, 0.1752106838230003, 0.17614610441076384, 0.19609793735404557, 0.19638380805484068, 0.1980782344968155, 0.24970912159250802, 0.1994140056324929, 0.1985255518735699, 0.20669893051401, 0.2130018377127717, 0.10476128906055071, 0.27509785347802596, 0.1807064744998803, 0.1262103236438361, 0.2657380270171469, 0.06943766188023415, 0.18159577580995778, 0.15813075860501535, 0.2166248805361045, 0.28646219687304686, 0.4000523213945735, 0.37854702276147345, 0.2656247642558396, 0.20257596354244833, 0.0750880367168909, 0.2790064163217869, 0.2816075822606213, 0.318779685530554, 0.1703656927857624, 0.06765578818261653, 0.09104522662696857, 0.08326477596464033, 0.18620505523847464, 0.10433423808948805, 0.11433431502589575, 0.1759335347559562, 0.09045851556891538, 0.22159324522375645, 0.24032708972785144, 0.25397243505517764, 0.2157415555265919, 0.18987517686264255, 0.243078769607446, 0.20536761929496883, 0.18460030897300417, 0.19140316095224175, 0.5528035915600908, 0.6413768328463679, 0.5721042481389762, 0.5988513597660479, 0.5341514075916016, 0.5662033494169015, 0.5825212887200591, 0.5256953897987886, 0.6504431832598583, 0.10698451237877615, 0.09693261198063596, 0.09348492403861597, 0.09504745783053492, 0.0813818636926621, 0.08444138392917044, 0.09716589029225309, 0.11711303316415234, 0.1114240481160621, 0.19693244823294953, 0.1786687723545316, 0.19937711130934466, 0.18946668528621358, 0.23021156552362054, 0.18495286151232526, 0.1965263399726317, 0.20461538988127614, 0.20310767865493895, 0.33937624907561936, 0.29660414729252227, 0.37634868729801696, 0.3179255850589596, 0.30578073713372256, 0.37843639386677563, 0.3543371385334828, 0.3786696499465535, 0.3667011359111032, 0.26679300361108926, 0.2262505527861285, 0.26199916505295817, 0.2600672849779406, 0.18620664581149782, 0.26283071034222405, 0.3058948210742507, 0.30868794665401433, 0.2880330243748709, 0.19038674184159954, 0.21362245837572058, 0.2290514153355102, 0.19636973171433814, 0.1920554983431706, 0.19413977429560259, 0.18224887052948935, 0.19490500874220207, 0.23815449417247114, 0.2112333904472221, 0.19769377043992709, 0.267052528755929, 0.1900435436449538, 0.20377019621385672, 0.19118776338819654, 0.25827528724443694, 0.19979996839170244, 0.19731348640050317, 0.6790868800562377, 0.19304962959505223, 0.7571786863831931, 0.5900588263409743, 0.6123646537771106, 0.5403087781891753, 0.18432449549012886, 0.16433263566150857, 0.6704970233611031, 0.20059775820238124, 0.728758186581556, 0.6518943739823779, 0.5401372219108633, 0.6453198162170132, 0.16389933088236974, 0.20208483216933115, 0.4217734638671091, 0.20512808235701752, 0.1970753470579204, 0.18588432026935853, 0.18595592450085874, 0.2023871204690353, 0.18244308078128446, 0.21655067933106542, 0.18563587396466863, 0.19446826557702213, 0.18469727742295594, 0.0759154433966196, 0.07762434049414058, 0.07123058247654246, 0.07230727239474488, 0.08247562258113061, 0.08703454873689498, 0.07567520178896414, 0.0824248677261521, 0.07447023044901924]}, "mutation_prompt": null}
{"id": "757d68c1-034a-4715-875f-42ec2905accc", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * (1 - diversity) * (self.evaluations / self.budget)  # Line changed\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Improve adaptive differential weight adjustment to enhance exploration-exploitation balance.", "configspace": "", "generation": 48, "fitness": 0.31923871542173904, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.22.", "error": "", "parent_id": "65ee22db-6af0-47e1-beb2-ea0c7352a9be", "metadata": {"aucs": [0.7153205079527815, 0.7216460816802432, 0.7137391162781916, 0.7073751316518642, 0.7174265777066489, 0.7077872465951018, 0.707528890669747, 0.6955581150563241, 0.6872688890363952, 0.3944051846833291, 0.31285469876866334, 0.3729894224259479, 0.367704484589398, 0.40500459472875705, 0.32783090553632266, 0.3930987111138553, 0.3673990429908125, 0.3954394745012928, 0.14561803646594484, 0.12408236191182442, 0.10700133494277253, 0.10065128125900924, 0.11576161256312667, 0.08569655603501847, 0.13162050036576545, 0.11956851076756869, 0.12690361048022591, 0.09739876565292127, 0.11988096783124436, 0.08771140448367154, 0.10193216739818167, 0.10145091563615238, 0.08827891036727031, 0.1063120746275763, 0.10535795870908127, 0.11023790668623146, 0.7270144333902049, 0.8682239809381985, 0.8954954993897513, 0.850736314202115, 0.9116665382553523, 0.8769321703851002, 0.957764640370033, 0.8832352654656048, 0.886650545850425, 0.3890186420947227, 0.3546778904417234, 0.35228793872641917, 0.4020437310541676, 0.3682010457861088, 0.3518948798942978, 0.36650946632062464, 0.34722971724534335, 0.3851748086540969, 0.7247102798013132, 0.6926151495304876, 0.5689090615897432, 0.6926211268216862, 0.7392405117041128, 0.3883903081014761, 0.7382328152876211, 0.5796934109022042, 0.6956967728965902, 0.2686696245941652, 0.20906195634440639, 0.25413926322241354, 0.2166283854819695, 0.2516907731895758, 0.2503226270020389, 0.1749162594501027, 0.28062226423292347, 0.24928599183113875, 0.25080417890356255, 0.2830766434939541, 0.25403491215162743, 0.30691146919609824, 0.2652614821529876, 0.31845485988677724, 0.2588593129673691, 0.30786544843598174, 0.23331786813348543, 0.2234822436247449, 0.2078942681621373, 0.21210140376962394, 0.27686493961489445, 0.1758359872396189, 0.2432376094051637, 0.23887821891249372, 0.19509352624936493, 0.21985149773763923, 0.2522105708662242, 0.36359062728299285, 0.30128127410961847, 0.3238326584022453, 0.2645277481468835, 0.1989438829672846, 0.1992474373844353, 0.22544129689842463, 0.24642247987144883, 0.09310707626155779, 0.055993042521298, 0.06237218913232956, 0.06340841104368755, 0.10784951288544309, 0.10149110025457098, 0.11399591805468645, 0.0759888357749311, 0.10372157640517576, 0.1930048251659594, 0.17619341234775587, 0.17927362734711783, 0.20981243969151686, 0.20385705165626467, 0.2117423844922185, 0.1989537630035143, 0.2059283378532344, 0.19787468339456193, 0.5836836657967153, 0.5505210918754406, 0.5829923051967101, 0.5280564807529715, 0.5308023355266498, 0.5159946559754331, 0.5353844576676582, 0.5607745170709155, 0.5100641706864408, 0.09163312890817599, 0.11105527900359813, 0.10976739439074368, 0.0985494554972689, 0.11203384414289597, 0.10768763899817513, 0.13842744384696215, 0.10943150105420829, 0.11433377293950253, 0.2557586509322638, 0.2997181174528477, 0.2168782441295074, 0.2578458793835836, 0.32239783499142294, 0.2605010283418123, 0.28814083126361223, 0.2481541679523136, 0.17286964501103053, 0.3039653694198341, 0.26356310452596965, 0.30545174580961343, 0.3297680257249356, 0.3391958234712549, 0.34994539693440874, 0.3047867172570353, 0.3233133579342591, 0.32165004940457653, 0.2549121422956945, 0.22142063221253416, 0.23635172268071014, 0.2399081933424192, 0.23594769079624722, 0.2677124760872548, 0.2630413689017068, 0.28775730403709154, 0.2594041236514979, 0.18556886445581566, 0.19573259295604462, 0.20314442690614565, 0.20660649952192234, 0.2215155644107898, 0.18619393317497668, 0.18778328093146013, 0.21077842850962247, 0.2060803647441518, 0.21025674544301987, 0.18487377036570818, 0.31261362449486596, 0.2081914964197814, 0.19236108181867295, 0.1806502493814549, 0.24869997795007603, 0.1989260205889526, 0.2456743076247031, 0.7859386945697381, 0.19462900439475828, 0.8290798607442408, 0.6516620489384249, 0.7139739008860545, 0.726132271408586, 0.18796938443398625, 0.7113353529824047, 0.6825665333971601, 0.1976853916992457, 0.7356645667414825, 0.6312133454691893, 0.20385234850847678, 0.6732063169854541, 0.16334405141983754, 0.6781966281392595, 0.16409322011839833, 0.20774994805700886, 0.19910840965732424, 0.18221112156155927, 0.18200197177231825, 0.18026559957988653, 0.19458485840512207, 0.21126688340576016, 0.21078581874224878, 0.1964272048169894, 0.2009070080090002, 0.08506590375938172, 0.08318850003868661, 0.08033796085196776, 0.0713447354246255, 0.0782984753556979, 0.08361765939974686, 0.08617957033150159, 0.07389083851302714, 0.07264505375258179]}, "mutation_prompt": null}
{"id": "de44aad3-e361-4277-9b3f-681189575594", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))  # New line added\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance solution diversity by applying perturbation in the global search process.", "configspace": "", "generation": 47, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "65ee22db-6af0-47e1-beb2-ea0c7352a9be", "metadata": {"aucs": [0.7607967017081234, 0.7519548315545355, 0.7007003834369634, 0.7441584399988928, 0.7729798970499207, 0.765451783615243, 0.7532637211014249, 0.7407305727950579, 0.7555785807516087, 0.4800752198025262, 0.489457758643717, 0.486952022450557, 0.5037921618842655, 0.48855140155163235, 0.5053785935075861, 0.4849393647161905, 0.4688929523513261, 0.4964498157138115, 0.09762685926842218, 0.10348748794405638, 0.11664356279167643, 0.10878146769209274, 0.10721687673595737, 0.09288086627235048, 0.12081382548181863, 0.11560724766710628, 0.12558651861333747, 0.0954126704737146, 0.10010429962020428, 0.07865035496053518, 0.10331926355192123, 0.10011974176647054, 0.10115693027094153, 0.08778916660401714, 0.09075183434793266, 0.09473864039553481, 0.8436856458406987, 0.8524742325802663, 0.8303730894092345, 0.9303275109576592, 0.9199442754012144, 0.8798031098136095, 0.9577589313331976, 0.8237674660691194, 0.9010965609048908, 0.40323854245171054, 0.3493812950400186, 0.3453647221151037, 0.4134729824050617, 0.36381483774890744, 0.36684309651440206, 0.35571566654481035, 0.37806900883187256, 0.40918386403555296, 0.7485332508948819, 0.7265109858189072, 0.7084729235152172, 0.6713183428282523, 0.7221131586890583, 0.2753714952776256, 0.7003153283821015, 0.718421942426746, 0.701609642615175, 0.17887635699793258, 0.2021231929183136, 0.20122187532773916, 0.5206360346969492, 0.22314694377035005, 0.20600715493230648, 0.28572989203331145, 0.22655122156406116, 0.1752106838230003, 0.17614610441076384, 0.19609793735404557, 0.19638380805484068, 0.1980782344968155, 0.24970912159250802, 0.1994140056324929, 0.1985255518735699, 0.20669893051401, 0.2130018377127717, 0.10476128906055071, 0.27509785347802596, 0.1807064744998803, 0.1262103236438361, 0.2657380270171469, 0.06943766188023415, 0.18159577580995778, 0.15813075860501535, 0.2166248805361045, 0.28646219687304686, 0.4000523213945735, 0.37854702276147345, 0.2656247642558396, 0.20257596354244833, 0.0750880367168909, 0.2790064163217869, 0.2816075822606213, 0.318779685530554, 0.1703656927857624, 0.06765578818261653, 0.09104522662696857, 0.08326477596464033, 0.18620505523847464, 0.10433423808948805, 0.11433431502589575, 0.1759335347559562, 0.09045851556891538, 0.22159324522375645, 0.24032708972785144, 0.25397243505517764, 0.2157415555265919, 0.18987517686264255, 0.243078769607446, 0.20536761929496883, 0.18460030897300417, 0.19140316095224175, 0.5528035915600908, 0.6413768328463679, 0.5721042481389762, 0.5988513597660479, 0.5341514075916016, 0.5662033494169015, 0.5825212887200591, 0.5256953897987886, 0.6504431832598583, 0.10698451237877615, 0.09693261198063596, 0.09348492403861597, 0.09504745783053492, 0.0813818636926621, 0.08444138392917044, 0.09716589029225309, 0.11711303316415234, 0.1114240481160621, 0.19693244823294953, 0.1786687723545316, 0.19937711130934466, 0.18946668528621358, 0.23021156552362054, 0.18495286151232526, 0.1965263399726317, 0.20461538988127614, 0.20310767865493895, 0.33937624907561936, 0.29660414729252227, 0.37634868729801696, 0.3179255850589596, 0.30578073713372256, 0.37843639386677563, 0.3543371385334828, 0.3786696499465535, 0.3667011359111032, 0.26679300361108926, 0.2262505527861285, 0.26199916505295817, 0.2600672849779406, 0.18620664581149782, 0.26283071034222405, 0.3058948210742507, 0.30868794665401433, 0.2880330243748709, 0.19038674184159954, 0.21362245837572058, 0.2290514153355102, 0.19636973171433814, 0.1920554983431706, 0.19413977429560259, 0.18224887052948935, 0.19490500874220207, 0.23815449417247114, 0.2112333904472221, 0.19769377043992709, 0.267052528755929, 0.1900435436449538, 0.20377019621385672, 0.19118776338819654, 0.25827528724443694, 0.19979996839170244, 0.19731348640050317, 0.6790868800562377, 0.19304962959505223, 0.7571786863831931, 0.5900588263409743, 0.6123646537771106, 0.5403087781891753, 0.18432449549012886, 0.16433263566150857, 0.6704970233611031, 0.20059775820238124, 0.728758186581556, 0.6518943739823779, 0.5401372219108633, 0.6453198162170132, 0.16389933088236974, 0.20208483216933115, 0.4217734638671091, 0.20512808235701752, 0.1970753470579204, 0.18588432026935853, 0.18595592450085874, 0.2023871204690353, 0.18244308078128446, 0.21655067933106542, 0.18563587396466863, 0.19446826557702213, 0.18469727742295594, 0.0759154433966196, 0.07762434049414058, 0.07123058247654246, 0.07230727239474488, 0.08247562258113061, 0.08703454873689498, 0.07567520178896414, 0.0824248677261521, 0.07447023044901924]}, "mutation_prompt": null}
{"id": "26f590e9-905f-466b-b7d1-115614fa9bd6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                self.cr = 0.5 + 0.5 * (1 - diversity)  # Line changed\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.2 * (1 - self.evaluations / self.budget) * (1 + diversity)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive parameter tuning by adjusting mutation factor based on diversity to enhance exploration capabilities.", "configspace": "", "generation": 50, "fitness": 0.2050721483495502, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.17.", "error": "", "parent_id": "65ee22db-6af0-47e1-beb2-ea0c7352a9be", "metadata": {"aucs": [0.5410634158002914, 0.5029194304418878, 0.7006913913216741, 0.5115575791007174, 0.5538000555976277, 0.5973907114378554, 0.5914236246408751, 0.5720274382548565, 0.4895927552492947, 9.999999999998899e-05, 9.999999999998899e-05, 0.17066680119496525, 9.999999999998899e-05, 0.1295660577574066, 0.15425412787430737, 9.999999999998899e-05, 9.999999999998899e-05, 0.13015223099259599, 0.042635512399991415, 0.09242237413354493, 0.0848131705316888, 0.09700200803299375, 0.04685541144874317, 0.11291094005472202, 0.10357888460669296, 0.06165589349725542, 0.08460288062519417, 0.09144200077587628, 0.086087470502346, 0.09700952812662089, 0.09034344787552984, 0.08859632035573572, 0.0949707943480711, 0.0927188490870905, 0.06801909476232049, 0.1002591415955969, 0.5974357738198377, 0.6660984656727438, 0.5124627039513652, 0.5874237608194912, 0.6347886655960173, 0.6092289637935016, 0.6348442006567792, 0.5602050619187606, 0.8950344356868206, 0.270630277661152, 0.2898591142231439, 0.24286155721938718, 0.33281538470960814, 0.2940444251071864, 0.28875180105479603, 0.30497968060215397, 0.29806113613468765, 0.2970600452588412, 0.21078903206165456, 0.19104664001459426, 0.28389631908099267, 0.24364581955968334, 0.2895212083226144, 0.34001643872600384, 0.2061781894881598, 0.20751300965232433, 0.2878866298890712, 0.18595702465597908, 0.14638737252957357, 0.14453926849679488, 0.1952901344217256, 0.14796433626993044, 0.12320149251979984, 0.1979465829856969, 0.1670896492075239, 0.1504076256478979, 0.15610596194985615, 0.14873905492824802, 0.1708231472282583, 0.15900126939152792, 0.24542691133480776, 0.16549938355680116, 0.15691538737245103, 0.151544710012812, 0.17695349026310192, 0.014962068192055478, 9.999999999998899e-05, 9.999999999998899e-05, 0.005942126009472304, 9.999999999998899e-05, 0.007839017739911247, 0.0090174394553455, 9.999999999998899e-05, 9.999999999998899e-05, 0.09118837902163801, 0.09955388119050879, 0.11273658925105323, 0.10542110825230788, 0.07606280848530189, 0.1080902763964845, 0.10172385278112195, 0.0749723587069775, 0.07552007603069999, 0.008221676371778952, 0.039736577086315616, 0.0037574295594593465, 0.011205021603968301, 0.006065540619632714, 0.007455454451042676, 0.004950062278998302, 0.07851943441159015, 0.050208994679328156, 0.21556842759424222, 0.09896704477748175, 0.17728404420981492, 0.16644336163738804, 0.14999275449852645, 0.13455344204634112, 0.1908710482778856, 0.12611023908506325, 0.1872356009689261, 0.5210685009147511, 0.5061082578196756, 0.5368832652758732, 0.5494579797215478, 0.5513235091676824, 0.5068230523681053, 0.45075636144029496, 0.4544011731020564, 0.605158223901159, 0.0809134847644778, 0.07639211198805096, 0.08638802011604352, 0.06326104463640492, 0.052273619474097144, 0.06446305330338886, 0.06635503440831292, 0.05439394407120035, 0.0947670009400905, 0.1900537472347199, 0.19597105476515841, 0.22170093350201558, 0.183087036433082, 0.21706737257089992, 0.1886345991712195, 0.20775009906252873, 0.20221798708789573, 0.18637861578832948, 0.17240564106753242, 0.14661145853970758, 0.18271733259338419, 0.1740511842030924, 0.14532520125057324, 0.2208225744695017, 0.1545881264631127, 0.2280436308815923, 0.11305875631202977, 0.09492244108348036, 0.14522025020417095, 0.13120344486339053, 0.11632514360674395, 0.13083994733815396, 0.18034743619469207, 0.11843067827961862, 0.14089740339048296, 0.08648326325538203, 0.16326713526819292, 0.15822198507680063, 0.19854342894934307, 0.16426811034843536, 0.16326165108505408, 0.19833374084289113, 0.19026513499576736, 0.16845589292651109, 0.16571130492359465, 0.18626984088714704, 0.18600964170376122, 0.1832528994918433, 0.206244519289561, 0.17942677040775612, 0.19762506093179866, 0.19068326475155717, 0.19102310215831286, 0.19709920932820146, 0.4383187190930793, 0.16514560491448826, 0.4459778021406796, 0.3945631637756468, 0.17709834238853672, 0.3471329116927836, 0.18325654598463847, 0.4678619175955848, 0.4573634956343975, 0.33687104377771904, 0.259629879341329, 0.32953518677141047, 0.40393877278021617, 0.22482371990184546, 0.2663907180242, 0.29773940538783783, 0.21522717608142805, 0.354404643919477, 0.1756742282467516, 0.17293805096379766, 0.17122617830054276, 0.1879317178986608, 0.17889129585903907, 0.17786534306190827, 0.1809751229875084, 0.16905804371211364, 0.1716060909731716, 0.07752729794043167, 0.06915546588296895, 0.055075721768056085, 0.07126019327594457, 0.05846563109075409, 0.07493825441240676, 0.05414811222095872, 0.0520431536563678, 0.05814238010473438]}, "mutation_prompt": null}
{"id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance dynamic adaptation of parameters to improve exploration and exploitation balance.", "configspace": "", "generation": 51, "fitness": 0.32137874318384135, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.23.", "error": "", "parent_id": "65ee22db-6af0-47e1-beb2-ea0c7352a9be", "metadata": {"aucs": [0.755742483948616, 0.7748408149139739, 0.773725404551783, 0.7421810199092524, 0.7521049786576524, 0.7402850576170419, 0.7538404968244774, 0.78015147501198, 0.7385476147016625, 0.47715366828320394, 0.4894555372892442, 0.3661108471234501, 0.4155290633968499, 0.4350058311985364, 0.47662590063134636, 0.4648011465382932, 0.27690813342835485, 0.5042179767362356, 0.10307227478581049, 0.09786114640322341, 0.09929554968667931, 0.11077350498583305, 0.09590473663535781, 0.11854785584492233, 0.12052234142020368, 0.11124382257840804, 0.11843411715950802, 0.08589793262417666, 0.10809434143263807, 0.12027478486699672, 0.11405856248082125, 0.08875467629686629, 0.09101379970289492, 0.08560689020289136, 0.10560357337586534, 0.0891436291958968, 0.8485791260179276, 0.8998336775463441, 0.8743189076875466, 0.9116909930078183, 0.9447062655300041, 0.9204912763884356, 0.957922790236956, 0.8630818620535072, 0.9238359787217509, 0.4380781325482276, 0.3471906944761748, 0.3981459448757194, 0.36991041287247695, 0.4011982434330812, 0.3803935956146035, 0.33501613840321953, 0.4375597992813447, 0.4230224570539515, 0.7977189920301244, 0.7061637671174072, 0.6860771167703135, 0.7191848946354275, 0.6382423987238981, 0.7565944660600205, 0.7033574528359938, 0.6461983467377399, 0.6812746913802659, 0.19156065545022105, 0.17434777023001702, 0.2244248768176621, 0.18049414032995825, 0.28529326892880646, 0.2026403832369824, 0.18451322417553806, 0.23136966496220768, 0.17308176867449, 0.1608038987273429, 0.18744972127961823, 0.1758928572825651, 0.1709952876973604, 0.2235826386992681, 0.19093097358499145, 0.19489626566432705, 0.1714239462136733, 0.23565665062788366, 0.15238853899373517, 0.21608043518102527, 0.24053326270070507, 0.19283929675918388, 0.18158962798973854, 0.20402514535205662, 0.1406095633790967, 0.1139458169040849, 0.19717914117352953, 0.2076570626158244, 0.3127512004177906, 0.2980066693844947, 0.3861959132225279, 0.21774796556603337, 0.2002737382771409, 0.2749717217331057, 0.3059096050586221, 0.13455885680000557, 0.043702225826872554, 0.10106083790962062, 0.13413556157575546, 0.0693233906320031, 0.15676292361854194, 0.17756422162009855, 0.1490483361029168, 0.10119382355091189, 0.15381947790479567, 0.1987127594143464, 0.20302608243132525, 0.234856516286144, 0.27324696480548616, 0.2549022637547578, 0.20106317224070813, 0.21644270875260363, 0.20655354542063764, 0.24966887643540836, 0.5998917951181317, 0.5956194769167102, 0.48384067227834837, 0.48637383517331556, 0.5459327979998196, 0.5432016225667806, 0.5735637397091135, 0.635884359796473, 0.6848621284569095, 0.09237804428705909, 0.10106529066839853, 0.10801904005966612, 0.09464277152388045, 0.10880398937434543, 0.10858466232251829, 0.1057296036879305, 0.10271302919227565, 0.09349272735294112, 0.1829937941664822, 0.17109684411537895, 0.17934461548154546, 0.1970878913358568, 0.191557296771665, 0.18615813358922073, 0.18121632147331912, 0.16937022753987419, 0.18607982220247354, 0.35455570362962596, 0.32395667002368556, 0.3163978945597714, 0.3402604245366708, 0.365494214755008, 0.30084055876290117, 0.3792338182047883, 0.4272247272377542, 0.34881125981572836, 0.31070462581681557, 0.23848126425916805, 0.23533553311208588, 0.27288485471527024, 0.24604063403984777, 0.3067969729351806, 0.2768838166322397, 0.2555513467089747, 0.29305172514978817, 0.18671295474676652, 0.19683869362057638, 0.23593050646897373, 0.18740426489578454, 0.20239821703476057, 0.18156546063139356, 0.17687391959756826, 0.1977854603856526, 0.19384328665805484, 0.2145809079541383, 0.1977979373622506, 0.24258205467033467, 0.35825297590812466, 0.21343247495290707, 0.19111473572647464, 0.2674567030234305, 0.36161752219027876, 0.19031935464146432, 0.7629081267532258, 0.6701203615583781, 0.8150120398282055, 0.19235346242697182, 0.6045071065254026, 0.1915423002268497, 0.626313293675715, 0.5189423762222208, 0.1948261691573946, 0.5642467512097455, 0.5627960387431232, 0.6533981744627726, 0.5327877424444232, 0.523148190302002, 0.19994239967759708, 0.20280355738498224, 0.43394506886592776, 0.2065603720144722, 0.17640861828158072, 0.19616009977779947, 0.17375607963282513, 0.19383558826695013, 0.19272325606282825, 0.17415782936186242, 0.1869348441699814, 0.20154233422333934, 0.17634209837041448, 0.08282142330032205, 0.08964306391086352, 0.08153285370835983, 0.07134688380678944, 0.08042657117197194, 0.08738775783237795, 0.0824195739904019, 0.08852554848683869, 0.07434790849436901]}, "mutation_prompt": null}
{"id": "e715457a-680c-4b8e-bc63-7785ac2a266a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance dynamic adaptation of parameters to improve exploration and exploitation balance.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.755742483948616, 0.7748408149139739, 0.773725404551783, 0.7421810199092524, 0.7521049786576524, 0.7402850576170419, 0.7538404968244774, 0.78015147501198, 0.7385476147016625, 0.47715366828320394, 0.4894555372892442, 0.3661108471234501, 0.4155290633968499, 0.4350058311985364, 0.47662590063134636, 0.4648011465382932, 0.27690813342835485, 0.5042179767362356, 0.10307227478581049, 0.09786114640322341, 0.09929554968667931, 0.11077350498583305, 0.09590473663535781, 0.11854785584492233, 0.12052234142020368, 0.11124382257840804, 0.11843411715950802, 0.08589793262417666, 0.10809434143263807, 0.12027478486699672, 0.11405856248082125, 0.08875467629686629, 0.09101379970289492, 0.08560689020289136, 0.10560357337586534, 0.0891436291958968, 0.8485791260179276, 0.8998336775463441, 0.8743189076875466, 0.9116909930078183, 0.9447062655300041, 0.9204912763884356, 0.957922790236956, 0.8630818620535072, 0.9238359787217509, 0.4380781325482276, 0.3471906944761748, 0.3981459448757194, 0.36991041287247695, 0.4011982434330812, 0.3803935956146035, 0.33501613840321953, 0.4375597992813447, 0.4230224570539515, 0.7977189920301244, 0.7061637671174072, 0.6860771167703135, 0.7191848946354275, 0.6382423987238981, 0.7565944660600205, 0.7033574528359938, 0.6461983467377399, 0.6812746913802659, 0.19156065545022105, 0.17434777023001702, 0.2244248768176621, 0.18049414032995825, 0.28529326892880646, 0.2026403832369824, 0.18451322417553806, 0.23136966496220768, 0.17308176867449, 0.1608038987273429, 0.18744972127961823, 0.1758928572825651, 0.1709952876973604, 0.2235826386992681, 0.19093097358499145, 0.19489626566432705, 0.1714239462136733, 0.23565665062788366, 0.15238853899373517, 0.21608043518102527, 0.24053326270070507, 0.19283929675918388, 0.18158962798973854, 0.20402514535205662, 0.1406095633790967, 0.1139458169040849, 0.19717914117352953, 0.2076570626158244, 0.3127512004177906, 0.2980066693844947, 0.3861959132225279, 0.21774796556603337, 0.2002737382771409, 0.2749717217331057, 0.3059096050586221, 0.13455885680000557, 0.043702225826872554, 0.10106083790962062, 0.13413556157575546, 0.0693233906320031, 0.15676292361854194, 0.17756422162009855, 0.1490483361029168, 0.10119382355091189, 0.15381947790479567, 0.1987127594143464, 0.20302608243132525, 0.234856516286144, 0.27324696480548616, 0.2549022637547578, 0.20106317224070813, 0.21644270875260363, 0.20655354542063764, 0.24966887643540836, 0.5998917951181317, 0.5956194769167102, 0.48384067227834837, 0.48637383517331556, 0.5459327979998196, 0.5432016225667806, 0.5735637397091135, 0.635884359796473, 0.6848621284569095, 0.09237804428705909, 0.10106529066839853, 0.10801904005966612, 0.09464277152388045, 0.10880398937434543, 0.10858466232251829, 0.1057296036879305, 0.10271302919227565, 0.09349272735294112, 0.1829937941664822, 0.17109684411537895, 0.17934461548154546, 0.1970878913358568, 0.191557296771665, 0.18615813358922073, 0.18121632147331912, 0.16937022753987419, 0.18607982220247354, 0.35455570362962596, 0.32395667002368556, 0.3163978945597714, 0.3402604245366708, 0.365494214755008, 0.30084055876290117, 0.3792338182047883, 0.4272247272377542, 0.34881125981572836, 0.31070462581681557, 0.23848126425916805, 0.23533553311208588, 0.27288485471527024, 0.24604063403984777, 0.3067969729351806, 0.2768838166322397, 0.2555513467089747, 0.29305172514978817, 0.18671295474676652, 0.19683869362057638, 0.23593050646897373, 0.18740426489578454, 0.20239821703476057, 0.18156546063139356, 0.17687391959756826, 0.1977854603856526, 0.19384328665805484, 0.2145809079541383, 0.1977979373622506, 0.24258205467033467, 0.35825297590812466, 0.21343247495290707, 0.19111473572647464, 0.2674567030234305, 0.36161752219027876, 0.19031935464146432, 0.7629081267532258, 0.6701203615583781, 0.8150120398282055, 0.19235346242697182, 0.6045071065254026, 0.1915423002268497, 0.626313293675715, 0.5189423762222208, 0.1948261691573946, 0.5642467512097455, 0.5627960387431232, 0.6533981744627726, 0.5327877424444232, 0.523148190302002, 0.19994239967759708, 0.20280355738498224, 0.43394506886592776, 0.2065603720144722, 0.17640861828158072, 0.19616009977779947, 0.17375607963282513, 0.19383558826695013, 0.19272325606282825, 0.17415782936186242, 0.1869348441699814, 0.20154233422333934, 0.17634209837041448, 0.08282142330032205, 0.08964306391086352, 0.08153285370835983, 0.07134688380678944, 0.08042657117197194, 0.08738775783237795, 0.0824195739904019, 0.08852554848683869, 0.07434790849436901]}, "mutation_prompt": null}
{"id": "a7db7ed9-bd86-4133-ad1d-d7e60dbc6524", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n            if self.evaluations % 10 == 0:  # Line changed\n                self.f *= 1.1 if trial_fitness < self.fitness[i] else 0.9\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive mutation by adjusting the differential weight based on fitness improvement.", "configspace": "", "generation": 53, "fitness": 0.31637310292609805, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.23.", "error": "", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.7788181158169196, 0.7550598803567394, 0.7862186604339519, 0.749698240701981, 0.7416377310602011, 0.7713177335651208, 0.7686590390361419, 0.7155173296093074, 0.7501497042342166, 0.12268295120478923, 0.4933918250286774, 0.4495279091568902, 0.49631831129550863, 0.5198323303305892, 0.5016898596854638, 0.4761389024983469, 0.48752153733884296, 0.0577172364526245, 0.11663789606859665, 0.10731711011797418, 0.11788569680621408, 0.08972186870394994, 0.09932437524017224, 0.09658171690100936, 0.11137647893196323, 0.1246467664178359, 0.10648152378309494, 0.0945685411110313, 0.0874512878184236, 0.10205884121784725, 0.10491698406254113, 0.10552365438822531, 0.1020368603768742, 0.10062135086500734, 0.1037897848948065, 0.08883288776368303, 0.8514561164724113, 0.8860400364511848, 0.7547174965449266, 0.8873559146495537, 0.939126608121021, 0.8955354201032688, 0.9579045415235659, 0.8733023242860639, 0.9223192597161882, 0.36139277164039074, 0.36759555945985845, 0.46713742405311864, 0.32721246495137934, 0.3315120304811655, 0.3450868688825943, 0.3221138067120438, 0.42505782545752435, 0.3895597353512432, 0.7365075230138416, 0.746209785786296, 0.2207745766327579, 0.6334049339605474, 0.7265524919748316, 0.6885353897394121, 0.6430351070598266, 0.7341475555973325, 0.7364914671967222, 0.1893921796562782, 0.21701793118630586, 0.16474286545164563, 0.1963834334250144, 0.20292311243223848, 0.19786964573650434, 0.1953481533377569, 0.18660079521617545, 0.17037920622359992, 0.16126005902127394, 0.1742700653636553, 0.15857414930434843, 0.17819899267516925, 0.17464235952497786, 0.17129703489447057, 0.2432352257085374, 0.15824316586973142, 0.17291471896187138, 0.11577492005991985, 0.1273811281167807, 0.18347583735878803, 0.16727544172384445, 0.20448118398331927, 0.1277613845093316, 0.2153857322415128, 0.26909862400042417, 0.15066251784038764, 0.18044235151257149, 0.23803614291500363, 0.35373884984134063, 0.28972217194109373, 0.3164138099470607, 0.11080232154892689, 0.38576336965073155, 0.22601545097341424, 0.21285990035190594, 0.054394694262222765, 0.08206434468684565, 0.04272885261563386, 0.14597680493444554, 0.09279912565126647, 0.12802008617987926, 0.17216870441307763, 0.13787119987829632, 0.09014172591579683, 0.18701103485333448, 0.22213340938718673, 0.2128000348044662, 0.23651588030051762, 0.19928813782210508, 0.25532808465438517, 0.22125798199613989, 0.2184684614187774, 0.2063928450398015, 0.5552826722435886, 0.600364490661375, 0.6291879182245631, 0.6398307669245175, 0.5558203242197473, 0.6060201616208472, 0.6016197680063249, 0.6080498840512885, 0.5877449573533494, 0.11314993464639389, 0.11186467606976513, 0.11916814778473217, 0.09681659923437125, 0.09844106382302509, 0.08623786136183076, 0.09180184549262371, 0.09209466509854725, 0.07931946350768049, 0.19243268362999721, 0.17189971340635124, 0.1965857457189324, 0.17620599283892935, 0.1951378174929974, 0.18869554528975818, 0.17289324642749815, 0.18284603589505777, 0.18069723391959125, 0.3828688214147704, 0.3608228185825473, 0.3889792238224177, 0.37045659973302103, 0.3707040753047671, 0.4116170855467566, 0.41863398445534716, 0.3514281806010612, 0.35591264081996565, 0.2827073350904903, 0.27184125741295107, 0.2952348751638024, 0.30181956886701733, 0.30112924334004176, 0.29222611738774895, 0.26818662259678316, 0.33372904135518056, 0.2984382825582108, 0.1912839181174778, 0.18240705754251696, 0.18487277813703695, 0.20984582367157245, 0.19079415841655278, 0.20273966326767423, 0.203870787751656, 0.20260186350388742, 0.20417310549817724, 0.19339800820905761, 0.31016226507378397, 0.20888725128202446, 0.19670890929933493, 0.20438331992837522, 0.18952673445669332, 0.18871977344225543, 0.17998689871877982, 0.20070107095873213, 0.7219274954688497, 0.1899844086062762, 0.8389406735357714, 0.4291518372609032, 0.7003554910091997, 0.4187252133921312, 0.6496751547309637, 0.16439738910319845, 0.1957237475426904, 0.6875939318360412, 0.5831962000371637, 0.45980481995895384, 0.7048148803587329, 0.5433755809110132, 0.5061276683859317, 0.1524674898102074, 0.629310287772745, 0.20697450410499652, 0.18602533420991474, 0.18262979433454396, 0.18922885767313324, 0.19124059998134246, 0.1821250222276647, 0.19709901310073386, 0.17685603147888684, 0.18116977699272974, 0.1764127214154927, 0.07791639032100972, 0.07814458180617967, 0.08197368688160334, 0.07477521191092162, 0.08034230209407012, 0.08672068920880971, 0.07612664591424922, 0.08663449682562874, 0.07111232514762578]}, "mutation_prompt": null}
{"id": "df3623ea-360e-46a4-b7ff-8b4b250c8620", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            diversity = np.mean(np.std(self.population, axis=0))\n            crossover = np.random.rand(self.dim) < (self.cr * diversity)  # Line changed\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive crossover probability based on population diversity to improve convergence speed.", "configspace": "", "generation": 54, "fitness": 0.24917727233705536, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.19.", "error": "", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.47294007692010165, 0.4981436021639416, 0.5275760260591849, 0.4610113084421634, 0.471160205954945, 0.49756543712309875, 0.47632750191450823, 0.48244613613467013, 0.4775559448713117, 0.262073583012684, 0.23004605427011415, 0.2671181058524362, 0.22591894598636586, 0.263688682215121, 0.2116605827568082, 0.23096121953481474, 0.2521234932347204, 0.23101928879220746, 0.10631938049635103, 0.11721098732123614, 0.14066297859355326, 0.1903071559320616, 0.1037006880079151, 0.15098493542392621, 0.1415986816384398, 0.12841691256795407, 0.17710191576094092, 0.136189110246268, 0.1305781192247556, 0.1119690740924354, 0.10930567426320248, 0.1147333062815229, 0.14581295932479166, 0.12133044395791914, 0.12441070415151734, 0.0992234466253118, 0.8758353517238344, 0.8698405558421713, 0.5098076740043984, 0.9050788224469819, 0.8898896421631205, 0.9882128459430952, 0.8850043247684433, 0.8789248316909599, 0.9527221421849166, 0.2916089014686466, 0.2864874336738621, 0.2898329821064992, 0.30357557631066134, 0.2818306215244709, 0.29834088723834606, 0.27954988232237643, 0.3039282925327168, 0.2942610597597567, 0.45858391679675947, 0.490297576144766, 0.22991183617250954, 0.45384142790237114, 0.3121614461429799, 0.2660029323566985, 0.2334845413928851, 0.6596502982269731, 0.439266366302539, 0.16729315693857394, 0.1583829252004818, 0.1593504495458934, 0.16569147168899212, 0.15841284327627458, 0.15754619467708875, 0.16896357740380774, 0.20544824087672964, 0.15619246919631735, 0.1507292110464703, 0.18721186080909813, 0.15081393070586746, 0.14486353576400157, 0.15667508208863234, 0.13732206947696668, 0.17918697697285424, 0.15841884615323287, 0.19158332217241592, 0.06623938794720885, 0.0764448486508098, 0.0608588077025477, 0.11968176000698272, 0.0771117558241804, 0.06047633005904518, 0.10018753042253392, 0.06608684247140195, 0.03722907271188414, 0.22209486904136277, 0.1678294474730163, 0.21847183688306426, 0.18152275725048672, 0.18247432227253568, 0.19533827664381975, 0.24360847121626605, 0.21577568049469997, 0.21256326398101177, 0.003222191093490978, 0.002966867639533133, 0.0044162715654585405, 0.003288331312674919, 0.005373872768795973, 0.0031233955650344924, 0.004372380406956422, 0.017950617407578306, 0.0039878991324802104, 0.1040897630385833, 0.10602176417226439, 0.09189607450558324, 0.12008135969210032, 0.09657855371821822, 0.105265281915213, 0.09792611914838456, 0.10008848159433836, 0.09914926737185381, 0.42303315171275324, 0.41002375306867167, 0.4459402703401387, 0.44125399314373637, 0.41977785578198157, 0.42062270068470275, 0.42598127622034176, 0.4439649126249483, 0.4222578611237412, 0.10830314561188648, 0.08870839788163687, 0.1033771051847363, 0.10013094586857785, 0.09794490944025258, 0.09466375655967862, 0.10587396207382316, 0.10111323837435904, 0.11270002707594262, 0.17867001822138995, 0.16138720430974796, 0.300133678997237, 0.1791852081060089, 0.1920927428399396, 0.18752906130898128, 0.19825439160199998, 0.18767365316923956, 0.18779103491239435, 0.277891023217384, 0.2626297082223771, 0.2702938094676318, 0.2727139270280754, 0.2996879356135185, 0.2852376459078553, 0.27810680223677553, 0.28966382435550386, 0.2817464202948703, 0.21544643080978942, 0.20007290883688988, 0.2153936380349516, 0.21947028473773533, 0.2177707875545526, 0.23789677833793632, 0.21442908112437908, 0.22889554464179263, 0.21122902331822235, 0.20240550632533139, 0.24752850771380386, 0.1973263762672285, 0.22175741201562227, 0.22165512808158894, 0.19430124273163196, 0.20783487185256977, 0.1935417496166365, 0.21055108150856627, 0.19570773195278413, 0.19439436136202715, 0.18769550321203265, 0.2089085277700139, 0.19144209099570553, 0.19829769726604296, 0.1911849785391515, 0.19607706055679142, 0.1987781886815283, 0.17418152283430643, 0.6982281985738434, 0.610903973360293, 0.7492524735829932, 0.5562251459954848, 0.6735886283367816, 0.6952523593006495, 0.17994382487063743, 0.6130414361416061, 0.284122708650031, 0.2077418433429371, 0.37220326475604637, 0.20439997134374854, 0.20431558363820657, 0.49706539312207876, 0.28631124161437804, 0.381943281699646, 0.10338184648038007, 0.18659431158777562, 0.2028884711843324, 0.18578181551353656, 0.1776686769216005, 0.1882736159389874, 0.1934327375719106, 0.17468081115675704, 0.18186076395823392, 0.18892148613677018, 0.07932707409149775, 0.07597829504000653, 0.07235757792746877, 0.07599545223360493, 0.08074988980252507, 0.07657554552435941, 0.08383424242959459, 0.10252983083798406, 0.08138092748668246]}, "mutation_prompt": null}
{"id": "76af36a3-2ff3-4cca-9850-c220790c5d88", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance dynamic adaptation of parameters to improve exploration and exploitation balance.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.755742483948616, 0.7748408149139739, 0.773725404551783, 0.7421810199092524, 0.7521049786576524, 0.7402850576170419, 0.7538404968244774, 0.78015147501198, 0.7385476147016625, 0.47715366828320394, 0.4894555372892442, 0.3661108471234501, 0.4155290633968499, 0.4350058311985364, 0.47662590063134636, 0.4648011465382932, 0.27690813342835485, 0.5042179767362356, 0.10307227478581049, 0.09786114640322341, 0.09929554968667931, 0.11077350498583305, 0.09590473663535781, 0.11854785584492233, 0.12052234142020368, 0.11124382257840804, 0.11843411715950802, 0.08589793262417666, 0.10809434143263807, 0.12027478486699672, 0.11405856248082125, 0.08875467629686629, 0.09101379970289492, 0.08560689020289136, 0.10560357337586534, 0.0891436291958968, 0.8485791260179276, 0.8998336775463441, 0.8743189076875466, 0.9116909930078183, 0.9447062655300041, 0.9204912763884356, 0.957922790236956, 0.8630818620535072, 0.9238359787217509, 0.4380781325482276, 0.3471906944761748, 0.3981459448757194, 0.36991041287247695, 0.4011982434330812, 0.3803935956146035, 0.33501613840321953, 0.4375597992813447, 0.4230224570539515, 0.7977189920301244, 0.7061637671174072, 0.6860771167703135, 0.7191848946354275, 0.6382423987238981, 0.7565944660600205, 0.7033574528359938, 0.6461983467377399, 0.6812746913802659, 0.19156065545022105, 0.17434777023001702, 0.2244248768176621, 0.18049414032995825, 0.28529326892880646, 0.2026403832369824, 0.18451322417553806, 0.23136966496220768, 0.17308176867449, 0.1608038987273429, 0.18744972127961823, 0.1758928572825651, 0.1709952876973604, 0.2235826386992681, 0.19093097358499145, 0.19489626566432705, 0.1714239462136733, 0.23565665062788366, 0.15238853899373517, 0.21608043518102527, 0.24053326270070507, 0.19283929675918388, 0.18158962798973854, 0.20402514535205662, 0.1406095633790967, 0.1139458169040849, 0.19717914117352953, 0.2076570626158244, 0.3127512004177906, 0.2980066693844947, 0.3861959132225279, 0.21774796556603337, 0.2002737382771409, 0.2749717217331057, 0.3059096050586221, 0.13455885680000557, 0.043702225826872554, 0.10106083790962062, 0.13413556157575546, 0.0693233906320031, 0.15676292361854194, 0.17756422162009855, 0.1490483361029168, 0.10119382355091189, 0.15381947790479567, 0.1987127594143464, 0.20302608243132525, 0.234856516286144, 0.27324696480548616, 0.2549022637547578, 0.20106317224070813, 0.21644270875260363, 0.20655354542063764, 0.24966887643540836, 0.5998917951181317, 0.5956194769167102, 0.48384067227834837, 0.48637383517331556, 0.5459327979998196, 0.5432016225667806, 0.5735637397091135, 0.635884359796473, 0.6848621284569095, 0.09237804428705909, 0.10106529066839853, 0.10801904005966612, 0.09464277152388045, 0.10880398937434543, 0.10858466232251829, 0.1057296036879305, 0.10271302919227565, 0.09349272735294112, 0.1829937941664822, 0.17109684411537895, 0.17934461548154546, 0.1970878913358568, 0.191557296771665, 0.18615813358922073, 0.18121632147331912, 0.16937022753987419, 0.18607982220247354, 0.35455570362962596, 0.32395667002368556, 0.3163978945597714, 0.3402604245366708, 0.365494214755008, 0.30084055876290117, 0.3792338182047883, 0.4272247272377542, 0.34881125981572836, 0.31070462581681557, 0.23848126425916805, 0.23533553311208588, 0.27288485471527024, 0.24604063403984777, 0.3067969729351806, 0.2768838166322397, 0.2555513467089747, 0.29305172514978817, 0.18671295474676652, 0.19683869362057638, 0.23593050646897373, 0.18740426489578454, 0.20239821703476057, 0.18156546063139356, 0.17687391959756826, 0.1977854603856526, 0.19384328665805484, 0.2145809079541383, 0.1977979373622506, 0.24258205467033467, 0.35825297590812466, 0.21343247495290707, 0.19111473572647464, 0.2674567030234305, 0.36161752219027876, 0.19031935464146432, 0.7629081267532258, 0.6701203615583781, 0.8150120398282055, 0.19235346242697182, 0.6045071065254026, 0.1915423002268497, 0.626313293675715, 0.5189423762222208, 0.1948261691573946, 0.5642467512097455, 0.5627960387431232, 0.6533981744627726, 0.5327877424444232, 0.523148190302002, 0.19994239967759708, 0.20280355738498224, 0.43394506886592776, 0.2065603720144722, 0.17640861828158072, 0.19616009977779947, 0.17375607963282513, 0.19383558826695013, 0.19272325606282825, 0.17415782936186242, 0.1869348441699814, 0.20154233422333934, 0.17634209837041448, 0.08282142330032205, 0.08964306391086352, 0.08153285370835983, 0.07134688380678944, 0.08042657117197194, 0.08738775783237795, 0.0824195739904019, 0.08852554848683869, 0.07434790849436901]}, "mutation_prompt": null}
{"id": "12c43b39-4464-40ec-a163-53367cfb9d2f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.3 * diversity * (1 - self.evaluations / self.budget)  # Line changed\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive differential weight scaling based on evaluation progression and population diversity.", "configspace": "", "generation": 56, "fitness": 0.30280378240254313, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.23.", "error": "", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.7393976583058979, 0.6889781448477317, 0.7445604867234061, 0.743332216765553, 0.7311820116153462, 0.7351248406625202, 0.731165042162609, 0.7184829323390742, 0.7168992929779443, 0.4091196964653093, 0.42909965922270754, 0.39593545621470916, 0.438633898841464, 0.2660018712922734, 0.3809075648433462, 0.4087998039395937, 0.4248186434421748, 0.3889729202679655, 0.10073919535454967, 0.10950801454893389, 0.09888869926528221, 0.09215769377764826, 0.08332603787129278, 0.09122147648862478, 0.10249302059130116, 0.10705045338717167, 0.08877823580951594, 0.09307229352630442, 0.09003159284538598, 0.07470829202074714, 0.08724688689185456, 0.10815689582200705, 0.09678970306345258, 0.10451736891554608, 0.09463036799027214, 0.0844632008057159, 0.9124881280361856, 0.9579788363327649, 0.9268181434872103, 0.916365096621088, 0.9082628998780912, 0.9897666492719775, 0.9380668017443439, 0.9466402293799604, 0.9887416459384742, 0.33539133296964607, 0.3613187739368503, 0.3716622256322425, 0.311622968141558, 0.32712456941857815, 0.3244093752616737, 0.32304623966135315, 0.37609496902818806, 0.3426278709247008, 0.6555475546107631, 0.6012420849053555, 0.537138871989213, 0.6229291450910817, 0.6664583539129139, 0.5937195303804259, 0.5889026174272621, 0.5682767451486814, 0.6628273267490232, 0.19114564501697362, 0.19852936427957213, 0.2139144954897797, 0.17922962743142035, 0.1687505092431364, 0.20731187134886364, 0.20505227441927543, 0.17296056372173296, 0.17060402500245564, 0.1587045799605563, 0.19426010610127487, 0.16611077454914358, 0.18818879698053037, 0.18415220765128915, 0.18513798968509243, 0.14786694629623742, 0.16896066843590907, 0.17025249683064558, 0.1551751520362692, 0.05558690612875394, 0.17383653053223136, 0.23457999076021296, 0.12511072169657478, 0.13697375472196893, 0.09958631894654812, 0.08939750376944955, 0.131113774216847, 0.15543822097352678, 0.18667859658681796, 0.27746313314892734, 0.20080848007773133, 0.1438064596072145, 0.2170511800918551, 0.26544940502031245, 0.23419886560693393, 0.27368579494536305, 0.05128716176643433, 0.03323791958260758, 0.08324914462632693, 0.07717756595676784, 0.08575182826622496, 0.14475113240012938, 0.0780548557608709, 0.09169645995715836, 0.05731462354339889, 0.207725007713081, 0.21023901978088666, 0.23065978791063024, 0.2589767575980182, 0.1586855488653246, 0.2625655452017911, 0.22540911912017603, 0.2327812653032285, 0.20727927129610868, 0.6302254429533216, 0.5177913783703229, 0.6178020909747942, 0.5463398324576951, 0.6351999321991441, 0.5544408451423568, 0.5728154889003786, 0.5511470778941647, 0.5382718163831661, 0.09065315997636303, 0.10323604913329021, 0.10279244473396121, 0.09531994090579776, 0.09496256448313722, 0.12002967984045043, 0.0877197132002242, 0.09282746455617019, 0.09696133106665328, 0.1439400062561459, 0.19595350897865904, 0.27702798032039067, 0.14919607212864228, 0.1674092727487494, 0.1721839992814712, 0.17146704306700578, 0.1854435385867389, 0.19000949302991055, 0.24250670854363432, 0.2924951138531323, 0.28631242916498933, 0.31837833315114905, 0.2865130712094044, 0.2940655955144442, 0.35749869191347583, 0.337534638183995, 0.35358452685337427, 0.20543853228238174, 0.194020943537772, 0.23870166195950848, 0.22797714951648063, 0.2102288136774415, 0.2547603335180908, 0.2857688766779999, 0.23931810572689804, 0.2314942819735507, 0.19132236600890984, 0.18344126591359855, 0.20736851781967736, 0.17140547279531715, 0.1785461268385119, 0.20399637006847238, 0.19856902443600344, 0.20860188358741827, 0.17932221135375725, 0.18213588199057384, 0.18440360684917945, 0.20605348683920033, 0.20934475369668404, 0.23504499404300405, 0.1823967417570942, 0.20124022126082042, 0.18605024408108772, 0.19410536716794946, 0.5508580938183611, 0.5850047554593426, 0.6964156286512102, 0.513446741318434, 0.4733176228172661, 0.518430777296756, 0.17066408151416712, 0.7019283042075952, 0.16959971002965357, 0.6200523703010898, 0.6222661372309838, 0.5499106702686443, 0.6376654728963387, 0.19515587762012243, 0.45057944188284216, 0.48722211528872494, 0.5766455094517434, 0.4891516729407628, 0.1952308199395386, 0.19152052257877916, 0.19347928557761607, 0.1837467305135494, 0.19873106300049193, 0.20417340184492527, 0.18615876733954273, 0.18147990029933603, 0.18972699744293564, 0.07392992577332025, 0.06952055894558218, 0.06962057216543815, 0.07060832289939478, 0.06790568711938372, 0.06285115146970843, 0.08910650123987385, 0.05922673966428105, 0.07059525506206432]}, "mutation_prompt": null}
{"id": "c8d25492-4d15-4611-bb03-13deea92f084", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Adaptive mutation factor and local search step size to balance exploration and exploitation dynamically.", "configspace": "", "generation": 57, "fitness": 0.32137874318384135, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.23.", "error": "", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.755742483948616, 0.7748408149139739, 0.773725404551783, 0.7421810199092524, 0.7521049786576524, 0.7402850576170419, 0.7538404968244774, 0.78015147501198, 0.7385476147016625, 0.47715366828320394, 0.4894555372892442, 0.3661108471234501, 0.4155290633968499, 0.4350058311985364, 0.47662590063134636, 0.4648011465382932, 0.27690813342835485, 0.5042179767362356, 0.10307227478581049, 0.09786114640322341, 0.09929554968667931, 0.11077350498583305, 0.09590473663535781, 0.11854785584492233, 0.12052234142020368, 0.11124382257840804, 0.11843411715950802, 0.08589793262417666, 0.10809434143263807, 0.12027478486699672, 0.11405856248082125, 0.08875467629686629, 0.09101379970289492, 0.08560689020289136, 0.10560357337586534, 0.0891436291958968, 0.8485791260179276, 0.8998336775463441, 0.8743189076875466, 0.9116909930078183, 0.9447062655300041, 0.9204912763884356, 0.957922790236956, 0.8630818620535072, 0.9238359787217509, 0.4380781325482276, 0.3471906944761748, 0.3981459448757194, 0.36991041287247695, 0.4011982434330812, 0.3803935956146035, 0.33501613840321953, 0.4375597992813447, 0.4230224570539515, 0.7977189920301244, 0.7061637671174072, 0.6860771167703135, 0.7191848946354275, 0.6382423987238981, 0.7565944660600205, 0.7033574528359938, 0.6461983467377399, 0.6812746913802659, 0.19156065545022105, 0.17434777023001702, 0.2244248768176621, 0.18049414032995825, 0.28529326892880646, 0.2026403832369824, 0.18451322417553806, 0.23136966496220768, 0.17308176867449, 0.1608038987273429, 0.18744972127961823, 0.1758928572825651, 0.1709952876973604, 0.2235826386992681, 0.19093097358499145, 0.19489626566432705, 0.1714239462136733, 0.23565665062788366, 0.15238853899373517, 0.21608043518102527, 0.24053326270070507, 0.19283929675918388, 0.18158962798973854, 0.20402514535205662, 0.1406095633790967, 0.1139458169040849, 0.19717914117352953, 0.2076570626158244, 0.3127512004177906, 0.2980066693844947, 0.3861959132225279, 0.21774796556603337, 0.2002737382771409, 0.2749717217331057, 0.3059096050586221, 0.13455885680000557, 0.043702225826872554, 0.10106083790962062, 0.13413556157575546, 0.0693233906320031, 0.15676292361854194, 0.17756422162009855, 0.1490483361029168, 0.10119382355091189, 0.15381947790479567, 0.1987127594143464, 0.20302608243132525, 0.234856516286144, 0.27324696480548616, 0.2549022637547578, 0.20106317224070813, 0.21644270875260363, 0.20655354542063764, 0.24966887643540836, 0.5998917951181317, 0.5956194769167102, 0.48384067227834837, 0.48637383517331556, 0.5459327979998196, 0.5432016225667806, 0.5735637397091135, 0.635884359796473, 0.6848621284569095, 0.09237804428705909, 0.10106529066839853, 0.10801904005966612, 0.09464277152388045, 0.10880398937434543, 0.10858466232251829, 0.1057296036879305, 0.10271302919227565, 0.09349272735294112, 0.1829937941664822, 0.17109684411537895, 0.17934461548154546, 0.1970878913358568, 0.191557296771665, 0.18615813358922073, 0.18121632147331912, 0.16937022753987419, 0.18607982220247354, 0.35455570362962596, 0.32395667002368556, 0.3163978945597714, 0.3402604245366708, 0.365494214755008, 0.30084055876290117, 0.3792338182047883, 0.4272247272377542, 0.34881125981572836, 0.31070462581681557, 0.23848126425916805, 0.23533553311208588, 0.27288485471527024, 0.24604063403984777, 0.3067969729351806, 0.2768838166322397, 0.2555513467089747, 0.29305172514978817, 0.18671295474676652, 0.19683869362057638, 0.23593050646897373, 0.18740426489578454, 0.20239821703476057, 0.18156546063139356, 0.17687391959756826, 0.1977854603856526, 0.19384328665805484, 0.2145809079541383, 0.1977979373622506, 0.24258205467033467, 0.35825297590812466, 0.21343247495290707, 0.19111473572647464, 0.2674567030234305, 0.36161752219027876, 0.19031935464146432, 0.7629081267532258, 0.6701203615583781, 0.8150120398282055, 0.19235346242697182, 0.6045071065254026, 0.1915423002268497, 0.626313293675715, 0.5189423762222208, 0.1948261691573946, 0.5642467512097455, 0.5627960387431232, 0.6533981744627726, 0.5327877424444232, 0.523148190302002, 0.19994239967759708, 0.20280355738498224, 0.43394506886592776, 0.2065603720144722, 0.17640861828158072, 0.19616009977779947, 0.17375607963282513, 0.19383558826695013, 0.19272325606282825, 0.17415782936186242, 0.1869348441699814, 0.20154233422333934, 0.17634209837041448, 0.08282142330032205, 0.08964306391086352, 0.08153285370835983, 0.07134688380678944, 0.08042657117197194, 0.08738775783237795, 0.0824195739904019, 0.08852554848683869, 0.07434790849436901]}, "mutation_prompt": null}
{"id": "8d64afe4-2fcf-4523-9ed0-a9ffe1e54331", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance dynamic adaptation of parameters to improve exploration and exploitation balance.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.755742483948616, 0.7748408149139739, 0.773725404551783, 0.7421810199092524, 0.7521049786576524, 0.7402850576170419, 0.7538404968244774, 0.78015147501198, 0.7385476147016625, 0.47715366828320394, 0.4894555372892442, 0.3661108471234501, 0.4155290633968499, 0.4350058311985364, 0.47662590063134636, 0.4648011465382932, 0.27690813342835485, 0.5042179767362356, 0.10307227478581049, 0.09786114640322341, 0.09929554968667931, 0.11077350498583305, 0.09590473663535781, 0.11854785584492233, 0.12052234142020368, 0.11124382257840804, 0.11843411715950802, 0.08589793262417666, 0.10809434143263807, 0.12027478486699672, 0.11405856248082125, 0.08875467629686629, 0.09101379970289492, 0.08560689020289136, 0.10560357337586534, 0.0891436291958968, 0.8485791260179276, 0.8998336775463441, 0.8743189076875466, 0.9116909930078183, 0.9447062655300041, 0.9204912763884356, 0.957922790236956, 0.8630818620535072, 0.9238359787217509, 0.4380781325482276, 0.3471906944761748, 0.3981459448757194, 0.36991041287247695, 0.4011982434330812, 0.3803935956146035, 0.33501613840321953, 0.4375597992813447, 0.4230224570539515, 0.7977189920301244, 0.7061637671174072, 0.6860771167703135, 0.7191848946354275, 0.6382423987238981, 0.7565944660600205, 0.7033574528359938, 0.6461983467377399, 0.6812746913802659, 0.19156065545022105, 0.17434777023001702, 0.2244248768176621, 0.18049414032995825, 0.28529326892880646, 0.2026403832369824, 0.18451322417553806, 0.23136966496220768, 0.17308176867449, 0.1608038987273429, 0.18744972127961823, 0.1758928572825651, 0.1709952876973604, 0.2235826386992681, 0.19093097358499145, 0.19489626566432705, 0.1714239462136733, 0.23565665062788366, 0.15238853899373517, 0.21608043518102527, 0.24053326270070507, 0.19283929675918388, 0.18158962798973854, 0.20402514535205662, 0.1406095633790967, 0.1139458169040849, 0.19717914117352953, 0.2076570626158244, 0.3127512004177906, 0.2980066693844947, 0.3861959132225279, 0.21774796556603337, 0.2002737382771409, 0.2749717217331057, 0.3059096050586221, 0.13455885680000557, 0.043702225826872554, 0.10106083790962062, 0.13413556157575546, 0.0693233906320031, 0.15676292361854194, 0.17756422162009855, 0.1490483361029168, 0.10119382355091189, 0.15381947790479567, 0.1987127594143464, 0.20302608243132525, 0.234856516286144, 0.27324696480548616, 0.2549022637547578, 0.20106317224070813, 0.21644270875260363, 0.20655354542063764, 0.24966887643540836, 0.5998917951181317, 0.5956194769167102, 0.48384067227834837, 0.48637383517331556, 0.5459327979998196, 0.5432016225667806, 0.5735637397091135, 0.635884359796473, 0.6848621284569095, 0.09237804428705909, 0.10106529066839853, 0.10801904005966612, 0.09464277152388045, 0.10880398937434543, 0.10858466232251829, 0.1057296036879305, 0.10271302919227565, 0.09349272735294112, 0.1829937941664822, 0.17109684411537895, 0.17934461548154546, 0.1970878913358568, 0.191557296771665, 0.18615813358922073, 0.18121632147331912, 0.16937022753987419, 0.18607982220247354, 0.35455570362962596, 0.32395667002368556, 0.3163978945597714, 0.3402604245366708, 0.365494214755008, 0.30084055876290117, 0.3792338182047883, 0.4272247272377542, 0.34881125981572836, 0.31070462581681557, 0.23848126425916805, 0.23533553311208588, 0.27288485471527024, 0.24604063403984777, 0.3067969729351806, 0.2768838166322397, 0.2555513467089747, 0.29305172514978817, 0.18671295474676652, 0.19683869362057638, 0.23593050646897373, 0.18740426489578454, 0.20239821703476057, 0.18156546063139356, 0.17687391959756826, 0.1977854603856526, 0.19384328665805484, 0.2145809079541383, 0.1977979373622506, 0.24258205467033467, 0.35825297590812466, 0.21343247495290707, 0.19111473572647464, 0.2674567030234305, 0.36161752219027876, 0.19031935464146432, 0.7629081267532258, 0.6701203615583781, 0.8150120398282055, 0.19235346242697182, 0.6045071065254026, 0.1915423002268497, 0.626313293675715, 0.5189423762222208, 0.1948261691573946, 0.5642467512097455, 0.5627960387431232, 0.6533981744627726, 0.5327877424444232, 0.523148190302002, 0.19994239967759708, 0.20280355738498224, 0.43394506886592776, 0.2065603720144722, 0.17640861828158072, 0.19616009977779947, 0.17375607963282513, 0.19383558826695013, 0.19272325606282825, 0.17415782936186242, 0.1869348441699814, 0.20154233422333934, 0.17634209837041448, 0.08282142330032205, 0.08964306391086352, 0.08153285370835983, 0.07134688380678944, 0.08042657117197194, 0.08738775783237795, 0.0824195739904019, 0.08852554848683869, 0.07434790849436901]}, "mutation_prompt": null}
{"id": "59a202bc-61ce-4a37-872a-d91d907b5fad", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Initial crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n                self.cr = 0.7 + 0.3 * (1 - diversity)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive crossover probability to enhance the balance between exploration and exploitation.", "configspace": "", "generation": 59, "fitness": 0.2502128434672232, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.25 with standard deviation 0.20.", "error": "", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.514157982865193, 0.5518255239449946, 0.5726817977380296, 0.49358762532725164, 0.5944302599244191, 0.5724881690780048, 0.5192106439517408, 0.5655179040550526, 0.5220135515123678, 0.2228768532569031, 0.2511835582776364, 0.4173124257443739, 0.2187705139618401, 0.3950742010498203, 0.19697820956894818, 0.2983412383362909, 0.34331621160294057, 0.3130298615142657, 0.11174139725180998, 0.12827507247347514, 0.10966654397190612, 0.11695596383241591, 0.11568460905537936, 0.110656242542578, 0.1520739075217007, 0.09695807763734698, 0.13491541535119356, 0.09850752194029122, 0.08193063558369174, 0.10434653094066382, 0.10979575247239393, 0.11692994042694205, 0.0952350977920845, 0.10281246447992165, 0.102654154837731, 0.10786601706699361, 0.882439713271132, 0.8593551321267427, 0.8605742819484754, 0.8567148812763621, 0.8919025605039537, 0.8730939947687711, 0.8705524303849994, 0.8894500464065849, 0.9286640687202316, 0.3022263419706298, 0.29356496266307275, 0.3152142714504381, 0.3050309698802173, 0.29862904343207597, 0.3200099228670794, 0.297195490637149, 0.3113942920468612, 0.34941372452892505, 0.48484952697372796, 0.45981702154627535, 0.5994511423048868, 0.5405156073653625, 0.656065321993369, 0.6378172576906957, 0.6255382469980985, 0.4823868317854081, 0.6255493289599189, 0.18059648421974217, 0.2540087711675574, 0.1987422653199612, 0.19000790738025297, 0.1740725027688046, 0.24769492737048682, 0.18410019765156338, 0.16957638911350226, 0.22543056132695527, 0.22053350153243023, 0.13435704646499635, 0.186337866807469, 0.21193117644031478, 0.1727009179732062, 0.19969724040634285, 0.15412091217394142, 0.17838470755722868, 0.1765286566361427, 0.006862673781974804, 0.0019128242284447428, 0.002080253136459209, 0.0012626046534267577, 0.003974574065490066, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05440810842035937, 0.06777757355372394, 0.0753405971315555, 0.10110249679648131, 0.0568909927993152, 0.05540576144003406, 0.08677662834926503, 0.0696582268222472, 0.06792725949098954, 0.0651866926227469, 0.05583267773479783, 0.026922088658803633, 0.09102496940347904, 0.07624681900864672, 0.09611007893653511, 0.11168378363893339, 0.10141458913453949, 0.11560015551026681, 0.1723147317220206, 0.16509668093363694, 0.15612331332293905, 0.14320186964624626, 0.21615463572453297, 0.16646369810870487, 0.15177240860057062, 0.20643192935986598, 0.15982324282772986, 0.5333934215482914, 0.5897354062221104, 0.49447605355620594, 0.5081080398605121, 0.4806966802831456, 0.5154875735224622, 0.5349311647124319, 0.5113440423914539, 0.5242102980042518, 0.09241423502810286, 0.09658623652680975, 0.10382772622193803, 0.08277551129766347, 0.09390469832176862, 0.10822714126742561, 0.09494118776448035, 0.09976002596726541, 0.11118729572125718, 0.18778711406679416, 0.16716107708133532, 0.17265981077054626, 0.19887981274501176, 0.2008909117301958, 0.20595922858346716, 0.19444654487639002, 0.17956383502770545, 0.1771618273476694, 0.2512708072313329, 0.21972008188231662, 0.24309260666119192, 0.22373917581007008, 0.27391163841842436, 0.27874665396967935, 0.31053071858065273, 0.24360355612568507, 0.21903249787170187, 0.16491012906919422, 0.17696116629088499, 0.1826512853817851, 0.19893513944356267, 0.16964451859500496, 0.16239458120010208, 0.24250633147136091, 0.1990761257180521, 0.1809960507330447, 0.2003653487271727, 0.193287490086957, 0.19244337591401406, 0.2011956408794746, 0.20498771659073323, 0.19212470357410816, 0.1984807820712765, 0.19007568743103176, 0.18920442396260695, 0.17970582602571306, 0.18739414888889727, 0.1987389927771397, 0.19646545288317663, 0.2290907806795781, 0.1954098322417659, 0.1851784709032055, 0.19131877144414555, 0.20449065948050138, 0.17781241879122867, 0.3133329193224651, 0.4195847191543417, 0.1906896044523556, 0.26449305957376135, 0.19038282314618393, 0.2932513495084963, 0.40327394406834816, 0.47666890257805294, 0.2783462776086433, 0.1998671796583288, 0.34088230050953905, 0.3400959731986005, 0.19284352494580836, 0.3429418762977555, 0.18990291197914677, 0.29460853745182436, 0.29374477319462944, 0.18966878562893552, 0.17982554018861752, 0.18674428789426134, 0.18212187940868763, 0.1808130734689023, 0.18703534047824855, 0.1968236987929155, 0.17513570499970466, 0.18232890311853656, 0.07920345383409255, 0.06224126437685995, 0.0892264720544832, 0.09007784862769308, 0.06909440343347817, 0.07225790619325412, 0.07178096347466822, 0.07991489320905132, 0.07153334157038493]}, "mutation_prompt": null}
{"id": "3a401502-ee1a-4e5e-82dd-4c7592071c84", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity)  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance dynamic adaptation of parameters to improve exploration and exploitation balance.", "configspace": "", "generation": 52, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.755742483948616, 0.7748408149139739, 0.773725404551783, 0.7421810199092524, 0.7521049786576524, 0.7402850576170419, 0.7538404968244774, 0.78015147501198, 0.7385476147016625, 0.47715366828320394, 0.4894555372892442, 0.3661108471234501, 0.4155290633968499, 0.4350058311985364, 0.47662590063134636, 0.4648011465382932, 0.27690813342835485, 0.5042179767362356, 0.10307227478581049, 0.09786114640322341, 0.09929554968667931, 0.11077350498583305, 0.09590473663535781, 0.11854785584492233, 0.12052234142020368, 0.11124382257840804, 0.11843411715950802, 0.08589793262417666, 0.10809434143263807, 0.12027478486699672, 0.11405856248082125, 0.08875467629686629, 0.09101379970289492, 0.08560689020289136, 0.10560357337586534, 0.0891436291958968, 0.8485791260179276, 0.8998336775463441, 0.8743189076875466, 0.9116909930078183, 0.9447062655300041, 0.9204912763884356, 0.957922790236956, 0.8630818620535072, 0.9238359787217509, 0.4380781325482276, 0.3471906944761748, 0.3981459448757194, 0.36991041287247695, 0.4011982434330812, 0.3803935956146035, 0.33501613840321953, 0.4375597992813447, 0.4230224570539515, 0.7977189920301244, 0.7061637671174072, 0.6860771167703135, 0.7191848946354275, 0.6382423987238981, 0.7565944660600205, 0.7033574528359938, 0.6461983467377399, 0.6812746913802659, 0.19156065545022105, 0.17434777023001702, 0.2244248768176621, 0.18049414032995825, 0.28529326892880646, 0.2026403832369824, 0.18451322417553806, 0.23136966496220768, 0.17308176867449, 0.1608038987273429, 0.18744972127961823, 0.1758928572825651, 0.1709952876973604, 0.2235826386992681, 0.19093097358499145, 0.19489626566432705, 0.1714239462136733, 0.23565665062788366, 0.15238853899373517, 0.21608043518102527, 0.24053326270070507, 0.19283929675918388, 0.18158962798973854, 0.20402514535205662, 0.1406095633790967, 0.1139458169040849, 0.19717914117352953, 0.2076570626158244, 0.3127512004177906, 0.2980066693844947, 0.3861959132225279, 0.21774796556603337, 0.2002737382771409, 0.2749717217331057, 0.3059096050586221, 0.13455885680000557, 0.043702225826872554, 0.10106083790962062, 0.13413556157575546, 0.0693233906320031, 0.15676292361854194, 0.17756422162009855, 0.1490483361029168, 0.10119382355091189, 0.15381947790479567, 0.1987127594143464, 0.20302608243132525, 0.234856516286144, 0.27324696480548616, 0.2549022637547578, 0.20106317224070813, 0.21644270875260363, 0.20655354542063764, 0.24966887643540836, 0.5998917951181317, 0.5956194769167102, 0.48384067227834837, 0.48637383517331556, 0.5459327979998196, 0.5432016225667806, 0.5735637397091135, 0.635884359796473, 0.6848621284569095, 0.09237804428705909, 0.10106529066839853, 0.10801904005966612, 0.09464277152388045, 0.10880398937434543, 0.10858466232251829, 0.1057296036879305, 0.10271302919227565, 0.09349272735294112, 0.1829937941664822, 0.17109684411537895, 0.17934461548154546, 0.1970878913358568, 0.191557296771665, 0.18615813358922073, 0.18121632147331912, 0.16937022753987419, 0.18607982220247354, 0.35455570362962596, 0.32395667002368556, 0.3163978945597714, 0.3402604245366708, 0.365494214755008, 0.30084055876290117, 0.3792338182047883, 0.4272247272377542, 0.34881125981572836, 0.31070462581681557, 0.23848126425916805, 0.23533553311208588, 0.27288485471527024, 0.24604063403984777, 0.3067969729351806, 0.2768838166322397, 0.2555513467089747, 0.29305172514978817, 0.18671295474676652, 0.19683869362057638, 0.23593050646897373, 0.18740426489578454, 0.20239821703476057, 0.18156546063139356, 0.17687391959756826, 0.1977854603856526, 0.19384328665805484, 0.2145809079541383, 0.1977979373622506, 0.24258205467033467, 0.35825297590812466, 0.21343247495290707, 0.19111473572647464, 0.2674567030234305, 0.36161752219027876, 0.19031935464146432, 0.7629081267532258, 0.6701203615583781, 0.8150120398282055, 0.19235346242697182, 0.6045071065254026, 0.1915423002268497, 0.626313293675715, 0.5189423762222208, 0.1948261691573946, 0.5642467512097455, 0.5627960387431232, 0.6533981744627726, 0.5327877424444232, 0.523148190302002, 0.19994239967759708, 0.20280355738498224, 0.43394506886592776, 0.2065603720144722, 0.17640861828158072, 0.19616009977779947, 0.17375607963282513, 0.19383558826695013, 0.19272325606282825, 0.17415782936186242, 0.1869348441699814, 0.20154233422333934, 0.17634209837041448, 0.08282142330032205, 0.08964306391086352, 0.08153285370835983, 0.07134688380678944, 0.08042657117197194, 0.08738775783237795, 0.0824195739904019, 0.08852554848683869, 0.07434790849436901]}, "mutation_prompt": null}
{"id": "08206a02-f186-4df9-b3da-95172061587a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic scaling to perturbation range for refined local search balance.", "configspace": "", "generation": 61, "fitness": 0.32810016412025866, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.23.", "error": "", "parent_id": "e8d5bb03-8903-4941-93f1-5d7ea7802113", "metadata": {"aucs": [0.7583618671789429, 0.7691767993814255, 0.7905072159994063, 0.7311472350509605, 0.7673534029664527, 0.7683148821533774, 0.7655845527407441, 0.7540500834917301, 0.7569186016118424, 0.408447101539809, 0.48803950158527665, 0.4705552311693757, 0.4926180023638208, 0.34384132043579074, 0.42036360132868866, 0.4360003069148355, 0.4521386505321491, 0.4588308045107695, 0.12134439489833004, 0.09622742002329887, 0.115620263761672, 0.08994549415413045, 0.1021383051627327, 0.12781593766061083, 0.19341498629052922, 0.11723452457750594, 0.14221341124493558, 0.09141833620805406, 0.08836739211908895, 0.10130139189365761, 0.12251641747355502, 0.11647592257922368, 0.1010609611904627, 0.12186662775759338, 0.09688055431128428, 0.10288304640718138, 0.8807778404978527, 0.8775799620061973, 0.8944543015044037, 0.8747346079287475, 0.9446438929763427, 0.9204102857564592, 0.9579085806493436, 0.8811548651059403, 0.9236160926838853, 0.37747110441568676, 0.43358215202803907, 0.4675336490224493, 0.4221013466219541, 0.3990331836073685, 0.45127578601814855, 0.37437957805073385, 0.4190204786007431, 0.40667113789035014, 0.6793005578437568, 0.7181584350199509, 0.6841943799645627, 0.7154897814794772, 0.6483104875347964, 0.2043018284267275, 0.7103009340736317, 0.7033680889498599, 0.7214004021084671, 0.2156210499034119, 0.18148047979110082, 0.19095920711572634, 0.18847278797225575, 0.19723085663736095, 0.2064255913301417, 0.3544820530404311, 0.18106756829757864, 0.19971306968143177, 0.25504846930370095, 0.19329243753175218, 0.17495825280173172, 0.181166290772506, 0.22314111368709777, 0.22394493734044696, 0.2304776406753536, 0.1477983874874682, 0.23464818604005322, 0.17878431757701563, 0.2093219848574357, 0.19815423044099312, 0.27531652097639925, 0.2139216182255591, 0.1654183793983217, 0.2385265565401954, 0.15223151195406937, 0.16980424152846463, 0.30878956588049467, 0.2747753281920764, 0.3903416900783876, 0.4691391941870021, 0.26745686454878537, 0.06706219421680071, 0.3507543308724079, 0.33973030285749917, 0.24704468315525407, 0.09386072238448617, 0.07423312315002217, 0.08880793520114982, 0.1326213349248927, 0.13003486765930306, 0.13001083590965268, 0.062179802653950955, 0.09953946688085435, 0.13450978643749478, 0.19153242528148318, 0.20579285053501095, 0.24329580319625776, 0.25012548418191227, 0.22790929342882904, 0.22174475460323428, 0.22602978067919177, 0.19359404642232214, 0.2873026946685605, 0.5350208533356657, 0.5441455435090077, 0.5724625345039944, 0.5990863017132309, 0.5740878312806872, 0.5426385477933863, 0.6244419618476642, 0.5281514693198979, 0.5046666878427741, 0.11504008241827446, 0.10295850150582553, 0.11165814171888855, 0.1146538633554759, 0.14157236378333238, 0.11559476908226063, 0.1170422020426678, 0.09459612747177093, 0.08192990672741651, 0.21304889498504398, 0.18378359852708626, 0.24904874271469968, 0.2294329440734998, 0.23170476720440547, 0.17855806536498875, 0.24241707363019782, 0.21178624343856622, 0.23321980963423516, 0.35333535327827603, 0.2501119268669145, 0.3519721981230549, 0.3641081262674235, 0.35034503258728467, 0.3355908051600177, 0.4147667120233999, 0.4012187510068016, 0.37518456940516753, 0.28343320070236044, 0.2795046965417418, 0.2538515795327201, 0.26731874839156655, 0.25128330937203414, 0.2826639558425965, 0.2853568203805461, 0.278017133059938, 0.26487602212643735, 0.20989378786068935, 0.19186019118633912, 0.21777491806713356, 0.19463043156955362, 0.20394220841191724, 0.1920800012503422, 0.26634319184346145, 0.20537650314886002, 0.21120562979296797, 0.19948092743617185, 0.20600048458954412, 0.22014867329763743, 0.20435991155915256, 0.19196445797805395, 0.37335327310297795, 0.1975401805684539, 0.1944732673532492, 0.20812183290612807, 0.7365583531219635, 0.6836381062498856, 0.8300262515145866, 0.2050719309455762, 0.6633620138576461, 0.6478940970352542, 0.6010776881396029, 0.5923115616237482, 0.2007860459212708, 0.6308709854108037, 0.3449739977234113, 0.6437169446737271, 0.6246859955463966, 0.5295720359599891, 0.4833996497241876, 0.20242251797947042, 0.20381635606554938, 0.20795639875876704, 0.19493568042168585, 0.192551252687436, 0.18816276678723087, 0.1815434876816262, 0.18887502845869863, 0.18491960162734222, 0.18687257375547073, 0.21146327991308078, 0.18844372009981925, 0.08173166056521952, 0.08439027644434516, 0.08557250361989133, 0.07823693438928403, 0.09105588096855188, 0.08172902700101325, 0.0783607410649565, 0.07615133982930455, 0.07648693046278354]}, "mutation_prompt": null}
{"id": "771cdaff-fc62-432d-8041-6617803e8ec7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic scaling to perturbation range for refined local search balance.", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "08206a02-f186-4df9-b3da-95172061587a", "metadata": {"aucs": [0.7583618671789429, 0.7691767993814255, 0.7905072159994063, 0.7311472350509605, 0.7673534029664527, 0.7683148821533774, 0.7655845527407441, 0.7540500834917301, 0.7569186016118424, 0.408447101539809, 0.48803950158527665, 0.4705552311693757, 0.4926180023638208, 0.34384132043579074, 0.42036360132868866, 0.4360003069148355, 0.4521386505321491, 0.4588308045107695, 0.12134439489833004, 0.09622742002329887, 0.115620263761672, 0.08994549415413045, 0.1021383051627327, 0.12781593766061083, 0.19341498629052922, 0.11723452457750594, 0.14221341124493558, 0.09141833620805406, 0.08836739211908895, 0.10130139189365761, 0.12251641747355502, 0.11647592257922368, 0.1010609611904627, 0.12186662775759338, 0.09688055431128428, 0.10288304640718138, 0.8807778404978527, 0.8775799620061973, 0.8944543015044037, 0.8747346079287475, 0.9446438929763427, 0.9204102857564592, 0.9579085806493436, 0.8811548651059403, 0.9236160926838853, 0.37747110441568676, 0.43358215202803907, 0.4675336490224493, 0.4221013466219541, 0.3990331836073685, 0.45127578601814855, 0.37437957805073385, 0.4190204786007431, 0.40667113789035014, 0.6793005578437568, 0.7181584350199509, 0.6841943799645627, 0.7154897814794772, 0.6483104875347964, 0.2043018284267275, 0.7103009340736317, 0.7033680889498599, 0.7214004021084671, 0.2156210499034119, 0.18148047979110082, 0.19095920711572634, 0.18847278797225575, 0.19723085663736095, 0.2064255913301417, 0.3544820530404311, 0.18106756829757864, 0.19971306968143177, 0.25504846930370095, 0.19329243753175218, 0.17495825280173172, 0.181166290772506, 0.22314111368709777, 0.22394493734044696, 0.2304776406753536, 0.1477983874874682, 0.23464818604005322, 0.17878431757701563, 0.2093219848574357, 0.19815423044099312, 0.27531652097639925, 0.2139216182255591, 0.1654183793983217, 0.2385265565401954, 0.15223151195406937, 0.16980424152846463, 0.30878956588049467, 0.2747753281920764, 0.3903416900783876, 0.4691391941870021, 0.26745686454878537, 0.06706219421680071, 0.3507543308724079, 0.33973030285749917, 0.24704468315525407, 0.09386072238448617, 0.07423312315002217, 0.08880793520114982, 0.1326213349248927, 0.13003486765930306, 0.13001083590965268, 0.062179802653950955, 0.09953946688085435, 0.13450978643749478, 0.19153242528148318, 0.20579285053501095, 0.24329580319625776, 0.25012548418191227, 0.22790929342882904, 0.22174475460323428, 0.22602978067919177, 0.19359404642232214, 0.2873026946685605, 0.5350208533356657, 0.5441455435090077, 0.5724625345039944, 0.5990863017132309, 0.5740878312806872, 0.5426385477933863, 0.6244419618476642, 0.5281514693198979, 0.5046666878427741, 0.11504008241827446, 0.10295850150582553, 0.11165814171888855, 0.1146538633554759, 0.14157236378333238, 0.11559476908226063, 0.1170422020426678, 0.09459612747177093, 0.08192990672741651, 0.21304889498504398, 0.18378359852708626, 0.24904874271469968, 0.2294329440734998, 0.23170476720440547, 0.17855806536498875, 0.24241707363019782, 0.21178624343856622, 0.23321980963423516, 0.35333535327827603, 0.2501119268669145, 0.3519721981230549, 0.3641081262674235, 0.35034503258728467, 0.3355908051600177, 0.4147667120233999, 0.4012187510068016, 0.37518456940516753, 0.28343320070236044, 0.2795046965417418, 0.2538515795327201, 0.26731874839156655, 0.25128330937203414, 0.2826639558425965, 0.2853568203805461, 0.278017133059938, 0.26487602212643735, 0.20989378786068935, 0.19186019118633912, 0.21777491806713356, 0.19463043156955362, 0.20394220841191724, 0.1920800012503422, 0.26634319184346145, 0.20537650314886002, 0.21120562979296797, 0.19948092743617185, 0.20600048458954412, 0.22014867329763743, 0.20435991155915256, 0.19196445797805395, 0.37335327310297795, 0.1975401805684539, 0.1944732673532492, 0.20812183290612807, 0.7365583531219635, 0.6836381062498856, 0.8300262515145866, 0.2050719309455762, 0.6633620138576461, 0.6478940970352542, 0.6010776881396029, 0.5923115616237482, 0.2007860459212708, 0.6308709854108037, 0.3449739977234113, 0.6437169446737271, 0.6246859955463966, 0.5295720359599891, 0.4833996497241876, 0.20242251797947042, 0.20381635606554938, 0.20795639875876704, 0.19493568042168585, 0.192551252687436, 0.18816276678723087, 0.1815434876816262, 0.18887502845869863, 0.18491960162734222, 0.18687257375547073, 0.21146327991308078, 0.18844372009981925, 0.08173166056521952, 0.08439027644434516, 0.08557250361989133, 0.07823693438928403, 0.09105588096855188, 0.08172902700101325, 0.0783607410649565, 0.07615133982930455, 0.07648693046278354]}, "mutation_prompt": null}
{"id": "0bb1bca2-9e90-49bd-9e80-6f651f965da3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * abs(self.fitness[i] - func(np.mean(self.population, axis=0)))  # Line changed\n            for _ in range(self.local_search_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive mutation scaling based on relative fitness improvement to enhance exploration-exploitation balance.", "configspace": "", "generation": 63, "fitness": 0.25609507457823943, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.26 with standard deviation 0.23.", "error": "", "parent_id": "08206a02-f186-4df9-b3da-95172061587a", "metadata": {"aucs": [0.6946473846175706, 0.678386637489717, 0.675685404333735, 0.7080174941837487, 0.721954203938372, 0.6909418148050359, 0.6607806082511369, 0.6814432753133147, 0.6845116645737409, 0.27301501016172625, 0.407167277089739, 0.3573466942880711, 0.3897065743850151, 0.3911695307439276, 0.37449434567158424, 0.3929680447848315, 0.3823561535232115, 0.31321607327870304, 0.07773834393975343, 0.08024305063761783, 0.09517081227079982, 0.09135496575345792, 0.07671786690624793, 0.09094870234657315, 0.0840983343015339, 0.08241967097135916, 0.08541684644295033, 0.08944762303284237, 0.06723553670120419, 0.07404462894416086, 0.09153109099205325, 0.07188316981128096, 0.07619856874258091, 0.0771595682670364, 0.06790965609054944, 0.08658301827564141, 0.9967578829555734, 0.9942628350780247, 0.9925917002580926, 0.9884589970728461, 0.9849716316199385, 0.9976588649504213, 0.9908046772441355, 0.9960280642265005, 0.9953343312266822, 0.30455863469505673, 0.3342584750526396, 0.2933700743341392, 0.34084083126066866, 0.2793053675173959, 0.29905413090567945, 0.268837869555986, 0.2548735820279193, 0.3054436330793966, 0.6209130663199207, 0.6082420817544918, 0.571777079698051, 0.6127762830716145, 0.5855593868540386, 0.1920294929056663, 0.5260587781137478, 0.5379870337798098, 0.5549947624340892, 0.1411943673234597, 0.16590808125145629, 0.12198629645920622, 0.1229695267098303, 0.1231338504230216, 0.13455720120695547, 0.11031153591062814, 0.1357384630609415, 0.1478874250130281, 0.1626807675090004, 0.12516895130823646, 0.10349210788409113, 0.17500487296970346, 0.16990779439691284, 0.11712652183745598, 0.17636466713154664, 0.13818823435113714, 0.1265074561330497, 0.20813002044509987, 0.013121626083218874, 0.07636933413901936, 0.12996641485390337, 0.03365154590535113, 0.0327178221589709, 0.05989185648291373, 0.09093361575258807, 0.020831362878751647, 0.235537703417264, 0.28416359006510694, 0.134176696399387, 0.12356068340949022, 0.1689364676526065, 0.08828753794375677, 0.08281653265376576, 0.20159175311933208, 0.06195430613145614, 0.048836694277378356, 0.037305046184557766, 0.037520674000756316, 0.05951194261930248, 0.06051118262170585, 0.05063634261230687, 0.05100018592773359, 9.999999999998899e-05, 0.06776795472348385, 0.15960378561553645, 0.1622322743453195, 0.17712443362625785, 0.1521476718279462, 0.17779216480289284, 0.23909871537492744, 0.17809595884127571, 0.140612529425994, 0.18092940931346446, 0.6024919825955766, 0.6484273748246896, 0.5779416813893686, 0.6034188416876274, 0.49502688294427444, 0.5051883411808924, 0.45334543150331796, 0.5468053458532195, 0.4776381211815115, 0.08308767359406377, 0.07091739259820373, 0.08593020921041461, 0.08725590931604854, 0.07960442246057486, 0.07685255064719765, 0.09110737884364484, 0.07882670867628239, 0.06821524061621076, 0.1696086297976679, 0.11934795543977894, 0.14122356272716774, 0.18924871293712098, 0.20052222695146327, 0.13740784523979876, 0.16707104458634603, 0.27641696443569097, 0.11866158028865825, 0.284518232577608, 0.31770454772297296, 0.36099499061919016, 0.30499038339528184, 0.30171663432687623, 0.31751205656517634, 0.34524677572299445, 0.30340407607391817, 0.29941834418207036, 0.2603820124234193, 0.22799447813656804, 0.23985009505372146, 0.273525211740168, 0.21049276956695262, 0.27769720722285796, 0.2671860596750435, 0.2300073956689569, 0.2748825903998552, 0.1830357036042909, 0.17612523790453183, 0.1733968392636458, 0.1813767065222175, 0.17587974459050948, 0.18751867450551907, 0.1751219707027678, 0.17265718076996328, 0.20104437571408773, 0.24317633433127117, 0.17847815153396263, 0.17506284608967015, 0.17526378125945752, 0.17633823268997695, 0.1874608841572304, 0.17580134379330925, 0.17624964666633347, 0.18703849706741937, 0.1575682725360864, 0.1542470489753177, 0.20322154038024742, 0.17666777144650236, 0.17688692051165456, 0.17118052513737236, 0.17245013533139686, 0.15160663621794523, 0.45109925333220346, 0.1821768805293127, 0.1649964354315141, 0.18501035666082644, 0.13786818162454584, 0.13829999044572816, 0.2727500749735312, 0.1987065808756996, 0.1968485222757015, 0.20574942652413386, 0.16982446961633835, 0.18817565711638495, 0.18433730782777535, 0.2084105289329896, 0.19758308924118995, 0.20236541047325296, 0.1910100673142282, 0.1963234697508639, 0.19888275620379348, 0.06516136757781732, 0.06672204910569013, 0.07408081321947224, 0.07201717092511406, 0.07687735051859634, 0.07256534716631435, 0.06011561976208213, 0.06976904078329282, 0.07758686602236409]}, "mutation_prompt": null}
{"id": "65168e12-15b1-4643-badd-20e06e23eb93", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive local search iteration based on evaluation progress for enhanced exploration-exploitation balance.", "configspace": "", "generation": 64, "fitness": 0.36521712754705576, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "08206a02-f186-4df9-b3da-95172061587a", "metadata": {"aucs": [0.7651670519707651, 0.8142977948712087, 0.8149903858690266, 0.8196247037438897, 0.7747064739024696, 0.7984836103681261, 0.8094158425452789, 0.8155265187579477, 0.7754780846296916, 0.5874386179669495, 0.5978185918163376, 0.5938502452104517, 0.6043890765734462, 0.5781578147057811, 0.6045671370188312, 0.6094618427579176, 0.5705083482943016, 0.5820625906998336, 0.3029464679858306, 0.10944856751443133, 0.2489666731083996, 0.12452917362508797, 0.11204620781622232, 0.12715804312769996, 0.16815821785814045, 0.120695215613839, 0.11296080325847724, 0.1056920656768694, 0.12081590430610978, 0.1151942576105508, 0.11100173294604387, 0.1892463618897392, 0.113440430537744, 0.09266533056264215, 0.11157727921236382, 0.11638687499247047, 0.9159891643797395, 0.8985236085714338, 0.9137765431936884, 0.8663933731285902, 0.8784600764704052, 0.9646067068451195, 0.905783716613274, 0.8973160257529047, 0.9408158112995415, 0.43435858869580835, 0.5356804738289713, 0.46742331675866056, 0.4044275284149166, 0.47178804448108147, 0.39515984586077924, 0.48160200080691284, 0.4168045994159708, 0.40568169619772776, 0.7758947968301048, 0.698225246386009, 0.6751472607484732, 0.7552478045963201, 0.79133662905106, 0.7912692850488483, 0.7501212481517365, 0.8139112028930304, 0.698923060482576, 0.19331861909440728, 0.21129984914676092, 0.22273976830932896, 0.23709762749462038, 0.4346108821969006, 0.22073356575329983, 0.19634553441990976, 0.19326638547715513, 0.22919653930421724, 0.18369909872257184, 0.186498073365017, 0.18021463263922377, 0.18879526807076252, 0.22343046104276032, 0.2195279705829648, 0.19579521521912757, 0.21275481183157652, 0.18723774162230622, 0.2046625873874658, 0.4459931196029224, 0.22445985231648669, 0.24098504041106394, 0.23626931457578726, 0.23036147869258528, 0.4144927700408474, 0.2089351261626382, 0.3658098254055372, 0.32159776276362906, 0.34301070287038604, 0.30231770697284044, 0.36991412371874033, 0.3618292662314545, 0.2658351542674472, 0.3643253783301088, 0.4682831409394762, 0.34854464646687977, 0.047123193573665456, 0.1371193763727543, 0.1817112056782445, 0.18337981353985933, 0.14638433770926718, 0.19388400034349507, 0.2318900242851636, 0.13244611266779027, 0.15197932598662278, 0.19454919894708467, 0.3303156107742208, 0.2409608353442062, 0.2406810458435541, 0.29377230671354915, 0.2621032949775316, 0.2122836400011735, 0.352718957155602, 0.22383977138845346, 0.5878880211797346, 0.5127630523086979, 0.6353817723896729, 0.4820190479794768, 0.5112626357626123, 0.6864732847777204, 0.5904660943273032, 0.5354908154953146, 0.7329954667915557, 0.11131461588747138, 0.13661399238015182, 0.10249853010000043, 0.1211656629931045, 0.11756036213838994, 0.11115126525702346, 0.12439210118778177, 0.09480461866515999, 0.1161351681078937, 0.2032225044348961, 0.20135304194494597, 0.1946619627617885, 0.21225019365970543, 0.23675121843256963, 0.2155589328383829, 0.19643946282186797, 0.19237983200816233, 0.22569558259013733, 0.43027803621361427, 0.41912234869719, 0.4426150947778389, 0.4847861069347882, 0.47439861490422297, 0.4286264075974143, 0.5035463312804251, 0.544893929251365, 0.4885448946087566, 0.3742812600265373, 0.3935342458245825, 0.2840933828520247, 0.37325233423660176, 0.3764485597534549, 0.3486763279886538, 0.3496273189646778, 0.36506195572967504, 0.3906022278583341, 0.19658957864551962, 0.19569032779131912, 0.20536631800420868, 0.18137649577723713, 0.2069150824421213, 0.23450379315252046, 0.19100125150678182, 0.19240561153427838, 0.21189702886748918, 0.21281722798351188, 0.20975942871574238, 0.2917667862852109, 0.18815009104622205, 0.23575668601805388, 0.21808021017917967, 0.1887510949210025, 0.21638214844104042, 0.21336963966582312, 0.7694877712078372, 0.1811895267241086, 0.7396157875526924, 0.19153211254793245, 0.7714836418327315, 0.7112261628941597, 0.19499536542473161, 0.597323399938092, 0.7358979118310358, 0.20378652526826213, 0.7297841954397352, 0.7507193790562153, 0.5874855701203432, 0.589793222330304, 0.6912580254430868, 0.3289734631961809, 0.16711901425431874, 0.7004611072846026, 0.18864815805750212, 0.17245221128334165, 0.18458977373830898, 0.17651170756434398, 0.18991151705722886, 0.2011299318233234, 0.19526330885128496, 0.19510845429844592, 0.18752281437061014, 0.08738349273003221, 0.07515750013703493, 0.07490189001957426, 0.0882270904058522, 0.08647077103483025, 0.08976238418105043, 0.10111976511023624, 0.07499076964546825, 0.06908532281021795]}, "mutation_prompt": null}
{"id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 65, "fitness": 0.37504207727183886, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.24.", "error": "", "parent_id": "65168e12-15b1-4643-badd-20e06e23eb93", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "d67d7be5-bfca-4033-8310-6b2312057e40", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "0bfeafe4-dd66-41ba-af3e-82dba00cc53a", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "897d3b28-1b3d-45b5-a266-6b0ae7640276", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance diversity by adjusting mutation strategy based on population's fitness variance.", "configspace": "", "generation": 68, "fitness": 0.37504207727183886, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "a193a53e-b231-4cbb-afa0-025ad46d149d", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            self.f = 0.5 + 0.5 * diversity  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance local search efficiency by incorporating adaptive mutation factor adjustment based on population diversity.", "configspace": "", "generation": 69, "fitness": 0.3482770490753206, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.23.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7619375337980114, 0.7575136121215519, 0.790901410758831, 0.7351481220031281, 0.775696326585231, 0.8118788506446022, 0.7769511886850728, 0.7784018551667219, 0.7487119803409942, 0.4164164318196619, 0.43412575718454605, 0.5670123744248237, 0.5571231910706571, 0.5826333897325864, 0.5572441039504161, 0.479521710368496, 0.5350646477759833, 0.5230991301001949, 0.13377502083044635, 0.11100311258106943, 0.2616176975284993, 0.12827033103598073, 0.22122237396748023, 0.1264687479606269, 0.1979530318223951, 0.1314041426838266, 0.1355384651929169, 0.24971679449856488, 0.17382147443831786, 0.11554514895006485, 0.11801320929399195, 0.16259405664311377, 0.11302706057424017, 0.11426899954337733, 0.15231733293117122, 0.11862273983429017, 0.9271439396132695, 0.9167576131608824, 0.917531066307305, 0.8294140484923176, 0.9444435411195137, 0.9574326407354384, 0.9254837429703143, 0.9601926134180854, 0.9348926219206628, 0.440850183036521, 0.4446285505274623, 0.4852216317800062, 0.5669903781515937, 0.5125578264922155, 0.38741955895828073, 0.4432505074244123, 0.4055407125869571, 0.5307545216794542, 0.6300302785603031, 0.6957681198723428, 0.7786338694366637, 0.6947536187102594, 0.6620140791143807, 0.740976441690701, 0.6926181628207859, 0.7077324810342798, 0.4685806872989474, 0.32114759481103494, 0.32515180980497715, 0.27054244679120254, 0.2801288396131527, 0.23958634538389278, 0.31398059436090875, 0.35864056329336313, 0.33920418901728366, 0.4554252308358011, 0.2787475957133586, 0.2701125134639383, 0.2236370166705035, 0.3413096248496339, 0.23219682858050605, 0.211583425884471, 0.41202449743588954, 0.29535584237829593, 0.2216182282104554, 0.22613139075389121, 0.29809149974637206, 0.2497519290538357, 0.2462819030940947, 0.19754557933082162, 0.27228088715408494, 0.23587030422053068, 0.15915011821216307, 0.149428527642685, 0.35396944596198165, 0.2884818811984735, 0.26865787291083976, 0.22944019840243712, 0.2742019157593826, 0.3772204256426598, 0.495181530039253, 0.37420010513349167, 0.5029254290068306, 0.0677115126630703, 0.2045435004801499, 0.12757882982492774, 0.1947287100135875, 0.1492429663126129, 0.10694406142485624, 0.1383497262514114, 0.11866882686952307, 0.07446060783337238, 0.2891317688353938, 0.2504335172706289, 0.26781630481800844, 0.2694404259722468, 0.299572556028179, 0.29723165686762576, 0.22534002944038445, 0.23580991810340735, 0.25977152202508347, 0.6299762289816867, 0.6990596813070182, 0.6410150471046806, 0.5859560191961961, 0.6415095718696031, 0.5133753515903604, 0.5542700796987605, 0.5984174316052855, 0.5905495995583125, 0.10893725929567954, 0.11708883152573357, 0.11003045374468312, 0.086033952600165, 0.1127757797415967, 0.0870226555681003, 0.12268848335931437, 0.12720905235053792, 0.10561618242131676, 0.24402054095818848, 0.20692340678199128, 0.1694273421610576, 0.21720873396239027, 0.19155136206639534, 0.18388683523304195, 0.19085088335561917, 0.17632628780766313, 0.18463327086700698, 0.3275511909161719, 0.32361522473829374, 0.37500684579982135, 0.36639454181388864, 0.37108618455211817, 0.41962815821565336, 0.33344106537194773, 0.38812076967142806, 0.40391506240299346, 0.2608778210742667, 0.25312716369269606, 0.18225769030245875, 0.24544919459193248, 0.30364507395662976, 0.2473645664577412, 0.2440089483114397, 0.29882184370691545, 0.29327229116728826, 0.19553440450203174, 0.18505117597897325, 0.21020183776125656, 0.19324093935935194, 0.17568951885572115, 0.18798497133218728, 0.20196492933669952, 0.18576627417819325, 0.1855688582640641, 0.30004932152273167, 0.1866816256408541, 0.2925481108736451, 0.3166045904775273, 0.21271419982772755, 0.27170435173668717, 0.19077342352421756, 0.19775806388570216, 0.18398237525587502, 0.6444930665862019, 0.19269692145633222, 0.6944130762397771, 0.20034166031689404, 0.5809369568023959, 0.20010579670798823, 0.5566006501929992, 0.7592759250414471, 0.20418914385016373, 0.20455613056312805, 0.20694987876206927, 0.6233305875801947, 0.627582953444249, 0.6448761056186294, 0.6113102275064171, 0.10365258837920577, 0.701786010226708, 0.1946961585808744, 0.19676814896665173, 0.1897997150813756, 0.19139001885682128, 0.18537871246547255, 0.18111756533508805, 0.18965100745142294, 0.18609253354717525, 0.19659471476014911, 0.19537666503086504, 0.08564680758159249, 0.08127447761947404, 0.06863589385670765, 0.07988607195343578, 0.0810877621186441, 0.09489067642042104, 0.08809181199275262, 0.08151955026148827, 0.0729283301923137]}, "mutation_prompt": null}
{"id": "1a7e6a77-9eed-439d-a889-0b6b8be88ee6", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            fitness_improvement = 1/(1 + np.absolute(best_fitness - self.fitness[i]))  # Line changed\n            perturbation_range = 0.3 * fitness_improvement * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance local search exploration by adjusting perturbation range based on fitness improvement rate.", "configspace": "", "generation": 70, "fitness": 0.37504207727183886, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "4f35a054-3ff0-41c7-a7f2-a6d8b509549f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "3500de13-3d37-4b6f-b048-87f3fe290308", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)**0.5  # Line changed\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance exploration by adapting the differential weight based on both diversity and evaluation progress.", "configspace": "", "generation": 72, "fitness": 0.3391536815622799, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.23.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7321511288393694, 0.7525596126114388, 0.7856733316209515, 0.6902896754501048, 0.7432137773053573, 0.8002739863260572, 0.7400754291032456, 0.7738948731063895, 0.7370014617833185, 0.22732956351764222, 0.36975015984863246, 0.5124591367048157, 0.4651873121790071, 0.4128208357800818, 0.455688544587739, 0.5011297550876034, 0.48500672694278846, 0.38426529734176385, 0.1339926266458661, 0.12886764129843375, 0.12222298408161636, 0.24807999093764943, 0.13548639260636486, 0.23586185274669802, 0.2503323110914861, 0.27727462802871927, 0.11568037545025722, 0.11228403565923839, 0.09356613447856166, 0.128675238437718, 0.11152055851265374, 0.11196221518529037, 0.12089178024311897, 0.11884153984723977, 0.19558266998596463, 0.10923328126402032, 0.9414033342735576, 0.9328104162861586, 0.9133349155798461, 0.9403435904799494, 0.9651388278133854, 0.9218756376071977, 0.8971518268982671, 0.9328339549782871, 0.9375020122176683, 0.390690924001027, 0.3555825855947268, 0.5373186813633699, 0.5298599732149194, 0.49311147622212537, 0.4488537463073984, 0.3632339975943232, 0.43849190054101495, 0.5178391778115066, 0.6602427584333985, 0.5568354367831371, 0.74036388157808, 0.6388631590041793, 0.6727195970293172, 0.720217388488985, 0.6394339130278083, 0.7198437593582439, 0.6757176427028173, 0.41662915613790086, 0.4038622780429889, 0.43303941968188875, 0.3555543968630015, 0.35960901594900196, 0.31997960511390133, 0.4213063782210037, 0.3249229491232669, 0.2748260600460539, 0.3755956028192827, 0.24436325851703544, 0.17749481592141414, 0.2566798107866154, 0.46261369459261226, 0.21851259282514823, 0.4226066960784758, 0.277494705776579, 0.23796545259445057, 0.13431993677025167, 0.106998013650901, 0.20831740270821153, 0.18103202881444858, 0.18219974208289047, 0.23793229239552316, 0.0749425878507618, 0.11388118540086345, 0.2576312590298062, 0.15398181547808576, 0.16540058421450776, 0.22371573806631517, 0.18109515604017934, 0.17523055780602625, 0.1747947120261053, 0.22219251400798068, 0.2154987437926249, 0.2935741504319943, 0.1257951694151136, 0.02988920873419354, 0.08778931808548185, 0.08276708397148691, 0.1424620819967074, 0.15221782801553418, 0.08125241892693125, 0.12296609908950418, 0.11314187735663217, 0.21568793658802166, 0.2555226901376625, 0.2829675032002369, 0.2855822138260887, 0.2878785837003215, 0.3165665062134103, 0.19960865607620049, 0.20018348424017718, 0.240164840625688, 0.605055770465498, 0.6622181450417888, 0.593092935541513, 0.6341807037375992, 0.6667022512897778, 0.5936049711780125, 0.6353409234332483, 0.7053930830972737, 0.6373325122262321, 0.13036141268667434, 0.1206473820529329, 0.11025165708435447, 0.12114575670305783, 0.09601242309597724, 0.10653725409063519, 0.11944039248963523, 0.10557231084132979, 0.09610988011563715, 0.18419724806530435, 0.22374724033635907, 0.21315895128061124, 0.22622803327254337, 0.20350644221503944, 0.21857131454531253, 0.20145735704124856, 0.19864327243217894, 0.21841720888582827, 0.3529934629959939, 0.3089370882801491, 0.32438027812173764, 0.36267676778899804, 0.32700553096714735, 0.4288156780943937, 0.3258589482214611, 0.3687261363058295, 0.3495022084661674, 0.22881536104996036, 0.20721150067453975, 0.2755782451624824, 0.2462326779160562, 0.2591816190824283, 0.2739281081554579, 0.24047212980473598, 0.3028843275837838, 0.27431888044396324, 0.17770081136558347, 0.19420074575532575, 0.20505120628918871, 0.19093030712443648, 0.17909767203527904, 0.17868845804105749, 0.17545931674480275, 0.1774230594893792, 0.21171380984895172, 0.19833892197901049, 0.2261263485924354, 0.2136049909220583, 0.49759862903904084, 0.37703644259854585, 0.2176851210124262, 0.19151388436065409, 0.19449702112547296, 0.42467572754786986, 0.6894224057767866, 0.18105179050277354, 0.6339922339273958, 0.7225318180792248, 0.19685790256059288, 0.1962473503590486, 0.18559791553490945, 0.6845484019168437, 0.6974282863563823, 0.20449863595783058, 0.7326490528973468, 0.5931110995995494, 0.6543664780072563, 0.5254706355924093, 0.20161703443012158, 0.162152233714566, 0.6916220056843303, 0.16538206199054006, 0.18496463259766016, 0.2388763562372278, 0.18975105034732598, 0.19494228662894864, 0.18855262942879858, 0.20235602436210554, 0.1897148966663189, 0.1852006528081701, 0.20159416810270503, 0.0845281537931929, 0.0843188857448709, 0.07849111651432628, 0.08721181999770633, 0.08552092755883756, 0.09254462745779723, 0.07039869681574473, 0.0700757581828495, 0.0848377454021445]}, "mutation_prompt": null}
{"id": "449a4de4-bc7a-4ab1-a768-8abef4ad485f", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "d248a2f9-bc9f-41db-94f9-4c9abc3631f5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.normal(0, perturbation_range, self.dim)  # Line changed\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance local search by using a dynamic Gaussian perturbation based on diversity.", "configspace": "", "generation": 74, "fitness": 0.36639264051818793, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7661931203300267, 0.7656823013248565, 0.7821068887116847, 0.7603666515929144, 0.7878279176894827, 0.7943842449391485, 0.7786052531474986, 0.7780269065803584, 0.7679583651655173, 0.5335150295264071, 0.5317270779257111, 0.6044601431526722, 0.553487668896629, 0.597122027545997, 0.6140833896262858, 0.5565069792199469, 0.5887822483670764, 0.5646341610030089, 0.20444712052928427, 0.20050225939642952, 0.10989113146491092, 0.12267781760027952, 0.177813945043784, 0.10681241473929481, 0.1393693059596528, 0.12562387858090407, 0.20954023334752625, 0.10279189007283662, 0.11809744344305273, 0.1243515587857793, 0.11140155068470103, 0.17121108893164783, 0.12278552301536838, 0.13184735638158163, 0.21251965788484972, 0.12203509149254865, 0.8869568287491931, 0.9225826569604344, 0.9305414821596582, 0.9236221872464959, 0.9421980994463012, 0.9558888533683547, 0.9171889579434167, 0.9460043625785165, 0.9809202509760729, 0.4810562950819832, 0.4584946949470843, 0.5114443640994004, 0.49986045687958836, 0.5246044465830084, 0.5313652955897654, 0.5144554417696532, 0.4926325488274734, 0.547793838613545, 0.7089510183278367, 0.7481097682702967, 0.7360179868891044, 0.7330794062579198, 0.6050253012175375, 0.7257974264208726, 0.7237475971678118, 0.7124679332898014, 0.728536741611256, 0.2936589599332803, 0.37598059434320574, 0.2646645580739624, 0.3957690211892194, 0.35607569212082235, 0.21237724303889127, 0.28570342536107696, 0.38212268921118187, 0.17486424420110924, 0.27229821979182, 0.27772299997910255, 0.21290164723021887, 0.2069162724793998, 0.24915169943559368, 0.26627346022879805, 0.33609996666656994, 0.3355649386175009, 0.2084786460916932, 0.2411736452958435, 0.27937830192981883, 0.12515793664322394, 0.3168459574344318, 0.045528166285745075, 0.2974523343022445, 0.23096214722804775, 0.18473030455123374, 0.3178092440403859, 0.4060157636954992, 0.43352660046760927, 0.37926907958537714, 0.3546853381510169, 0.34953024709521485, 0.25202658934098043, 0.3947504485092548, 0.5444546515125298, 0.5086355409405234, 0.08856626009413249, 0.11122591066135701, 0.07912250406623411, 0.21961062811169452, 0.09408247801567537, 0.3404731019073981, 0.20124818389301768, 0.11215635809155011, 0.14122937417274228, 0.2685673194393373, 0.24260839173415238, 0.3100303604329331, 0.2603128642617275, 0.2780307203857757, 0.31805181992477294, 0.2483943879782271, 0.2620863366539574, 0.2601658693314627, 0.5396724780490862, 0.6067032052937305, 0.6189630161664199, 0.6060379035042323, 0.6745612549007678, 0.656444746035068, 0.6209932540975764, 0.6339777425471256, 0.5729834836540034, 0.11067805279045151, 0.12431034842814392, 0.11646266678624628, 0.12528398255517625, 0.12234336862886286, 0.11810522272414747, 0.11314840947111093, 0.12266357324200328, 0.10584916230503827, 0.17372119192073132, 0.19188858520378826, 0.17236582451515292, 0.18505387370809545, 0.19668492972266238, 0.1753045289952564, 0.18152233339899326, 0.19092372213785935, 0.1930956085903468, 0.40256328274445485, 0.4119251090668772, 0.4172776119842093, 0.3913447856703418, 0.4560522498008813, 0.44655304004115803, 0.3967464877826632, 0.47495756300798564, 0.45794738897762566, 0.3526895299604521, 0.29198700295071356, 0.3380440520276433, 0.3069395356327551, 0.3584501965085771, 0.3427487155305107, 0.2649628183719177, 0.2799028225318141, 0.3412364824930344, 0.2050956690779686, 0.1975570462794456, 0.20942236028538153, 0.18778425542347899, 0.21438902799435522, 0.2290928206317825, 0.19192504563583712, 0.18741451082702565, 0.18092093918362584, 0.3230148971328295, 0.2896263777423258, 0.28109668703737756, 0.2111869833428094, 0.2100614050665176, 0.30685099196101107, 0.3014499926095504, 0.3741746825590495, 0.18571852768799646, 0.18842833857039587, 0.7902388746543975, 0.6132799088359744, 0.20498051727750422, 0.5216165464509686, 0.626371030088706, 0.16715722992921733, 0.6894309980779998, 0.7093634630096635, 0.20278549207156693, 0.20416923355196237, 0.7475099246074501, 0.693947309892293, 0.7440391878225192, 0.633190610827559, 0.20743048042609646, 0.19896172356262665, 0.5860924971590065, 0.1799464033003686, 0.19009831212995254, 0.18215911707079835, 0.18773400719944144, 0.17753012346755748, 0.1820101762850591, 0.1889358337342978, 0.1919003825545349, 0.20501460309495823, 0.07167313278122289, 0.07895543329310006, 0.08981388431222936, 0.08450059256524234, 0.07369467998425427, 0.0836390715174945, 0.07735194986731608, 0.08608351342274145, 0.07886907606744753]}, "mutation_prompt": null}
{"id": "7efdd51b-7d23-4699-8c2a-001ec4de646e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "dab03243-91e8-4b63-903b-ecfb1add9f1b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity * 0.5, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Refine the mutation strategy in differential evolution to enhance exploration capability.", "configspace": "", "generation": 76, "fitness": 0.37504207727183886, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "6935a4e0-e605-4b48-bc92-ef9e5220fecd", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n                self.cr = 0.5 + 0.5 * (1 - diversity)  # Adaptive crossover probability\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce an adaptive crossover strategy to balance exploration and exploitation dynamically.", "configspace": "", "generation": 77, "fitness": 0.23546254645388254, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.19.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7575958678195962, 0.7487179513935052, 0.7638521934243105, 0.7627545722119076, 0.7156215180605433, 0.7321043259451204, 0.7353691044627472, 0.7432508115434416, 0.7277322156795318, 9.999999999998899e-05, 0.003284071397131827, 9.999999999998899e-05, 0.000371807463030005, 0.35430141082334865, 0.2840793163347255, 0.09619540728340947, 9.999999999998899e-05, 0.011051246161337125, 0.40689428670654637, 0.350821284649366, 0.13619846177109685, 0.13548730088827488, 0.3780767279285474, 0.13876273751907353, 0.3184566065734141, 0.2661033527109822, 0.3402981236318037, 0.14180344510468745, 0.279410519969443, 0.1180716016513419, 0.37438419818677626, 0.32400876944804846, 0.13777368267941836, 0.3041066220137315, 0.2832858548039181, 0.29748958747467613, 0.7064207088183154, 0.6811959140517205, 0.2715928242358554, 0.6937146163949082, 0.7629907357844566, 0.6879051737040359, 0.7623492895552888, 0.6583261115367498, 0.7889476369133912, 0.294254783258024, 0.3018676837847376, 0.289408441018167, 0.41454921349358087, 0.3115395786038444, 0.3197448468058356, 0.2709843105200571, 0.290755820064015, 0.33683339477040775, 0.30667727752287377, 0.2016763619162779, 0.2988965321825998, 0.28499642854380836, 0.201702862170283, 0.27719088045358964, 0.41815946462136133, 0.28006922798155953, 0.20857241827612638, 0.14899136141819036, 0.14046680395882416, 0.18922842778876225, 0.19316529444978692, 0.1828596671568573, 0.1360397322791328, 0.18039427912464978, 0.15229746137867528, 0.25025803124774293, 0.17660889608073727, 0.17131301094066198, 0.177375156452947, 0.20040548445173423, 0.17741959967264043, 0.21909311830996425, 0.15545093935146814, 0.1741939486257903, 0.17141333824478988, 0.023758059318653824, 9.999999999998899e-05, 0.002460669722661235, 9.999999999998899e-05, 0.0016394355077029577, 0.020637471435840604, 9.999999999998899e-05, 9.999999999998899e-05, 0.0038836126222513423, 0.06785810256552582, 0.06333164760808208, 0.10288513500262308, 0.1395737019431308, 0.07704598824781206, 0.09130446002588122, 0.08323176942075605, 0.07056095439988053, 0.06609058599410489, 0.014734194180949789, 0.022952683904192805, 0.01829003291703757, 0.023457348527541555, 0.019395082476524883, 0.019366943275856086, 0.031641012612459773, 0.015916015559388486, 0.016408299848148955, 0.10075751503634178, 0.08186907450366854, 0.09847248492547755, 0.11369894620228094, 0.1247502947751038, 0.09586779290783876, 0.09400199232331219, 0.09248250870840724, 0.11839724601081902, 0.43104472239123026, 0.4669619729016117, 0.5092330431888654, 0.46583084802078345, 0.42786279846149977, 0.44343846835676903, 0.4389753725194103, 0.5096520834100917, 0.5040096576442037, 0.06763883752420097, 0.11689145982278348, 0.079432083810003, 0.08389961568449322, 0.06236924399655108, 0.08117830814185178, 0.09534446944003028, 0.06649437976808281, 0.08052763456311784, 0.19482587997663992, 0.22067544889470359, 0.21111606316371168, 0.2519304805613348, 0.18575781259708424, 0.18021334153625412, 0.20547989415386303, 0.16255722215568258, 0.20244046393333426, 0.2317945977936452, 0.21531239737474317, 0.20944770895076625, 0.19894889045720554, 0.22859969125124058, 0.23527091767287134, 0.21835474063882943, 0.2180066952218631, 0.16894974649004202, 0.13748012793087616, 0.15030760765985907, 0.14414231071102535, 0.1717938057469559, 0.18376138929418828, 0.1847066051923969, 0.12062098573528313, 0.14124183439533367, 0.14094760344806967, 0.19255461135278196, 0.18487217806279554, 0.17727750744048476, 0.1833273173888268, 0.18161964782882334, 0.19509922273424662, 0.1881629852423694, 0.1967393121688108, 0.19320169953469835, 0.275601113330152, 0.2124228210628133, 0.2714806322757404, 0.23534727215402396, 0.23488152474099766, 0.2713959465591028, 0.29198122247873803, 0.2304027790270784, 0.3947055094264108, 0.29654462478553056, 0.31383906455708355, 0.5348869072798443, 0.1756290103174042, 0.19642497144064286, 0.38672774436487234, 0.18560829957910407, 0.27667307013095566, 0.5034759433314933, 0.25177296811035776, 0.3353849563123871, 0.3691153427611885, 0.2909291264171414, 0.39013406055072164, 0.48836647754857054, 0.21665387800637714, 0.16854350592491196, 0.38255510191920317, 0.18006817414771592, 0.18218681064419717, 0.222612557395654, 0.19535401142413544, 0.18085762266214855, 0.19199471325497075, 0.1741295038886257, 0.20623442889422083, 0.18746996895662082, 0.07352064071098086, 0.05342870305900982, 0.06097049992372028, 0.06492337041903595, 0.06729088790009574, 0.0638704706128399, 0.07651031446905054, 0.06864619470410105, 0.08660040810111658]}, "mutation_prompt": null}
{"id": "5a0398a1-0b6c-4c79-a2eb-6c96cccd0a25", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n    \n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance exploration by dynamically adjusting mutation scale based on population mean distance.", "configspace": "", "generation": 78, "fitness": 0.37504207727183886, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "26a3de1d-d7ed-449c-8929-c6f33414df9b", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n                self.cr = 0.7 + 0.3 * diversity  # Line added\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive crossover probability based on diversity to enhance exploration and exploitation balance.", "configspace": "", "generation": 79, "fitness": 0.3480981788980512, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.25.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7976099180330842, 0.6760284268993018, 0.7865592745200549, 0.801013306552596, 0.7563436698086357, 0.8164541752881052, 0.7846568469283195, 0.7762919535085755, 0.7684284193644254, 0.3793991863753905, 0.43014422479876535, 0.07301521529152866, 0.6099023164970363, 0.5546502993639343, 0.05842595911211412, 0.05045366400215934, 0.5428200158377541, 0.05736447308799819, 0.11539279768161337, 0.1255362585898121, 0.1263628396168478, 0.12432852603702249, 0.12582262427346536, 0.1019379385409942, 0.3300078147501463, 0.10824125591682565, 0.11595256616102778, 0.1200916034448668, 0.11672925530415268, 0.11897040044809637, 0.10771122648643416, 0.0977254148608836, 0.12460674270363803, 0.12209123439760639, 0.11625505547255977, 0.10534593196073638, 0.7949803208368912, 0.8921769731273843, 0.7543159419303814, 0.8744875219200149, 0.9383328989184391, 0.9287086255609007, 0.9382578678063518, 0.9295576668735941, 0.9372905824650641, 0.3344029377021931, 0.336894365413392, 0.4649808904065025, 0.5702861290799536, 0.4875609737508062, 0.5001027797080629, 0.34841223486485506, 0.35507801837809927, 0.45407657215834973, 0.7816941902670783, 0.7725836733786945, 0.7710650722691891, 0.7505576525234349, 0.36396401295242453, 0.8089153572463863, 0.7809433532386909, 0.7534693946386443, 0.7893986523408095, 0.2265894107213149, 0.21019413904584527, 0.23549859315146782, 0.19916739614402834, 0.1903638081603869, 0.20534666529984713, 0.26325904876740913, 0.2236968372951127, 0.229339418079053, 0.21562697061398006, 0.23458925567501043, 0.38160726119360955, 0.2904750843828878, 0.1979032076555748, 0.20206586378118352, 0.2016328361520766, 0.28576278043924663, 0.20401055807664514, 0.2191219425137938, 0.12811171139945798, 0.41954126996356345, 0.07127135259233852, 0.1601300278448614, 0.16214024797960191, 0.07818491562995422, 0.1953326174965775, 0.15926012783496513, 0.3138350668702198, 0.19227136097303588, 0.43548930880819037, 0.34623282230667596, 0.39061673669932984, 0.4153466117665785, 0.3517123492800094, 0.24870050098181606, 0.16256413436579475, 0.17481530415731816, 0.1490437636944818, 0.062095843547874896, 0.12533421785645538, 0.139852446586874, 0.40951337207539174, 0.19780448109975846, 0.141439377325836, 0.12077178964723623, 0.26998032409846784, 0.30200446250662427, 0.35916659914785376, 0.24630811996690904, 0.39561489951060724, 0.2509169550765531, 0.22638818307234365, 0.19506231820120412, 0.21024683687146117, 0.642959177600943, 0.6485601474832775, 0.6345178138787692, 0.5585537912908152, 0.4750452828719579, 0.5226226844872734, 0.6621293809460735, 0.5184500332355716, 0.6789391734743127, 0.09854780373496719, 0.1228020414024289, 0.10536917112061106, 0.1106522296481256, 0.19352512819559575, 0.13972983800132044, 0.0822010816367611, 0.11019927024239828, 0.12406017796722446, 0.1663919112684341, 0.19776067481242532, 0.30567191108580083, 0.20784749157270987, 0.2383241625601915, 0.2949524025415825, 0.21129085755492183, 0.21206087780538774, 0.18315196791330368, 0.34249060234467743, 0.3057443473738314, 0.3969754992908687, 0.3161274741454626, 0.43753782154858967, 0.4557402475539948, 0.3736720836895183, 0.4489558107895467, 0.3544621861149905, 0.29295548724093856, 0.27098317671295635, 0.3821718707514449, 0.2998690911007812, 0.3087328270585784, 0.2853989638894243, 0.26186974345889324, 0.37274313860545005, 0.35185854691963037, 0.18994472133134754, 0.19733514292727683, 0.197072250925878, 0.2027265091887046, 0.196965382603548, 0.18439834102295516, 0.19164430603172944, 0.19495473487628345, 0.20322980476477992, 0.3581467921316329, 0.22375180666997074, 0.20265739084019418, 0.5416117066949149, 0.20911469640919023, 0.2045326470418024, 0.20984943735292383, 0.1979076431004534, 0.1863142049174602, 0.7834615064177416, 0.1836341360692907, 0.7656528475767765, 0.7655375197786809, 0.2001944750823329, 0.2048448426242091, 0.18829433447725252, 0.6374409252256499, 0.7723199930771997, 0.754421128071106, 0.799397539259582, 0.7847912049916314, 0.7803586263850432, 0.7051028081035777, 0.7382530180763973, 0.8515374300753, 0.7444990095741222, 0.1634195436772521, 0.19320636458018348, 0.18872475700240343, 0.1938938390570515, 0.18808252252982927, 0.19140770639033133, 0.1870313727598828, 0.1853869872507361, 0.2054263634928165, 0.1949008638441705, 0.10091463189502614, 0.08379995336971369, 0.07569909386467466, 0.08714808706981236, 0.08761560091183196, 0.08993940647525345, 0.07431341976378336, 0.1005668861508866, 0.08270794921594204]}, "mutation_prompt": null}
{"id": "118664b2-7efa-46e1-912f-cd17b5dae731", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "e5cc5749-2907-4f97-ba79-60f5ab58fa0e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "840fc878-7b4e-41ea-aa8b-83bff15698e3", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.4 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget  # Line changed\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance adaptive local search by increasing exploration potential through increased perturbation range.", "configspace": "", "generation": 82, "fitness": 0.36982451078334017, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7698406129945887, 0.759211641175568, 0.7876696396283419, 0.776608656532224, 0.7995989503613461, 0.8104972186085335, 0.7885655012735082, 0.7758246494639205, 0.7642348539053048, 0.5473729536231211, 0.5754673964456649, 0.5871184090375139, 0.6143536503392472, 0.5774715960494368, 0.6119041375813883, 0.6109818811316271, 0.5887078427015886, 0.5745185410662966, 0.13643981579681985, 0.11909704904328233, 0.12412621086428444, 0.1225946678843538, 0.16270930866805555, 0.12940348400697343, 0.1926157239288635, 0.20173612998445667, 0.10789606968246013, 0.15516464227820148, 0.11245336184469812, 0.11479155869898583, 0.12075693373976248, 0.13890019511846208, 0.11270687118489897, 0.11042350881016283, 0.10938141846510929, 0.11538530707894101, 0.9293969997231426, 0.9180210254965371, 0.9263454215583662, 0.9096856673545568, 0.9298296452806312, 0.9530142197624457, 0.9023323406253025, 0.9563308636345798, 0.9638593713829415, 0.43658996366045777, 0.4884326399198229, 0.550812800344259, 0.5499628137862841, 0.43745657695844, 0.5016600257912756, 0.4856038916252511, 0.5199655036180069, 0.5106708375085887, 0.6873111387476523, 0.6932293370628212, 0.2125371308348002, 0.7500665786544092, 0.7826839336302976, 0.7449284140828197, 0.6882971582097315, 0.8006709402251362, 0.6880719255939718, 0.3289111840195835, 0.22587868551690404, 0.19596425364850945, 0.3880495626903633, 0.22744333451443632, 0.30136158940749225, 0.39644144333131515, 0.2224872689988151, 0.32435425323567235, 0.21340429426318752, 0.2029511623266217, 0.247896350474756, 0.22825078036486302, 0.49067183664335146, 0.1899844566006179, 0.3750238381403499, 0.17996664934504203, 0.20832241911888927, 0.11594653243662179, 0.3457614002435455, 0.3250017694683478, 0.2843212668521431, 0.28225561897220564, 0.28078861699528956, 0.23183238053776378, 0.28870345169894085, 0.0965146102309764, 0.3416912223868245, 0.4055434273759684, 0.38500013721653215, 0.36094225347376907, 0.2536500051902494, 0.33868590386844877, 0.5336478991500777, 0.3457810198857155, 0.5772504605096083, 0.09498780996878797, 0.08336399485741441, 0.0975369194974155, 0.13235866960739118, 0.12554323058098893, 0.15678690850823274, 0.21779780457197762, 0.06987090929936968, 0.10149613510621769, 0.342488425942723, 0.2517671903524793, 0.21503461101025, 0.2974848629335717, 0.2104877009384588, 0.3237050460993123, 0.2762394228333581, 0.3303232815082626, 0.2602796437787105, 0.6743743959518917, 0.675660147917112, 0.5577344796425164, 0.6805622979835975, 0.5669848382153448, 0.5428824435884014, 0.5868496974986395, 0.6402591181298773, 0.655674990859864, 0.11592372298423326, 0.13450155867221003, 0.13598357464012134, 0.09174874002329958, 0.11918751050372522, 0.10222965077153479, 0.12178465603346755, 0.12137985804807172, 0.12256510588723979, 0.23282124414287275, 0.21772151523616434, 0.2773263233078844, 0.2113026104601049, 0.21791026751330178, 0.17877623635803974, 0.23393967860550424, 0.2180243172355798, 0.1929860855637514, 0.3984699543614997, 0.40115733771005024, 0.38517293778568495, 0.3969962484072236, 0.4627670333426672, 0.5248558443672395, 0.36230724311581464, 0.41060867767231546, 0.46879042267626714, 0.3195231831148382, 0.24221151078846948, 0.37170343240434145, 0.2708358070260942, 0.26351644912631844, 0.36571910448344125, 0.269569320870257, 0.2754595289124663, 0.37802882115061265, 0.2095023452804724, 0.21834529692468896, 0.2113605952473443, 0.18349247194376972, 0.18808816249770766, 0.2014856476695851, 0.18591511841533015, 0.21399130716745363, 0.19788618843363948, 0.20251102112107788, 0.41386750630931113, 0.19220143250341604, 0.21440797031645764, 0.18640432341937907, 0.33074261304974195, 0.32695403680644264, 0.37271742260963103, 0.4082890368176286, 0.7351960469014263, 0.1792828492943459, 0.7634422851172769, 0.6651400353802852, 0.6704062500489423, 0.5478113245464191, 0.192656581383841, 0.7358985849931362, 0.6520104826728217, 0.20565379714285692, 0.660287595672022, 0.7091016694839569, 0.6833877340557902, 0.6170147803183368, 0.6236616596842678, 0.15331282250549716, 0.6997283944325814, 0.16183810719360203, 0.18080783043946647, 0.19940598205625137, 0.18424001312819838, 0.18765090008796526, 0.18692757886116074, 0.1981451024450377, 0.18263513957086075, 0.2355316114885262, 0.2352892221507198, 0.08418440453229181, 0.08034302071617772, 0.0920553118769567, 0.08702014636298083, 0.09679853329169474, 0.09462803094409589, 0.09755634344380704, 0.11725545448057906, 0.08030682227503183]}, "mutation_prompt": null}
{"id": "8fffe1ca-8109-42ba-a2a9-fd69843b62de", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            diversity = np.mean(np.std(self.population, axis=0))  # Moved from another position\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive differential weight scaling based on diversity to improve convergence without compromising exploration.", "configspace": "", "generation": 83, "fitness": 0.36779719601811983, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7925814887789568, 0.7791392100305992, 0.7875507378662749, 0.7660551859070847, 0.7841976054445727, 0.7952327188849587, 0.7761911906394743, 0.801140002110108, 0.786245728228345, 0.5050882517166486, 0.600368988836544, 0.5833139970483929, 0.6224985008470701, 0.5784317686844105, 0.5568621373706109, 0.5448085047463851, 0.6178720899464436, 0.6107823039979795, 0.26427835310000614, 0.20641687269809783, 0.13608684433747786, 0.1271920483882314, 0.13315245346625948, 0.1144204052397314, 0.12682448894173193, 0.18342746923347508, 0.11508461991937835, 0.1325125755355877, 0.1185908935666965, 0.09119503508582838, 0.11867764037871587, 0.11758034169915188, 0.11513645189256494, 0.11179979343841406, 0.13399284347367446, 0.13126743437024402, 0.9476094295458751, 0.9122749430200636, 0.927123238090495, 0.9081413444982264, 0.9397221087402547, 0.9517194260541165, 0.9212862481841188, 0.9311098209750271, 0.9539961439413992, 0.4612184578915358, 0.4956472270125619, 0.5465419035920832, 0.4968916421503755, 0.5721913955572131, 0.5358175137573773, 0.484098716860494, 0.48351320617787374, 0.615884617294321, 0.7125761518850654, 0.7286573060394741, 0.7888762450248646, 0.7450936920684594, 0.7577929044227895, 0.7048253511521957, 0.7563351710735835, 0.6927802096362108, 0.6714515448655853, 0.22756382117048635, 0.41062192928334296, 0.2067682477076941, 0.34131952983813185, 0.20555788587815638, 0.2183467252737562, 0.2561667558941172, 0.5417192333876135, 0.2299411136472591, 0.38803451655713284, 0.42235767290517534, 0.21064172139793147, 0.2923344261595764, 0.2257436235124528, 0.4040708136674358, 0.2844462738202911, 0.32729465426028714, 0.2133168854809292, 0.3157273945473441, 0.2702059488461599, 0.30931870040053977, 0.18363799181029938, 0.2356224207279365, 0.23955962150954913, 0.24582422361152423, 0.4196714513182621, 0.17337391310659, 0.2730768757015344, 0.43033651472536083, 0.2728817349999597, 0.5118154543622369, 0.43241903229197387, 0.3361242510862006, 0.4131658243606696, 0.37127665101058216, 0.39797414394204567, 0.10031831460484952, 0.10537685844430467, 0.05852563312991221, 0.1611907306919207, 0.19220199348160372, 0.10094932286690983, 0.1834129419170436, 0.0775162089876349, 0.09855463257382147, 0.21800250084580974, 0.2629653871946689, 0.24001003302290624, 0.3032914673150371, 0.3754786009766836, 0.30257861170090483, 0.25186425018355985, 0.27036631790969323, 0.2790886043966577, 0.6614247564937741, 0.682368234216998, 0.6115510367141934, 0.5936091763053875, 0.7172689370488001, 0.5500855118312509, 0.5881626299030266, 0.6460916470833777, 0.5430319207708469, 0.12416116451224768, 0.12642011012164933, 0.11710152437607957, 0.12136587662953824, 0.11128387233993908, 0.10442431349305903, 0.11003506253113626, 0.11543581520954505, 0.11999329384407176, 0.2387342419950188, 0.20941761656722957, 0.2303166456729, 0.23555378074924005, 0.18727029587959365, 0.1931950006581853, 0.185250156149243, 0.20245896950317965, 0.21934856820905002, 0.3857654246696979, 0.3305017181796952, 0.42367651733713274, 0.4347014254451639, 0.4513236255917149, 0.37591661122202047, 0.38286211928890523, 0.4190905478064688, 0.5096337948236851, 0.2924618171077875, 0.29340560617531797, 0.3307304734375517, 0.2446203462256441, 0.3035747830791433, 0.30762211342887025, 0.2725804634840242, 0.31346420366719974, 0.3459868829027969, 0.19942539440204055, 0.22670799077267656, 0.1816988444617187, 0.19860689069333226, 0.18836481939905325, 0.19621880254023438, 0.19453750285790916, 0.20215129364445394, 0.19945168747594288, 0.19396307400330814, 0.28703149665329697, 0.20345592282676483, 0.3718108205559897, 0.4588544622398234, 0.22990470231706372, 0.20851799716296515, 0.20943319944271932, 0.22086899505343904, 0.6737777647386356, 0.19192717292297534, 0.7597122502919897, 0.7115728424886065, 0.20402909160178662, 0.7221357230124237, 0.18569145674226173, 0.7222452068031865, 0.2005921790063252, 0.2059925544603214, 0.20784750493539106, 0.6083235805035347, 0.6192550520267224, 0.6931558555823933, 0.7358502874943673, 0.2059766078266091, 0.7600272758675309, 0.16580672384952655, 0.19950661479296794, 0.17662113570531202, 0.18655336874160566, 0.21761656606151603, 0.19075430272613947, 0.20540930582598793, 0.192602087561495, 0.19016196749567293, 0.18617758597797063, 0.07550474249019967, 0.09024793854830038, 0.08121198604240476, 0.08396718103168299, 0.09816382842113636, 0.08306667626344588, 0.08072293639605577, 0.08352261629522528, 0.08505851639184436]}, "mutation_prompt": null}
{"id": "7f54f4ec-a4b9-4af5-ba64-5cdc747eb4ab", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8  # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * (1 - diversity) * (self.evaluations / self.budget)  # Line changed\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance the exploration capability by adjusting the differential weight based on budget usage and population diversity.", "configspace": "", "generation": 84, "fitness": 0.3401478835484928, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.25.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7793367631367186, 0.7992344700043352, 0.7952841513960083, 0.7574891082676232, 0.815611935902086, 0.8176130412543787, 0.7832490897095508, 0.7993809081067649, 0.7825742452352207, 0.5593798706608353, 0.4326108341804815, 0.6429962476386238, 0.6535168280839758, 0.622981463910188, 0.4382585296582342, 0.6410024895903828, 0.36947107372506627, 0.0672284402935649, 0.1287472825165733, 0.12435927975487271, 0.12720289918660188, 0.13695901230375307, 0.13187855417051486, 0.12558245926332579, 0.13349064375652853, 0.19845301145324978, 0.12559341195129725, 0.11000274635350638, 0.1153430393136825, 0.1404063995931183, 0.11742537815350784, 0.11336993667059991, 0.1213226875868253, 0.10749230040378188, 0.13401277462485617, 0.12107616576998459, 0.879440886474862, 0.918179671969427, 0.9095131337649959, 0.8877988310903768, 0.9346354347144119, 0.9127394614664348, 0.9011948996275101, 0.9363444087962358, 0.9657771398921582, 0.36908533117411657, 0.38103195501206366, 0.47688360834224275, 0.39540362150569675, 0.3563083244172819, 0.514817413243152, 0.3371840280496945, 0.34535338198719345, 0.3828042807416908, 0.7876398287805213, 0.8160749849057214, 0.741852593898806, 0.7731748583009799, 0.7503870454926762, 0.7769103257475519, 0.7663447632433694, 0.7967742860040709, 0.7961442531322717, 0.19853417378563054, 0.23276872542048777, 0.18698738126952696, 0.20559158229859087, 0.18325617905270153, 0.15766022523322387, 0.19907687082285397, 0.18794602141624162, 0.3352394028853659, 0.17651625655746395, 0.20125409013290274, 0.26133255557529744, 0.2171416557854594, 0.2930201408619978, 0.18435677242702608, 0.17326365996107196, 0.17879732780479007, 0.17797865754061426, 0.12069841932828607, 0.009852365457867052, 0.09270326882126922, 0.1411732518340556, 0.1729352569977387, 0.2507673576697662, 0.07181388483580631, 0.02064812668151461, 0.16457553581061024, 0.13584096429496473, 0.21551597955278323, 0.3095117502148902, 0.3054204647226315, 0.059405056070884754, 0.12031250785723913, 0.24311703008493324, 0.23703242054067497, 0.09483780640103667, 0.09903662963606708, 0.07937108465830411, 0.21609295541518958, 0.203642355831412, 0.0700255633545448, 0.15271642269606578, 0.10695048303002352, 0.119140966169479, 0.18284991816652407, 0.19703205115690559, 0.28831292335624825, 0.2691135620614249, 0.33413567158124513, 0.27390091219247936, 0.23237281779811358, 0.23438003790284845, 0.23577679197311296, 0.19069404917630495, 0.603797904287012, 0.5082807091578673, 0.48079405732308567, 0.5994420808692505, 0.5295360852306266, 0.6238253978165463, 0.6062978124414371, 0.5643183241342912, 0.6283795999268085, 0.11801900265837661, 0.12896254140828645, 0.11283986085533781, 0.1074121518819493, 0.09459516676161472, 0.11121018281064332, 0.10939059861139122, 0.12199179863026144, 0.12273391353646856, 0.23387757592395209, 0.18217137017547036, 0.2002480348564799, 0.20056977364255113, 0.2680862992031764, 0.24938052638134378, 0.294999125050761, 0.21051134097454727, 0.33212259546905165, 0.43653241346329674, 0.32790838664185495, 0.45990706029166417, 0.41978984391007657, 0.44144549855161075, 0.4144945689129419, 0.5448008103723541, 0.42073696029722873, 0.5717109493307211, 0.3069865568070934, 0.3582761075248073, 0.3919509448334304, 0.2555432928112574, 0.3575879960985804, 0.2728852616730386, 0.35615982857136574, 0.32393176979083327, 0.3361094350737649, 0.2047094501109049, 0.20892394979337447, 0.21188665643599858, 0.2064900864806103, 0.22899814906441673, 0.23461118759519828, 0.20261047383344655, 0.20117744737085308, 0.2170442684174051, 0.3155107872347904, 0.1908661758343031, 0.20823035056217842, 0.20694139215004914, 0.22720077874662248, 0.18958933333579275, 0.21533365544699767, 0.2098037795901153, 0.5500715559662291, 0.6404484249186762, 0.1650061173366577, 0.8230338868066291, 0.19517903880244836, 0.203605262222877, 0.6541532882808883, 0.19215950694123318, 0.6350738643683871, 0.7470869616550002, 0.2047416794079434, 0.20885372661474444, 0.6898726545268941, 0.6399439609686999, 0.759907193812964, 0.6270555284797972, 0.506746112175501, 0.6555676154883232, 0.16608766882371706, 0.1775488696628097, 0.186321348421275, 0.18421264475069177, 0.1935849610989031, 0.19450889593731702, 0.2185224147557825, 0.18006564850931261, 0.19360834216240386, 0.19160519637938067, 0.08999098569823039, 0.07113636811043778, 0.08138115634452991, 0.0835559965281194, 0.09704229061020431, 0.11325886115100225, 0.08079352863612621, 0.09118489265467378, 0.07638241296744741]}, "mutation_prompt": null}
{"id": "63b6cf27-4732-4790-8fde-e5e41cef61cb", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity**2) * (self.budget - self.evaluations) / self.budget  # Line changed\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance local search by scaling perturbation range with diversity to refine exploitation.", "configspace": "", "generation": 85, "fitness": 0.36311783757140437, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.36 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.799271276308416, 0.796991563722832, 0.8029636505653017, 0.781719926901351, 0.786717153461876, 0.8217350774774564, 0.7885356665120331, 0.8164547590826668, 0.7852633575055897, 0.5812379481254661, 0.5414869920388978, 0.5542733915867929, 0.49879140007405576, 0.5979190514681226, 0.5697038672405238, 0.5904013066597715, 0.5829355441778972, 0.5766977048768388, 0.13171746575301846, 0.12781543856657462, 0.20644839422308692, 0.1572614763071455, 0.3138350322302558, 0.1499289158254663, 0.123707380286041, 0.19128375871664693, 0.2470878925413892, 0.21477661039148987, 0.1292658561401342, 0.12484964161407497, 0.12033689305498607, 0.20001102894370748, 0.3117733867502356, 0.10756949763234003, 0.14084129790783606, 0.1086087306359268, 0.9409044566442029, 0.9447954572944259, 0.9427985774443902, 0.9277788825474302, 0.958442355087764, 0.9339582471731271, 0.9077007391551618, 0.9396930141733623, 0.9549107017288191, 0.4890994199358101, 0.5180751730636897, 0.53266364444848, 0.6173854728349919, 0.5725429957455741, 0.521360026283946, 0.446646972014219, 0.5331610594596721, 0.5594565471325649, 0.7370129402046115, 0.7064432462571719, 0.7903360812282979, 0.7585122770505366, 0.6994387850438222, 0.7076779703619929, 0.7793936832758303, 0.22738694060426645, 0.7498149362077187, 0.3235086883366879, 0.38248479263537516, 0.13051709673836742, 0.24301367194233658, 0.2107746188316323, 0.263389805594357, 0.2926434063060177, 0.3133877420056097, 0.22456688858130425, 0.2847524892673464, 0.24809999794174087, 0.17472189218587209, 0.3279269839488106, 0.2445993392857304, 0.2707053787430387, 0.31199448532793816, 0.2305183657914024, 0.19290400370408556, 0.2945524712456268, 0.2655433725557068, 0.16446380884108425, 0.27565652829562026, 0.13653891433222776, 0.25330143322417087, 0.26612264286921616, 0.18999266191227293, 0.18934568624873105, 0.33678315395040936, 0.19957355485159534, 0.41741797708805484, 0.1349712284642759, 0.35712245522677755, 0.3577233853524432, 0.4780410428746198, 0.5186703078980179, 0.446229228142048, 0.07159312565430087, 0.11214622885133974, 0.1812075517695373, 0.12288365501749976, 0.21356278191828904, 0.14807159664887692, 0.18013572666822564, 0.08680071049628846, 0.10873162343012432, 0.22187822277018265, 0.3101643856577926, 0.30067791486565687, 0.3527865173820338, 0.25686539881530923, 0.2417660737979942, 0.24467571734375237, 0.25191754732080396, 0.24193809613648953, 0.6956967502058754, 0.6889172664922256, 0.6540606733959631, 0.6228709073645337, 0.6334742314512114, 0.5499940578773416, 0.5706115211735017, 0.7194105756212381, 0.6155744879509483, 0.1296168244862128, 0.11032969114391256, 0.11273417598462343, 0.13828924684101562, 0.11698775642415471, 0.11971528068741466, 0.12133620407796586, 0.10620141300857044, 0.12198192318364198, 0.20683202703541792, 0.17033982695703886, 0.2862872265200561, 0.14733035054856447, 0.1729792054097139, 0.17862964978462137, 0.19644217787368834, 0.16402990125393047, 0.19789040679484393, 0.40859004393641885, 0.44924847279569147, 0.4320125985099863, 0.40171420177491823, 0.44544690524913244, 0.5327862147036244, 0.3971717941646501, 0.4659811214153555, 0.45150136667640095, 0.29556130905591704, 0.3017973219877904, 0.3438506683132839, 0.30478410139745316, 0.26648779270223244, 0.29852559918089805, 0.25732445576787755, 0.32767524899485545, 0.35621386253329, 0.23686047595801907, 0.19311657811084504, 0.2155925686728548, 0.1974805625145034, 0.17711436629511368, 0.19534618715792507, 0.18289495215050788, 0.21412484212912797, 0.20858892425844267, 0.38549332434284067, 0.19016535524167544, 0.21461649971267627, 0.2122708991039648, 0.20574894533572985, 0.20222129334864714, 0.2077712707958388, 0.3939414890355455, 0.2910176773280505, 0.5997902919377822, 0.5447654193971925, 0.6154847961303276, 0.5499481105303308, 0.5831951299821276, 0.704158356497078, 0.18439086037982888, 0.7444148431539973, 0.7100129930064697, 0.2002101746112811, 0.20646684624345113, 0.6632945994563424, 0.5871936740294934, 0.5384525326290615, 0.19673059854462271, 0.16212411912119273, 0.2101826258598931, 0.2023327431420605, 0.1940906288115667, 0.18960899446271628, 0.1786724447513861, 0.1845346184529909, 0.18752725558631567, 0.18497691753772194, 0.18707968685335552, 0.18790181144358253, 0.1824117224541727, 0.08550839328574056, 0.08231371186396996, 0.09270856770234237, 0.08207781941976533, 0.07112698448282295, 0.09299987204450377, 0.09798005129073084, 0.08481664532710531, 0.0763937120065521]}, "mutation_prompt": null}
{"id": "d7cd43d1-f94e-45b6-ad34-311bdbfaa0a7", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity * 0.5, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance diversity control by introducing noise to trial solutions based on population variability.", "configspace": "", "generation": 86, "fitness": 0.37504207727183886, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.38 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "3c6a557e-84e1-4a57-87c4-b9c348a49c33", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutation_scale = self.f + 0.3 * (1 - self.evaluations / self.budget)  # Line changed\n            mutant = np.clip(a + mutation_scale * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance mutation in Differential Evolution by introducing adaptive scaling based on evaluation progress.", "configspace": "", "generation": 87, "fitness": 0.33337776664197005, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.33 with standard deviation 0.22.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7090006129735058, 0.6993009060256334, 0.7234908390604855, 0.7008879833220983, 0.7097757903889976, 0.7200065653210108, 0.729508894598125, 0.7493913058458122, 0.7170781687975152, 0.31209134513397585, 0.358790931152708, 0.44370343911713317, 0.4225177522221337, 0.43627034901755724, 0.4458972591238394, 0.442583268304345, 0.4563384522554781, 0.4318493724108998, 0.13625191048919527, 0.3165793205570371, 0.2666827775251318, 0.20013329923162826, 0.22623040726071664, 0.3484533286010998, 0.27384911446272053, 0.12213746161507422, 0.1321788035653111, 0.12346634086822872, 0.283926538686336, 0.12337434565081329, 0.13048714058475763, 0.11237174625712598, 0.17617025049511792, 0.10456047966486826, 0.12859324882677825, 0.12043609509015585, 0.8788958725254854, 0.9562185891697363, 0.9464477976154948, 0.8858364288089393, 0.9663115882999488, 0.9272039206370358, 0.923979309997354, 0.903257289813014, 0.9464664509578227, 0.46340539522882784, 0.35406147916251784, 0.45204399385256544, 0.44722532337457976, 0.38329038493197976, 0.4853526460397417, 0.39517271432221246, 0.40989449732051364, 0.4475652515616524, 0.6104793985783583, 0.6512656839187752, 0.616956967114282, 0.6195200729163262, 0.6324526464993905, 0.6763387409832606, 0.6523260629368027, 0.5637276801905577, 0.6221926707425933, 0.29320140684590057, 0.3226088633229378, 0.41924216654651636, 0.3874187778991446, 0.38023221308217237, 0.38207546992243246, 0.3850879651650654, 0.3193790511134278, 0.3590205798210362, 0.34549363987297854, 0.3820284879396404, 0.21817242543500726, 0.2734233154743221, 0.40847941254901643, 0.3654314247374063, 0.26616484583259625, 0.2987297816916289, 0.3306982388839165, 0.1253669960067475, 0.16355146327745973, 0.18773339982886217, 0.10792047497242385, 0.2067424241544783, 0.12161628389903179, 0.08527463114892975, 0.14339173409693917, 0.09429142228247367, 0.2446138387436888, 0.3028573326247922, 0.16031391292579233, 0.3236536500079715, 0.16170605416332706, 0.23374380428911268, 0.300315926377717, 0.2706157131441689, 0.23261719669312553, 0.02405113101889933, 0.04820130242185128, 0.03778274201708154, 0.06453143902540537, 0.18194636757471105, 0.058488048042985796, 0.06484159872659334, 0.1445125871487688, 0.08935084065402732, 0.22532646630665354, 0.2320832903042046, 0.22780307214404305, 0.23728538211941763, 0.27661958385400076, 0.22155463475574577, 0.2125763610722552, 0.21839539452282097, 0.19886335541013855, 0.6063794682633248, 0.563595832126548, 0.5842664911677229, 0.48897469959209927, 0.5545661110852087, 0.5812995393527656, 0.552564715809992, 0.574152081258475, 0.6246112270132993, 0.11740128117353688, 0.10986910677910433, 0.09329631733669375, 0.09234902077473128, 0.11271409893212314, 0.11404871249402426, 0.1183485854583467, 0.11826806116997102, 0.08455189439465216, 0.13896311672754458, 0.21876613045765603, 0.2666954063328979, 0.25400181500691443, 0.2446671314344534, 0.20967045498355663, 0.18117001285369239, 0.18998216320812167, 0.24785205396646215, 0.2793890701358801, 0.31968370069216934, 0.3403940761275742, 0.31537115054879805, 0.2937404168671012, 0.34483186194567483, 0.3018915976635941, 0.3611227301303448, 0.35894786810385604, 0.22677223619439746, 0.2390269186690741, 0.26623684148852056, 0.2421854432978091, 0.27514860175573275, 0.27097397738105744, 0.23516689890605647, 0.24244890511553363, 0.25728428087525623, 0.18782250696964986, 0.20944812065168394, 0.18920095740265175, 0.20359687121580206, 0.19590753079567003, 0.20150691040006763, 0.20431874919103932, 0.21108134673409829, 0.17834519329785103, 0.36595531340361886, 0.20840865185902602, 0.35856660018366193, 0.46053514876708657, 0.39802202817362464, 0.20529624201466246, 0.35785960582514476, 0.19645838177835773, 0.1937975229771628, 0.6585055619227747, 0.19376552262529323, 0.5746305134913322, 0.6053068065857455, 0.20424080962045765, 0.18924602934709067, 0.1845672702069785, 0.6169784915510995, 0.636904599982949, 0.6123756791636796, 0.6881854827626102, 0.6443550252785943, 0.46017933749201756, 0.5540874344656632, 0.19763197517745745, 0.20157315239988538, 0.7097796125230353, 0.20494524262128722, 0.17971309142712688, 0.19476598199163087, 0.1907615997223363, 0.18128139959734058, 0.19679294811283576, 0.18097705222956872, 0.17679192460335724, 0.18850953191416475, 0.18297638100192937, 0.08111445015709373, 0.08176563855946095, 0.07952551329087398, 0.0960005419389165, 0.08114184838081706, 0.07693410083476193, 0.07893552343476717, 0.07603572961490013, 0.08886338004756866]}, "mutation_prompt": null}
{"id": "3dd769a7-1220-418b-93ed-0b948ff56b5e", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * (1 - diversity) * (self.evaluations / self.budget)  # Line changed\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance exploration by introducing adaptive mutation scale based on diversity and progress.", "configspace": "", "generation": 88, "fitness": 0.3401478835484928, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.34 with standard deviation 0.25.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7793367631367186, 0.7992344700043352, 0.7952841513960083, 0.7574891082676232, 0.815611935902086, 0.8176130412543787, 0.7832490897095508, 0.7993809081067649, 0.7825742452352207, 0.5593798706608353, 0.4326108341804815, 0.6429962476386238, 0.6535168280839758, 0.622981463910188, 0.4382585296582342, 0.6410024895903828, 0.36947107372506627, 0.0672284402935649, 0.1287472825165733, 0.12435927975487271, 0.12720289918660188, 0.13695901230375307, 0.13187855417051486, 0.12558245926332579, 0.13349064375652853, 0.19845301145324978, 0.12559341195129725, 0.11000274635350638, 0.1153430393136825, 0.1404063995931183, 0.11742537815350784, 0.11336993667059991, 0.1213226875868253, 0.10749230040378188, 0.13401277462485617, 0.12107616576998459, 0.879440886474862, 0.918179671969427, 0.9095131337649959, 0.8877988310903768, 0.9346354347144119, 0.9127394614664348, 0.9011948996275101, 0.9363444087962358, 0.9657771398921582, 0.36908533117411657, 0.38103195501206366, 0.47688360834224275, 0.39540362150569675, 0.3563083244172819, 0.514817413243152, 0.3371840280496945, 0.34535338198719345, 0.3828042807416908, 0.7876398287805213, 0.8160749849057214, 0.741852593898806, 0.7731748583009799, 0.7503870454926762, 0.7769103257475519, 0.7663447632433694, 0.7967742860040709, 0.7961442531322717, 0.19853417378563054, 0.23276872542048777, 0.18698738126952696, 0.20559158229859087, 0.18325617905270153, 0.15766022523322387, 0.19907687082285397, 0.18794602141624162, 0.3352394028853659, 0.17651625655746395, 0.20125409013290274, 0.26133255557529744, 0.2171416557854594, 0.2930201408619978, 0.18435677242702608, 0.17326365996107196, 0.17879732780479007, 0.17797865754061426, 0.12069841932828607, 0.009852365457867052, 0.09270326882126922, 0.1411732518340556, 0.1729352569977387, 0.2507673576697662, 0.07181388483580631, 0.02064812668151461, 0.16457553581061024, 0.13584096429496473, 0.21551597955278323, 0.3095117502148902, 0.3054204647226315, 0.059405056070884754, 0.12031250785723913, 0.24311703008493324, 0.23703242054067497, 0.09483780640103667, 0.09903662963606708, 0.07937108465830411, 0.21609295541518958, 0.203642355831412, 0.0700255633545448, 0.15271642269606578, 0.10695048303002352, 0.119140966169479, 0.18284991816652407, 0.19703205115690559, 0.28831292335624825, 0.2691135620614249, 0.33413567158124513, 0.27390091219247936, 0.23237281779811358, 0.23438003790284845, 0.23577679197311296, 0.19069404917630495, 0.603797904287012, 0.5082807091578673, 0.48079405732308567, 0.5994420808692505, 0.5295360852306266, 0.6238253978165463, 0.6062978124414371, 0.5643183241342912, 0.6283795999268085, 0.11801900265837661, 0.12896254140828645, 0.11283986085533781, 0.1074121518819493, 0.09459516676161472, 0.11121018281064332, 0.10939059861139122, 0.12199179863026144, 0.12273391353646856, 0.23387757592395209, 0.18217137017547036, 0.2002480348564799, 0.20056977364255113, 0.2680862992031764, 0.24938052638134378, 0.294999125050761, 0.21051134097454727, 0.33212259546905165, 0.43653241346329674, 0.32790838664185495, 0.45990706029166417, 0.41978984391007657, 0.44144549855161075, 0.4144945689129419, 0.5448008103723541, 0.42073696029722873, 0.5717109493307211, 0.3069865568070934, 0.3582761075248073, 0.3919509448334304, 0.2555432928112574, 0.3575879960985804, 0.2728852616730386, 0.35615982857136574, 0.32393176979083327, 0.3361094350737649, 0.2047094501109049, 0.20892394979337447, 0.21188665643599858, 0.2064900864806103, 0.22899814906441673, 0.23461118759519828, 0.20261047383344655, 0.20117744737085308, 0.2170442684174051, 0.3155107872347904, 0.1908661758343031, 0.20823035056217842, 0.20694139215004914, 0.22720077874662248, 0.18958933333579275, 0.21533365544699767, 0.2098037795901153, 0.5500715559662291, 0.6404484249186762, 0.1650061173366577, 0.8230338868066291, 0.19517903880244836, 0.203605262222877, 0.6541532882808883, 0.19215950694123318, 0.6350738643683871, 0.7470869616550002, 0.2047416794079434, 0.20885372661474444, 0.6898726545268941, 0.6399439609686999, 0.759907193812964, 0.6270555284797972, 0.506746112175501, 0.6555676154883232, 0.16608766882371706, 0.1775488696628097, 0.186321348421275, 0.18421264475069177, 0.1935849610989031, 0.19450889593731702, 0.2185224147557825, 0.18006564850931261, 0.19360834216240386, 0.19160519637938067, 0.08999098569823039, 0.07113636811043778, 0.08138115634452991, 0.0835559965281194, 0.09704229061020431, 0.11325886115100225, 0.08079352863612621, 0.09118489265467378, 0.07638241296744741]}, "mutation_prompt": null}
{"id": "f37abb0b-6035-4039-9750-bc5202b4c424", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "b723a80a-7147-4da6-abad-cf16ebe9cecf", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            diversity = np.mean(np.std(self.population, axis=0))  # Added line\n            self.cr = 0.7 + 0.2 * diversity  # Changed line\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance exploration by dynamically adjusting crossover probability based on diversity during differential evolution.", "configspace": "", "generation": 90, "fitness": 0.3729818201933757, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7893362412823854, 0.7660190858655943, 0.8057706365028439, 0.7951397303305284, 0.7764930739478084, 0.8266270290783526, 0.8071724436647005, 0.7891733028688376, 0.7936468925499701, 0.6025442493977738, 0.5815335198429255, 0.6019374988962999, 0.5594141938631064, 0.5576459085715966, 0.5546794904897179, 0.574442883047636, 0.6290299998025661, 0.5333703920609474, 0.12712734153260208, 0.1408231364986805, 0.12359752598070661, 0.11479930554539675, 0.1282844878637297, 0.12085356887067022, 0.28385322088584686, 0.12617327716639615, 0.07997894483400614, 0.10997400771601751, 0.1041536954679636, 0.10966545612186929, 0.11283733359900983, 0.10768381252242376, 0.18363537709570232, 0.12371845601815767, 0.10404170075314745, 0.1043326589078053, 0.8061354517037025, 0.9184128394788778, 0.763185184407877, 0.9144823269078988, 0.8957266203998608, 0.9369150454765062, 0.8475594311489312, 0.8629767970645816, 0.9500187798913786, 0.49137528274834086, 0.5207771316854479, 0.5273646835868846, 0.5409298870586668, 0.5487638925296376, 0.47847927279307456, 0.5351837239640642, 0.5060872928961702, 0.5657758433259116, 0.7192143481199549, 0.6952571253073165, 0.7708318739750071, 0.8115387685116836, 0.8331710822416416, 0.7678645376796321, 0.23072691725261052, 0.7535480760529758, 0.7216726621349259, 0.28489724807480876, 0.37187463356649564, 0.2667866363230471, 0.35645513628968795, 0.2241205493269851, 0.2868005065841275, 0.28556368946158805, 0.3575167973064045, 0.3249843275243547, 0.2570917959760205, 0.2441319124692638, 0.21571911269232968, 0.20091776092015978, 0.2589727941714358, 0.21638594583292947, 0.21329947574559305, 0.27894308267120005, 0.21281876409247535, 0.19534927190613915, 0.3568844411256572, 0.27676307389222154, 0.29909256181442956, 0.23763008275833053, 0.16610569230300265, 0.4087651301071752, 0.3675480412066643, 0.16270763008071376, 0.28756540771310124, 0.19592209262416416, 0.2873773996205383, 0.25529400321033624, 0.16425467578926622, 0.5370305324206528, 0.5690279125064721, 0.5151565045855002, 0.339503376992249, 0.15003180774591152, 0.10403043345150231, 0.1493457223289001, 0.16205800487350952, 0.28808859138265763, 0.1521878380651277, 0.14391519296341027, 0.10088766655544457, 0.08371390956176672, 0.27969348456328, 0.30893881612788787, 0.24998444473298875, 0.2995134896931547, 0.2983207809468861, 0.3163346456891529, 0.2676980105484912, 0.22477778622379685, 0.2837078385373639, 0.5922876801328789, 0.6433554644069222, 0.5991575301918393, 0.6061915038784751, 0.6701957257629263, 0.6110153239988758, 0.6159720372557314, 0.6791853215798571, 0.6189319076858495, 0.09376717610138863, 0.11341445877107581, 0.12005484805123523, 0.11868965399546283, 0.1207663190679863, 0.08291486001685477, 0.11782065468653002, 0.12506571714039294, 0.10534926193770733, 0.22254696457678647, 0.25997437981704696, 0.25315917793009224, 0.24615915262509536, 0.25167608285904264, 0.23142437220175072, 0.20321824813666334, 0.19028704760959558, 0.22459561012165197, 0.40577125058654484, 0.4346851236049789, 0.3748865082158973, 0.4053060685024328, 0.4857019723384314, 0.4237540759756038, 0.4352051029458429, 0.4293495633795793, 0.3997572729265101, 0.28174856761814526, 0.28759232047970584, 0.3309498550879103, 0.2827180458247741, 0.29836636826515883, 0.31388640407873725, 0.2788984605765824, 0.36495522180615647, 0.31350639471339947, 0.22171133202318638, 0.1861890056406612, 0.19166518619767103, 0.20089034238264758, 0.20030038579524756, 0.20297394906363797, 0.2247414556587246, 0.2162952841507486, 0.1950512012224881, 0.28901680570340127, 0.22844918599741815, 0.38404724666420686, 0.20227993629763164, 0.43890316479132585, 0.21503138937185584, 0.4347789358600833, 0.3106774769352205, 0.1905122851317268, 0.18222480733685997, 0.7725643750383596, 0.770911726868939, 0.17944265793604808, 0.6822272344961533, 0.19681711784041722, 0.17650173223521948, 0.770407827202947, 0.19979824388046297, 0.7850478516339569, 0.7593404126098943, 0.7475715593419057, 0.675584856734326, 0.6634279849007422, 0.6874129557948077, 0.7205376761962726, 0.7395550072563355, 0.6747722638455113, 0.18850601692967361, 0.17552406193442116, 0.18929157057530677, 0.19414811345880245, 0.19336856397100433, 0.19127820866758127, 0.18482525558256135, 0.19677881787291895, 0.19031330362774312, 0.08630455247838853, 0.08241228364340569, 0.08976933134447751, 0.09042246306596158, 0.08695079369213476, 0.09184965530871181, 0.08269613243087859, 0.071565717664263, 0.0902211805537354]}, "mutation_prompt": null}
{"id": "42d99cbe-f0f7-424f-ab89-a5c35d5011d0", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - (self.evaluations / self.budget)**0.5) * (1 + diversity) * (self.budget - self.evaluations) / self.budget  # Line changed\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Refine the perturbation range scaling to better balance exploration and exploitation throughout the budget.", "configspace": "", "generation": 91, "fitness": 0.3699733024816353, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7953848078344143, 0.8033044951913921, 0.7817054331423019, 0.7756632934450169, 0.7754554771799094, 0.8138927246103764, 0.7773848861906937, 0.8320421026072077, 0.7866532776607902, 0.4691664883007357, 0.5013438966431666, 0.5637179851330063, 0.5756323012649598, 0.5871992759741427, 0.5633611619224783, 0.6002970825515412, 0.5558008658762591, 0.5717802472316187, 0.1675823344765648, 0.1805165314075492, 0.12507695415798792, 0.12549635639216428, 0.2232007166231369, 0.1296493713690785, 0.17176802841018146, 0.3711330879749343, 0.1250965656869879, 0.11919708181403821, 0.22684885288991918, 0.11521290784531646, 0.15423210952117095, 0.13415773510486106, 0.11115489252479949, 0.17328289012316656, 0.11314979660021074, 0.13813761778603673, 0.9367564723873787, 0.8984662957662595, 0.9019433556402894, 0.8914110224759221, 0.9362915719529484, 0.9516313511265498, 0.9125938915505496, 0.9084397670776563, 0.9412963361069203, 0.47643380109406175, 0.5128603747547236, 0.5702755847416603, 0.5596306956208354, 0.5637846063318701, 0.5838325854682198, 0.48681505777692713, 0.48695081590611367, 0.5280651827908869, 0.6789195469053824, 0.7745373984667601, 0.7445168126840087, 0.7315203351197135, 0.7488912514050331, 0.767484685017614, 0.7320936509556994, 0.7122688389892691, 0.7775042906314977, 0.3045607050283705, 0.359247489183418, 0.2202082730839411, 0.29280895643504845, 0.24194142751486547, 0.4478417625817208, 0.5346436843068161, 0.25616921238889523, 0.2751732991777608, 0.36911917361287927, 0.36009223300789706, 0.2655298959313255, 0.24046052425369835, 0.2800952001936827, 0.21150646860653288, 0.3777559073732034, 0.3104616437013715, 0.2548999111899459, 0.40532928744219443, 0.33797974761110594, 0.0694862149427452, 0.21714040632327047, 0.25458693004524413, 0.34237600180505434, 0.12204206982166999, 0.08794408575787926, 0.23556889260389358, 0.3451255722184622, 0.2570078783683829, 0.2687645977998576, 0.18304351693046184, 0.29832751910273725, 0.31524533902231, 0.49501386051261187, 0.48878631100649916, 0.3962051640613944, 0.06812519214930035, 0.13523871160103462, 0.1804469899098482, 0.1375042011763704, 0.10048071074464948, 0.2739823697111863, 0.2748399624396254, 0.20110071234770743, 0.22195975493222952, 0.2510864310665747, 0.2400154373892649, 0.3072263217192941, 0.352190892213314, 0.2708774888134491, 0.2970876037133897, 0.3289872523857883, 0.20988940672504608, 0.2261918462167164, 0.6614733972646327, 0.7190443986578615, 0.5900012907873783, 0.6098708942312445, 0.5794160158497509, 0.5641482220836758, 0.7284479793049221, 0.6899828385848611, 0.5677323848120569, 0.13895405838685237, 0.12353854940610343, 0.12412009453343453, 0.135003130122204, 0.1417606772325023, 0.12601725877437364, 0.11230855408579588, 0.14016975406614385, 0.14142582534272574, 0.24005920902405675, 0.2605730667449546, 0.26031749507486046, 0.22823087152653942, 0.2600166327912329, 0.21078539437564747, 0.20161840689324106, 0.2474233077518211, 0.2347538244927031, 0.3918143415328741, 0.3785482004743379, 0.4143040279379817, 0.38519502742089795, 0.4490241155255431, 0.45844574974482344, 0.4111254289115229, 0.43522866055940646, 0.4366344810681805, 0.30717527783965715, 0.3173141015820715, 0.2840805671969281, 0.2935254429254175, 0.280221653402157, 0.3054312907778912, 0.28807345686742303, 0.31718258154822154, 0.2907308012674442, 0.1855180422169146, 0.21066108300310415, 0.19686604577498112, 0.20272455589893557, 0.19450120123739145, 0.19022758838735654, 0.19684208792381985, 0.2008307533871242, 0.19435469707612651, 0.2037281184635915, 0.1942834718340214, 0.21978945332891175, 0.21723169152290633, 0.20655114025662547, 0.35716759042513224, 0.4029234483208838, 0.21005676035901477, 0.6102693381611073, 0.14907788611026118, 0.19379532242267727, 0.7388351369525352, 0.1960734160083697, 0.20628987544155386, 0.6693520083349815, 0.17171431193390507, 0.7213503375769046, 0.7227386740122993, 0.20406440009044713, 0.2080713065625891, 0.7028606469561259, 0.8059555842985986, 0.6747742351173646, 0.5448457021517269, 0.20458972779941964, 0.7020816729133406, 0.1651199985170031, 0.18939895830132436, 0.182733731858425, 0.1882544493488335, 0.18932909246195773, 0.19317590094283676, 0.19366330655142494, 0.20356822649595374, 0.18477093736236505, 0.1909049926668127, 0.08483920307375925, 0.08385189306912744, 0.0941279051100552, 0.08321767178341744, 0.07377560933737881, 0.11212127523049709, 0.09279698758407229, 0.08694081462563441, 0.07978067025213154]}, "mutation_prompt": null}
{"id": "7886c2aa-020b-4513-8728-7b8127c4b5c5", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce dynamic population size scaling based on evaluation progress for improved exploration and convergence.", "configspace": "", "generation": 66, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.781232966734882, 0.7781058376317294, 0.7855558402834006, 0.7725881263008015, 0.7835707884730331, 0.8080440455726885, 0.7850715714075989, 0.7973945501840092, 0.7722668044699098, 0.5632008013241214, 0.5918444094937811, 0.5457373174588926, 0.6105620792154794, 0.603198120796381, 0.558498282792337, 0.5964259296742669, 0.641498426761183, 0.5447860174959042, 0.1791479920890482, 0.24524900596864285, 0.1402187204323343, 0.20500563209789135, 0.28685565281159675, 0.26064886825615985, 0.16602607458074925, 0.3231140550328929, 0.11922103448544907, 0.12663599350797905, 0.11140719300930846, 0.10346584046675178, 0.12643941883235854, 0.18033891684574788, 0.11776225164553, 0.13172612131737438, 0.1286145151610415, 0.1277056362627973, 0.9476091739880219, 0.912250034378571, 0.9271197988465371, 0.9082167702676117, 0.939733325380654, 0.951719777038482, 0.921288153250226, 0.931111429803965, 0.9540166599524824, 0.5012130000751837, 0.5162543216784659, 0.5614426534447055, 0.5249539092418484, 0.55229455378606, 0.5754832280164128, 0.47072947189004544, 0.48936526575798367, 0.4664216642654536, 0.713264659229488, 0.6713965541950575, 0.7683088683544891, 0.7473945060353815, 0.7081484388480905, 0.7312577152073885, 0.7284148376068158, 0.6680156126358014, 0.677522792283547, 0.34009464397177913, 0.48773091191681195, 0.2313223194613162, 0.3730122382054557, 0.20598392820616307, 0.2461555473858159, 0.24725172577253207, 0.5677480461227917, 0.31724454744600117, 0.23879029881677794, 0.41385976976802963, 0.18071937309619857, 0.24835691943757265, 0.2890960174689403, 0.5782340298902786, 0.25836363587905975, 0.2360266210188806, 0.19775425420391957, 0.3393958773297262, 0.2168774917366384, 0.2901301743932748, 0.36439477782975327, 0.1498843235757078, 0.1547557140895266, 0.3127466761201815, 0.3613049076267306, 0.08821060781037904, 0.4181172143684917, 0.5016373611390981, 0.4065715226886588, 0.4574543250871247, 0.3476749593610997, 0.30513415632125407, 0.4570842373862102, 0.5126016040830135, 0.3341578489938133, 0.07923083880607518, 0.08866784273670769, 0.0661476515177375, 0.14556976102654773, 0.2628423270971636, 0.143723793434391, 0.10695212722726155, 0.13031317584518698, 0.07694523264468711, 0.29734405696480304, 0.2214606596460601, 0.24952983768424097, 0.37689846328891086, 0.3301984185144662, 0.2994365435808991, 0.2501724206439748, 0.28262285396540343, 0.27363758678707883, 0.690972742963662, 0.6841442240123973, 0.5091730308822712, 0.6798808706770891, 0.5646375102344267, 0.644100808696892, 0.6817444963748764, 0.7254451397411884, 0.5460939770905395, 0.11562988438875998, 0.10824213446846498, 0.1223795119176655, 0.24349908068555226, 0.11396787737600822, 0.11094139748565501, 0.11022268540087266, 0.11753327720168127, 0.09980816736774845, 0.24342204003974288, 0.20940646154114773, 0.19350998198955416, 0.18204532953141805, 0.2186266910735677, 0.16674812759377777, 0.21969472339273288, 0.25537765688358083, 0.22801611029636348, 0.4109364433581433, 0.34554175821292343, 0.3778037846490161, 0.3821868458085399, 0.41274495840224357, 0.4705017785686435, 0.39371555785100876, 0.43011452829302155, 0.4710296965901023, 0.25596642736832176, 0.29127929905588457, 0.321982429996007, 0.26186895007116695, 0.3540826578613603, 0.3222998948408071, 0.30442003342593027, 0.3574900829514721, 0.3672988477488125, 0.2081783015478541, 0.19274105347707382, 0.18341176497908618, 0.2049606172125037, 0.18352757278148624, 0.2293426762582076, 0.19912461048470464, 0.18983563770159406, 0.19472777059341795, 0.36464119758858826, 0.19863607587545806, 0.19589655030108355, 0.36999376056403754, 0.47486051566821275, 0.22943016689731732, 0.19109296160161582, 0.42021372642786214, 0.22330571268107002, 0.6725841774848625, 0.19199708460957032, 0.7609250969924805, 0.7131353097667569, 0.2040253395811965, 0.7119467532787085, 0.18529524677682174, 0.7229321793635408, 0.2004734447412232, 0.2059926018120537, 0.20778844160684096, 0.6258159626997548, 0.6186814212763583, 0.7014781192867061, 0.7225319458958642, 0.20592513795243939, 0.7282043661545138, 0.16583134803361188, 0.1990804674794353, 0.19775705031359425, 0.18910546390117267, 0.19487849253739098, 0.19053583416632447, 0.1862898696091464, 0.18772445500539614, 0.19693171921654706, 0.18574695631751803, 0.07903563143175474, 0.08489169368549976, 0.08119921392701746, 0.08695452424684458, 0.09775498465040122, 0.07804860437508143, 0.08070585224603599, 0.08370576141373198, 0.07104533812534808]}, "mutation_prompt": null}
{"id": "81c35164-315d-41ba-9cf6-a6e5ffffa7a4", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)  # Line changed\n                self.cr = 0.9 * (1 + 0.1 * diversity) * (1 - self.evaluations / self.budget)  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive crossover probability scaling based on evaluation progress to enhance exploration and convergence.", "configspace": "", "generation": 93, "fitness": 0.32359507004785437, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.32 with standard deviation 0.23.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7776449830286796, 0.7513314735945081, 0.7976135603753345, 0.7710230927620247, 0.7915250966670256, 0.8099194006053629, 0.7652331591082111, 0.7905673449761077, 0.7739794354197519, 0.5625664192445403, 0.5653187380092175, 0.5729011231497985, 0.5767664837395804, 0.5775616724452336, 0.5754096043807204, 0.543612856557871, 0.589343226950447, 0.5326720326866003, 0.1493034328278774, 0.31805902041178524, 0.3963968379923001, 0.33438867026630903, 0.14049996671566933, 0.3200706266691059, 0.3575010036299606, 0.37939531601029985, 0.31609405508889676, 0.25107489529696536, 0.13492411832798334, 0.12940204399578992, 0.25784735762193955, 0.24496819535909176, 0.28623151309799355, 0.2742675953193061, 0.14351038098295177, 0.3271697239181731, 0.8064246915683697, 0.9024483519655849, 0.8181050869500055, 0.8139734680100266, 0.9383328989184391, 0.9159691485781944, 0.9323617379514553, 0.9295557668830953, 0.9372021533739812, 0.40640746526556615, 0.38818524437661395, 0.37110168046212033, 0.4278373607810505, 0.43031550254947937, 0.4307971237968401, 0.3611522502434117, 0.382631657505933, 0.37062988632119276, 0.7147360296159794, 0.7015155172408973, 0.6581890298239035, 0.5469792243216962, 0.7211901130722949, 0.6830446563491923, 0.5890942700015324, 0.6895545934346383, 0.7576898736000035, 0.18541571924394784, 0.2013115515970868, 0.17765672801810284, 0.1761876455069603, 0.12578614727358017, 0.18921193568240802, 0.21253373934071773, 0.18479167968214238, 0.16367952016914056, 0.19538532222233673, 0.1892972072123288, 0.18287899317910783, 0.1806742578332805, 0.17031413299532328, 0.1830763438340166, 0.2155694078628777, 0.1838370825379464, 0.2206641052603987, 0.08183484500251126, 0.09138271655195151, 0.05099855531124742, 0.010765636816064905, 0.08899434399349593, 0.07358441012912442, 0.022636574094859307, 0.054559886994618334, 0.12195297227678636, 0.2257840075543318, 0.15279585594659562, 0.24892483428247492, 0.15948062924616602, 0.19441249027520202, 0.19667960876448343, 0.20743997220457033, 0.23629821381610605, 0.1964539743029251, 0.02761056480614066, 0.025921986214129555, 0.03596632414912715, 0.04640418080876274, 0.018396271361533212, 0.016762170987382863, 0.03768775609884378, 0.05311615656989055, 0.030598662051530612, 0.17103192807488543, 0.15705057223755248, 0.1579106213814213, 0.1609978037363229, 0.16727878588084355, 0.18611344131132523, 0.1476919473132564, 0.13004793073130472, 0.15006453001710285, 0.49273857285677725, 0.5071384407421338, 0.4897896612904892, 0.5078650026542011, 0.5071639665655412, 0.5026414294769355, 0.45380662211447764, 0.5095984185799222, 0.511527916577107, 0.09418125295013813, 0.12117584076130339, 0.17055740748795123, 0.11857902738248305, 0.1130711798993903, 0.11196148481221413, 0.09336195946384429, 0.09883337533400338, 0.09774367294153541, 0.16704723118371367, 0.21615345043700784, 0.2998242410802461, 0.22522241720438319, 0.22506852789970044, 0.24440110554479533, 0.2000865564453005, 0.22959779972798655, 0.24972485049451187, 0.33363807998290007, 0.2699222495288832, 0.29934688217818206, 0.31383917673663486, 0.3227702059772586, 0.3139741051395104, 0.37496386352691125, 0.35297121079257854, 0.38695927906112115, 0.22808875641126625, 0.2550076038687372, 0.2298777349217811, 0.2526611851694158, 0.24943977735059286, 0.23931997504745572, 0.2089739569857083, 0.25293492827895725, 0.26190488491721997, 0.1938228398693903, 0.20498077967655992, 0.21175506693622648, 0.19549131387268714, 0.20105698712036324, 0.1911419328362972, 0.2131922669922286, 0.2056731886622556, 0.22110048327696197, 0.3251616070064849, 0.28108161304124857, 0.2100553798805026, 0.27844499213652507, 0.2151900921703429, 0.2382399950919989, 0.2344581827041019, 0.25622716569167236, 0.19638704568907528, 0.7360759972210278, 0.18342672898511192, 0.7009849389459327, 0.7454325918628514, 0.19840512428303458, 0.20520264948050682, 0.18284640760144344, 0.5232282715122015, 0.6247368986657797, 0.40644755736104365, 0.5324246304647248, 0.6047817096889833, 0.5957399001432129, 0.5212937841687667, 0.5047507566492004, 0.6973884190778107, 0.5446573323473345, 0.1633627323538387, 0.19334825634379638, 0.18274039124800034, 0.1886523725957563, 0.18553112875629119, 0.18967535370575006, 0.18800924740237246, 0.18056972506880464, 0.19052097422787384, 0.19636671783822324, 0.09920187988577034, 0.075029536348028, 0.0811291924234614, 0.08923983055242368, 0.09383340967964016, 0.07516537409753332, 0.08701788206581573, 0.08049503450227935, 0.08448427140229653]}, "mutation_prompt": null}
{"id": "dec9bda2-b0a6-474b-a1a8-942e65e93514", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < np.random.uniform(0.7, 0.9)  # Line changed\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce random sampling of crossover probabilities during differential evolution to enhance exploration capabilities.", "configspace": "", "generation": 94, "fitness": 0.3484649781771378, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.35 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7813379113929779, 0.8010933187121334, 0.7706153022776339, 0.7791683895042013, 0.7991187612468456, 0.7289836909721771, 0.7634859238145361, 0.7909673075439331, 0.7714743419801724, 0.5608316965524737, 0.599042441127514, 0.6223081880405518, 0.577799738931273, 0.6095770833544483, 0.5627010471260717, 0.5549392249216792, 0.61214601974553, 0.5827215467234057, 0.263958535495178, 0.19113309372005338, 0.31095581597778166, 0.22845078196476898, 0.32224510026053355, 0.24932258300470056, 0.25295453225319864, 0.23218205032350003, 0.3477713861363262, 0.19069114525715136, 0.12118858892516982, 0.15631276386974513, 0.19312760283884634, 0.12237450100545755, 0.11592538020229326, 0.09834743015463787, 0.157126344753157, 0.12615014812003844, 0.9278761506687467, 0.9193428780397594, 0.9348694695745263, 0.9100433158417018, 0.9177194833422608, 0.9821498504462047, 0.913126658318789, 0.9191683958416883, 0.9532950893564297, 0.45975224616611843, 0.5295859555503439, 0.573135895907878, 0.41881366731261094, 0.48482303116956516, 0.4615394921102376, 0.5165678213365748, 0.5299144226650866, 0.48749795465320234, 0.6391111601933462, 0.6640621295317952, 0.5940468745337892, 0.728094949135112, 0.663321180571362, 0.6475821886284374, 0.5927981779635798, 0.6496663546022087, 0.7208928076325336, 0.25122935069664487, 0.34656564513798893, 0.3105408733724626, 0.36168092740836133, 0.25900527245390004, 0.21654148214919255, 0.3412560612456932, 0.2177553883491885, 0.21148823159657582, 0.12277254684619332, 0.1985683139510076, 0.17945723068732655, 0.2591218899329276, 0.27873053236714285, 0.24979905483780496, 0.2644643812979638, 0.22160897880150965, 0.22314370857982635, 0.17867235852012286, 0.21848569531494633, 0.11694113257615013, 0.16866935394658578, 0.0644800618661624, 0.1902310030590877, 0.13878726730193325, 0.1617374663190302, 0.13853430768451003, 0.23346668912400492, 0.3612040292772807, 0.21703916154266245, 0.237879386277555, 0.19921403099717594, 0.18471636581350648, 0.20458248628860098, 0.3198470672334296, 0.3622098362434334, 0.04747935495912681, 0.07308433657528424, 0.08736413335474114, 0.09510027175225966, 0.11401727399342143, 0.09261817871823896, 0.10102442897882213, 0.11577236793556134, 0.054161052055319514, 0.21520146684679775, 0.22043696318969563, 0.20065559064664773, 0.2818544216144584, 0.24370737343774962, 0.26937835974310764, 0.22174684491815788, 0.23951186638841004, 0.23013821643945354, 0.6590793943237201, 0.5900779987343232, 0.6792939492706916, 0.5182652697372547, 0.5546199996868394, 0.5976819896862429, 0.617705750351217, 0.572973934694088, 0.5937041690463309, 0.11294827433629251, 0.11276664653153146, 0.11302090167329237, 0.1095003716934645, 0.1124495148645841, 0.09211211854777102, 0.10100475478818427, 0.09906667277446923, 0.10087793500378883, 0.19152469552786688, 0.21901964207447477, 0.19769762153417547, 0.1921946282017888, 0.18138572818656762, 0.23934184289726423, 0.21801388559603296, 0.1982966107928137, 0.186176165686191, 0.3077524996779992, 0.34135858574214284, 0.37531976975453396, 0.43351523571189166, 0.3606796246751224, 0.29444123661479726, 0.34791879367251966, 0.3544894296175991, 0.3798880436245048, 0.24852096882852048, 0.2658744893795545, 0.21104836991277964, 0.25957952558541997, 0.27375185655917433, 0.2805824776647823, 0.2808966105778443, 0.27325436882919585, 0.24752900846899062, 0.20876699002360688, 0.21818272978671327, 0.21746650457312855, 0.2027295423445784, 0.20795591249411027, 0.18771289684545445, 0.1956845975620657, 0.17576275137582054, 0.1856763708678021, 0.2113141140972601, 0.19124594150466245, 0.22641499002373955, 0.27763766046575733, 0.20391351324154183, 0.1901262634123877, 0.2038694213372524, 0.1951234429034584, 0.20729458475595897, 0.7598437211554723, 0.7040328357304235, 0.20239026170610563, 0.5997028740747217, 0.7710046182465138, 0.6491217119875334, 0.5539349451768936, 0.7456077029501567, 0.1620007573207024, 0.5345380014922506, 0.5781261337852241, 0.6509817307699629, 0.575914122585251, 0.6116351987111781, 0.5606794306728364, 0.6288887205214541, 0.21204422177413695, 0.15354117386208177, 0.17971041350026518, 0.19218211868312707, 0.19815256418950178, 0.19244562660274633, 0.184912373819906, 0.18363965583434105, 0.19118250465964304, 0.20101251179242963, 0.18525538776976214, 0.08155330353526302, 0.08408307912347557, 0.07518073708426509, 0.0721992152653873, 0.0831456250342748, 0.06659869487698544, 0.08096980370960649, 0.08721561255143151, 0.0699209169833992]}, "mutation_prompt": null}
{"id": "f3b0a9ea-092c-4576-93f5-743793e9c612", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            diversity = np.mean(np.std(self.population, axis=0))\n            self.cr = 0.6 + 0.3 * diversity  # Line changed\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance population diversity by adjusting crossover probability dynamically based on diversity.", "configspace": "", "generation": 95, "fitness": 0.37163342685960293, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7736266917446271, 0.7873698046145698, 0.7987851030916907, 0.7832464873360137, 0.801448648072854, 0.798661369111406, 0.7914796589248255, 0.799980417228084, 0.7783403759364793, 0.5853175938702785, 0.5751429521820604, 0.564759381541007, 0.5163386311176195, 0.595976066570729, 0.54807024204014, 0.5913910428942648, 0.6243174521357703, 0.5097043880571384, 0.11468989687575282, 0.19791287703788418, 0.1358543480279193, 0.43707103239332423, 0.12267860284328358, 0.13313098519147115, 0.12674334669138465, 0.11236818962255624, 0.12789322387795332, 0.10753316818644743, 0.11211766700496884, 0.12054189790136682, 0.11688515661288734, 0.12601180711140492, 0.11548313799337961, 0.1153474806653143, 0.11683290251674461, 0.1267692756168255, 0.7760233617568773, 0.9184128394788778, 0.8180473219316231, 0.8912085314620792, 0.8957266194929348, 0.9368800160753878, 0.7794358479294615, 0.8581784500639406, 0.9484970497019906, 0.5595182754578885, 0.4852949302839483, 0.4827359100413001, 0.5418167343375657, 0.48432698570642896, 0.5851678007966581, 0.543971511536902, 0.47801683518533067, 0.5310067390320576, 0.7833117124060495, 0.7304349993280672, 0.7149501745440423, 0.7583602172460556, 0.7520540942321661, 0.7941367445447821, 0.6779232257639032, 0.7522627293429976, 0.7528878595126706, 0.2731593864475651, 0.30710012326418423, 0.2876948419855818, 0.26827185141018206, 0.3420453980706776, 0.2659121013200071, 0.2381956714346566, 0.3598951966090044, 0.32287735403926876, 0.25479783763072805, 0.2149461006177349, 0.29949566731286636, 0.22625683450000056, 0.32860396907893963, 0.19067961323572213, 0.2084738073207154, 0.31535391924949596, 0.21742247565836348, 0.13749388542881913, 0.2606213436652288, 0.1523320999996438, 0.1748808233976915, 0.2329530784079814, 0.4797159247200984, 0.2642686044465664, 0.26984874843638007, 0.24655543756431242, 0.3993629932107867, 0.24150901389928114, 0.3224883752292914, 0.3794893489173985, 0.14850421182211881, 0.6072660663596308, 0.5695707445155871, 0.3274034924421513, 0.5298806330396011, 0.13125957146499512, 0.14478106342633623, 0.2513259959422357, 0.17362876653006065, 0.15944034636997972, 0.2075792597095587, 0.10744944477830742, 0.111675340010437, 0.0645643073386003, 0.2615489250425782, 0.29944300350069075, 0.29887084305187717, 0.28587995252528475, 0.24159191431059868, 0.28799051997404945, 0.21629313752381152, 0.21278324549148642, 0.2544295931855489, 0.6313395157803612, 0.6524932787038517, 0.640046366502484, 0.5777572799510107, 0.5909952005475141, 0.624538268536817, 0.590780321097538, 0.58738053240776, 0.5841194652670622, 0.09363855540263444, 0.12717758241070387, 0.11152770001801726, 0.11070128882986263, 0.11085570187690141, 0.09175133911181255, 0.10959169826809079, 0.13194041891529618, 0.11608541604164746, 0.22254696457678647, 0.25997437981704696, 0.25315917793009224, 0.24615915262509536, 0.25167608285904264, 0.23142437220175072, 0.20321824813666334, 0.19028704760959558, 0.22459561012165197, 0.4034557230409178, 0.37850424183282694, 0.3846592049143053, 0.3727828782650042, 0.43824812782511424, 0.40521455652822125, 0.4271825737578767, 0.4648175447997188, 0.45851355075820555, 0.30687919308284806, 0.31083103988990357, 0.31345685424193326, 0.2994974555487885, 0.3193406471967781, 0.2960688860780002, 0.27883990572925266, 0.3255409914845222, 0.33097536874586353, 0.2262556294585647, 0.1861890056406612, 0.19166518619767103, 0.20089034238264758, 0.20030038579524756, 0.20297394906363797, 0.2123671987870812, 0.2162952841507486, 0.1950512012224881, 0.3346961290044874, 0.22790498914006585, 0.202567535244641, 0.20015937997833066, 0.22080445439913776, 0.21661490795012284, 0.19155884872834383, 0.20542096416349476, 0.1871642945278894, 0.18222708953194078, 0.7725643750383596, 0.770911726868939, 0.17943703171525138, 0.6854896413857277, 0.1967770981131448, 0.1765879875700248, 0.7691282394064212, 0.19979230375084223, 0.7813259358111162, 0.7426283570071555, 0.7472043061158626, 0.7611906004982437, 0.7059604122124141, 0.6832004548582479, 0.7036535300232545, 0.7445280545167201, 0.7042988058902238, 0.18850601692967361, 0.17552406193442116, 0.18929157057530677, 0.19414811345880245, 0.19336856397100433, 0.19127820866758127, 0.18482525558256135, 0.19677881787291895, 0.19031330362774312, 0.07713773061962093, 0.08157855263545821, 0.08976933134447751, 0.09042246306596158, 0.08964432717564363, 0.09184965530871181, 0.0827187002654165, 0.071565717664263, 0.09147344086123244]}, "mutation_prompt": null}
{"id": "3c028b7e-2420-411e-bf06-f112f3827747", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n                self.cr = 0.9 * (1 - diversity) + 0.1  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce an adaptive crossover rate to balance exploration and exploitation during optimization.", "configspace": "", "generation": 96, "fitness": 0.19262582654391178, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.16.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.6989326468251181, 0.45574525689754275, 0.609726760417895, 0.6582182238303785, 0.4476115644681934, 0.4412698754229679, 0.44158013192037227, 0.445024041242029, 0.43882941396193076, 9.999999999998899e-05, 0.003284071397131827, 9.999999999998899e-05, 0.000371807463030005, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011051246161337125, 0.08844108522351524, 0.0748454739846024, 0.05871035174173089, 0.08442836470478865, 0.09184921638131605, 0.06629147597705942, 0.07299725787486555, 0.06236644050279627, 0.09383474797867641, 0.0760335229311373, 0.04778718682789751, 0.040687974201857435, 0.06844032647305232, 0.07891040940285199, 0.05447299268683492, 0.06722116078333473, 0.06643388914285497, 0.0540385418817968, 0.7064207088183154, 0.6811959140517205, 0.2715928242358554, 0.21201055950252068, 0.7629907357844566, 0.6879051737040359, 0.732513428542245, 0.6583261115367498, 0.7889476369133912, 0.26961501153134126, 0.28491499891098115, 0.25701431167514666, 0.2951936237185492, 0.279077657151806, 0.2860469895377913, 0.28029943853750816, 0.27645854194024255, 0.27257895376884633, 0.292614781256871, 0.19878032240925447, 0.24739260795957851, 0.2906702139804177, 0.22870959353331233, 0.2650492709459923, 0.41815946462136133, 0.2500472911958673, 0.20857241827612638, 0.1360940467958509, 0.1291838089717534, 0.15919631623845887, 0.1422143025909105, 0.14051102353314127, 0.13516874433033954, 0.16476677116025162, 0.1700188244158397, 0.12866084470095085, 0.14685561716491624, 0.12971610252458998, 0.1200740089544644, 0.13823544346239014, 0.14893606332044385, 0.15185950017464744, 0.17504507277256542, 0.1381202396236928, 0.15214445354888884, 0.023758059318653824, 9.999999999998899e-05, 0.002464000185538495, 9.999999999998899e-05, 0.0016394355077029577, 0.020637471435840604, 9.999999999998899e-05, 9.999999999998899e-05, 0.0038836126222513423, 0.06785810256552582, 0.06333164760808208, 0.10288513500262308, 0.1395737019431308, 0.07704598824781206, 0.09130446002588122, 0.08323176942075605, 0.07056095439988053, 0.06609058599410489, 0.017388406536412382, 0.021648114968400134, 0.02226288011665145, 0.023341218664148067, 0.030314857632772862, 0.02040376620022466, 0.016990862754101554, 0.01806468898105562, 0.016848155638804374, 0.08929646027236993, 0.09089297989984046, 0.10236456866056765, 0.08986772275381938, 0.08795292071500627, 0.09317829757384444, 0.09903218419408166, 0.09088010855906326, 0.0980204634812617, 0.3823557865234102, 0.4126814303480897, 0.41937781085258086, 0.3701802862688568, 0.3748364295547614, 0.38248323693482733, 0.38744020277677327, 0.39677491631671813, 0.396540636322094, 0.06512510155484397, 0.1163973054463957, 0.06162433559744673, 0.0636546429264021, 0.061284187177680916, 0.08167848569270608, 0.06372910251769337, 0.06618582647409821, 0.05520839759974494, 0.19482587997663992, 0.22067544889470359, 0.21111606316371168, 0.2519304805613348, 0.18575781259708424, 0.18021334153625412, 0.20547989415386303, 0.16255722215568258, 0.20244046393333426, 0.2317945977936452, 0.21531239737474317, 0.20944770895076625, 0.19894889045720554, 0.22859969125124058, 0.23527091767287134, 0.21835474063882943, 0.2180066952218631, 0.16894974649004202, 0.13748012793087616, 0.15030760765985907, 0.14414231071102535, 0.1717938057469559, 0.18376138929418828, 0.1847066051923969, 0.12062098573528313, 0.14124183439533367, 0.14094760344806967, 0.19255689122978825, 0.19005219188243705, 0.17727750744048476, 0.17774055724951576, 0.18187539762475857, 0.1896451939713667, 0.17967806140838039, 0.19505901945095305, 0.2116990861684922, 0.18564850391731935, 0.17610799805898225, 0.18815248540893315, 0.19358479932255146, 0.2007734071347711, 0.18373628302301204, 0.20257035078124486, 0.18102521418269923, 0.27447005798680413, 0.29654462478553056, 0.31383906455708355, 0.5348869072798443, 0.1756290103174042, 0.19642497144064286, 0.38672774436487234, 0.18560829957910407, 0.27667307013095566, 0.5034759433314933, 0.25177296811035776, 0.3353849563123871, 0.3691153427611885, 0.2909291264171414, 0.39013406055072164, 0.48836647754857054, 0.21665387800637714, 0.16854350592491196, 0.38255510191920317, 0.18006817414771592, 0.18218681064419717, 0.222612557395654, 0.19535401142413544, 0.18085762266214855, 0.19199471325497075, 0.1741295038886257, 0.20623442889422083, 0.18746996895662082, 0.07352064071098086, 0.05342870305900982, 0.06097049992372028, 0.06492337041903595, 0.06729088790009574, 0.0638704706128399, 0.07651031446905054, 0.06864619470410105, 0.08660040810111658]}, "mutation_prompt": null}
{"id": "7bc91b14-396d-4010-9077-089a972e4557", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        diversity = np.mean(np.std(self.population, axis=0))  # Line added\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget)\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive mutation based on diversity to enhance exploration efficacy.", "configspace": "", "generation": 97, "fitness": 0.37334812382227345, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7781909793381625, 0.7788577786434899, 0.7929282103434407, 0.7560053650908762, 0.7878876787757801, 0.813832289437631, 0.802227043814413, 0.8082739535558214, 0.7601761385332763, 0.5662957544998026, 0.5994757437227364, 0.5628610547799557, 0.5998235673904341, 0.5917094958477027, 0.5781184824900147, 0.6153579978870474, 0.5831034812752108, 0.59077832763482, 0.21526640187160406, 0.1774345697437737, 0.13189302783698764, 0.208770063349059, 0.16216956465179444, 0.12463158746143166, 0.28605174191702143, 0.13269036326880035, 0.15695422049769936, 0.11725700068469358, 0.11277781646832408, 0.12740079679073302, 0.12372068426697647, 0.18857098469537337, 0.12301980155331582, 0.189519542885353, 0.13013257206379947, 0.10560346626866635, 0.9476121515633251, 0.9122584595351784, 0.9271173868446434, 0.9085194383712523, 0.9397791840587383, 0.9442120689255259, 0.9212834172873806, 0.9311190096765056, 0.9539240404824272, 0.45482833475191065, 0.524729780903676, 0.49046976488998606, 0.5420745251561098, 0.5366209052742706, 0.5107644956970012, 0.472382468589134, 0.5366995236852594, 0.6019097947115646, 0.7081279967558374, 0.7149609574443605, 0.7351944941088714, 0.7939904130356155, 0.716224994160553, 0.7359624425003403, 0.8268999867207194, 0.6998812387065823, 0.6846259106796474, 0.27331053903173375, 0.4261900902451483, 0.22176334907940765, 0.2622487284368785, 0.24239323641355004, 0.18997463107021528, 0.3598273452605818, 0.28044567575978097, 0.30134882075140446, 0.29371443602818326, 0.3646450760100073, 0.2037144458800797, 0.5000433436213321, 0.2171380947116106, 0.19680540059657503, 0.2929604729723275, 0.28952096396893634, 0.2142812192289857, 0.3200433807000236, 0.3191202384674867, 0.18722766841381322, 0.1785244647912816, 0.28033290872647154, 0.40044641341060316, 0.10746939685128332, 0.35370393277780554, 0.2673728668542279, 0.37470341610558877, 0.31663103016979244, 0.3374474794864183, 0.4848391974468146, 0.2391169759769084, 0.47305707377626793, 0.4613812547209135, 0.4500370257370606, 0.43066446655445123, 0.1866764788906814, 0.08872248984179931, 0.11674502095070893, 0.22253935480614306, 0.10158372048193376, 0.1600844242868823, 0.22099958070054515, 0.16394526875431525, 0.06143645803735087, 0.27943567387508006, 0.3167749882914116, 0.2743821898276537, 0.28492855130879413, 0.3416885773092019, 0.32540585526333365, 0.27050351667303085, 0.29846408654402257, 0.248507162904526, 0.5933295860668648, 0.6447226776931818, 0.6254661760404823, 0.6387166430548148, 0.6627142640730114, 0.646813405076994, 0.6569113914194613, 0.573540141463764, 0.7494006241202232, 0.11204395590022886, 0.12147764377074632, 0.11509943004670586, 0.11923848198285925, 0.09751598699282238, 0.10309962983384613, 0.12221836294253863, 0.11107052934683581, 0.09949154966194074, 0.21458350952824967, 0.2350496493598807, 0.23268240266576556, 0.1902053051657403, 0.1835473383303221, 0.17970067230966402, 0.17533598472005474, 0.18990623850479493, 0.2255451356507363, 0.4132578690784525, 0.3963461151896538, 0.39989939393636265, 0.4285668688155835, 0.4862174555660901, 0.39318731480837343, 0.37120048850760945, 0.5145778083043084, 0.5149862030179618, 0.3008833537679788, 0.2972521363659061, 0.34209928475422313, 0.27420444367286445, 0.30189753376896145, 0.2984837491957053, 0.24845019473641394, 0.30477979952408485, 0.37401877046910426, 0.18783750863106097, 0.18825297841523336, 0.1944557495656225, 0.2005947265415683, 0.19983992126209593, 0.20579228699817675, 0.19795304331849206, 0.17640210635848885, 0.19578698282634333, 0.2969698750639054, 0.21244106606103708, 0.193735003927216, 0.1986310021205686, 0.5541005523475718, 0.4022981559435921, 0.27750090874554567, 0.23790524666216117, 0.3905043984119574, 0.6740223062672186, 0.1921422143532705, 0.772821807912267, 0.7107851414261448, 0.20418257455521438, 0.7134855197873107, 0.18591763303674513, 0.7247061139995618, 0.20043633985025167, 0.20595145981377927, 0.20786167571023995, 0.6020588914461005, 0.6461765676950237, 0.6071945280877171, 0.7307856273328797, 0.20590286633454458, 0.7211659164882203, 0.16581776520135716, 0.19899162397228554, 0.18859859438345605, 0.19511475734252492, 0.1797984852223644, 0.18291818458303633, 0.18867372646163805, 0.18758316637615058, 0.1948719632856588, 0.1914853056050425, 0.08102976250339944, 0.07836588794138555, 0.0828062870301175, 0.08660495678231561, 0.09477824807208579, 0.08590044589400658, 0.08290144657888754, 0.08512905707985774, 0.06828169216240254]}, "mutation_prompt": null}
{"id": "54158f9e-66c3-47ab-90d0-9c269fccf669", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (1 - self.evaluations / self.budget)  # Line changed\n                trial += np.random.normal(0, diversity, self.dim)\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Enhance convergence by introducing adaptive scaling of mutation factor based on diversity and remaining budget. ", "configspace": "", "generation": 98, "fitness": 0.3035919877415808, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.30 with standard deviation 0.23.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7095840289871922, 0.7029292126771387, 0.7365645463196013, 0.6773997625549769, 0.7296605137623133, 0.7575312530107853, 0.7033876798989374, 0.740392180342812, 0.7350191715666194, 0.048103221591887624, 0.3727955154276086, 0.3862317859180343, 0.045516736736538776, 0.39189891697723855, 0.386268587526726, 0.39167013168709974, 0.41389990118672837, 0.3712288785850051, 0.11462495750304502, 0.28176812014317165, 0.11917004011968879, 0.16667076153621163, 0.1370088475201373, 0.11552261533619435, 0.11552663460825674, 0.20532333293482796, 0.12588156060566635, 0.09041848416646192, 0.08738220995517454, 0.0787497382215262, 0.11806409884424485, 0.09639635769901178, 0.09333620421131439, 0.09088341343431405, 0.10034174507493954, 0.10931423274848917, 0.9657538331455563, 0.9623471937623144, 0.9906057910698935, 0.9559947583137192, 0.9911958254675509, 0.9565421924278309, 0.934267153033196, 0.9908902540996071, 0.9683814648997999, 0.34397211093010827, 0.43597570796042706, 0.45773386216374434, 0.45894283370527433, 0.39673017408161493, 0.3920881080519414, 0.44336497579805223, 0.3856984107695546, 0.4249587127909299, 0.6266067855335782, 0.5845548577577764, 0.5388363287756084, 0.5841376316541564, 0.5722255735938122, 0.5929285295983551, 0.6810808834794888, 0.578253484459452, 0.5490320671636151, 0.19913282694913337, 0.2214500343152207, 0.20821949163133402, 0.2052700986535082, 0.20208622277360666, 0.2629510417113452, 0.4081845201185488, 0.19234958012387404, 0.1850063016027943, 0.20368046866476686, 0.22756432744583377, 0.18733769184236426, 0.27610747578600225, 0.18880264416380876, 0.3041475493509199, 0.18914365853493642, 0.26852271610185907, 0.1918326344339819, 0.10152291306322891, 0.14525017096132375, 0.2567345272018837, 0.10230930421941553, 0.12641215321565014, 0.12363516092802906, 0.19341868367366055, 0.14271112132720642, 0.08329544879030104, 0.1610991350623835, 0.16540094595998833, 0.21548557219789466, 0.16739012340611736, 0.10490375975008448, 0.1367011771719293, 0.1099955630932744, 0.129157659977306, 0.18784697140097095, 0.037593720347651294, 0.06726429286706825, 0.04470653857475315, 0.1606032524484584, 0.08452726517209941, 0.14341150324064889, 0.07338012409653583, 0.14172971751696006, 0.08598709977264662, 0.20345749327115115, 0.20220494003056333, 0.21698841802776114, 0.2773352514019052, 0.20106194590641424, 0.23506713608730578, 0.265483906785417, 0.21980402157624335, 0.20534890371327008, 0.5636377103645313, 0.6402649746543413, 0.5625391777472233, 0.502440351770224, 0.48270315828999566, 0.6348974931982613, 0.5420308870958712, 0.5840125315751599, 0.5243054404322014, 0.10674298362319079, 0.09239902118108634, 0.10319785431970518, 0.10158170463610061, 0.11976692046095738, 0.08645958245581153, 0.10324010705227449, 0.10231236710123615, 0.08845470200124206, 0.359615181721997, 0.4859507736740647, 0.23756649881423686, 0.35295448834302356, 0.20653315661657712, 0.276086640902226, 0.18606553764039768, 0.27760490604344, 0.21968321185287365, 0.315439994549792, 0.305672067924077, 0.3023976533135053, 0.3419773675353013, 0.3008035026439515, 0.2013108593126799, 0.3280712259819878, 0.29712890923424207, 0.28844073411463245, 0.21153562350990773, 0.2420492356191133, 0.16390019140778533, 0.18969283691236838, 0.21430997263173313, 0.23238552616802222, 0.24017100792003931, 0.1822226946846126, 0.2454203704781568, 0.2086319104841624, 0.19221919798384302, 0.1742508137916955, 0.19389712083916832, 0.1710934593887139, 0.18001866036259584, 0.20111088454922255, 0.20935992839116668, 0.1852059216166324, 0.18836352559191616, 0.24919601976921746, 0.19197103357391188, 0.206637518171771, 0.20129001579213557, 0.34348497822632873, 0.20029293161290562, 0.32683656472807165, 0.36283875379716024, 0.5543750547315831, 0.5078022606407084, 0.6360155755110779, 0.19923671671291765, 0.20138154831569144, 0.21984377372008135, 0.1852434083366975, 0.18234731264416226, 0.18620321964722697, 0.5412022218713697, 0.200078587581076, 0.6690334012649627, 0.5913535620264556, 0.6414341350468535, 0.19596900983690968, 0.6412934499694867, 0.5232641899964927, 0.19773613666516954, 0.19707951654235745, 0.20313475936628855, 0.1950206401299842, 0.1822639885524917, 0.19363694967131573, 0.18960336027996505, 0.2089435837110385, 0.19290079104286673, 0.1889188713737373, 0.06825974083959607, 0.06083259026325982, 0.05947187364565598, 0.07576026218632836, 0.0687856985025157, 0.0898197911282197, 0.09242819778622524, 0.07957162145356322, 0.07236708465812314]}, "mutation_prompt": null}
{"id": "ca17ceb1-d9fb-4198-81e5-03c26f53e732", "solution": "import numpy as np\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.population_size = 20\n        self.cr = 0.9  # Crossover probability\n        self.f = 0.8   # Differential weight\n        self.local_search_iter = 5\n        self.init_population()\n    \n    def init_population(self):\n        self.population = np.random.uniform(self.lower_bound, self.upper_bound, \n                                            (self.population_size, self.dim))\n        self.fitness = np.full(self.population_size, float('inf'))\n        self.evaluations = 0\n    \n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            self.run_differential_evolution(func)\n            self.run_greedy_local_search(func)\n        \n        best_idx = np.argmin(self.fitness)\n        return self.population[best_idx], self.fitness[best_idx]\n    \n    def run_differential_evolution(self, func):\n        for i in range(self.population_size):\n            indices = [idx for idx in range(self.population_size) if idx != i]\n            a, b, c = self.population[np.random.choice(indices, 3, replace=False)]\n            mutant = np.clip(a + self.f * (b - c), self.lower_bound, self.upper_bound)\n            crossover = np.random.rand(self.dim) < self.cr\n            trial = np.where(crossover, mutant, self.population[i])\n            trial_fitness = func(trial)\n            self.evaluations += 1\n            if trial_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = trial, trial_fitness\n            if self.evaluations % 5 == 0:\n                diversity = np.mean(np.std(self.population, axis=0))\n                self.f = 0.5 + 0.5 * diversity * (self.evaluations / self.budget) * 0.9  # Line changed\n\n    def run_greedy_local_search(self, func):\n        self.population_size = max(5, int(20 * (1 - self.evaluations / (2 * self.budget))))  # Line changed\n        current_population_size = max(5, int(self.population_size * (1 - self.evaluations / self.budget)))\n        diversity = np.mean(np.std(self.population, axis=0))\n        for i in range(current_population_size):\n            candidate = self.population[i]\n            best_candidate = candidate.copy()\n            best_fitness = self.fitness[i]\n            perturbation_range = 0.3 * (1 - self.evaluations / self.budget) * (1 + diversity) * (self.budget - self.evaluations) / self.budget\n            adaptive_local_iter = max(1, int(self.local_search_iter * (1 - self.evaluations / self.budget)))  # Line changed\n            for _ in range(adaptive_local_iter):\n                perturbed = candidate + np.random.uniform(-perturbation_range, perturbation_range, self.dim)\n                perturbed = np.clip(perturbed, self.lower_bound, self.upper_bound)\n                perturbed_fitness = func(perturbed)\n                self.evaluations += 1\n                if perturbed_fitness < best_fitness:\n                    best_candidate, best_fitness = perturbed, perturbed_fitness\n            if best_fitness < self.fitness[i]:\n                self.population[i], self.fitness[i] = best_candidate, best_fitness", "name": "HybridMetaheuristic", "description": "Introduce adaptive scaling for the differential weight to enhance exploration and convergence balance.", "configspace": "", "generation": 99, "fitness": 0.3660108209436633, "feedback": "The algorithm HybridMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.37 with standard deviation 0.24.", "error": "", "parent_id": "e7d0dfae-f5a9-4548-8b0f-8e328fb9f8a6", "metadata": {"aucs": [0.7818309356158268, 0.7828750235332785, 0.8166564612276739, 0.8071872026381679, 0.7889356589044336, 0.8037478457128135, 0.7883502282238977, 0.7907796928619032, 0.7697254317330453, 0.613936921756487, 0.5338652864866125, 0.6100987118239507, 0.5759355515813309, 0.5817607474662263, 0.6014330981558015, 0.5390454132901953, 0.6326688482630334, 0.6151302150074665, 0.1446223186494866, 0.17598457451454996, 0.12212524003297331, 0.18809528238606854, 0.20934322441762732, 0.19237317957825184, 0.11407153819098315, 0.15619766237106436, 0.11751263457850314, 0.13107467648385485, 0.13319123100396935, 0.1235707193390887, 0.12571724755757097, 0.11142491799563126, 0.17032987987224946, 0.11915626699217896, 0.11767050380333455, 0.11255637223972659, 0.8885529849988975, 0.902935675815831, 0.8758757704666309, 0.8920474826853839, 0.9534069216915759, 0.8922234271952083, 0.9696490804977248, 0.927079867484218, 0.9446805238456368, 0.5402466898237785, 0.5259267679784354, 0.48578289827963794, 0.5403109158816444, 0.5914495446662085, 0.5377254844866204, 0.5062046888937055, 0.5169028020531194, 0.5153489402552669, 0.20540951675790353, 0.7172431720341352, 0.744287104500403, 0.3504726265878275, 0.760125369665459, 0.7932509404885711, 0.744405436538349, 0.7260113688322125, 0.7447964401743148, 0.23454437471378287, 0.2355529286899508, 0.2223044134537676, 0.37808126341417014, 0.24906693886629538, 0.21932514682267668, 0.3432158559557298, 0.3022012809122656, 0.2902686697165745, 0.25723441714437245, 0.26299982844693837, 0.18549686096633888, 0.321214090263623, 0.2468885147735933, 0.19968026340420142, 0.21086317316305903, 0.3226641429661501, 0.1780012872018265, 0.05471066953763215, 0.41332787494613277, 0.31477021779115244, 0.3866276982052538, 0.3029890246588459, 0.2438566933605777, 0.14953398349049818, 0.15979174079323677, 0.2656403044698279, 0.5064678181001562, 0.4636174083649036, 0.31775322931593397, 0.4493989496911819, 0.4432461947966446, 0.23944656849113255, 0.3596938791759662, 0.5330569627523366, 0.25299069201722335, 0.12120185554852725, 0.030217003560461864, 0.1278363729880344, 0.17919469653934084, 0.17240346090595504, 0.23280882620880472, 0.11609344085074824, 0.1147447019791431, 0.11629271459221113, 0.31560762276898113, 0.22377807449473408, 0.2373447944733852, 0.300093899694733, 0.3500740883932243, 0.2728523245914546, 0.2926001156227177, 0.26813596035747145, 0.2586910073372307, 0.7111238835273348, 0.7261676458363691, 0.576675912731322, 0.5581020517457486, 0.6464024859279578, 0.6789179302595111, 0.7245625510536674, 0.6062027709902178, 0.5437906763544569, 0.13121306028476665, 0.09624457458235736, 0.11045023079311067, 0.103366509243068, 0.10569871576406098, 0.11943325917836156, 0.12236565309758518, 0.12287791836274009, 0.10270043542821294, 0.22341819458068402, 0.23826260044139003, 0.22350871505932068, 0.22709756700422068, 0.23484802678197025, 0.2407483964060516, 0.22914906762375653, 0.21602376551338454, 0.23886602340526597, 0.42463436948933075, 0.4072523189396414, 0.4491313159114291, 0.39814403639603957, 0.36253555220220746, 0.37990697060899403, 0.4898017623604649, 0.43819779805904513, 0.46162572945818703, 0.33194828543420873, 0.30956043085746054, 0.35800369397289655, 0.3340357881026722, 0.29048796256487897, 0.3874323105517583, 0.3325165021006856, 0.33905261074895965, 0.3764608769889468, 0.19907628259845012, 0.20118974300557035, 0.2079464678403553, 0.20480584285892078, 0.19698375609136742, 0.2288389873259591, 0.19266867352038597, 0.2420504563363497, 0.2333241975918402, 0.21030763089909366, 0.20779025004347762, 0.21464572394198211, 0.21495737775020496, 0.20593448308152063, 0.3103601767457449, 0.19298309302824013, 0.285469543900701, 0.2189453250067478, 0.19236841387382664, 0.17233953449116712, 0.7504433390012312, 0.19180635924474077, 0.7689144953179377, 0.7355607606827154, 0.7345413349702516, 0.7687293694656459, 0.17322736307822906, 0.7937189654256952, 0.20571228558614663, 0.7551628263089306, 0.6343580242436262, 0.705198127596518, 0.7107363419355492, 0.16161593512404504, 0.16297693002361335, 0.20622235195840122, 0.1990778249822419, 0.21789691623293883, 0.18284396208382026, 0.1967610014991381, 0.1850467958189852, 0.18171025007788888, 0.19450366834717014, 0.19726171139193738, 0.181499524697339, 0.09732136369856759, 0.09154545197388875, 0.07395457441402808, 0.08391570737130483, 0.07971012859177751, 0.09289924484402634, 0.07681097641271062, 0.09722934216287571, 0.06966366400168955]}, "mutation_prompt": null}

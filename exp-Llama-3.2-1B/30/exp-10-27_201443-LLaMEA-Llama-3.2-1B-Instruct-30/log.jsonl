{"id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "solution": "import numpy as np\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "", "configspace": "", "generation": 0, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": null, "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "e6595628-1066-453a-9a5e-309dea504c79", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f'DABU: {self.dim}D: {self.budget} evaluations'\n\nclass DABU2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.search_history = []\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            self.search_history.append(self.search_space)\n        return func_value\n\n    def __str__(self):\n        return f'DABU2: {self.dim}D: {self.budget} evaluations'\n\nclass DABU3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.search_history = []\n        self.covariance = np.array([[1, 0.5], [0.5, 1]])\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            self.search_history.append(self.search_space)\n        return func_value\n\n    def __str__(self):\n        return f'DABU3: {self.dim}D: {self.budget} evaluations'\n\nclass DABU4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.search_history = []\n        self.covariance = np.array([[1, 0.5, 0.25], [0.5, 1, 0.5], [0.25, 0.5, 1]])\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            self.search_history.append(self.search_space)\n        return func_value\n\n    def __str__(self):\n        return f'DABU4: {self.dim}D: {self.budget} evaluations'\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu2 = DABU2(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu2(test_function))  # prints a random value between -10 and 10\n\ndabu3 = DABU3(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu3(test_function))  # prints a random value between -10 and 10\n\ndabu4 = DABU4(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu4(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 1, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "f50a7fef-81d6-4321-8dd6-e378253e965f", "solution": "import numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def adaptive_search(self, func, initial_solution, alpha=0.1, beta=0.01):\n        # Generate a random initial solution\n        solution = initial_solution\n        \n        # Perform adaptive search\n        while self.func_evaluations < self.budget:\n            # Evaluate the function at the current solution\n            func_value = func(solution)\n            \n            # If the function value is close to zero, stop\n            if np.abs(func_value) < 1e-6:\n                break\n            \n            # Update the solution using the best-fitting data point\n            solution = np.array([x for x, _ in zip(self.search_space, func_value)])\n            \n            # Update the search space using the best-fitting data point\n            best_idx = np.argmax(np.abs(func_value))\n            self.search_space[best_idx] = alpha * self.search_space[best_idx] + beta * (1 - alpha) * (1 - best_idx)\n        \n        # Refine the solution using the best-fitting data point\n        best_idx = np.argmax(np.abs(func_value))\n        self.search_space[best_idx] = alpha * self.search_space[best_idx] + beta * (1 - alpha) * (1 - best_idx)\n        \n        return solution\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\ndef best_func(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nbest_solution = dabu.adaptive_search(best_func, x0=[1, 1])\nprint(best_solution)  # prints a refined solution\n\ndef random_func(x):\n    return np.random.rand(2)\n\nrandom_solution = dabu.adaptive_search(random_func, x0=[1, 1])\nprint(random_solution)  # prints a random solution", "name": "DABU", "description": "\"DABU: Dynamic Adaptive Best-First-Exploitation\"", "configspace": "", "generation": 2, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"DABU.adaptive_search() got an unexpected keyword argument 'x0'\").", "error": "TypeError(\"DABU.adaptive_search() got an unexpected keyword argument 'x0'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "c7d2c8d1-e03d-4061-8577-0d94f17a78a2", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.learning_rate = 0.01\n        self.diversity = 0.1\n        self.population_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def evolve(self, population):\n        # Select parents using tournament selection\n        parents = random.sample(population, self.population_size)\n        for _ in range(10):  # evolve for 10 generations\n            # Create offspring by crossover and mutation\n            offspring = []\n            for _ in range(self.population_size):\n                parent1, parent2 = random.sample(parents, 2)\n                child = (0.5 * (parent1 + parent2)) / 2\n                if random.random() < self.diversity:\n                    child[0] += random.uniform(-1, 1)\n                    child[1] += random.uniform(-1, 1)\n                offspring.append(child)\n            population = offspring\n\n        # Replace least fit individuals with new ones\n        population = [func(self.search_space) for func in population]\n\n        # Evolve for another generation\n        self.learning_rate *= 0.9\n        self.diversity *= 0.9\n\n        return population\n\n    def optimize(self, func):\n        population = [func(self.search_space) for func in self.evolve([func])]\n        return self.__call__(func)", "name": "DABU", "description": "Evolutionary Algorithm with Adaptive Learning Rate and Diversity", "configspace": "", "generation": 3, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "91db6d70-c67e-4d8e-821f-bbd04e8fc279", "solution": "import numpy as np\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "35f24fba-a99a-4304-889e-509d6e01ffbe", "solution": "import numpy as np\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\nclass BlackBoxOptimizer:\n    def __init__(self, budget, dim, alpha=0.3, beta=0.7):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if np.random.rand() < self.alpha:\n                # Refine the strategy with probability alpha\n                self.search_space = np.linspace(func_value - 1e-6, func_value + 1e-6, self.dim)\n            elif np.random.rand() < self.beta:\n                # Explore the search space with probability beta\n                self.search_space = self.search_space * 1.2\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\noptimizer = BlackBoxOptimizer(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(optimizer(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 5, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "9d3e6212-d65b-4aeb-8938-890a8f54fbaf", "solution": "import numpy as np\n\nclass APLOS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def adaptive_pareto(self, func, iterations):\n        best_func = None\n        best_func_value = float('-inf')\n        best_dim = None\n        best_dim_value = float('-inf')\n        for _ in range(iterations):\n            func_values = []\n            for dim in range(self.dim):\n                func_value = func(self.search_space)\n                func_values.append(func_value)\n            func_values.sort()\n            for i, func_value in enumerate(func_values):\n                if i == 0:\n                    best_func = func\n                    best_func_value = func_value\n                    best_dim = dim\n                    best_dim_value = func_value\n                elif func_value > best_func_value:\n                    best_func = func\n                    best_func_value = func_value\n                    best_dim = dim\n                    best_dim_value = func_value\n            func_value = best_func(best_dim_value)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return best_func, best_func_value, best_dim, best_dim_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\naplos = APLOS(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(aplos(test_function))  # prints a random value between -10 and 10\n\ndef test_pareto_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\naplos_pareto, aplos_pareto_value, aplos_pareto_best_dim, aplos_pareto_best_dim_value = aplos.adaptive_pareto(test_function, 10)\nprint(f\"Best Pareto Function: {aplos_pareto}\")\nprint(f\"Best Pareto Value: {aplos_pareto_value}\")\nprint(f\"Best Pareto Dimension: {aplos_pareto_best_dim}\")\nprint(f\"Best Pareto Dimension Value: {aplos_pareto_best_dim_value}\")", "name": "APLOS", "description": "Adaptive Pareto-Based Optimization Using Local Search (APLOS)", "configspace": "", "generation": 6, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('invalid index to scalar variable.').", "error": "IndexError('invalid index to scalar variable.')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "523f2d8c-8f6b-49fe-afda-c67b15ddb397", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"DABU: Function evaluations: {self.func_evaluations}/{self.budget}\"\n\nclass EMA_DABU(DABU):\n    def __init__(self, budget, dim):\n        super().__init__(budget, dim)\n        self.ema_coefficient = 0.1\n\n    def __call__(self, func):\n        ema_value = self.ema(self.search_space, self.budget, self.func_evaluations)\n        func_value = func(self.search_space)\n        new_value = ema_value + (1 - self.ema_coefficient) * (func_value - ema_value)\n        return new_value\n\n    def ema(self, x, budget, func_evaluations):\n        mean = np.mean(x)\n        variance = np.var(x)\n        return mean + (1 - self.ema_coefficient) * variance / (1 + self.ema_coefficient * variance)\n\nclass L1_DABU(DABU):\n    def __init__(self, budget, dim):\n        super().__init__(budget, dim)\n        self.l1_coefficient = 0.1\n\n    def __call__(self, func):\n        def objective(x):\n            return np.sum(np.abs(func(x)))\n        return objective\n\n    def __str__(self):\n        return f\"L1_DABU: Objective function: {self.l1_coefficient * np.sum(np.abs(self.search_space))}\"\n\nclass L2_DABU(DABU):\n    def __init__(self, budget, dim):\n        super().__init__(budget, dim)\n        self.l2_coefficient = 0.1\n\n    def __call__(self, func):\n        def objective(x):\n            return np.sum((func(x) - self.search_space)**2)\n        return objective\n\n    def __str__(self):\n        return f\"L2_DABU: Objective function: {self.l2_coefficient * np.sum((func(self.search_space) - self.search_space)**2)}\"\n\n# Description: Differential Evolution Algorithm with Adaptive EMA\n# Code: \n# ```python\n# import numpy as np\n# import scipy.optimize as optimize\n#\n# class DAE_DABU(DABU):\n#     def __init__(self, budget, dim):\n#         super().__init__(budget, dim)\n#         self.optimization_function = optimize.differential_evolution\n#\n#     def __call__(self, func):\n#         try:\n#             result = self.optimization_function(func, bounds=[(-5, 5), (-5, 5)], x0=[np.random.rand(self.dim)]*self.dim)\n#         except Exception as e:\n#             print(f\"Error: {e}\")\n#         return result[0]", "name": "DABU", "description": "Differential Evolution Algorithm with Adaptive EMA", "configspace": "", "generation": 7, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "7918ed71-9546-4789-a429-0c6fe22f8e84", "solution": "import numpy as np\nimport random\nfrom scipy.optimize import differential_evolution\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def differential_evolution(self, func, bounds):\n        res = differential_evolution(func, bounds)\n        return res.fun, res.x\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nres, x = dabu.differential_evolution(test_function, [(-5.0, 5.0), (-5.0, 5.0)])\nprint(f\"Optimal solution: {x}\")\nprint(f\"Optimal function value: {res}\")\n\n# Refine the strategy by changing the number of iterations and the step size\ndabu = DABU(1000, 2)\ndabu.search_space = np.linspace(-3.0, 3.0, 3)\nres, x = dabu.differential_evolution(test_function, [(-3.0, 3.0), (-3.0, 3.0)])\nprint(f\"Optimal solution: {x}\")\nprint(f\"Optimal function value: {res}\")", "name": "DABU", "description": "DABU: Dynamic Adaptive Black Box Optimization using Differential Evolution", "configspace": "", "generation": 8, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "4c21ba86-3b49-4517-a3fc-7b7949c4c434", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def refine_strategy(self, func):\n        # Refine the search space using genetic algorithm\n        population = self.generate_population()\n        for _ in range(10):  # Run 10 generations\n            # Select parents using tournament selection\n            parents = self.select_parents(population)\n            # Crossover (reproduce) offspring using uniform crossover\n            offspring = self.crossover(parents)\n            # Mutate offspring using bit-flip mutation\n            offspring = self.mutate(offspring)\n            # Replace the old population with the new one\n            population = self.replace_population(population, offspring)\n\n    def generate_population(self):\n        # Generate a population of random solutions\n        population = []\n        for _ in range(100):\n            solution = self.search_space + np.random.uniform(-1, 1, self.dim)\n            population.append(solution)\n        return population\n\n    def select_parents(self, population):\n        # Select parents using tournament selection\n        tournament_size = 3\n        tournament_results = []\n        for _ in range(100):\n            parent1, parent2, parent3 = random.sample(population, tournament_size)\n            results = [np.abs(x - y) for x, y in zip(parent1, parent2) if np.abs(x - y) < 1e-6]\n            tournament_results.append(results[0])\n        tournament_results = np.array(tournament_results).reshape(-1, tournament_size)\n        return tournament_results\n\n    def crossover(self, parents):\n        # Crossover (reproduce) offspring using uniform crossover\n        offspring = parents.copy()\n        for i in range(len(parents) // 2):\n            if random.random() < 0.5:  # 50% chance of crossover\n                parent1, parent2 = parents[i], parents[-i - 1]\n                idx = random.randint(0, len(parent1) - 1)\n                offspring[idx] = parent2[idx]\n        return offspring\n\n    def mutate(self, offspring):\n        # Mutate offspring using bit-flip mutation\n        mutated_offspring = []\n        for solution in offspring:\n            mutated_solution = solution.copy()\n            for i in range(len(mutated_solution)):\n                if random.random() < 0.1:  # 10% chance of mutation\n                    mutated_solution[i] ^= 1\n            mutated_offspring.append(mutated_solution)\n        return mutated_offspring\n\n    def replace_population(self, population, offspring):\n        # Replace the old population with the new one\n        population[:] = offspring\n        return population\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\ndabu.refine_strategy(test_function)\nprint(dabu(test_function))  # prints a refined value between -10 and 10", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 9, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "1cafbbbf-4fd7-4335-99c4-76f67ab7b531", "solution": "import numpy as np\nimport random\nfrom collections import deque\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.population = deque(maxlen=self.budget)\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            self.population.append(func_value)\n            if len(self.population) > self.budget:\n                random.shuffle(self.population)\n        return random.choice(self.population)\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Novel Metaheuristic Algorithm: Adaptive Multi-Step Greedy (AMSG)\n# Description: Adaptive Multi-Step Greedy algorithm that adapts its strategy based on the performance of its solutions.\n# Code: ", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 10, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('Cannot choose from an empty sequence').", "error": "IndexError('Cannot choose from an empty sequence')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "f0609052-0fa7-4e66-83d6-e4b71c6d7343", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\n\nclass NovelDABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        # Refine the search space using probability 0.3\n        probability = np.random.rand(2)  # 0.3 chance to refine the search space\n        if probability < 0.3:\n            self.search_space = np.linspace(0.0, 10.0, self.dim)  # refine the lower bound\n        else:\n            self.search_space = np.linspace(-5.0, 5.0, self.dim)  # refine the upper bound\n        # Optimize the function using differential evolution\n        res = differential_evolution(func, self.search_space)\n        # Update the function evaluations\n        self.func_evaluations += 1\n        return res.fun\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnovel_dabu = NovelDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(novel_dabu(test_function))  # prints a random value between -10 and 10\n\n# Test the function\ndef test_function_refined(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nrefined_dabu = NovelDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(refined_dabu(test_function_refined))  # prints a random value between -10 and 10", "name": "NovelDABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 11, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "e82dc569-c994-456f-a72b-ce4f2637f7c9", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"DABU: {self.budget} evaluations, {self.dim} dimensions\"\n\n    def __str_func_evals__(self, func_evals):\n        return f\"DABU: {func_evals} evaluations\"\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Novel Metaheuristic Algorithm: Adaptive Multi-Step Hill Climbing (AMSHC)\n# The algorithm adapts its strategy based on the convergence rate of the current solution\nclass AMSHC:\n    def __init__(self, budget, dim, step_size, alpha, beta):\n        self.budget = budget\n        self.dim = dim\n        self.step_size = step_size\n        self.alpha = alpha\n        self.beta = beta\n        self.func_evaluations = 0\n        self.current_solution = None\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            if self.current_solution is None:\n                self.current_solution = func(self.search_space)\n                self.func_evaluations += 1\n            else:\n                # Calculate the new solution using the current solution and step size\n                new_solution = self.current_solution + self.step_size * np.random.normal(0, 1, self.dim)\n                new_func_value = func(new_solution)\n\n                # Evaluate the new function value\n                if np.abs(new_func_value) < 1e-6:  # stop if the function value is close to zero\n                    break\n\n                # Update the current solution and function evaluations\n                self.current_solution = new_solution\n                self.func_evaluations += 1\n\n                # Adapt the strategy based on the convergence rate\n                if new_func_value < self.alpha * self.func_evaluations:\n                    # Increase the step size to accelerate convergence\n                    self.step_size *= self.beta\n                elif new_func_value > self.alpha * self.func_evaluations + self.beta * self.func_evaluations:\n                    # Decrease the step size to slow down convergence\n                    self.step_size /= self.beta\n\n    def __str__(self):\n        return f\"AMSHC: {self.budget} evaluations, {self.dim} dimensions\"\n\n    def __str_func_evals__(self, func_evals):\n        return f\"AMSHC: {func_evals} evaluations\"\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\namshc = AMSHC(1000, 2, 0.1, 0.5, 1.0)  # 1000 function evaluations, 2 dimensions\nprint(amshc(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 12, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'AMSHC' object has no attribute 'search_space'\").", "error": "AttributeError(\"'AMSHC' object has no attribute 'search_space'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "ad45db55-3a83-40fe-92a1-873377e792ff", "solution": "import numpy as np\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def refine_strategy(self):\n        # Refine the search space by increasing the lower bound\n        self.search_space[0] = -10.0\n        # Refine the search space by decreasing the upper bound\n        self.search_space[1] = 5.0\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Update the DABU algorithm with a novel metaheuristic strategy\nclass DABURefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.refine_strategy()\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        self.refine_strategy()\n        return func_value\n\n    def refine_strategy(self):\n        # Refine the search space by increasing the lower bound\n        self.search_space[0] = -10.0\n        # Refine the search space by decreasing the upper bound\n        self.search_space[1] = 5.0\n\n# Evaluate the updated DABURefined algorithm\ndaru = DABURefined(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(daru(test_function))  # prints a random value between -10 and 10\n\n# Evaluate the DABU algorithm with a refined strategy\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Evaluate the DABURefined algorithm with a novel metaheuristic strategy\ndaru_refined = DABURefined(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(daru_refined(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 13, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "b8cb0ef2-f874-46dd-9fd8-6071f0a58880", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\n\nclass NovelMetaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.search_space_min = -5.0\n        self.search_space_max = 5.0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def optimize(self, func):\n        # Refine the search space using probability 0.3\n        search_space = self.search_space.copy()\n        if np.random.rand() < 0.3:\n            # Increase the upper bound by 10%\n            self.search_space_max *= 1.1\n        else:\n            # Decrease the upper bound by 10%\n            self.search_space_max /= 1.1\n        if np.random.rand() < 0.3:\n            # Increase the lower bound by 10%\n            self.search_space_min *= 1.1\n        else:\n            # Decrease the lower bound by 10%\n            self.search_space_min /= 1.1\n        return self.optimize_func(func, search_space)\n\n    def optimize_func(self, func, search_space):\n        # Perform differential evolution to optimize the function\n        res = differential_evolution(func, search_space)\n        return res.fun\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnovel_metaheuristic = NovelMetaheuristic(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(novel_metaheuristic(test_function))  # prints a random value between -10 and 10", "name": "NovelMetaheuristic", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 14, "fitness": 0.010166584100840514, "feedback": "The algorithm NovelMetaheuristic got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "dd13a3cf-596a-4612-8c4d-6e182557cdf2", "solution": "import numpy as np\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def adapt_search_space(self, func, initial_search_space):\n        # Calculate the best function value and corresponding search space\n        best_func_value = np.min([func(x) for x in initial_search_space])\n        best_search_space = initial_search_space[np.argmin([func(x) for x in initial_search_space])]\n\n        # Refine the search space based on the best function value\n        if np.abs(best_func_value) > 1e-6:\n            # If the best function value is significantly different from the minimum, refine the search space\n            step_size = 0.1\n            for i in range(self.dim):\n                new_search_space = initial_search_space.copy()\n                new_search_space[i] += step_size\n                new_search_space = np.clip(new_search_space, best_search_space - 2*step_size, best_search_space + 2*step_size)\n                self.search_space = new_search_space\n                func_value = func(new_search_space)\n                if np.abs(func_value) < 1e-6:\n                    break\n            self.search_space = np.clip(self.search_space, best_search_space - 2*step_size, best_search_space + 2*step_size)\n        return self.search_space\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\ninitial_search_space = np.linspace(-5.0, 5.0, 2)\ndabu.search_space = dabu.adapt_search_space(test_function, initial_search_space)\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# DABU's adaptive search space refinement strategy:\n# 1. Calculate the best function value and corresponding search space\n# 2. If the best function value is significantly different from the minimum, refine the search space\n# 3. Repeat steps 1-2 until the budget is exhausted", "name": "DABU", "description": "DABU - Dynamic Adaptive Boundary Utilization", "configspace": "", "generation": 15, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('invalid index to scalar variable.').", "error": "IndexError('invalid index to scalar variable.')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "d0416b10-ceec-498b-882a-597300fd1340", "solution": "import numpy as np\n\nclass AMGD:\n    def __init__(self, budget, dim, learning_rate, multi_step_size, alpha):\n        self.budget = budget\n        self.dim = dim\n        self.learning_rate = learning_rate\n        self.multi_step_size = multi_step_size\n        self.alpha = alpha\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            # Select a multi-step search strategy based on the current function value\n            if np.abs(func(self.search_space)) < 1e-6:  # stop if the function value is close to zero\n                return func(self.search_space)\n            # Perform a single step gradient descent\n            step = np.zeros(self.dim)\n            for i in range(self.dim):\n                step[i] = (func(self.search_space[i]) - func(self.search_space[i-1])) / self.multi_step_size\n            # Update the search direction using the adaptive learning rate\n            self.learning_rate = max(0.01, min(self.learning_rate, 0.1 * np.linalg.norm(step) / self.alpha))\n            # Update the search space using the adaptive multi-step size\n            self.search_space = np.linspace(self.search_space[0] - self.multi_step_size, self.search_space[0] + self.multi_step_size, self.dim)\n            self.func_evaluations += 1\n        return func(self.search_space)", "name": "AMGD", "description": "Adaptive Multi-Step Gradient Descent (AMGD) is a novel metaheuristic algorithm that combines the strengths of gradient descent with the adaptability of multi-step methods.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"AMGD.__init__() missing 3 required positional arguments: 'learning_rate', 'multi_step_size', and 'alpha'\").", "error": "TypeError(\"AMGD.__init__() missing 3 required positional arguments: 'learning_rate', 'multi_step_size', and 'alpha'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "6c899f8b-4a18-440a-b816-45f0670948ab", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"DABU: {self.budget} function evaluations, {self.dim} dimensions\"\n\nclass DASO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"DASO: {self.budget} function evaluations, {self.dim} dimensions\"\n\nclass ADAM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = 0.9\n        self.beta = 0.999\n        self.moving_average = np.zeros(self.dim)\n        self.variance = np.zeros(self.dim)\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            self.variance = np.mean((self.variance * self.beta + self.moving_average * (1 - self.beta)) ** 2)\n            self.moving_average = self.beta * self.moving_average + (1 - self.beta) * func_value\n            self.variance = self.beta * self.variance + (1 - self.beta) * self.variance * self.variance\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"ADAM: {self.budget} function evaluations, {self.dim} dimensions\"\n\nclass PSO:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.particles = []\n        self.vectors = []\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"PSO: {self.budget} function evaluations, {self.dim} dimensions\"\n\nclass NSGAII:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.population = []\n        self.fitness = np.zeros(self.budget)\n        self.pareto = False\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"NSGAII: {self.budget} function evaluations, {self.dim} dimensions\"\n\n# Description: Genetic Algorithm\n# Code: ", "name": "DABU", "description": "Genetic Algorithm", "configspace": "", "generation": 17, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "4becf547-41b7-4505-b517-8e29abadf354", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\n\nclass DynamicAdaptiveBoundedOptimization:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def adaptive_strategy(self, func):\n        # Refine the search space based on the function value\n        if np.abs(func(self.search_space)) < 1e-6:\n            # If the function value is close to zero, expand the search space\n            self.search_space = np.linspace(-5.0, 5.0, self.dim * 2)\n        else:\n            # If the function value is not close to zero, contract the search space\n            self.search_space = np.linspace(-5.0, 5.0, self.dim)\n\n    def bounded_search(self, func, initial_point, bounds):\n        # Perform a bounded search using differential evolution\n        result = differential_evolution(func, bounds, x0=initial_point)\n        return result\n\n    def run(self, func, initial_point, bounds):\n        # Run the optimization algorithm\n        self.adaptive_strategy(func)\n        bounded_search_result = self.bounded_search(func, initial_point, bounds)\n        # Refine the search space based on the bounded search result\n        if bounded_search_result.x[0] < 0:\n            self.search_space = np.linspace(-5.0, 5.0, self.dim)\n        else:\n            self.search_space = np.linspace(-5.0, 5.0, self.dim * 2)\n        return bounded_search_result\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DynamicAdaptiveBoundedOptimization(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10", "name": "DynamicAdaptiveBoundedOptimization", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 18, "fitness": 0.010166584100840514, "feedback": "The algorithm DynamicAdaptiveBoundedOptimization got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "c9f5364f-e6ea-4ab0-8c86-a60a10e10ba1", "solution": "import numpy as np\n\nclass AES:\n    def __init__(self, budget, dim, alpha=0.01, beta=0.9, gamma=0.01, mu=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.alpha = alpha\n        self.beta = beta\n        self.gamma = gamma\n        self.mu = mu\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.best_func = None\n        self.best_score = float('-inf')\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def adapt(self, func, new_func, new_score):\n        if new_score > self.best_score:\n            self.best_func = new_func\n            self.best_score = new_score\n        if new_score - self.best_score > 3 * self.alpha * (self.best_score - self.alpha * self.mu):\n            self.alpha = self.alpha * (1 - self.beta)\n        elif new_score - self.best_score > 3 * self.alpha * (self.alpha * self.mu - self.beta * self.mu):\n            self.beta = self.beta * (1 - self.gamma)\n        else:\n            self.beta = self.beta * (1 - self.gamma)\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndef evaluate_func(func, x):\n    return func(x)\n\ndef test_func(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\naes = AES(1000, 2)  # 1000 function evaluations, 2 dimensions\naes.adapt(test_function, test_func, evaluate_func(test_func, aes.search_space))\n\nprint(aes(test_function))  # prints a random value between -10 and 10", "name": "AES", "description": "Adaptive Evolution Strategy (AES) - Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 19, "fitness": 0.010166584100840514, "feedback": "The algorithm AES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "dd31dc42-cd05-4818-84e2-0f2f985a74ff", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def update_strategy(self):\n        if self.func_evaluations < self.budget // 3:\n            # Refine strategy by increasing the upper bound\n            self.search_space = np.linspace(5.0, 10.0, self.dim)\n            self.func_evaluations = 0\n        elif self.func_evaluations < self.budget // 2:\n            # Refine strategy by decreasing the lower bound\n            self.search_space = np.linspace(0.0, -5.0, self.dim)\n            self.func_evaluations = 0\n        else:\n            # Refine strategy by increasing the upper bound\n            self.search_space = np.linspace(5.0, 10.0, self.dim)\n            self.func_evaluations = 0\n\n    def __str__(self):\n        return f\"DABU with {self.budget} function evaluations, {self.dim} dimensions\"\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\ndabu.update_strategy()\nprint(dabu)  # prints DABU with 500 function evaluations, 2 dimensions", "name": "DABU", "description": "DABU: Dynamic Adaptive Binary Optimization using Adaptive Binary Updater", "configspace": "", "generation": 20, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "94820c44-c57d-4130-b82e-24008afa8fb2", "solution": "import numpy as np\nfrom scipy.optimize import minimize_scalar\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"DABU: Optimizing {self.dim}-dimensional function using {self.budget} evaluations\"\n\n    def __repr__(self):\n        return f\"DABU(budget={self.budget}, dim={self.dim})\"\n\n    def optimize(self, func):\n        # Refine the search space based on the results of the first evaluation\n        if self.func_evaluations == 0:\n            self.search_space = np.linspace(-5.0, 5.0, self.dim)\n        else:\n            # Use the previously optimized search space as a starting point\n            self.search_space = np.linspace(-5.0, 5.0, self.dim)\n            for _ in range(10):\n                # Use a random search within the current search space\n                new_search_space = np.random.uniform(self.search_space)\n                # Evaluate the function at the new search space\n                func_value = func(new_search_space)\n                # If the function value is close to zero, stop exploring this branch\n                if np.abs(func_value) < 1e-6:\n                    break\n                # Otherwise, update the search space for the next iteration\n                self.search_space = new_search_space\n\n        # Perform a random search within the refined search space\n        func_value = func(self.search_space)\n        if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n            break\n        self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Refine the search space based on the results of the first evaluation\ndabu.optimize(test_function)\n\n# Update the algorithm with the refined search space\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Evaluate the function using the updated algorithm\ndabu.optimize(test_function)", "name": "DABU", "description": "DABU: Optimizes black box functions using a hybrid search algorithm", "configspace": "", "generation": 21, "fitness": -Infinity, "feedback": "An exception occurred: SyntaxError(\"'break' outside loop\", ('<string>', 46, 13, None, 46, 18)).", "error": "SyntaxError(\"'break' outside loop\", ('<string>', 46, 13, None, 46, 18))", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "7597490c-2f13-4ea9-9d01-5af66f07f22f", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\nimport random\n\nclass Refiner:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def refine(self, func, initial_solution):\n        # Initialize the refined solution with the initial solution\n        refined_solution = initial_solution.copy()\n\n        # Refine the solution using a modified genetic algorithm\n        for _ in range(self.dim):\n            # Generate a new solution by perturbing the current solution\n            new_solution = refined_solution.copy()\n            for i in range(self.dim):\n                new_solution[i] += random.uniform(-1, 1)\n            new_solution = np.clip(new_solution, self.search_space, None)\n\n            # Evaluate the new solution using the function\n            func_value = func(new_solution)\n\n            # If the new solution is better, replace the current solution\n            if func_value > np.abs(func(refined_solution)):\n                refined_solution = new_solution\n\n        return refined_solution\n\nclass DABU(Refiner):\n    def __init__(self, budget, dim):\n        super().__init__(budget, dim)\n\n    def __call__(self, func):\n        # Use the Refiner to refine the solution\n        refined_solution = self.refine(func, self.search_space)\n        return Refiner.__call__(self, func)(refined_solution)\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# One-line description with main idea\n# Novel metaheuristic algorithm for black box optimization, \n# utilizing a refined strategy to improve convergence and efficiency.", "name": "Refiner", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 22, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'numpy.float64' object is not callable\").", "error": "TypeError(\"'numpy.float64' object is not callable\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "3daf9b02-ae46-4384-991b-635994fa5a31", "solution": "import numpy as np\n\nclass ACR:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.convergence_rate = 0.5  # initial convergence rate\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            self.convergence_rate = np.clip(self.convergence_rate * 0.9, 0.01, 0.1)  # adapt convergence rate\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nacr = ACR(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(acr(test_function))  # prints a random value between -10 and 10", "name": "ACR", "description": "DABU", "configspace": "", "generation": 23, "fitness": 0.010166584100840514, "feedback": "The algorithm ACR got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "49b55093-3318-40b1-82b5-f277e83a1255", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\n\nclass AdaptiveDDE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.local_search = False\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def adaptive_local_search(self, func):\n        while self.func_evaluations < self.budget:\n            x, _ = differential_evolution(func, self.search_space)\n            if np.abs(x[0]**2 + x[1]**2) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.local_search:\n                self.search_space = np.linspace(-5.0, 5.0, self.dim)\n            else:\n                self.search_space = np.linspace(-5.0, 5.0, self.dim) * 2\n            self.local_search = not self.local_search", "name": "AdaptiveDDE", "description": "Adaptive Differential Evolution Using Local Search", "configspace": "", "generation": 24, "fitness": 0.010166584100840514, "feedback": "The algorithm AdaptiveDDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "a910fb38-430a-45b7-9bef-0b73d611e98b", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass ACR:\n    def __init__(self, budget, dim, initial_strategy, refinement_factor):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.initial_strategy = initial_strategy\n        self.refinement_factor = refinement_factor\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def optimize(self, func):\n        # Initialize strategy with the initial strategy\n        strategy = self.initial_strategy\n        # Refine strategy based on the number of function evaluations\n        for _ in range(self.budget - 1):\n            # Evaluate the function at the current strategy\n            func_value = func(strategy)\n            # Refine the strategy based on the convergence rate\n            if np.abs(func_value) < 1e-6:\n                break\n            # Update the strategy based on the refinement factor\n            strategy = strategy + self.refinement_factor * np.random.uniform(-1, 1, self.dim)\n        return strategy\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndef optimize_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = ACR(1000, 2, test_function, 0.5)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Update the solution\ndabu = ACR(1000, 2, dabu.optimize(test_function), 0.5)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a refined value between -10 and 10", "name": "ACR", "description": "ACR is a novel metaheuristic algorithm that combines the benefits of adaptive convergence refinement and evolutionary optimization. The algorithm starts with an initial strategy and refines it based on the convergence rate of the optimization process. The refinement factor controls the rate at which the strategy is refined.", "configspace": "", "generation": 25, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'function' object is not subscriptable\").", "error": "TypeError(\"'function' object is not subscriptable\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "f6d896a6-0a66-41ef-af87-a124760b1547", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.population = self.initialize_population()\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def initialize_population(self):\n        population = []\n        for _ in range(100):  # population size is 100\n            individual = [random.uniform(-5.0, 5.0) for _ in range(self.dim)]\n            population.append(individual)\n        return population\n\n    def mutate(self, individual):\n        mutated_individual = individual.copy()\n        if random.random() < 0.5:  # mutation probability is 50%\n            mutated_individual[random.randint(0, self.dim-1)] = random.uniform(-5.0, 5.0)\n        return mutated_individual\n\n    def crossover(self, parent1, parent2):\n        child = parent1.copy()\n        if random.random() < 0.5:  # crossover probability is 50%\n            crossover_point = random.randint(0, self.dim-1)\n            child[crossover_point] = parent2[crossover_point]\n        return child\n\n    def selection(self, population):\n        fitnesses = [self.evaluate_function(individual) for individual in population]\n        sorted_indices = np.argsort(fitnesses)\n        return population[sorted_indices[:self.budget]]\n\n    def evaluate_function(self, individual):\n        func_value = self.func_evaluations(individual)\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Novel strategy: \n# 1.  Use a combination of mutation and crossover to increase exploration\n# 2.  Introduce a \"memory\" of the best individuals to inform the selection process\ndabu.memory = dabu.population[:10]  # keep the first 10 individuals as a \"memory\"\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel Metaheuristic Algorithm for Black Box Optimization\n# Code: ", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 26, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "0a32a5c2-2713-4839-9da4-ded6eafc2273", "solution": "import numpy as np\nimport random\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.5, sigma=0.1, mu=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.alpha = alpha\n        self.beta = beta\n        self.sigma = sigma\n        self.mu = mu\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.population_size = 100\n        self.population = [np.random.uniform(self.search_space, self.search_space) for _ in range(self.population_size)]\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            # Adaptive scaling\n            self.mu = self.alpha * self.mu + (1 - self.alpha) * self.search_space[0]\n            self.mu = np.clip(self.mu, -5.0, 5.0)\n\n            # Local search\n            for _ in range(self.population_size):\n                x = self.population[random.randint(0, self.population_size - 1)]\n                f_x = func(x)\n                if np.abs(f_x) < 1e-6:  # stop if the function value is close to zero\n                    break\n            self.population.append(x)\n\n            # Differential evolution\n            self.func_evaluations += 1\n            func_value = func(self.population[-1])\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n        return func(self.population[-1])\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nadaptive_de = AdaptiveDE(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(adaptive_de(test_function))  # prints a random value between -10 and 10", "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Adaptive Scaling and Local Search", "configspace": "", "generation": 27, "fitness": 0.010166584100840514, "feedback": "The algorithm AdaptiveDE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "4a26bd27-0bfa-4bb8-bae2-42b80d033328", "solution": "import numpy as np\nfrom scipy.optimize import minimize_scalar\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.iterations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def adapt_sampling(self):\n        if self.iterations < 100:\n            self.iterations += 1\n            if np.random.rand() < 0.3:\n                self.search_space = np.linspace(0.0, 5.0, self.dim)\n            else:\n                self.search_space = np.linspace(-5.0, 0.0, self.dim)\n        else:\n            self.search_space = np.linspace(0.0, 5.0, self.dim)\n\n    def refine(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Initial solution\ninitial_solution = np.random.uniform(-5.0, 5.0, (2,))\n\n# Run the DABU algorithm\nbest_func_value = np.inf\nbest_func = None\nfor _ in range(100):\n    func_value = dabu(test_function)\n    if func_value < best_func_value:\n        best_func_value = func_value\n        best_func = dabu(refine(test_function))(initial_solution)\n    dabu.adapt_sampling()\n\n# Print the final solution\nprint(best_func)", "name": "DABU", "description": "Improved DABU Algorithm with Adaptive Sampling and Iterative Refining", "configspace": "", "generation": 28, "fitness": -Infinity, "feedback": "An exception occurred: NameError(\"name 'refine' is not defined\").", "error": "NameError(\"name 'refine' is not defined\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "1cadf803-d0b5-4372-9496-18b99eb79de6", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\nfrom typing import Dict, List\n\nclass DABU:\n    def __init__(self, budget: int, dim: int):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func: callable) -> float:\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def optimize_function(self, func: callable) -> float:\n        # Refine the search space based on the current function value\n        if np.abs(func(self.search_space)) < 1e-6:  # stop if the function value is close to zero\n            return self.search_space[0]\n        else:\n            # Use differential evolution to refine the search space\n            result = differential_evolution(lambda x: -func(x), [(x, self.search_space) for x in x], x0=self.search_space, bounds=[(-5.0, 5.0)] * self.dim)\n            return result.x[0]\n\n# Example usage:\ndef test_function(x: np.ndarray) -> float:\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Refine the search space based on the current function value\ndabu_refined = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu_refined(test_function))  # prints a value between -10 and 10\n\n# Use differential evolution to refine the search space\ndabu_differential = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu_differential.optimize_function(test_function))  # prints a value between -10 and 10\n\n# Description: DABU: Differential Evolution Algorithm for Black Box Optimization\n# Code: \n# ```python\n# import numpy as np\n# import scipy.optimize as optimize\n# import random\n# from typing import Dict, List\n\n# class DABU:\n#     def __init__(self, budget: int, dim: int):\n#         self.budget = budget\n#         self.dim = dim\n#         self.search_space = np.linspace(-5.0, 5.0, dim)\n#         self.func_evaluations = 0\n\n#     def __call__(self, func: callable) -> float:\n#         while self.func_evaluations < self.budget:\n#             func_value = func(self.search_space)\n#             if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n#                 break\n#             self.func_evaluations += 1\n#         return func_value\n\n#     def optimize_function(self, func: callable) -> float:\n#         # Refine the search space based on the current function value\n#         if np.abs(func(self.search_space)) < 1e-6:  # stop if the function value is close to zero\n#             return self.search_space[0]\n#         else:\n#             # Use differential evolution to refine the search space\n#             result = optimize.differential_evolution(lambda x: -func(x), [(x, self.search_space) for x in x], x0=self.search_space, bounds=[(-5.0, 5.0)] * self.dim)\n#             return result.x[0]\n\n# # Example usage:\n# def test_function(x: np.ndarray) -> float:\n#     return np.exp(-x[0]**2 - x[1]**2)\n\n# dabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\n# print(dabu(test_function))  # prints a random value between -10 and 10\n\n# Refine the search space based on the current function value\ndabu_refined = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu_refined(test_function))  # prints a value between -10 and 10\n\n# Use differential evolution to refine the search space\ndabu_differential = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu_differential.optimize_function(test_function))  # prints a value between -10 and 10", "name": "DABU", "description": "DABU: Differential Evolution Algorithm for Black Box Optimization", "configspace": "", "generation": 29, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "59b7f56d-0970-409a-8276-e12b4314b6ed", "solution": "import numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.iterations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def update_search_space(self, new_search_space):\n        if self.iterations < 100:\n            self.search_space = new_search_space\n            self.iterations += 1\n            return self.search_space\n        else:\n            return new_search_space\n\n    def __str__(self):\n        return f'DABU(budget={self.budget}, dim={self.dim})'\n\n# Description: A novel metaheuristic algorithm for solving black box optimization problems.\n# Code: \n# ```python\ndef update_search_space_DABU(self, new_search_space):\n    # Use probability 0.3 to refine the search space\n    if random.random() < 0.3:\n        # Use the new search space as the initial new search space\n        new_search_space = self.update_search_space(new_search_space)\n    else:\n        # Otherwise, use the current search space as the new search space\n        new_search_space = self.search_space\n    return new_search_space\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def update_search_space_DABU(self, new_search_space):\n        return self.update_search_space_DABU(new_search_space)\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\ndabu_func = dabu(test_function)\nprint(dabu_func)  # prints a random value between -10 and 10\n\n# Update the search space with probability 0.3\nnew_search_space = dabu_func\ndabu.update_search_space_DABU(new_search_space)\nprint(new_search_space)  # prints a new search space\n\n# Plot the convergence curve\nx = np.linspace(-5.0, 5.0, 100)\ny = np.exp(-x**2 - x**2)\nplt.plot(x, y)\nplt.title('Convergence Curve')\nplt.xlabel('x')\nplt.ylabel('f(x)')\nplt.show()", "name": "DABU", "description": "A novel metaheuristic algorithm for solving black box optimization problems.", "configspace": "", "generation": 30, "fitness": -Infinity, "feedback": "An exception occurred: RecursionError('maximum recursion depth exceeded').", "error": "RecursionError('maximum recursion depth exceeded')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "ee63638e-aabe-4ed6-a9b7-e34067418c62", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.tuning_parameters = [0.3, 0.7]  # probability of changing individual lines\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def tune(self, func, initial_tuning_parameters):\n        for i in range(len(initial_tuning_parameters)):\n            # Randomly select an individual line to change\n            line_to_change = np.random.choice(len(self.search_space), 1)\n            new_tuning_parameters = initial_tuning_parameters.copy()\n            new_tuning_parameters[i] += random.uniform(-0.1, 0.1)\n            # Calculate the new objective value\n            new_func_value = func(self.search_space)\n            # Update the objective function evaluations\n            self.func_evaluations += 1\n            # If the new objective value is better, update the objective function evaluations\n            if np.abs(new_func_value) < 1e-6:\n                self.func_evaluations += 1\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\ninitial_tuning_parameters = [0.3, 0.7]\n\nprint(\"Original DABU:\", dabu(test_function))\n\n# Tune the DABU algorithm\ndabu.tune(test_function, initial_tuning_parameters)\n\nprint(\"Tuned DABU:\", dabu(test_function))", "name": "DABU", "description": "Refining the DABU Algorithm using Bayesian Optimization", "configspace": "", "generation": 31, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "51cfc999-79aa-4631-8b35-7f7a3a6a4609", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\n\nclass Metaheuristic:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func, initial_guess=None):\n        if initial_guess is None:\n            initial_guess = np.random.uniform(self.search_space)\n        for _ in range(self.budget):\n            func_value = func(initial_guess)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            initial_guess = np.random.uniform(self.search_space)\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndef optimize_function(func, initial_guess, budget=1000):\n    metaheuristic = Metaheuristic(budget, funcdim=2)  # funcdim=2 for 2D space\n    result = metaheuristic(initial_guess)\n    return result\n\n# Evaluate the selected solution\nselected_solution = optimize_function(test_function, np.array([1.0, 1.0]))\nprint(selected_solution)", "name": "Metaheuristic", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 32, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"Metaheuristic.__init__() got an unexpected keyword argument 'funcdim'\").", "error": "TypeError(\"Metaheuristic.__init__() got an unexpected keyword argument 'funcdim'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "47cf1bb3-dd07-4f4c-a495-cfc8208a7dad", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"Population: {self.func_evaluations}/{self.budget}\"\n\nclass BBOOpt:\n    def __init__(self, algorithm, budget, dim):\n        self.algorithm = algorithm\n        self.budget = budget\n        self.dim = dim\n\n    def optimize(self, func, initial_solution, iterations=1000):\n        # Initialize the population with random solutions\n        population = [initial_solution]\n        for _ in range(iterations):\n            # Evaluate the fitness of each solution\n            fitnesses = [self.algorithm(func, solution) for solution in population]\n            # Select the fittest solutions\n            self.algorithm.select(population, fitnesses)\n            # Generate new solutions by perturbing the fittest solutions\n            new_population = []\n            for _ in range(self.budget):\n                new_solution = [random.uniform(self.algorithm.search_space[i] - 1, self.algorithm.search_space[i] + 1) for i in range(self.dim)]\n                # Ensure the new solution is within the search space\n                new_solution = [max(self.algorithm.search_space[i], min(new_solution[i], self.algorithm.search_space[i])) for i in range(self.dim)]\n                new_population.append(new_solution)\n            population = new_population\n        return population\n\n    def select(self, population, fitnesses):\n        # Use tournament selection to select the fittest solutions\n        tournament_size = 3\n        winners = []\n        for _ in range(len(population)):\n            winner_index = random.randint(0, len(population) - 1)\n            winner = population[winner_index]\n            for _ in range(tournament_size):\n                winner_index = random.randint(0, len(population) - 1)\n                winner = population[winner_index]\n                if fitnesses[winner_index] > fitnesses[winner]:\n                    winner = winner\n                    break\n            winners.append(winner)\n        return winners\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndef bbo_optimize(func, initial_solution, budget=1000, dim=2):\n    algorithm = DABU(budget, dim)\n    population = [initial_solution]\n    for _ in range(budget):\n        population = algorithm.optimize(func, population)\n    return population\n\n# Run the BBO optimization algorithm\npopulation = bbo_optimize(test_function, [0, 0], dim=2)\nprint(f\"Population: {len(population)}\")\nprint(f\"Fitness: {min(fitnesses) / len(fitnesses)}\")", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 33, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'DABU' object has no attribute 'optimize'\").", "error": "AttributeError(\"'DABU' object has no attribute 'optimize'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "d70b702c-e722-4c2a-b7aa-220fc53cdcb4", "solution": "import numpy as np\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.search_space_history = self.search_space.copy()\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            self.search_space_history.append(self.search_space.copy())\n\n        # Refine the search space based on the function evaluations\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.search_space = np.array([self.search_space])\n        self.search_space = self.search_space[np.argsort(self.search_space_evaluations)]\n\n        # Add the most recent search space to the history\n        self.search_space_history.append(self.search_space.copy())\n\n        return func_value\n\n    def search_space_evaluations(self):\n        return np.array(self.search_space_evaluations)\n\n# One-line description with the main idea\n# DABU: Dynamic Adaptive Black Box Optimization using Dynamic Search Space Refining\n\n# Description: DABU uses a dynamic search space to adaptively refine its search space based on the function evaluations, allowing for efficient exploration-exploitation tradeoff.\n# Code:\n# ```python\n# DABU: Dynamic Adaptive Black Box Optimization using Dynamic Search Space Refining\n# ```\n# ```python\n# def test_function(x):\n#     return np.exp(-x[0]**2 - x[1]**2)\n\n# dabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\n# print(dabu(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "DABU uses a dynamic search space to adaptively refine its search space based on the function evaluations, allowing for efficient exploration-exploitation tradeoff.", "configspace": "", "generation": 34, "fitness": -Infinity, "feedback": "An exception occurred: AttributeError(\"'numpy.ndarray' object has no attribute 'append'\").", "error": "AttributeError(\"'numpy.ndarray' object has no attribute 'append'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "a36f3842-e688-4a6a-b683-ac6c3c04f9d7", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def adapt_search_space(self, func_values):\n        # Refine the search space based on the convergence rate of the current algorithm\n        # This line is modified to refine the strategy\n        avg_func_value = np.mean(func_values)\n        if avg_func_value < 1.0:  # convergence rate is low\n            self.search_space = np.linspace(-5.0, 5.0, self.dim)\n        elif avg_func_value > 1.0:  # convergence rate is high\n            self.search_space = np.linspace(1.0, 5.0, self.dim)\n        else:\n            # Use a weighted average of the current and previous search spaces\n            weights = [0.5, 0.3, 0.2]  # 50% of the time use the previous search space, 30% use the current search space, 20% use a random search space\n            self.search_space = np.random.choice(self.search_space, p=weights)\n\n    def __str__(self):\n        return f\"Budget: {self.budget}, Dim: {self.dim}, Search Space: {self.search_space}\"\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Select a solution to update\nselected_solution = dabu\n\n# Update the algorithm with the selected solution\nnew_dabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nnew_dabu.budget = selected_solution.budget  # keep the same budget\nnew_dabu.dim = selected_solution.dim  # keep the same dimensionality\nnew_dabu.search_space = selected_solution.search_space  # keep the same search space\nnew_dabu.func_evaluations = 0  # reset the number of function evaluations\nnew_dabu.adapt_search_space([func(test_function(x)) for x in np.random.rand(1000, 2)])  # adapt the search space\n\n# Print the updated algorithm\nprint(new_dabu)", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 35, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('invalid index to scalar variable.').", "error": "IndexError('invalid index to scalar variable.')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "0c5667e8-313e-48f4-a72f-767ce24db5cc", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"DABU with {self.budget} function evaluations, {self.dim} dimensions\"\n\nclass DABU2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.fitness_scores = []\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        self.fitness_scores.append(func_value)\n\n    def get_average_fitness(self):\n        return np.mean(self.fitness_scores)\n\n    def get_average_fitness_score(self):\n        return np.std(self.fitness_scores)\n\n# Description: A novel metaheuristic algorithm that combines the strengths of DABU and DABU2.\n# Code: \n# ```python\n# import numpy as np\n# import scipy.optimize as optimize\n\n# class DABU2:\n#     def __init__(self, budget, dim):\n#         self.budget = budget\n#         self.dim = dim\n#         self.search_space = np.linspace(-5.0, 5.0, dim)\n#         self.func_evaluations = 0\n#         self.fitness_scores = []\n\n#     def __call__(self, func):\n#         while self.func_evaluations < self.budget:\n#             func_value = func(self.search_space)\n#             if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n#                 break\n#             self.func_evaluations += 1\n#         self.fitness_scores.append(func_value)\n\n#     def get_average_fitness(self):\n#         return np.mean(self.fitness_scores)\n\n#     def get_average_fitness_score(self):\n#         return np.std(self.fitness_scores)\n\n#     def __str__(self):\n#         return f\"DABU2 with {self.budget} function evaluations, {self.dim} dimensions\"\n\n# def optimize_function(func, search_space, budget):\n#     return DABU2(budget, len(search_space))\n\n# def test_function(x):\n#     return np.exp(-x[0]**2 - x[1]**2)\n\n# dabu2 = optimize_function(test_function, np.linspace(-5.0, 5.0, 2), 1000)\n# print(dabu2.x)", "name": "DABU", "description": "A novel metaheuristic algorithm that combines the strengths of DABU and DABU2.", "configspace": "", "generation": 36, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "f9c9e42e-27a3-4d27-8f06-7c8560d385e1", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"DABU: {self.budget} evaluations, {self.dim} dimensions\"\n\n    def refine_strategy(self, func, search_space):\n        # Refine the search space by perturbing the current search space and evaluating the function\n        perturbed_search_space = search_space + np.random.normal(0, 1, self.dim)\n        func_value = func(perturbed_search_space)\n        if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n            return perturbed_search_space\n        else:\n            # Refine the search space by taking the average of the current search space and the perturbed search space\n            new_search_space = (self.search_space + perturbed_search_space) / 2\n            return new_search_space\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndef refine_search_space(func, search_space):\n    return DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\nnew_search_space = dabu.refine_strategy(test_function, dabu.search_space)\nprint(new_search_space)", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 37, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "7b263185-02f5-4fb8-8564-6ead0d5f62d1", "solution": "import numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.fitness_history = [0.01] * budget\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def select_strategy(self, func, budget):\n        if budget > self.budget:\n            return self.budget\n        else:\n            if random.random() < 0.3:\n                return 1000\n            else:\n                return 500\n\n    def mutate(self, func, mutation_rate):\n        for _ in range(self.select_strategy(func, self.budget)):\n            func_value = func(self.search_space)\n            if np.random.rand() < mutation_rate:\n                self.search_space = self.search_space + np.random.uniform(-1, 1, self.dim)\n\n    def __repr__(self):\n        return f\"DABU(budget={self.budget}, dim={self.dim})\"\n\n# Description: DABU algorithm with adaptive search space and mutation strategy.\n# Code: \n# ```python\n# DABU(budget=1000, dim=2)\n# DABU(budget=1000, dim=2)\n# ```\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\ndabu.mutate(test_function, 0.01)  # mutate the search space\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\n# Plot the fitness curve\nplt.plot(dabu.fitness_history)\nplt.xlabel('Evaluation')\nplt.ylabel('Fitness')\nplt.title('Fitness over Convergence Curve')\nplt.show()", "name": "DABU", "description": "DABU algorithm with adaptive search space and mutation strategy.", "configspace": "", "generation": 38, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "07ef4b90-0f24-4cf7-8fd7-ab4f7e8e6761", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"DABU: {self.budget} function evaluations, {self.dim} dimensions\"\n\nclass AGBU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.best_func = None\n        self.best_score = 0.0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        if self.func_evaluations > self.budget:\n            return None\n        return func_value\n\n    def __str__(self):\n        return f\"AGBU: {self.budget} function evaluations, {self.dim} dimensions\"\n\nclass BFGS:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.best_func = None\n        self.best_score = 0.0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            # Gradient-based optimization\n            grad = np.zeros(self.dim)\n            for i in range(self.dim):\n                grad[i] = func(self.search_space[i])\n            # Compute the inverse Hessian\n            H = np.diag(np.abs(grad)**2)\n            # Newton step\n            x_new = np.linalg.inv(H).dot(grad)\n            # Update the search space\n            self.search_space = np.linspace(-5.0, 5.0, self.dim)\n            self.func_evaluations += 1\n            # Check convergence\n            if np.allclose(self.search_space, x_new, atol=1e-6):\n                break\n        return func(self.search_space)\n\n    def __str__(self):\n        return f\"BFGS: {self.budget} function evaluations, {self.dim} dimensions\"\n\nclass L-BFGS-B:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.best_func = None\n        self.best_score = 0.0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            # Broyden-Fletcher-Goldfarb-Shanno (BFGS) optimization\n            H = np.diag(np.abs(np.array(self.search_space) - np.array(self.search_space[0])))\n            x_new = np.linalg.inv(H).dot(np.array(self.search_space) - np.array(self.search_space[0]))\n            # Update the search space\n            self.search_space = np.linspace(-5.0, 5.0, self.dim)\n            self.func_evaluations += 1\n            # Check convergence\n            if np.allclose(self.search_space, x_new, atol=1e-6):\n                break\n        return func(self.search_space)\n\n    def __str__(self):\n        return f\"L-BFGS-B: {self.budget} function evaluations, {self.dim} dimensions\"\n\n# Test the algorithms\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\nagbu = AGBU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(agbu(test_function))  # prints a random value between -10 and 10\n\nbfgs = BFGS(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(bfgs(test_function))  # prints a random value between -10 and 10\n\nlbfgs_b = L-BFGS-B(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(lbfgs_b(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "", "configspace": "", "generation": 39, "fitness": -Infinity, "feedback": "An exception occurred: SyntaxError('invalid syntax', ('<string>', 74, 8, 'class L-BFGS-B:\\n', 74, 9)).", "error": "SyntaxError('invalid syntax', ('<string>', 74, 8, 'class L-BFGS-B:\\n', 74, 9))", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "f542b0a6-9c90-452f-9a87-0f32de132117", "solution": "# Description: Adaptive Differential Evolution for Black Box Optimization\n# Code: \n# ```python\nimport numpy as np\nfrom scipy.optimize import differential_evolution\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"DABU: {self.dim}D optimization with Area over the convergence curve (AOCC) score of {self.score:.4f}\"\n\ndef adaptive_differential_evolution(func, bounds, budget):\n    # Initialize the population with random solutions\n    population = [random.uniform(bounds[0], bounds[1]) for _ in range(50)]\n\n    for _ in range(10):\n        # Evaluate the objective function for each individual in the population\n        results = differential_evolution(lambda x: -func(x), [(bounds[0], bounds[1])], popcount=population)\n\n        # Update the population with the best individual\n        population = [x for x, _ in results]\n\n    # Evaluate the objective function for the final population\n    results = differential_evolution(lambda x: -func(x), [(bounds[0], bounds[1])], popcount=population)\n\n    # Return the best solution\n    return population[0]\n\n# Define the test function\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\n# Run the algorithm\nresult = adaptive_differential_evolution(test_function, (-10, 10), 1000)\n\n# Print the result\nprint(f\"Result: {result}\")", "name": "DABU", "description": "Adaptive Differential Evolution for Black Box Optimization", "configspace": "", "generation": 40, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"differential_evolution() got an unexpected keyword argument 'popcount'\").", "error": "TypeError(\"differential_evolution() got an unexpected keyword argument 'popcount'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "92f2eb45-e754-4731-a916-07219a408201", "solution": "import numpy as np\n\nclass AdaptiveDE:\n    def __init__(self, budget, dim, mutation_rate, mutation_threshold):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.mutation_rate = mutation_rate\n        self.mutation_threshold = mutation_threshold\n        self.population_size = 100\n        self.population = np.random.uniform(self.search_space, size=(self.population_size, self.dim))\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            # Select parents using tournament selection\n            parents = np.array([self.select_parents(func, self.population, self.dim) for _ in range(self.population_size // 2)])\n\n            # Create offspring using crossover\n            offspring = np.array([self.crossover(parents[0], parents[1]) for _ in range(self.population_size // 2)])\n\n            # Apply mutation\n            self.population = np.array([self.applyMutation(offspring, self.population, self.mutation_rate, self.mutation_threshold) for _ in range(self.population_size)])\n\n            # Evaluate the new population\n            self.func_evaluations += 1\n            func_value = func(self.population)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n\n        return func_value\n\n    def select_parents(self, func, population, dim):\n        # Select parents using tournament selection\n        tournament_size = 3\n        tournament_indices = np.random.choice(population.shape[0], tournament_size, replace=False)\n        tournament_values = np.array([func(population[i]) for i in tournament_indices])\n        selected_indices = np.argsort(tournament_values)[:tournament_size]\n        selected_parents = population[selected_indices]\n        return selected_parents\n\n    def crossover(self, parent1, parent2):\n        # Create offspring using crossover\n        crossover_point = np.random.randint(1, self.dim)\n        offspring = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n        return offspring\n\n    def applyMutation(self, offspring, population, mutation_rate, mutation_threshold):\n        # Apply mutation\n        mutated_offspring = np.copy(offspring)\n        for i in range(self.population_size):\n            if np.random.rand() < mutation_rate:\n                mutated_offspring[i] += np.random.uniform(-mutation_threshold, mutation_threshold)\n        return mutated_offspring\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nadaptive_de = AdaptiveDE(1000, 2, 0.1, 0.5)\nprint(adaptive_de(test_function))  # prints a random value between -10 and 10", "name": "AdaptiveDE", "description": "Adaptive Differential Evolution with Adaptive Mutation is a novel metaheuristic algorithm that adapts its strategy based on the performance of the individual lines of the selected solution.", "configspace": "", "generation": 41, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 53 is out of bounds for axis 0 with size 50').", "error": "IndexError('index 53 is out of bounds for axis 0 with size 50')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "589b34b7-348b-4606-a462-5f5e991194d5", "solution": "import numpy as np\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "56445995-bf20-42e7-a758-ca3c69478749", "solution": "import numpy as np\nimport random\n\nclass ABBOES:\n    def __init__(self, budget, dim, mutation_rate=0.01, alpha=0.1, beta=0.9):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.population_size = 100\n        self.mutation_rate = mutation_rate\n        self.alpha = alpha\n        self.beta = beta\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def select_solution(self, func):\n        # Select the fittest solution from the current population\n        fitnesses = np.array([func(x) for x in self.search_space])\n        self.fittest_solution = np.argmax(fitnesses)\n        self.fittest_solution = self.search_space[self.fittest_solution]\n        # Refine the solution using the adaptive mutation strategy\n        if random.random() < self.beta:\n            # Randomly swap two random elements in the solution\n            i = random.randint(0, self.dim - 1)\n            j = random.randint(0, self.dim - 1)\n            self.fittest_solution[i], self.fittest_solution[j] = self.fittest_solution[j], self.fittest_solution[i]\n        return self.fittest_solution\n\n    def evolve_population(self):\n        # Evolve the population using the selection and mutation strategies\n        solutions = [self.select_solution(func) for func in self.search_space]\n        solutions = np.array(solutions)\n        solutions = np.sort(solutions)\n        solutions = solutions[:self.population_size]\n        solutions = self.alpha * solutions + (1 - self.alpha) * np.random.choice(self.search_space, size=solutions.shape, replace=True)\n        return solutions\n\n    def optimize_function(self, func, population):\n        # Optimize the function using the evolved population\n        optimized_func = func(population[0])\n        for i in range(1, len(population)):\n            optimized_func = np.max([optimized_func, func(population[i])])\n        return optimized_func", "name": "ABBOES", "description": "", "configspace": "", "generation": 43, "fitness": 0.010166584100840514, "feedback": "The algorithm ABBOES got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "06fec7f0-65c7-48db-8b19-1b6ab2d81f9c", "solution": "import numpy as np\n\nclass AdaptiveHyperbandSearch:\n    def __init__(self, budget, dim, initial_hyperbands):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.initial_hyperbands = initial_hyperbands\n        self.current_hyperband = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            # Select the current hyperband based on the performance of the individual lines\n            if self.current_hyperband < len(self.initial_hyperbands):\n                current_hyperband = self.initial_hyperbands[self.current_hyperband]\n            else:\n                current_hyperband = self.initial_hyperbands[-1]\n\n            # Search within the current hyperband\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n\n            # Update the current hyperband if necessary\n            if self.func_evaluations / self.budget > current_hyperband / self.budget:\n                current_hyperband += 1\n                if current_hyperband >= len(self.initial_hyperbands):\n                    current_hyperband = 0\n\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nadaptive_hyperband_search = AdaptiveHyperbandSearch(1000, 2, [5, 10, 20])\nprint(adaptive_hyperband_search(test_function))  # prints a random value between -10 and 10", "name": "AdaptiveHyperbandSearch", "description": "DABU is a well-established metaheuristic algorithm for black box optimization.", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"AdaptiveHyperbandSearch.__init__() missing 1 required positional argument: 'initial_hyperbands'\").", "error": "TypeError(\"AdaptiveHyperbandSearch.__init__() missing 1 required positional argument: 'initial_hyperbands'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "b0226810-f651-43a3-b664-3d43dff0cede", "solution": "import numpy as np\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f'DABU: {self.dim}D, {self.budget} evaluations, Area over convergence curve (AOCC): {self.func_evaluations}/1000'\n\nclass AdaptiveDABU(DABU):\n    def __init__(self, budget, dim):\n        super().__init__(budget, dim)\n\n    def __call__(self, func):\n        # Initialize a random search space\n        search_space = np.random.uniform(-5.0, 5.0, self.dim)\n\n        # Perform 10 initial evaluations\n        results = [func(x) for x in search_space]\n\n        # Calculate the average function value\n        avg_func_value = np.mean(results)\n\n        # Refine the search space based on the average function value\n        if np.abs(avg_func_value) < 1e-6:\n            # If the average function value is close to zero, stop exploring the search space\n            return avg_func_value\n        else:\n            # Otherwise, try to move the search space towards the average function value\n            search_space = np.linspace(avg_func_value - 1e-6, avg_func_value + 1e-6, self.dim)\n            return func(search_space)\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = AdaptiveDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 45, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('invalid index to scalar variable.').", "error": "IndexError('invalid index to scalar variable.')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "c478cdf2-5fe5-4b7c-a626-61688321fbe7", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def refine_strategy(self, func, initial_solution, budget):\n        # Initialize the population with random solutions\n        population = [initial_solution]\n        for _ in range(budget):\n            # Evaluate the fitness of each solution and select the fittest one\n            fitnesses = [func(solution) for solution in population]\n            fittest_index = np.argmin(fitnesses)\n            new_solution = population[fittest_index]\n            # Apply a mutation strategy to introduce randomness\n            mutation_rate = 0.01\n            if random.random() < mutation_rate:\n                new_solution[0] += random.uniform(-1, 1)\n                new_solution[1] += random.uniform(-1, 1)\n            # Add the new solution to the population\n            population.append(new_solution)\n        # Select the fittest solution from the new population\n        fittest_solution = population[np.argmax([func(solution) for solution in population])]\n        return fittest_solution, budget - self.func_evaluations\n\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndef bbopt(func, initial_solution, budget):\n    return DABU(budget, len(initial_solution)).refine_strategy(func, initial_solution, budget)\n\n# Example usage:\ninitial_solution = np.array([-2, -2])\nfittest_solution, budget = bbopt(test_function, initial_solution, 1000)\nprint(f\"Fittest solution: {fittest_solution}\")\nprint(f\"Fitness: {test_function(fittest_solution)}\")", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 46, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "0e91c79d-106e-4c7d-b21b-923d64d9e21b", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def refine_strategy(self):\n        # Refine the strategy by changing the individual lines of the selected solution\n        # to refine its strategy\n        # (1) Increase the budget by 50%\n        self.budget *= 2\n        # (2) Change the search space to (-5.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0) to explore more of the solution space\n        self.search_space = np.linspace(-5.0, 5.0, 10)\n        # (3) Introduce a penalty term for the function value\n        self.func_evaluations += 1e-6 * np.sum(np.abs(func_value - 1e-6) for func_value in self.func_evaluations)\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu(test_function))  # prints a random value between -10 and 10\n\n# Run the algorithm\ndabu_func = DABU(100, 2)  # 100 function evaluations, 2 dimensions\ndabu_func(test_function)  # prints a random value between -10 and 10\n\n# Update the selected solution\ndabu = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\ndabu_func = DABU(1000, 2)  # 1000 function evaluations, 2 dimensions\ndabu_func(test_function)  # prints a random value between -10 and 10", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 47, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "9a9b6a9a-93b2-41a9-b013-ded099139bc9", "solution": "import numpy as np\nimport random\n\nclass ABSEC:\n    def __init__(self, budget, dim, mutation_rate=0.01):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.mutation_rate = mutation_rate\n        self.population_size = 100\n\n    def __call__(self, func):\n        population = [func(np.random.uniform(self.search_space)) for _ in range(self.population_size)]\n        while self.func_evaluations < self.budget:\n            for i in range(self.population_size):\n                for j in range(i+1, self.population_size):\n                    if random.random() < self.mutation_rate:\n                        population[i] += (population[j] - population[i]) * (random.random() - 0.5)\n            population = sorted(population, key=func, reverse=True)\n            func_value = population[0]\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def adapt_boundaries(self, func):\n        boundaries = [np.linspace(-5.0, 5.0, self.dim), np.linspace(-5.0, 5.0, self.dim)]\n        while True:\n            new_boundaries = []\n            for i in range(self.dim):\n                new_boundaries.append(np.linspace(-5.0, 5.0, self.dim)[i] + random.uniform(-1, 1) * (self.search_space[i] + random.uniform(-1, 1)))\n            new_func_value = func(np.array(new_boundaries))\n            if np.abs(new_func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.search_space = new_boundaries\n            func_value = new_func_value\n        return func_value", "name": "ABSEC", "description": "Adaptive Boundary Search with Evolutionary Crossover (ABSEC)", "configspace": "", "generation": 48, "fitness": -Infinity, "feedback": "An exception occurred: TypeError('__call__(): incompatible function arguments. The following argument types are supported:\\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\\n\\nInvoked with: <RealSingleObjectiveProblem 1. Sphere (iid=1 dim=5)>, 133.46637316873984').", "error": "TypeError('__call__(): incompatible function arguments. The following argument types are supported:\\n    1. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[float]) -> float\\n    2. (self: ioh.iohcpp.problem.RealSingleObjective, arg0: List[List[float]]) -> List[float]\\n\\nInvoked with: <RealSingleObjectiveProblem 1. Sphere (iid=1 dim=5)>, 133.46637316873984')", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "1d97356e-f677-4b32-9176-1028a37508e4", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass EvolutionaryAlgorithm:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.population_size = 50\n        self.mutation_rate = 0.1\n\n    def __call__(self, func):\n        def objective(x):\n            return func(x)\n\n        # Initialize population with random solutions\n        population = np.random.uniform(self.search_space, size=(self.population_size, self.dim))\n\n        for _ in range(self.budget):\n            # Evaluate the objective function for each individual in the population\n            evaluations = [objective(x) for x in population]\n\n            # Select the fittest individuals\n            fittest_indices = np.argsort(evaluations)[::-1][:self.population_size//2]\n            fittest_individuals = population[fittest_indices]\n\n            # Create a new population by mutating the fittest individuals\n            new_population = np.array([x + np.random.normal(0, 1, self.dim) for x in fittest_individuals])\n\n            # Evaluate the new population\n            new_evaluations = [objective(x) for x in new_population]\n\n            # Replace the old population with the new one\n            population = np.concatenate((fittest_individuals, new_population), axis=0)\n\n            # Apply mutation to the new population\n            population = np.concatenate((population[:self.population_size//2], population[self.population_size//2:]), axis=0)\n            population = np.random.uniform(self.search_space, size=(self.population_size, self.dim), axis=0) + np.random.normal(0, 1, self.dim, size=(self.population_size, self.dim))\n\n            # Evaluate the new population\n            new_evaluations = [objective(x) for x in population]\n\n            # Replace the old population with the new one\n            population = np.concatenate((population[:self.population_size//2], new_population), axis=0)\n\n        # Return the fittest individual in the final population\n        return population[np.argmax(evaluations)][self.dim//2]\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nevolutionary_algorithm = EvolutionaryAlgorithm(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(evolutionary_algorithm(test_function))  # prints a random value between -10 and 10", "name": "EvolutionaryAlgorithm", "description": "Evolutionary Algorithm with Adaptive Population Size and Mutation", "configspace": "", "generation": 49, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"uniform() got an unexpected keyword argument 'axis'\").", "error": "TypeError(\"uniform() got an unexpected keyword argument 'axis'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "13ae4f98-e038-40bd-98e1-1cfa5ec6db8b", "solution": "import numpy as np\nimport random\n\nclass DABU:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def __str__(self):\n        return f\"Budget: {self.budget}, Dim: {self.dim}, Search Space: {self.search_space}\"\n\nclass DABUWithProbabilityOfChange:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.change_probability = 0.3\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        if random.random() < self.change_probability:\n            self.search_space = np.linspace(-5.0, 5.0, self.dim)\n            self.func_evaluations = 0\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndabu_with_probability = DABUWithProbabilityOfChange(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(dabu_with_probability(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel Metaheuristic Algorithm for Black Box Optimization\n# Code: ", "name": "DABU", "description": "Novel Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 50, "fitness": 0.010166584100840514, "feedback": "The algorithm DABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.01 with standard deviation 0.02.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.005041614870535005, 0.005041614870535005, 0.005041614870535005, 0.045755541975245784, 0.045755541975245784, 0.045755541975245784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008039214358934066, 0.008039214358934066, 0.008039214358934066, 0.039430825391241875, 0.039430825391241875, 0.039430825391241875, 0.008308200702316415, 0.008308200702316415, 0.008308200702316415, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005825264699244492, 0.005825264699244492, 0.005825264699244492, 0.017022130720544593, 0.017022130720544593, 0.017022130720544593, 0.05013714583522355, 0.05013714583522355, 0.05013714583522355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05569533266127491, 0.05569533266127491, 0.05569533266127491, 0.10625870831065853, 0.10625870831065853, 0.10625870831065853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01125402670375264, 0.01125402670375264, 0.01125402670375264, 0.021962121150816305, 0.021962121150816305, 0.021962121150816305, 0.007537869869834846, 0.007537869869834846, 0.007537869869834846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011771670241926602, 0.011771670241926602, 0.011771670241926602, 0.011010504542485422, 0.011010504542485422, 0.011010504542485422, 0.009423108421699355, 0.009423108421699355, 0.009423108421699355, 0.017935459985101487, 0.017935459985101487, 0.017935459985101487, 0.020775227734934787, 0.020775227734934787, 0.020775227734934787, 0.015599054940352963, 0.015599054940352963, 0.015599054940352963, 0.04868894102010457, 0.04868894102010457, 0.04868894102010457, 0.07710207648247469, 0.07710207648247469, 0.07710207648247469, 0.12824960395567886, 0.12824960395567886, 0.12824960395567886, 0.0042704106861356506, 0.0042704106861356506, 0.0042704106861356506, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05]}, "mutation_prompt": null}
{"id": "24d413a1-2567-493a-841e-7e57f0dcb4f5", "solution": "import numpy as np\nimport random\n\nclass HybridMetaheuristic:\n    def __init__(self, budget, dim, refines=0.7, initial_refine=0.3):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.refined = False\n        self.refine_factor = initial_refine\n        self.refine_counter = 0\n\n    def __call__(self, func, num_evaluations):\n        if self.refined:\n            self.refine()\n        else:\n            self.refine(num_evaluations)\n\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def refine(self):\n        if not self.refined:\n            self.refine_factor = random.uniform(0.7, 1.3)\n            self.refine_counter = 0\n            while self.refine_counter < 10:  # refine strategy: increase the refine factor\n                if random.random() < self.refine_factor:\n                    self.refine_counter += 1\n                    if self.refine_counter >= 5:  # refine strategy: increase the refine factor by 10%\n                        self.refine_factor *= 1.1\n                else:\n                    break\n            self.refined = True\n\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nhybrid = HybridMetaheuristic(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(hybrid(test_function))  # prints a random value between -10 and 10", "name": "HybridMetaheuristic", "description": "Novel Hybrid Metaheuristic Algorithm for Black Box Optimization", "configspace": "", "generation": 51, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"HybridMetaheuristic.__call__() missing 1 required positional argument: 'num_evaluations'\").", "error": "TypeError(\"HybridMetaheuristic.__call__() missing 1 required positional argument: 'num_evaluations'\")", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {}, "mutation_prompt": null}
{"id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "solution": "import numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Adapt the strategy to convergence rate\n            if self.func_evaluations / self.budget > 0.8:\n                self.alpha *= self.beta\n            if self.func_evaluations / self.budget > 0.9:\n                self.beta *= self.alpha\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 52, "fitness": 0.08277565838902362, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "b5531566-4cd5-4046-92aa-91e1de80f1e5", "metadata": {"aucs": [0.17811228511659283, 0.1670876511573015, 0.16997140280693823, 0.14569327484516814, 0.15667902123979494, 0.1881961406995426, 0.15949205695045898, 0.15974767789512456, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03423928745896687, 0.03593837250574039, 0.033571355382174595, 0.03318577742055118, 0.026194566891766913, 0.02507883121664467, 0.03903112663244923, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.023935403473872796, 0.07283315076944907, 0.06918025590944965, 0.07280602198077835, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.055818548799969725, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09822769883638283, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.09873506255300601, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0174646271267902, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.17454458154495756, 0.19437567421992485, 0.18230327784753597, 0.18028339902675194, 0.18301895640066757, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.1183387252180571, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14721232261851835, 0.15180851126014805, 0.15486974050415314, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831623470350714, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10483195788613042, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1481079051764851, 0.1469637019063026, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.1434952077918843, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16351131264504526, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12072183340434695, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12168293515567408, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04353693718730378, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.042988770006852195]}, "mutation_prompt": null}
{"id": "84fdb2ae-c2f8-460c-83ac-c19af370ec96", "solution": "import numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.best_func_value = None\n        self.best_func_func = None\n        self.best_func_func_evaluations = 0\n        self.alpha_history = [self.alpha]\n        self.beta_history = [self.beta]\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Adapt the strategy to convergence rate\n            if self.func_evaluations / self.budget > 0.8:\n                self.alpha *= self.beta\n            if self.func_evaluations / self.budget > 0.9:\n                self.beta *= self.alpha\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Update best function value and its evaluations\n            if func_value < self.best_func_value or (func_value == self.best_func_value and self.func_evaluations > self.best_func_func_evaluations):\n                self.best_func_value = func_value\n                self.best_func_func = func\n                self.best_func_func_evaluations = self.func_evaluations\n        return self.best_func_func\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 53, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'<' not supported between instances of 'float' and 'NoneType'\").", "error": "TypeError(\"'<' not supported between instances of 'float' and 'NoneType'\")", "parent_id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "metadata": {}, "mutation_prompt": null}
{"id": "33986be2-717e-4863-8965-0acd06d2fcc8", "solution": "import numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.best_func_value = None\n        self.best_func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Adapt the strategy to convergence rate\n            if self.func_evaluations / self.budget > 0.8:\n                self.alpha *= self.beta\n            if self.func_evaluations / self.budget > 0.9:\n                self.beta *= self.alpha\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Update the best function value and number of evaluations\n            if func_value > self.best_func_value:\n                self.best_func_value = func_value\n                self.best_func_evaluations = self.func_evaluations\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 54, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'>' not supported between instances of 'float' and 'NoneType'\").", "error": "TypeError(\"'>' not supported between instances of 'float' and 'NoneType'\")", "parent_id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "metadata": {}, "mutation_prompt": null}
{"id": "2ba82d60-c739-435e-97a0-e000f647b416", "solution": "import numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Adapt the strategy to convergence rate\n            if self.func_evaluations / self.budget > 0.8:\n                self.alpha *= self.beta\n            if self.func_evaluations / self.budget > 0.9:\n                self.beta *= self.alpha\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 53, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('list index out of range').", "error": "IndexError('list index out of range')", "parent_id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "metadata": {"aucs": [0.17811228511659283, 0.1670876511573015, 0.16997140280693823, 0.14569327484516814, 0.15667902123979494, 0.1881961406995426, 0.15949205695045898, 0.15974767789512456, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03423928745896687, 0.03593837250574039, 0.033571355382174595, 0.03318577742055118, 0.026194566891766913, 0.02507883121664467, 0.03903112663244923, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.023935403473872796, 0.07283315076944907, 0.06918025590944965, 0.07280602198077835, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.055818548799969725, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09822769883638283, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.09873506255300601, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0174646271267902, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.17454458154495756, 0.19437567421992485, 0.18230327784753597, 0.18028339902675194, 0.18301895640066757, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.1183387252180571, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14721232261851835, 0.15180851126014805, 0.15486974050415314, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831623470350714, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10483195788613042, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1481079051764851, 0.1469637019063026, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.1434952077918843, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16351131264504526, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12072183340434695, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12168293515567408, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04353693718730378, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.042988770006852195]}, "mutation_prompt": null}
{"id": "9d3d3fcd-c88c-4e4b-bd04-a031d5efea06", "solution": "import numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.best_func_value = None\n        self.best_func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Adapt the strategy to convergence rate\n            if self.func_evaluations / self.budget > 0.8:\n                self.alpha *= self.beta\n            if self.func_evaluations / self.budget > 0.9:\n                self.beta *= self.alpha\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Update best function value and evaluations\n            if func_value < self.best_func_value:\n                self.best_func_value = func_value\n                self.best_func_evaluations = self.func_evaluations\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: ", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 56, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'<' not supported between instances of 'float' and 'NoneType'\").", "error": "TypeError(\"'<' not supported between instances of 'float' and 'NoneType'\")", "parent_id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "metadata": {}, "mutation_prompt": null}
{"id": "d9c12d3a-a51f-4fc0-bcdf-83a6d30d114f", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.99, min_beta=0.01, max_beta=0.99):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Adapt the strategy to convergence rate\n            if self.func_evaluations / self.budget > 0.8:\n                self.alpha *= self.beta\n            if self.func_evaluations / self.budget > 0.9:\n                self.beta *= self.alpha\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 57, "fitness": 0.08178642318438524, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "metadata": {"aucs": [0.15866285211108788, 0.17350575753430986, 0.15219728067261207, 0.19411198969353527, 0.1319260023051495, 0.151912727441757, 0.18183404713500162, 0.13774289302647214, 0.1893319275125318, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04113397825594911, 0.035014661512112744, 0.05531669935317729, 0.06734917476586832, 0.04203727499437715, 0.03346688833247757, 0.032535825521011086, 0.03444962477107261, 0.040033369595413704, 0.043243714366137276, 0.036435119936198634, 0.03871301942056726, 0.03152574318939094, 0.02005495899005505, 0.025599237693903376, 0.03960884578410517, 0.03708605814080235, 0.018664869775735005, 0.06398865666922615, 0.06497314318625502, 0.07414236326564239, 0.08223546770452062, 0.07770401422903384, 0.07528984506899428, 0.06805491119946583, 0.07719704429803331, 0.07145325153427051, 0.07684921076689155, 0.08079199462273556, 0.05788513979987098, 0.059578022624364846, 0.04946628150269394, 0.05271360745135567, 0.09044265586383937, 0.04908401180502897, 0.05317665717716613, 0.09041951510238266, 0.11074922158784661, 0.11861964361751265, 0.12318811000414898, 0.13619160810218744, 0.09595923364333103, 0.10765440131757753, 0.09163859414099462, 0.16109860620389083, 9.999999999998899e-05, 0.02556459868447636, 9.999999999998899e-05, 9.999999999998899e-05, 0.010156070498547942, 0.002866486480210151, 9.999999999998899e-05, 0.0025591184967539427, 9.999999999998899e-05, 9.999999999998899e-05, 0.03997429900298144, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006879484775039746, 9.999999999998899e-05, 0.0018276911527096429, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05429143404201864, 0.03964021012148278, 0.044062418822053195, 0.006313517140965064, 0.03443656853641075, 0.04455225936226803, 0.041532334864154086, 0.03024207783117494, 0.04927456137387032, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008932127906221665, 9.999999999998899e-05, 0.021358510302412315, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.17947298887397067, 0.16765621744592296, 0.19334586550911326, 0.1861058903227587, 0.1726613901759818, 0.22674882116972017, 0.1749074833943769, 0.17978861038737792, 0.18312397757194054, 0.03719748949979462, 0.04424900771752305, 0.0367659430434264, 0.029835820532436608, 0.03624947623985464, 0.03812729255478786, 0.04094457553759234, 0.034140526250719616, 0.03885170623867906, 0.11665066727422313, 0.1286949050200148, 0.11254462379849306, 0.12277957229978875, 0.13337187179283194, 0.11438279009858832, 0.12084374178231028, 0.13211062193974898, 0.13721552852347518, 0.1621894517475233, 0.14573583743600105, 0.1484694347932467, 0.15300381544681207, 0.16086692232849797, 0.1499523204369938, 0.15586650660232082, 0.15019846567385753, 0.1684634812654776, 0.10209479323798476, 0.10028606585907252, 0.10716262399625698, 0.10832056800983358, 0.09329706534921312, 0.12806301381914398, 0.10302268130352732, 0.09507304425126184, 0.0946842735067337, 0.16713393445842506, 0.14402140836938138, 0.14937845637760783, 0.15180903933300638, 0.16463306909115472, 0.14964602559535722, 0.1527288600850334, 0.12985105395852092, 0.14744483043200252, 0.14029193974003007, 0.12384949313058968, 0.12441374397258353, 0.1516320929436491, 0.13857936460328224, 0.13532436235359624, 0.12376287326835422, 0.13136739963409128, 0.11286892677901161, 0.16362758659625165, 0.13637058683361158, 0.13994972446881804, 0.14254587931186202, 0.14416315859541717, 0.17305991417160915, 0.1866515978868034, 0.1677104573360524, 0.15675792918754528, 0.13519156721295567, 0.1617301655460862, 0.16233727146382404, 0.1360734746222706, 0.12295433245776644, 0.14419769631013735, 0.171916264479281, 0.1099247217296675, 0.24730048381797587, 0.167315285036157, 0.1769995171300618, 0.1722901516410671, 0.1656938177207341, 0.1924928363173498, 0.1790174348135759, 0.1713579124879363, 0.1713138890478052, 0.17342054331679047, 0.04603725035382977, 0.054213492856645784, 0.05768250791935203, 0.05208927227005877, 0.04887783632261544, 0.054001868500042516, 0.04204951340163732, 0.04275677767052488, 0.04472805739191621]}, "mutation_prompt": null}
{"id": "7a120a7b-720f-4fd5-a8d9-61ee608d00f8", "solution": "import numpy as np\nfrom scipy.optimize import differential_evolution\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Adapt the strategy to convergence rate\n            if self.func_evaluations / self.budget > 0.8:\n                self.alpha *= self.beta\n            if self.func_evaluations / self.budget > 0.9:\n                self.beta *= self.alpha\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel Metaheuristic Algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 58, "fitness": 0.08277565838902362, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "metadata": {"aucs": [0.17811228511659283, 0.1670876511573015, 0.16997140280693823, 0.14569327484516814, 0.15667902123979494, 0.1881961406995426, 0.15949205695045898, 0.15974767789512456, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03423928745896687, 0.03593837250574039, 0.033571355382174595, 0.03318577742055118, 0.026194566891766913, 0.02507883121664467, 0.03903112663244923, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.023935403473872796, 0.07283315076944907, 0.06918025590944965, 0.07280602198077835, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.055818548799969725, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09822769883638283, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.09873506255300601, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0174646271267902, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.17454458154495756, 0.19437567421992485, 0.18230327784753597, 0.18028339902675194, 0.18301895640066757, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.1183387252180571, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14721232261851835, 0.15180851126014805, 0.15486974050415314, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831623470350714, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10483195788613042, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1481079051764851, 0.1469637019063026, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.1434952077918843, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16351131264504526, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12072183340434695, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12168293515567408, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04353693718730378, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.042988770006852195]}, "mutation_prompt": null}
{"id": "9fcfff9b-0dc5-4486-aa8e-77dcb396b5bc", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.best_func_value = None\n        self.best_func_evaluations = 0\n        self.current_func_value = None\n        self.current_func_evaluations = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            self.func_evaluations += 1\n            if self.current_func_value is not None and np.abs(self.current_func_value) < 1e-6:\n                break\n            if self.func_evaluations / self.budget > 0.8:\n                self.alpha *= self.beta\n            if self.func_evaluations / self.budget > 0.9:\n                self.beta *= self.alpha\n            if self.func_evaluations / self.budget > 0.95:\n                # Refine the strategy\n                self.alpha *= 0.7\n                self.beta *= 0.3\n                # Non-Local Search\n                for i in range(self.dim):\n                    for j in range(self.dim):\n                        if np.random.rand() < self.alpha:\n                            self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                            self.search_space[j] = np.random.uniform(-5.0, 5.0)\n                # Evaluate the function with the new search space\n                func_value = func(self.search_space)\n                if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                    break\n            self.current_func_value = func(self.search_space)\n            self.current_func_evaluations += 1\n            # Update the best function value and evaluations\n            if self.current_func_value < self.best_func_value or self.best_func_evaluations == 0:\n                self.best_func_value = self.current_func_value\n                self.best_func_evaluations = self.current_func_evaluations\n        return self.current_func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate and Variable Dimensionality", "configspace": "", "generation": 59, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'<' not supported between instances of 'float' and 'NoneType'\").", "error": "TypeError(\"'<' not supported between instances of 'float' and 'NoneType'\")", "parent_id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "metadata": {}, "mutation_prompt": null}
{"id": "ab3aa8ef-be0d-41cc-a62d-d9c332d723c3", "solution": "import numpy as np\nfrom scipy.optimize import minimize\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.x_history = None\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Adapt the strategy to convergence rate\n            if self.func_evaluations / self.budget > 0.8:\n                self.alpha *= self.beta\n            if self.func_evaluations / self.budget > 0.9:\n                self.beta *= self.alpha\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def optimize(self, func):\n        result = minimize(func, self.search_space, method=\"SLSQP\", bounds=[(-5.0, 5.0)] * self.dim)\n        self.x_history = [self.search_space, result.x]\n        return result.fun\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# NonLocalDABU\n# ```", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 60, "fitness": 0.08277565838902362, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "metadata": {"aucs": [0.17811228511659283, 0.1670876511573015, 0.16997140280693823, 0.14569327484516814, 0.15667902123979494, 0.1881961406995426, 0.15949205695045898, 0.15974767789512456, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03423928745896687, 0.03593837250574039, 0.033571355382174595, 0.03318577742055118, 0.026194566891766913, 0.02507883121664467, 0.03903112663244923, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.023935403473872796, 0.07283315076944907, 0.06918025590944965, 0.07280602198077835, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.055818548799969725, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09822769883638283, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.09873506255300601, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0174646271267902, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.17454458154495756, 0.19437567421992485, 0.18230327784753597, 0.18028339902675194, 0.18301895640066757, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.1183387252180571, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14721232261851835, 0.15180851126014805, 0.15486974050415314, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831623470350714, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10483195788613042, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1481079051764851, 0.1469637019063026, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.1434952077918843, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16351131264504526, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12072183340434695, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12168293515567408, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04353693718730378, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.042988770006852195]}, "mutation_prompt": null}
{"id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 61, "fitness": 0.08305945708896363, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "a1b039da-b3c1-4036-8231-38a2c0a26454", "metadata": {"aucs": [0.17811228511659283, 0.17125428943597432, 0.16997140280693823, 0.14590188431645323, 0.15907042543305394, 0.1881961406995426, 0.1594968597522598, 0.16746318634462876, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03482663502253103, 0.03593837250574039, 0.033571355382174595, 0.03318910727171076, 0.026194566891766913, 0.02507883121664467, 0.04047212116803656, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.028655919437340027, 0.07283315076944907, 0.06918025590944965, 0.07320688396009867, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.056944930723173415, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09923009748998357, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.0992898968264333, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002995010250029795, 9.999999999998899e-05, 0.001361821512583683, 0.0174646271267902, 9.999999999998899e-05, 0.005398539824088222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.1816915196407456, 0.19437567421992485, 0.1825535536379882, 0.18028339902675194, 0.183074092679402, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.11836805777908999, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14956430621717387, 0.15180851126014805, 0.15490722242942523, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831968305966476, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10537493812000032, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1540337190357357, 0.15061676565535076, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.14396329332591962, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16563339032044078, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12435815156479368, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12429899444667392, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04371994695449266, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.044183794018039624]}, "mutation_prompt": null}
{"id": "befed54e-b46d-47a9-9fc5-888804ed92e5", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {"aucs": [0.17811228511659283, 0.17125428943597432, 0.16997140280693823, 0.14590188431645323, 0.15907042543305394, 0.1881961406995426, 0.1594968597522598, 0.16746318634462876, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03482663502253103, 0.03593837250574039, 0.033571355382174595, 0.03318910727171076, 0.026194566891766913, 0.02507883121664467, 0.04047212116803656, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.028655919437340027, 0.07283315076944907, 0.06918025590944965, 0.07320688396009867, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.056944930723173415, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09923009748998357, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.0992898968264333, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002995010250029795, 9.999999999998899e-05, 0.001361821512583683, 0.0174646271267902, 9.999999999998899e-05, 0.005398539824088222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.1816915196407456, 0.19437567421992485, 0.1825535536379882, 0.18028339902675194, 0.183074092679402, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.11836805777908999, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14956430621717387, 0.15180851126014805, 0.15490722242942523, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831968305966476, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10537493812000032, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1540337190357357, 0.15061676565535076, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.14396329332591962, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16563339032044078, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12435815156479368, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12429899444667392, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04371994695449266, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.044183794018039624]}, "mutation_prompt": null}
{"id": "de74452f-2512-40b7-af6c-36efea8fbade", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {"aucs": [0.17811228511659283, 0.17125428943597432, 0.16997140280693823, 0.14590188431645323, 0.15907042543305394, 0.1881961406995426, 0.1594968597522598, 0.16746318634462876, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03482663502253103, 0.03593837250574039, 0.033571355382174595, 0.03318910727171076, 0.026194566891766913, 0.02507883121664467, 0.04047212116803656, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.028655919437340027, 0.07283315076944907, 0.06918025590944965, 0.07320688396009867, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.056944930723173415, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09923009748998357, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.0992898968264333, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002995010250029795, 9.999999999998899e-05, 0.001361821512583683, 0.0174646271267902, 9.999999999998899e-05, 0.005398539824088222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.1816915196407456, 0.19437567421992485, 0.1825535536379882, 0.18028339902675194, 0.183074092679402, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.11836805777908999, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14956430621717387, 0.15180851126014805, 0.15490722242942523, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831968305966476, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10537493812000032, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1540337190357357, 0.15061676565535076, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.14396329332591962, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16563339032044078, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12435815156479368, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12429899444667392, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04371994695449266, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.044183794018039624]}, "mutation_prompt": null}
{"id": "70a6f799-cdac-45c9-a3fd-591f621ff3ab", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.population = [\n            {\n                \"name\": \"NonLocalDABU\",\n                \"description\": \"Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\",\n                \"score\": 0.08305945708896363,\n                \"average_AOCC\": 1.0,\n                \"average_stddev\": 0.07,\n            }\n        ]\n        self.population_index = 0\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Novel Metaheuristic Algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Description: Novel Metaheuristic Algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, population_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.population = np.random.choice(\n            [\n                {\"name\": \"NonLocalDABU\", \"description\": \"Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\", \"score\": 0.08305945708896363, \"average_AOCC\": 1.0, \"average_stddev\": 0.07},\n                {\"name\": \"NonLocalDABU\", \"description\": \"Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\", \"score\": 0.08305945708896363, \"average_AOCC\": 1.0, \"average_stddev\": 0.07},\n            ],\n            p=0.3,\n        )\n        self.population_index = 0\n        self.population_size = population_size\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Novel Metaheuristic Algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Description: Novel Metaheuristic Algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, population_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.population = np.random.choice(\n            [\n                {\"name\": \"NonLocalDABU\", \"description\": \"Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\", \"score\": 0.08305945708896363, \"average_AOCC\": 1.0, \"average_stddev\": 0.07},\n                {\"name\": \"NonLocalDABU\", \"description\": \"Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\", \"score\": 0.08305945708896363, \"average_AOCC\": 1.0, \"average_stddev\": 0.07},\n            ],\n            p=0.3,\n        )\n        self.population_index = 0\n        self.population_size = population_size\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Novel Metaheuristic Algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Description: Novel Metaheuristic Algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, population_size=100):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.population = np.random.choice(\n            [\n                {\"name\": \"NonLocalDABU\", \"description\": \"Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\", \"score\": 0.08305945708896363, \"average_AOCC\": 1.0, \"average_stddev\": 0.07},\n                {\"name\": \"NonLocalDABU\", \"description\": \"Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\", \"score\": 0.08305945708896363, \"average_AOCC\": 1.0, \"average_stddev\": 0.07},\n            ],\n            p=0.3,\n        )\n        self.population_index = 0\n        self.population_size = population_size\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel Metaheuristic Algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 64, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"object of type 'float' has no len()\").", "error": "TypeError(\"object of type 'float' has no len()\")", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {}, "mutation_prompt": null}
{"id": "cd6a42b5-5008-4216-83fb-c15814ad9451", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {"aucs": [0.17811228511659283, 0.17125428943597432, 0.16997140280693823, 0.14590188431645323, 0.15907042543305394, 0.1881961406995426, 0.1594968597522598, 0.16746318634462876, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03482663502253103, 0.03593837250574039, 0.033571355382174595, 0.03318910727171076, 0.026194566891766913, 0.02507883121664467, 0.04047212116803656, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.028655919437340027, 0.07283315076944907, 0.06918025590944965, 0.07320688396009867, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.056944930723173415, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09923009748998357, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.0992898968264333, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002995010250029795, 9.999999999998899e-05, 0.001361821512583683, 0.0174646271267902, 9.999999999998899e-05, 0.005398539824088222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.1816915196407456, 0.19437567421992485, 0.1825535536379882, 0.18028339902675194, 0.183074092679402, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.11836805777908999, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14956430621717387, 0.15180851126014805, 0.15490722242942523, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831968305966476, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10537493812000032, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1540337190357357, 0.15061676565535076, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.14396329332591962, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16563339032044078, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12435815156479368, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12429899444667392, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04371994695449266, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.044183794018039624]}, "mutation_prompt": null}
{"id": "58127ade-6a05-419c-af30-9926f1caf792", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {"aucs": [0.17811228511659283, 0.17125428943597432, 0.16997140280693823, 0.14590188431645323, 0.15907042543305394, 0.1881961406995426, 0.1594968597522598, 0.16746318634462876, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03482663502253103, 0.03593837250574039, 0.033571355382174595, 0.03318910727171076, 0.026194566891766913, 0.02507883121664467, 0.04047212116803656, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.028655919437340027, 0.07283315076944907, 0.06918025590944965, 0.07320688396009867, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.056944930723173415, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09923009748998357, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.0992898968264333, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002995010250029795, 9.999999999998899e-05, 0.001361821512583683, 0.0174646271267902, 9.999999999998899e-05, 0.005398539824088222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.1816915196407456, 0.19437567421992485, 0.1825535536379882, 0.18028339902675194, 0.183074092679402, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.11836805777908999, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14956430621717387, 0.15180851126014805, 0.15490722242942523, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831968305966476, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10537493812000032, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1540337190357357, 0.15061676565535076, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.14396329332591962, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16563339032044078, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12435815156479368, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12429899444667392, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04371994695449266, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.044183794018039624]}, "mutation_prompt": null}
{"id": "fe499807-d845-4e66-ae80-4eb57feb391c", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {"aucs": [0.17811228511659283, 0.17125428943597432, 0.16997140280693823, 0.14590188431645323, 0.15907042543305394, 0.1881961406995426, 0.1594968597522598, 0.16746318634462876, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03482663502253103, 0.03593837250574039, 0.033571355382174595, 0.03318910727171076, 0.026194566891766913, 0.02507883121664467, 0.04047212116803656, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.028655919437340027, 0.07283315076944907, 0.06918025590944965, 0.07320688396009867, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.056944930723173415, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09923009748998357, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.0992898968264333, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002995010250029795, 9.999999999998899e-05, 0.001361821512583683, 0.0174646271267902, 9.999999999998899e-05, 0.005398539824088222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.1816915196407456, 0.19437567421992485, 0.1825535536379882, 0.18028339902675194, 0.183074092679402, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.11836805777908999, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14956430621717387, 0.15180851126014805, 0.15490722242942523, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831968305966476, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10537493812000032, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1540337190357357, 0.15061676565535076, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.14396329332591962, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16563339032044078, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12435815156479368, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12429899444667392, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04371994695449266, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.044183794018039624]}, "mutation_prompt": null}
{"id": "c225c2bc-fd7d-4fea-9faf-ce9a91dac46f", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.max_iterations = 1000\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Adaptation strategy to change individual lines of the selected solution\n# to refine its strategy\ndef adaptation(nonlocal_dabu, func, max_iterations):\n    for _ in range(max_iterations):\n        # Non-Local Search\n        for i in range(nonlocal_dabu.dim):\n            for j in range(nonlocal_dabu.dim):\n                if np.random.rand() < nonlocal_dabu.alpha:\n                    nonlocal_dabu.search_space[i] = np.random.uniform(-5.0, 5.0)\n                    nonlocal_dabu.search_space[j] = np.random.uniform(-5.0, 5.0)\n        # Evaluate the function with the new search space\n        func_value = func(nonlocal_dabu.search_space)\n        if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n            break\n        # Adaptation to convergence rate\n        nonlocal_dabu.alpha *= nonlocal_dabu.beta\n        if nonlocal_dabu.alpha < 0.1:\n            nonlocal_dabu.alpha = 0.1\n        nonlocal_dabu.beta *= nonlocal_dabu.alpha\n        if nonlocal_dabu.beta < 0.1:\n            nonlocal_dabu.beta = 0.1\n        # Check convergence\n        if nonlocal_dabu.func_evaluations / nonlocal_dabu.budget > nonlocal_dabu.convergence_rate:\n            break\n    return nonlocal_dabu\n\nnonlocal_dabu = adaptation(nonlocal_dabu, test_function, 1000)\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 68, "fitness": 0.08305945708896363, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {"aucs": [0.17811228511659283, 0.17125428943597432, 0.16997140280693823, 0.14590188431645323, 0.15907042543305394, 0.1881961406995426, 0.1594968597522598, 0.16746318634462876, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03482663502253103, 0.03593837250574039, 0.033571355382174595, 0.03318910727171076, 0.026194566891766913, 0.02507883121664467, 0.04047212116803656, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.028655919437340027, 0.07283315076944907, 0.06918025590944965, 0.07320688396009867, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.056944930723173415, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09923009748998357, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.0992898968264333, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002995010250029795, 9.999999999998899e-05, 0.001361821512583683, 0.0174646271267902, 9.999999999998899e-05, 0.005398539824088222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.1816915196407456, 0.19437567421992485, 0.1825535536379882, 0.18028339902675194, 0.183074092679402, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.11836805777908999, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14956430621717387, 0.15180851126014805, 0.15490722242942523, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831968305966476, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10537493812000032, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1540337190357357, 0.15061676565535076, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.14396329332591962, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16563339032044078, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12435815156479368, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12429899444667392, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04371994695449266, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.044183794018039624]}, "mutation_prompt": null}
{"id": "9b9ab8bd-54fb-4370-99a6-6e24c56f6453", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {"aucs": [0.17811228511659283, 0.17125428943597432, 0.16997140280693823, 0.14590188431645323, 0.15907042543305394, 0.1881961406995426, 0.1594968597522598, 0.16746318634462876, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03482663502253103, 0.03593837250574039, 0.033571355382174595, 0.03318910727171076, 0.026194566891766913, 0.02507883121664467, 0.04047212116803656, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.028655919437340027, 0.07283315076944907, 0.06918025590944965, 0.07320688396009867, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.056944930723173415, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09923009748998357, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.0992898968264333, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002995010250029795, 9.999999999998899e-05, 0.001361821512583683, 0.0174646271267902, 9.999999999998899e-05, 0.005398539824088222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.1816915196407456, 0.19437567421992485, 0.1825535536379882, 0.18028339902675194, 0.183074092679402, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.11836805777908999, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14956430621717387, 0.15180851126014805, 0.15490722242942523, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831968305966476, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10537493812000032, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1540337190357357, 0.15061676565535076, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.14396329332591962, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16563339032044078, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12435815156479368, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12429899444667392, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04371994695449266, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.044183794018039624]}, "mutation_prompt": null}
{"id": "fbd3763a-1ee3-4060-b6fe-fc09e5433168", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < 0.1:\n                    self.alpha = 0.1\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < 0.1:\n                    self.beta = 0.1\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if np.random.rand() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 62, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {"aucs": [0.17811228511659283, 0.17125428943597432, 0.16997140280693823, 0.14590188431645323, 0.15907042543305394, 0.1881961406995426, 0.1594968597522598, 0.16746318634462876, 0.16943054704609972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600285903009653, 0.048328534225045794, 0.031196454878918867, 0.04612406383476286, 0.04073891981276756, 0.03418714607495621, 0.054885075657629234, 0.03482663502253103, 0.03593837250574039, 0.033571355382174595, 0.03318910727171076, 0.026194566891766913, 0.02507883121664467, 0.04047212116803656, 0.04325520609984812, 0.019826269374881078, 0.03268213416008314, 0.028655919437340027, 0.07283315076944907, 0.06918025590944965, 0.07320688396009867, 0.07915435735793563, 0.06930229992009829, 0.07217770281834779, 0.07986930019182836, 0.07183320826714867, 0.07829356107630758, 0.06738292562536552, 0.056944930723173415, 0.05323891700498862, 0.058314454018799755, 0.06714200842200224, 0.059721093066542164, 0.0778239398446603, 0.06603034854495249, 0.07242555826589414, 0.10139341547246472, 0.1641423604672405, 0.09923009748998357, 0.1049640128098015, 0.10177871059083665, 0.09690712021083525, 0.0992898968264333, 0.12149934458512268, 0.11531874766365946, 0.012606650597911773, 9.999999999998899e-05, 9.999999999998899e-05, 0.04465270994174275, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0002995010250029795, 9.999999999998899e-05, 0.001361821512583683, 0.0174646271267902, 9.999999999998899e-05, 0.005398539824088222, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.028365747187098167, 0.050517711665649556, 0.053666593596108814, 0.0313334098739646, 0.013245866035469067, 0.043217324427701875, 0.02545798397651655, 0.021751791285202327, 0.02421873084877335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006418237754624023, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005003082470411702, 9.999999999998899e-05, 9.999999999998899e-05, 0.20288823958571, 0.1816915196407456, 0.19437567421992485, 0.1825535536379882, 0.18028339902675194, 0.183074092679402, 0.21921033446383997, 0.20690314257443965, 0.1729151372090546, 0.03567687998654201, 0.031093645529528646, 0.04551163286398219, 0.046513508282775895, 0.03707764242252365, 0.03811335785503511, 0.04708114113748485, 0.043663754711403824, 0.03998488283039192, 0.17412931609609095, 0.13687874013667956, 0.13726374126500818, 0.11836805777908999, 0.11988935475231632, 0.12076706735010123, 0.12554450428231234, 0.12886304657890646, 0.14113825764209287, 0.15564036975360274, 0.1553326043694222, 0.14956430621717387, 0.15180851126014805, 0.15490722242942523, 0.15251286014575238, 0.15611391240827466, 0.16653991974036797, 0.16405364926184174, 0.09985279175053763, 0.09361082926780151, 0.09958030505792959, 0.0932867917959267, 0.09831968305966476, 0.10864954111467884, 0.09767102742077727, 0.09168202004786141, 0.10537493812000032, 0.14712721020744435, 0.15100805098069392, 0.14342036352007415, 0.15360249814593752, 0.1540337190357357, 0.15061676565535076, 0.18120095643529655, 0.1413628376765299, 0.14975452262990208, 0.143596874116387, 0.1140267117610585, 0.09044976690966977, 0.14396329332591962, 0.1444649874613444, 0.10467158358662731, 0.1362009859452442, 0.14936033840848928, 0.13248074218478656, 0.13659229938215034, 0.14620995434305228, 0.2326569215859131, 0.16563339032044078, 0.15561991436016853, 0.19567380349991137, 0.16009313930233315, 0.18139870507687994, 0.28330661055065154, 0.14117993599392065, 0.12435815156479368, 0.1496895545992709, 0.13865068552089, 0.1678292487795381, 0.14804931434695168, 0.18053781667397084, 0.12429899444667392, 0.12240639421669641, 0.1830984873053414, 0.16626900538602862, 0.1771316806162746, 0.18443244854787366, 0.1839561007630638, 0.17831610022613964, 0.1954079954601069, 0.17501897048385584, 0.18847391496422128, 0.045815476676669076, 0.054156794265258545, 0.04371994695449266, 0.04263015449915619, 0.049927305232285835, 0.05237534882264572, 0.05045505525828342, 0.04721613430652383, 0.044183794018039624]}, "mutation_prompt": null}
{"id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 71, "fitness": 0.08418017325300074, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "1396cee8-f68f-40e5-8679-a4f3578832d7", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "e72abd9f-0f82-46bb-96b4-f48f0cf500c4", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "88b1e92f-6e29-4c4b-afa2-97e1b9d28d9a", "solution": "import numpy as np\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n    def update(self, func, new_func_value):\n        # Adapt the search space to the new function value\n        for i in range(self.dim):\n            for j in range(self.dim):\n                if random.random() < self.alpha:\n                    self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                    self.search_space[j] = np.random.uniform(-5.0, 5.0)\n        # Evaluate the new function value\n        new_func_value = func(self.search_space)\n        # Update the function value\n        if np.abs(new_func_value) < 1e-6:  # stop if the new function value is close to zero\n            break\n        self.func_evaluations += 1\n        # Update the search space\n        for i in range(self.dim):\n            for j in range(self.dim):\n                if random.random() < self.alpha:\n                    self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                    self.search_space[j] = np.random.uniform(-5.0, 5.0)\n        # Evaluate the new function value\n        new_func_value = func(self.search_space)\n        # Update the function value\n        if np.abs(new_func_value) < 1e-6:  # stop if the new function value is close to zero\n            break\n        self.func_evaluations += 1\n        return new_func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python\n# Update the search space with the new function value\nnew_func_value = nonlocal_dabu.update(test_function, nonlocal_dabu(test_function))\nprint(\"New function value:\", new_func_value)\n\n# Get the best function value\nbest_func_value = nonlocal_dabu.func(test_function)\nprint(\"Best function value:\", best_func_value)\n\n# Update the search space for the best function value\nbest_func_value = nonlocal_dabu.update(test_function, best_func_value)\nprint(\"Best function value after update:\", best_func_value)\n\n# Get the best function value\nbest_func_value = nonlocal_dabu.func(test_function)\nprint(\"Best function value after update:\", best_func_value)", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 73, "fitness": -Infinity, "feedback": "An exception occurred: SyntaxError(\"'break' outside loop\", ('<string>', 67, 13, None, 67, 18)).", "error": "SyntaxError(\"'break' outside loop\", ('<string>', 67, 13, None, 67, 18))", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {}, "mutation_prompt": null}
{"id": "18b21131-a277-4d5e-9d66-567b2bcb26e9", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "80ba050f-722e-48ec-a3cb-015e78cc90ce", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "47de42fd-366d-4ea4-8806-c1dbd4660b48", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "4f81ab01-be0e-475d-ba91-397615289b16", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "31655283-9ce6-4263-a3e5-3e28020162e2", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "35a08974-4bfe-43f0-8d32-50c7fb5c9baf", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\ndef nonlocal_dabu_test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(nonlocal_dabu_test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python\n# def nonlocal_dabu_test_function(x):\n#     return np.exp(-x[0]**2 - x[1]**2)\n\n# def test_function(x):\n#     return np.exp(-x[0]**2 - x[1]**2)\n\n# nonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\n# print(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 79, "fitness": 0.08319703342015118, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.1795324263137833, 0.15226769000678853, 0.15644774716296928, 0.1513353522519879, 0.18325880604496092, 0.147630920053203, 0.16577366692820028, 0.15728523534143346, 0.2119038566139929, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03316422297493027, 0.038945921898306146, 0.037755471973310306, 0.03663023641663965, 0.03557152624365956, 0.03909689018967544, 0.04661243623024203, 0.037593438391859135, 0.039246764246541166, 0.035298363124973586, 0.018286235265735362, 0.031120405971335474, 0.03994785406676815, 0.020655160219693047, 0.031493609997857996, 0.034260613149005414, 0.045407218295729246, 0.03813964766250155, 0.0688017504309375, 0.0867428365420877, 0.07094384090729888, 0.06931560446251639, 0.08474955826472774, 0.07231791820581168, 0.07566092246803069, 0.07225194641828436, 0.08411730252719485, 0.053641411937128236, 0.0635312775134238, 0.0608759352467676, 0.06457866699277615, 0.062476972935880615, 0.08236910872795866, 0.0850168580596492, 0.04745467397939629, 0.051627974732154636, 0.08581353638219902, 0.09552610181685739, 0.15103697405707373, 0.12367749041894471, 0.10408475871545453, 0.1265213767909119, 0.1511750163410972, 0.15148747315291888, 0.1332090332527418, 9.999999999998899e-05, 9.999999999998899e-05, 0.007354451009150442, 0.004156571946978382, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0018722371931573223, 0.0008562704155181677, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03637194929905163, 0.0002844235059906719, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06093949574340496, 0.031194347694886382, 0.028706168848955493, 0.03684322893057668, 0.03637285106433297, 0.011294812992000525, 0.07210025333588765, 0.0626457705509822, 0.027450916921503254, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0007430396959716701, 9.999999999998899e-05, 9.999999999998899e-05, 0.2019298543533169, 0.1924557786374138, 0.17279930794122778, 0.18074460105132384, 0.16987434254883194, 0.1734543756691599, 0.18175294456481783, 0.19797122692138613, 0.18249153773757576, 0.03616871418019563, 0.03583652391859682, 0.034276736215697046, 0.04302147835908621, 0.04945721680360693, 0.04293746391796793, 0.0358655078898692, 0.045327191813510526, 0.040247278249416873, 0.13368542445083753, 0.13081127330418696, 0.15336671602241914, 0.14271810911280003, 0.13646984120945704, 0.11543407434324926, 0.1256943854088045, 0.12903558279930472, 0.13958537716518726, 0.15187350508026154, 0.16842460489397248, 0.15145492949326833, 0.15519619518202166, 0.1529113196622811, 0.15279281223239016, 0.1535422666200047, 0.17890118565495017, 0.16211590904226525, 0.08875125036122677, 0.09417038859269522, 0.10244930685404852, 0.11630172203188305, 0.10334807697104154, 0.11145019722403393, 0.0911160621006667, 0.1170758187769323, 0.10832683118670794, 0.17823128039815417, 0.14249688370702918, 0.13994360628664781, 0.14375763325054736, 0.16943213070843088, 0.14595337525959806, 0.15645749405192344, 0.1335182855978917, 0.15683716957992033, 0.1304588525280187, 0.13397309751320552, 0.17677609192139665, 0.15265925911656564, 0.1408999080406682, 0.14515281844715777, 0.14200783873208545, 0.1461697545748335, 0.13771500161606232, 0.1579632679806895, 0.1610088052446943, 0.150292475993679, 0.16390535981180943, 0.15268531279427677, 0.16227157378118684, 0.14654836095111967, 0.1440820855705215, 0.16568311281267956, 0.15486258887579551, 0.13119929953235465, 0.11959153282283097, 0.14983898595186473, 0.13227116333046052, 0.10037627394116111, 0.20081335922442156, 0.1441908210120102, 0.17960534149929375, 0.17008848664629006, 0.1848969572670479, 0.17444496501994944, 0.18699479128228602, 0.17486659360286827, 0.16992962602605022, 0.1751470181178595, 0.19007012871867324, 0.16509567427874827, 0.05756305916823168, 0.04743344959804763, 0.05950867294271267, 0.05708861552630373, 0.043284985260439446, 0.044901896169570854, 0.04857025897805123, 0.04795003760516503, 0.05192372606881768]}, "mutation_prompt": null}
{"id": "8c00745a-456a-459b-aa89-9fe35f0e4379", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\ndef adapt_convergence_rate(nonlocal_dabu):\n    while True:\n        # Calculate the average function value\n        avg_func_value = np.mean([nonlocal_dabu(test_function(i)) for i in range(nonlocal_dabu.search_space_size)])\n        \n        # Calculate the average alpha value\n        avg_alpha = np.mean([nonlocal_dabu.alpha for _ in range(nonlocal_dabu.search_space_size)])\n        \n        # Calculate the average beta value\n        avg_beta = np.mean([nonlocal_dabu.beta for _ in range(nonlocal_dabu.search_space_size)])\n        \n        # If the average function value is close to zero, stop\n        if np.abs(avg_func_value) < 1e-6:\n            break\n        \n        # Calculate the new alpha and beta values\n        new_alpha = avg_alpha * nonlocal_dabu.beta\n        new_beta = avg_beta * nonlocal_dabu.alpha\n        \n        # Apply the new alpha and beta values\n        nonlocal_dabu.alpha = new_alpha\n        nonlocal_dabu.beta = new_beta\n\n        # Adapt the convergence rate\n        if nonlocal_dabu.alpha < nonlocal_dabu.min_alpha:\n            nonlocal_dabu.alpha = nonlocal_dabu.min_alpha\n        if nonlocal_dabu.alpha > nonlocal_dabu.max_alpha:\n            nonlocal_dabu.alpha = nonlocal_dabu.max_alpha\n        if nonlocal_dabu.beta < nonlocal_dabu.min_beta:\n            nonlocal_dabu.beta = nonlocal_dabu.min_beta\n        if nonlocal_dabu.beta > nonlocal_dabu.max_beta:\n            nonlocal_dabu.beta = nonlocal_dabu.max_beta\n\n# Adapt the NonLocalDABU algorithm\nadapt_convergence_rate(nonlocal_dabu)\n\nprint(nonlocal_dabu.test_function())  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 80, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'int' object is not subscriptable\").", "error": "TypeError(\"'int' object is not subscriptable\")", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {}, "mutation_prompt": null}
{"id": "bf49d710-e9e2-4894-a348-18adfa75dd1c", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "5de8cffc-38a5-4f99-b7f9-02d75933bde0", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "0071c096-ec13-4f99-a228-480b43f4de8e", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "db4374b0-4614-475d-af25-93c2acbd43b9", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "4f136bac-990d-461e-a5a7-cf42d7aacd2d", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "52da3fc9-c108-4e94-b0e6-93e2e4455671", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "5136d143-5971-4a91-9e4a-fa13cf7c3fd0", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# Non-LocalDABU(budget=1000, dim=2, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1)", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 87, "fitness": 0.08377639199992391, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.15880983815397298, 0.148424018534561, 0.14857140815177772, 0.1832276514859098, 0.18269602417116249, 0.16463597379194217, 0.16486299746778987, 0.15184694991456926, 0.1663133140082964, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.032250202527164595, 0.036354751469877766, 0.03394250948674349, 0.04039731691273485, 0.04294405928430156, 0.06521146708943582, 0.04422388691264345, 0.05156952233927381, 0.05447865097211069, 0.019621838722988505, 0.02399315226296983, 0.026954283945739177, 0.028315426395348786, 0.03280530068458698, 0.02395912844835435, 0.021771859898434887, 0.03172437392831595, 0.03110840372764756, 0.06736058470572459, 0.0697351073512853, 0.06935661560134088, 0.08078107654181277, 0.08594120260664662, 0.06474528551042802, 0.0731853412127006, 0.07737453985682463, 0.07695271796913783, 0.06959764489983244, 0.05668027608270587, 0.11786598441393858, 0.08511742692194546, 0.05810824927657088, 0.07120432323567782, 0.08008558616009209, 0.07367092923459406, 0.08019794486897414, 0.1122774916405559, 0.09274957103186354, 0.15444291244313024, 0.12393411400578203, 0.14891541273848197, 0.1422033212295124, 0.1254737300054829, 0.10343894005052168, 0.11734739551169426, 9.999999999998899e-05, 0.011114751913854692, 9.999999999998899e-05, 0.014463441273194433, 0.0054372345885073115, 9.999999999998899e-05, 9.999999999998899e-05, 0.003748125560595117, 0.06131211778792511, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012503749316092994, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0033007173141728074, 0.015980770067136607, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0600168709008998, 0.06353508357623472, 0.04478369110430136, 0.03161944582331799, 0.04604407280387646, 0.01326792776008101, 0.04638057302169962, 0.07800057773242752, 0.036646298860279924, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0028608532268256104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1832632866889765, 0.17567549457044684, 0.24633193160875066, 0.20033161542348632, 0.17455312432547776, 0.18676234648512813, 0.1943251255990157, 0.18358773034201048, 0.18885536416547666, 0.02914008025741399, 0.037011808468818685, 0.038567880138816735, 0.032667472456444524, 0.03330188949284052, 0.04340141665960473, 0.05419421850956607, 0.03706501591780087, 0.02953964878674542, 0.11561640304584886, 0.11585344246520723, 0.11676643590747948, 0.11940086143231532, 0.11930702357925271, 0.11371863601758125, 0.15989262608769217, 0.12691385795434595, 0.1597324735696477, 0.14719742417600445, 0.15739422388592617, 0.14615522418399574, 0.15376984780802627, 0.16167931361740973, 0.15001730687443038, 0.1469873108529557, 0.15175562328035463, 0.15310152516264608, 0.11382589099665708, 0.1052338034725333, 0.0929772359406057, 0.09383449147316203, 0.11289110189028817, 0.12260292841501597, 0.11633998204448803, 0.09685652940932321, 0.10211693502172003, 0.1397508380763588, 0.15028317600006558, 0.15320763909354862, 0.15161301079584066, 0.13988718924925325, 0.13630393872836122, 0.16780478718277314, 0.14825413843358914, 0.15516823355045728, 0.14421821686189307, 0.10017617525004441, 0.12172281179380495, 0.13634730254151695, 0.1326427389860193, 0.141741080667091, 0.1536540283421558, 0.12787390199034576, 0.13398148496629603, 0.20723316393458868, 0.13208109001539192, 0.15422280736899885, 0.13357721484221552, 0.14658962806949416, 0.14461832160111465, 0.16518095592057802, 0.20028558819284703, 0.16043522578168123, 0.17789960587776754, 0.15960357851763496, 0.15235004394323948, 0.17553907144922398, 0.2017801876714328, 0.15690632819627404, 0.14944938790647833, 0.12121165555656355, 0.11914193860830147, 0.1792316671951112, 0.1979472938409128, 0.18331290182216609, 0.17804515246100217, 0.177917479131124, 0.1701375173795836, 0.17293913344746148, 0.16546585871592123, 0.17199713273355832, 0.04781872769396178, 0.04579655232839008, 0.0465883255831554, 0.03990030034829051, 0.0468228514706136, 0.058915142540422516, 0.04536824793299288, 0.04481081570997725, 0.04416083879661059]}, "mutation_prompt": null}
{"id": "efb7d757-a02e-4e87-8e04-97819c3e4b2d", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "4d9121ed-caab-42c5-9f28-1e66595013fe", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "69bcf4fe-6c92-48b6-923d-b03db0c57fe4", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "970e6965-6542-499d-acbc-ca54227bdab5", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\ndef adapt_convergence_rate(alpha, beta, func_value, func_evaluations):\n    if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n        return 0.8\n    else:\n        return min(alpha * beta, max(alpha * beta, 0.1))\n\ndef adapt_convergence_threshold(alpha, beta, func_value, func_evaluations):\n    if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n        return 0.9\n    else:\n        return max(alpha * beta, 0.1)\n\ndef adapt_convergence_rate_threshold(alpha, beta, func_value, func_evaluations):\n    if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n        return 0.8\n    else:\n        return min(alpha * beta, max(alpha * beta, 0.1))\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\ndef adapt_convergence_rate_alpha(alpha, beta, func_value, func_evaluations):\n    return adapt_convergence_rate(alpha, beta, func_value, func_evaluations)\n\ndef adapt_convergence_rate_beta(alpha, beta, func_value, func_evaluations):\n    return adapt_convergence_rate(alpha, beta, func_value, func_evaluations)\n\ndef adapt_convergence_rate_alpha_beta(alpha, beta, func_value, func_evaluations):\n    return min(alpha * beta, max(alpha * beta, 0.1))\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 91, "fitness": 0.08329237502710989, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.08 with standard deviation 0.07.", "error": "", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.15131509309220204, 0.20879540574308997, 0.17413081784447682, 0.16210444697944926, 0.17392061450908347, 0.18938072956156404, 0.15451812165811352, 0.1510904676319813, 0.14764094109687453, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.041457511113259016, 0.06368002835005826, 0.05592616434276987, 0.07138161886134131, 0.04593170742066399, 0.03969809035762295, 0.03397634994160437, 0.038336154898048536, 0.045080150874632685, 0.03415247765642904, 0.038295553697907936, 0.02750822925849894, 0.024473355499335825, 0.03666755559240553, 0.03249863068012515, 0.023301789769018755, 0.024101116004610068, 0.0192706879670137, 0.07895384684859985, 0.07157577539592108, 0.07205722751375254, 0.08754682590405449, 0.12926030600863647, 0.07190909950959123, 0.078472735957556, 0.06590796222259998, 0.08841255380572366, 0.07754506808112527, 0.0734868610142495, 0.0454867511468483, 0.04404583155950126, 0.06380251537015558, 0.1226080211406837, 0.07567647296532487, 0.05476330212591951, 0.08733587099658069, 0.08850969060502756, 0.09880425085955269, 0.08857604085883208, 0.08854212649658566, 0.11561746337884415, 0.1192070731189131, 0.12124612840421323, 0.11543442613627342, 0.10611801914742824, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0029992410608638, 9.999999999998899e-05, 9.999999999998899e-05, 0.024227992607527282, 9.999999999998899e-05, 0.039668907593667924, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03451123400651268, 0.038034703568828654, 0.034472075352620646, 0.06667443260234363, 0.06852793407414504, 0.013059157351298922, 0.025082991735747573, 0.04020370651703453, 0.01713973162403981, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19623800691458715, 0.1969875552737722, 0.18985287952717345, 0.17470273422271443, 0.21713461820155422, 0.1871035807298177, 0.22243864667548852, 0.17928419193050704, 0.1776804179039263, 0.0554120976273913, 0.032420219926581506, 0.03122421348461979, 0.0466985165022743, 0.034509213098936065, 0.04444088405862989, 0.03527936721479985, 0.05181506497337629, 0.04743948503948081, 0.11816258070855079, 0.13282619898728065, 0.1270988156774845, 0.12416054862820314, 0.12345368151217595, 0.12986845229222432, 0.13043392469211101, 0.13254679181885476, 0.13720673249711912, 0.15968513631968984, 0.15771690022887674, 0.15891217037472383, 0.16545329087885108, 0.15176738263212686, 0.15024297466347758, 0.1513613934766943, 0.1544053905418934, 0.16065607133585313, 0.08601845484639581, 0.11393948242359164, 0.10102889509941981, 0.1119579283698855, 0.11028971414380817, 0.115566787793279, 0.10410086457930445, 0.12018974162551388, 0.09718131099482485, 0.1368893602547463, 0.15338452477067333, 0.13696885099658562, 0.14048893588272438, 0.14156231441011224, 0.1476749636407847, 0.16177358074584625, 0.1579961523924176, 0.14218860407935374, 0.14995916454249314, 0.14737811526680378, 0.10505891272420598, 0.1305854655532419, 0.12098188739168458, 0.14303902748891628, 0.11840296844221354, 0.13599338495799385, 0.13386962170591554, 0.1812526364668947, 0.21613587303266868, 0.13273839660329156, 0.13906488878979495, 0.13315714807337387, 0.16773757172184456, 0.144452338028064, 0.14449176446307777, 0.2111666603143778, 0.12694720178163044, 0.15451551573481426, 0.19379214224432972, 0.20876535752465353, 0.15108230711633552, 0.129409834275651, 0.1587157150547378, 0.1342176921786371, 0.12166398894118724, 0.17438620940856053, 0.1726740779992888, 0.18030553007404904, 0.18637725255230408, 0.17012210258576888, 0.16917866376342516, 0.1944427987595786, 0.1750537221444718, 0.19278174306490636, 0.041591022167718816, 0.04568168375723469, 0.041524920841577884, 0.04986333426974321, 0.050624900488770774, 0.04772586972101178, 0.04188141385888755, 0.06170431262547027, 0.04559910466374384]}, "mutation_prompt": null}
{"id": "fdb467cf-04d2-4b20-9f30-f169402e7e5c", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 72, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.23800843606888045, 0.1586311309863886, 0.16486704868866797, 0.1762615272771476, 0.16008331598232106, 0.16411039860782128, 0.18672054748245848, 0.14154601187957416, 0.14910328311311383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05041625698686081, 0.04419689148043415, 0.06217861360658794, 0.060933442853221664, 0.034408332270175146, 0.04170515652074225, 0.039233673267528135, 0.03830405512543433, 0.043626759533140325, 0.028421060665907882, 0.029774112263754482, 0.04427682640163855, 0.04295725493058833, 0.04629834990613202, 0.022816139120052092, 0.04728690438301164, 0.021179286337260406, 0.021964492923224443, 0.06745477371873054, 0.06821882414885438, 0.08950474086935467, 0.08108864583183095, 0.09182761173557197, 0.07827788360427201, 0.0696890443106869, 0.07763991131895598, 0.09143748640798821, 0.05724516100063559, 0.07421043330775356, 0.059516602388999695, 0.04956842823813845, 0.04985245172039687, 0.05390619884180359, 0.06216614997212255, 0.0396727169244121, 0.13305178956208386, 0.1194013393161858, 0.09682611301874822, 0.08685711242784966, 0.10227019321596276, 0.11783286232491286, 0.14778427820060047, 0.10769560102175024, 0.16725014970906726, 0.11110092732408683, 9.999999999998899e-05, 0.0014413808210621548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007600534671429737, 9.999999999998899e-05, 9.999999999998899e-05, 0.04422242100351437, 0.0013595955344116728, 9.999999999998899e-05, 0.025610270264160517, 9.999999999998899e-05, 0.02259991376281889, 0.09306302006579248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024756446698349865, 0.05611859265597419, 0.04487193149934976, 0.013054921607625114, 0.06413290704095453, 0.019067112867097613, 0.047390736394267496, 0.04867165476823043, 0.07122057408502191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006612762796399885, 0.0008500433878827485, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1822421702571151, 0.2098350490741827, 0.1861148278571123, 0.18952197192178288, 0.20439258609122735, 0.17762287525992637, 0.17267215852621198, 0.17884338263725008, 0.2001337204458865, 0.03008355577381916, 0.03916364116968507, 0.03361061299848367, 0.04993014434949328, 0.026894173809620447, 0.03848031793787454, 0.06116602380363689, 0.03264573989621278, 0.036355799562919344, 0.1372743810400716, 0.13623191534447976, 0.1339047348145992, 0.13636843728281234, 0.13289466031452635, 0.1554562671020654, 0.13698480356008824, 0.12868711391663834, 0.14243885815281232, 0.1549271952249488, 0.15283720541239987, 0.16315269073649974, 0.16032050332088388, 0.1561620098009282, 0.16161956035072034, 0.1626739521012096, 0.17073863932852984, 0.1533485944391223, 0.09970783277743356, 0.11529142127070025, 0.09388609484359745, 0.10420863241963885, 0.11389906305444797, 0.10404678275927814, 0.08873279300081027, 0.11797234633427, 0.0938862761321756, 0.14482525059603746, 0.14180278225635778, 0.1447769572962172, 0.1400225113685234, 0.16420339277775953, 0.15177698802228456, 0.13382052960002133, 0.15863291054789186, 0.1385682609767811, 0.1369758776679968, 0.1283448304696776, 0.13594852971505766, 0.12953762514568712, 0.1330913479580642, 0.10732924471572791, 0.1472137659469408, 0.11293517126864971, 0.1553668786890977, 0.15293263882316044, 0.19747157359233292, 0.1440724567169116, 0.1636977767686778, 0.13894201680898188, 0.16154046413368384, 0.15192576606118824, 0.1721743094902799, 0.1532710606750658, 0.12855069562364263, 0.16030092332114654, 0.1590192327088522, 0.1221884315249161, 0.156562303028416, 0.21719384075354853, 0.11797886468012653, 0.12133247780654188, 0.17244473909987879, 0.1832200888382377, 0.17498246353342672, 0.17404797983069598, 0.17516614330002522, 0.17686651834768796, 0.16982349996047919, 0.17431849194947102, 0.1702207929525602, 0.1966458246175513, 0.04360373975378384, 0.05147309007271905, 0.043044117799327486, 0.04639825130752706, 0.047537104224936955, 0.051532355642344596, 0.0441928924986279, 0.050076220332276544, 0.047832345794061815]}, "mutation_prompt": null}
{"id": "38fbd86c-0d15-4968-ae0c-018224c1b1b4", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.convergence_history = []\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Store the convergence history\n            self.convergence_history.append(np.abs(func_value))\n            if len(self.convergence_history) > 10:\n                self.convergence_history.pop(0)\n            # Non-Local Search\n            for k in range(self.dim):\n                for l in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[k] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[l] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python\n# ```python\n# # Refine the strategy by changing the individual lines\ndef refine_strategy(nonlocal_dabu):\n    # Increase the budget to 5000\n    nonlocal_dabu.budget = 5000\n    # Increase the number of dimensions to 3\n    nonlocal_dabu.dim = 3\n    # Increase the alpha value to 0.7\n    nonlocal_dabu.alpha = 0.7\n    # Decrease the convergence threshold to 0.8\n    nonlocal_dabu.convergence_threshold = 0.8\n    # Increase the number of convergence history entries to 20\n    nonlocal_dabu.convergence_history = []\n    return nonlocal_dabu\n\nnonlocal_dabu = refine_strategy(nonlocal_dabu)\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 93, "fitness": 0.0871745530012762, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.07.", "error": "", "parent_id": "fadefa68-1ffa-4606-9cfd-1ca8a4a24133", "metadata": {"aucs": [0.1788959740446877, 0.16439524168940312, 0.18822895652585958, 0.1425491241258574, 0.1493399738317226, 0.15270011973417819, 0.19224301294380808, 0.1564634898035251, 0.1548065233813486, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04962651907053239, 0.04801067392067704, 0.04236043905738862, 0.03640718639585161, 0.05169350504802295, 0.046057928189484065, 0.04210603682012948, 0.044009460694015456, 0.04895886484880707, 0.028534329246989176, 0.04346535451303335, 0.03511672754872652, 0.027074378323380555, 0.018814890149511432, 0.026348378521424465, 0.041794581331417446, 0.03696752773036205, 0.03249806018965906, 0.08927729899320402, 0.08266559969246823, 0.08558353835893251, 0.07294903175377399, 0.08027772185378812, 0.08201106529572866, 0.07325024674930503, 0.1040063003600199, 0.08197076558493777, 0.0675126246955593, 0.06246086467750411, 0.0695438216697396, 0.07250697001007378, 0.04979050695396403, 0.06938152258845964, 0.07146982014126912, 0.060420159447280075, 0.10273702689473152, 0.10926977621305944, 0.1653045329722328, 0.17437395036089243, 0.11439992729500048, 0.13376942235925127, 0.1085012850032635, 0.15481007922291867, 0.10725445678561041, 0.1187017726232088, 9.999999999998899e-05, 0.00321294263331362, 9.999999999998899e-05, 0.04154918851572165, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006533696723265536, 9.999999999998899e-05, 0.011997921682340151, 0.022956002170980483, 0.0017058137790154637, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007293145082701291, 9.999999999998899e-05, 0.01919325612817535, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02783084186883611, 0.04768245592410236, 0.031619798796862275, 0.035979340758349077, 0.09526695544942865, 0.07659932571766637, 0.07799598099040028, 0.05569194958038892, 0.05113190694100811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002834703799934557, 9.999999999998899e-05, 0.0014571522793347391, 0.19117360497392033, 0.24733998692378367, 0.1755559915101208, 0.1859618553467396, 0.18934183577342278, 0.17880934739943843, 0.22021674245894274, 0.18037933781023274, 0.19297513157713952, 0.03253052177517113, 0.034872808115048115, 0.058505918534136114, 0.03514793718007425, 0.03440726147175732, 0.061953339491450765, 0.05272739879573951, 0.04308800422622239, 0.05271649690245017, 0.1391793192850711, 0.12317483512956495, 0.13021987995580042, 0.13435608370795038, 0.1277130212056944, 0.12742361754418163, 0.14345276778555893, 0.12247147961989158, 0.13773029846145768, 0.17082447530593725, 0.15733780557470578, 0.1648698666641112, 0.16592387489976823, 0.15063588530646943, 0.1747389650468658, 0.15181135894656927, 0.17601924017196524, 0.16369619423232873, 0.1072881579179028, 0.09837903899973754, 0.10505413672739905, 0.11007679511672619, 0.11109384245080511, 0.12084463378040033, 0.1066636043523409, 0.1037342460570484, 0.10943538433293742, 0.14364244515918034, 0.16007013785233137, 0.1418022670987612, 0.15426902711545476, 0.18044790013228595, 0.16782497860367496, 0.15630748047041287, 0.15994985564536035, 0.19511431278543223, 0.14924014220813642, 0.15904445361252206, 0.1378265284166953, 0.14618942742224805, 0.1272844255921265, 0.1583114640646387, 0.1357390420778387, 0.14154950463445515, 0.1424888098151751, 0.15465812383655753, 0.1486408299117522, 0.17391091366389444, 0.15479747427084856, 0.15297934450245199, 0.14395883200278747, 0.18646611011480618, 0.18891165701848778, 0.13473999053265528, 0.15839559850122553, 0.16349702349352357, 0.18697752394561862, 0.1564182155673849, 0.18757861761791805, 0.12971423267992777, 0.10610860913194464, 0.17533201969902457, 0.12534925064988023, 0.17460092847567776, 0.1862236313536222, 0.17555539439830736, 0.19163670958669188, 0.1956447064495187, 0.1843627635692635, 0.17484192050848124, 0.18069644220399117, 0.194273550863849, 0.03989434295102168, 0.047819882853694984, 0.05066412388167518, 0.05214657934515454, 0.04056011794875136, 0.048297501727378234, 0.04075381747004503, 0.0449361709457593, 0.05280623999256984]}, "mutation_prompt": null}
{"id": "a0ff3b7c-e50b-421e-8969-c0ba7a3b4e3e", "solution": "# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\nimport numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.convergence_history = []\n        self.refine_strategy = False\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Store the convergence history\n            self.convergence_history.append(np.abs(func_value))\n            if len(self.convergence_history) > 10:\n                self.convergence_history.pop(0)\n            # Non-Local Search\n            for k in range(self.dim):\n                for l in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[k] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[l] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        if self.refine_strategy:\n            # Refine the strategy by changing the individual lines\n            # Increase the budget to 5000\n            self.budget = 5000\n            # Increase the number of dimensions to 3\n            self.dim = 3\n            # Increase the alpha value to 0.7\n            self.alpha = 0.7\n            # Decrease the convergence threshold to 0.8\n            self.convergence_threshold = 0.8\n            # Increase the number of convergence history entries to 20\n            self.convergence_history = []\n            # Update the convergence rate\n            self.convergence_rate *= 0.8\n            # Update the convergence threshold\n            self.convergence_threshold *= 0.8\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python\n# # Refine the strategy by changing the individual lines\ndef refine_strategy(nonlocal_dabu):\n    if np.random.rand() < 0.3:\n        nonlocal_dabu.alpha = 0.7\n        nonlocal_dabu.convergence_rate *= 0.8\n        nonlocal_dabu.convergence_threshold *= 0.8\n    return nonlocal_dabu\n\nnonlocal_dabu = refine_strategy(nonlocal_dabu)\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 94, "fitness": 0.08781124796926354, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.07.", "error": "", "parent_id": "38fbd86c-0d15-4968-ae0c-018224c1b1b4", "metadata": {"aucs": [0.16721220199617015, 0.16948795412297646, 0.17301941275521726, 0.16540535991511152, 0.1618973681490079, 0.1869332904860297, 0.17705267206989828, 0.21734481211055656, 0.2056176543673266, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04041347304912091, 0.058057358290565575, 0.047853231569915056, 0.04498814190843181, 0.062183162065888586, 0.03823301988297678, 0.04535560925701898, 0.04417087411734155, 0.03218029826845137, 0.030633195567935534, 0.049739680027136135, 0.020117377781145085, 0.02982234665139183, 0.05555524545129409, 0.029368801553995794, 0.03442257279956262, 0.029551886204745248, 0.0327582981417216, 0.08280403908112877, 0.09038939068053897, 0.08710650458920721, 0.09412663500580132, 0.08293124812072505, 0.0743890189754548, 0.08710091794987618, 0.07613755857139548, 0.07292756430326719, 0.07604723889312803, 0.08253047238667388, 0.06858461399577576, 0.06763024636911485, 0.06038283239946374, 0.07283149060752281, 0.06361755164155314, 0.08879534077803797, 0.04631932648378623, 0.11371162117641398, 0.11337284039801065, 0.09903511374736795, 0.14616105444656657, 0.10541175537476899, 0.12236479104048525, 0.11894742149984994, 0.12285226302180585, 0.10782082758790112, 9.999999999998899e-05, 0.007393550623528422, 9.999999999998899e-05, 9.999999999998899e-05, 0.005390468753804667, 9.999999999998899e-05, 0.025088559993000525, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005421571451533547, 9.999999999998899e-05, 0.008211198856480806, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05223869664669678, 0.050778931680978134, 0.023872218534479406, 0.04267544390942857, 0.03174468259907792, 0.050268320789198184, 0.06792582091609944, 0.035232400019432286, 0.050657944172057934, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004310894313670488, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.17575494939190628, 0.1896609749435283, 0.17252356334570995, 0.17361606899038307, 0.22059214093889645, 0.17844312976184518, 0.18873699056580884, 0.18371832950914158, 0.17122099026699655, 0.05699986852722527, 0.035203179180060995, 0.055749991622982664, 0.04807528344138534, 0.04838656691941612, 0.03796655800569637, 0.037226936873085426, 0.035584192167333994, 0.04476234574472204, 0.13268574793811827, 0.18655069623090892, 0.14456895284750682, 0.14724434605196368, 0.18484487307644326, 0.139702304881684, 0.12952786454082665, 0.15194688174116877, 0.1540292410811973, 0.15686564676839698, 0.1562635003379913, 0.16731850606653642, 0.16565853620752768, 0.1841165912218793, 0.15222076769526083, 0.16211885329938436, 0.15602767193892175, 0.15786073728761985, 0.09994844442781736, 0.11138464043865892, 0.10379620251883903, 0.10829983245505914, 0.10084080842949805, 0.11045735389273525, 0.10643814656228101, 0.10989025247789763, 0.10758074978125498, 0.18863378368311212, 0.1545096576427395, 0.15265830680397885, 0.15341635836167788, 0.1477922848158172, 0.14487003538691534, 0.1545515581811414, 0.15964141243176855, 0.15084007853399195, 0.14300447829480578, 0.13331249793462052, 0.1458316205067962, 0.13941952178461847, 0.13960998738172803, 0.14478027277714212, 0.14813446438553057, 0.1455673595239667, 0.14561601595739504, 0.1436437437116026, 0.16410816803706474, 0.22837650726062997, 0.17994164214313313, 0.14609379092487962, 0.15088958127451046, 0.21348830062802038, 0.17625889210819345, 0.18239296229037505, 0.22960905645720475, 0.15719939566414265, 0.15068234492964383, 0.18437387793313487, 0.16010819103957474, 0.1948955233685724, 0.13929723892141865, 0.13187806091054577, 0.18384264830196717, 0.1835157691580227, 0.18006448551947507, 0.18951441402325597, 0.17574865516898752, 0.1724251625096933, 0.1773466684300563, 0.1881206904469781, 0.18666308794696684, 0.1739679661392003, 0.043998620636502506, 0.044548702523208195, 0.047047436098380246, 0.05569208092164646, 0.05509836463352147, 0.04881010964321009, 0.06330640817609579, 0.045981043370459385, 0.04398438438338126]}, "mutation_prompt": null}
{"id": "bbabd937-fbd4-48a3-97a9-1a175e396e5a", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.convergence_history = []\n        self.refine_strategy = False\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Store the convergence history\n            self.convergence_history.append(np.abs(func_value))\n            if len(self.convergence_history) > 10:\n                self.convergence_history.pop(0)\n            # Non-Local Search\n            for k in range(self.dim):\n                for l in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[k] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[l] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        if self.refine_strategy:\n            # Refine the strategy by changing the individual lines\n            # Increase the budget to 5000\n            self.budget = 5000\n            # Increase the number of dimensions to 3\n            self.dim = 3\n            # Increase the alpha value to 0.7\n            self.alpha = 0.7\n            # Decrease the convergence threshold to 0.8\n            self.convergence_threshold = 0.8\n            # Increase the number of convergence history entries to 20\n            self.convergence_history = []\n            # Update the convergence rate\n            self.convergence_rate *= 0.8\n            # Update the convergence threshold\n            self.convergence_threshold *= 0.8\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\ndef refine_strategy(nonlocal_dabu):\n    if random.random() < 0.3:\n        nonlocal_dabu.alpha = 0.7\n        nonlocal_dabu.convergence_rate *= 0.8\n        nonlocal_dabu.convergence_threshold *= 0.8\n\nnonlocal_dabu = refine_strategy(nonlocal_dabu)\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 95, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'NoneType' object is not callable\").", "error": "TypeError(\"'NoneType' object is not callable\")", "parent_id": "a0ff3b7c-e50b-421e-8969-c0ba7a3b4e3e", "metadata": {}, "mutation_prompt": null}
{"id": "e93bbbdf-c653-4fa5-a4bc-d3a45fbd637d", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.convergence_history = []\n        self.refine_strategy = False\n        self.refine_strategy_history = []\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Store the convergence history\n            self.convergence_history.append(np.abs(func_value))\n            if len(self.convergence_history) > 10:\n                self.convergence_history.pop(0)\n            # Non-Local Search\n            for k in range(self.dim):\n                for l in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[k] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[l] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        if self.refine_strategy:\n            # Refine the strategy by changing the individual lines\n            # Increase the budget to 5000\n            self.budget = 5000\n            # Increase the number of dimensions to 3\n            self.dim = 3\n            # Increase the alpha value to 0.7\n            self.alpha = 0.7\n            # Decrease the convergence threshold to 0.8\n            self.convergence_threshold = 0.8\n            # Increase the number of convergence history entries to 20\n            self.convergence_history = []\n            # Update the convergence rate\n            self.convergence_rate *= 0.8\n            # Update the convergence threshold\n            self.convergence_threshold *= 0.8\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Refine the strategy by changing the individual lines\ndef refine_strategy(nonlocal_dabu):\n    if random.random() < 0.3:\n        nonlocal_dabu.alpha = 0.7\n        nonlocal_dabu.convergence_rate *= 0.8\n        nonlocal_dabu.convergence_threshold *= 0.8\n    return nonlocal_dabu\n\nnonlocal_dabu = refine_strategy(nonlocal_dabu)\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# ```python\n# NonLocalDABU\n# ```python\n# ```python\n# ```python\n# ```python\n# ```python\n# ```python\n# ```python\n# # Refine the strategy by changing the individual lines\n# def refine_strategy(nonlocal_dabu):\n#     if random.random() < 0.3:\n#         nonlocal_dabu.alpha = 0.7\n#         nonlocal_dabu.convergence_rate *= 0.8\n#         nonlocal_dabu.convergence_threshold *= 0.8\n#     return nonlocal_dabu\n\n# nonlocal_dabu = refine_strategy(nonlocal_dabu)\n# print(nonlocal_dabu(test_function))  # prints a random value between -10 and 10", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 96, "fitness": 0.0870947802530434, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.07.", "error": "", "parent_id": "a0ff3b7c-e50b-421e-8969-c0ba7a3b4e3e", "metadata": {"aucs": [0.15865067025691082, 0.2346598069136523, 0.16204444347613756, 0.1617064631097319, 0.166683431907112, 0.19928216803546395, 0.17469622151925124, 0.15616403750975172, 0.17388233410991016, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04294911599927598, 0.03269532351605631, 0.048855770641927476, 0.04219336593072642, 0.03961195436344478, 0.045940194550213365, 0.0316387618610281, 0.03513684696359343, 0.039204472033925186, 0.020839840716085356, 0.023895775541667663, 0.02573750475193959, 0.04092875885364555, 0.031078407090752935, 0.025192670224564395, 0.031093066226373756, 0.03737455340200957, 0.046949063762204424, 0.07492596047456168, 0.08356320921754268, 0.07457215170422171, 0.0892618404995621, 0.09913412392393006, 0.07027121547962867, 0.08228975372921066, 0.07850280518948272, 0.09485677750126376, 0.08324238157872221, 0.060574865244637066, 0.08647991419314316, 0.068098632933282, 0.06789285248111754, 0.059920195475622995, 0.07818582276568653, 0.09576599683779441, 0.05592202729037199, 0.13813743885416463, 0.13705263424172476, 0.10743128325853091, 0.11136552651431664, 0.11762927024309466, 0.11777809067739253, 0.11202510945620303, 0.12483220808308781, 0.12402784957088675, 9.999999999998899e-05, 0.007409956425059483, 0.0006357005645850622, 9.999999999998899e-05, 0.004046257925158225, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006015473221144818, 0.004801914799404616, 9.999999999998899e-05, 9.999999999998899e-05, 0.003122970600110575, 9.999999999998899e-05, 0.02050160277575941, 0.013491548357743133, 0.03464202613855505, 0.020913017723302674, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07834234329976586, 0.03048252761330661, 0.03399400591834345, 0.038344227871363046, 0.05052422968460979, 0.03806595226738896, 0.07540626084401025, 0.06619733471165568, 0.06140141258257226, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013683794824646989, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.18469958601695968, 0.18888125909262043, 0.19036104441596846, 0.1918124664781733, 0.19739587258324243, 0.18827678853979624, 0.1913163842124206, 0.19541561015616904, 0.17843406440103193, 0.050319128125374535, 0.05598254350639109, 0.044970239278331436, 0.0518689475343459, 0.04596413828166446, 0.04378777152475599, 0.041070237038052126, 0.04514151171311409, 0.03847957044442174, 0.1346819086572838, 0.1584055489300885, 0.16008238683633058, 0.1710575325393343, 0.12844016538982672, 0.1281519290742541, 0.1419938048173699, 0.12888561907893714, 0.12264347602010461, 0.18807819005857018, 0.17275358255698614, 0.15299845059161832, 0.15888975300327202, 0.15353975792909258, 0.15978954310778648, 0.16554812313808165, 0.15357980016087602, 0.16016552666607053, 0.10209218069856829, 0.11244075669798914, 0.12489598265720214, 0.10713278557104366, 0.10531554975450796, 0.1083149219874846, 0.09926533516775848, 0.10329080063374951, 0.11422425612498444, 0.15138660191847864, 0.1529753882234831, 0.15066391460023332, 0.15900433330526287, 0.17676672776672897, 0.14183698217645602, 0.15264599318141647, 0.16075538251902033, 0.17849180077450588, 0.13506960050394667, 0.14202781634961503, 0.1363389948631606, 0.1358361516734662, 0.14320820229248532, 0.12972789184300815, 0.1410641134338726, 0.1471995054477777, 0.14978301809304084, 0.1591638152342526, 0.17296109995511288, 0.14677687337498213, 0.18059194943858092, 0.16623580381282066, 0.15604502488761374, 0.16279696439316138, 0.16717038759971947, 0.18154149213544168, 0.12326127852421176, 0.19384642209312308, 0.12337428490210933, 0.15216712523520515, 0.14237102201078955, 0.16358806837433149, 0.1594200254355057, 0.12833342407082182, 0.16495562566372568, 0.19446275704484905, 0.19456115087624348, 0.18149529552938293, 0.1771956742542118, 0.1815415346786602, 0.17871632719217645, 0.1774402061295579, 0.19188950184590858, 0.17927157669378668, 0.04350288954243364, 0.04696862493836995, 0.04698178488382765, 0.043389377047386324, 0.043930613810192365, 0.06506805926293746, 0.06461295665490929, 0.05062418995445328, 0.05686848408262135]}, "mutation_prompt": null}
{"id": "ea3f0b5a-b22c-4c8f-ab9a-73cd32b120f1", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.convergence_history = []\n        self.refine_strategy = False\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Store the convergence history\n            self.convergence_history.append(np.abs(func_value))\n            if len(self.convergence_history) > 10:\n                self.convergence_history.pop(0)\n            # Non-Local Search\n            for k in range(self.dim):\n                for l in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[k] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[l] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        if self.refine_strategy:\n            # Refine the strategy by changing the individual lines\n            # Increase the budget to 5000\n            self.budget = 5000\n            # Increase the number of dimensions to 3\n            self.dim = 3\n            # Increase the alpha value to 0.7\n            self.alpha = 0.7\n            # Decrease the convergence threshold to 0.8\n            self.convergence_threshold = 0.8\n            # Increase the number of convergence history entries to 20\n            self.convergence_history = []\n            # Update the convergence rate\n            self.convergence_rate *= 0.8\n            # Update the convergence threshold\n            self.convergence_threshold *= 0.8\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# NonLocalDABU is a novel metaheuristic algorithm that uses Non-Local Search with Adaptation to Convergence Rate to optimize black box functions.\n# The algorithm refines its strategy by changing the individual lines of the selected solution, which improves its convergence rate.\n# The probability of refinement is 0.3, and the individual lines are changed when the convergence rate or threshold is exceeded.", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 97, "fitness": 0.08902592146096876, "feedback": "The algorithm NonLocalDABU got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.07.", "error": "", "parent_id": "a0ff3b7c-e50b-421e-8969-c0ba7a3b4e3e", "metadata": {"aucs": [0.17103494619483806, 0.20337184348587378, 0.20616253647542115, 0.17306771440460578, 0.1758804055363169, 0.14706482234262963, 0.16028797449257093, 0.17858258653207082, 0.170197464955278, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04654172574596227, 0.044599904547448554, 0.03557551377911228, 0.04117746400669697, 0.03623051505889585, 0.03972899496636506, 0.04834852809265755, 0.07128396748515697, 0.07250921249152398, 0.02133807838245705, 0.07009366185369548, 0.029871168075455312, 0.025682538382036713, 0.024265845332836267, 0.03634107724093705, 0.031100734848785616, 0.039707363380740435, 0.032779740081691155, 0.07540549792518703, 0.07225541761349685, 0.07718202158383647, 0.08779543203779472, 0.07808203193629537, 0.08476574336400466, 0.09079381396367392, 0.07062371162258518, 0.07132078746472958, 0.08053814192194042, 0.06571578383190158, 0.08090281433769664, 0.06861399313955441, 0.12989032626703445, 0.04835075480917128, 0.06489894129943563, 0.08846185187745448, 0.043915730685255894, 0.10337823110928546, 0.12229105854169808, 0.1012622836113658, 0.10285912528904395, 0.09619581210522632, 0.11383134593125943, 0.11131353183308024, 0.14018235998564665, 0.09701439313185034, 0.009152401474250116, 0.0028140138396134384, 0.019222399547697, 9.999999999998899e-05, 0.05940918347209967, 0.004184792210524257, 9.999999999998899e-05, 9.999999999998899e-05, 0.02585968462399746, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0215798444223414, 0.000900873356806775, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10608911175035096, 0.02242861524230122, 0.03379109925134438, 0.04719073787032069, 0.05366158348857841, 0.08415800780440263, 0.07142672841263942, 0.049878469582578466, 0.03289695705789086, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001703192968604883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1854925812469772, 0.20449482803142205, 0.21453795555594124, 0.18533302808555963, 0.2463258771576402, 0.18406281833176608, 0.20548790335370126, 0.22599733675561406, 0.17481044762276776, 0.040762372510397826, 0.06304089496148735, 0.05740133516185175, 0.035008593735472604, 0.06409242774855561, 0.038127652697462544, 0.030352752878950784, 0.04581722938209243, 0.04903820507392431, 0.13731658756426368, 0.1402774683027428, 0.1491138423984084, 0.13037656576554835, 0.14352624347090992, 0.11548286991399748, 0.12296840648168073, 0.18947712581810505, 0.14073019554739497, 0.17939499800206526, 0.16863043606301076, 0.17037014820682694, 0.17498484729380492, 0.15910954807338473, 0.1538671365650458, 0.17750009128226718, 0.16028791265682263, 0.15235167667753158, 0.11054636947178986, 0.09699397019286993, 0.11469299135213928, 0.11232133585966908, 0.11267393981149576, 0.11436928737218388, 0.11206754634322136, 0.10737520064693673, 0.09546946883816676, 0.143610864271716, 0.1630260530144948, 0.15696017284153874, 0.18551085913261445, 0.14073215457316546, 0.15353214362983458, 0.1568771553226005, 0.16134220635327712, 0.14706066446248733, 0.14246111447967447, 0.16672154392229166, 0.14276653110740212, 0.15316069325613768, 0.15527213084470226, 0.15741762330296127, 0.13761021578448074, 0.128623081178189, 0.12778626049719077, 0.19985474221488975, 0.15871901758336737, 0.1646951313372057, 0.16885161641413615, 0.1770831132962023, 0.1628490039507291, 0.15060784629092527, 0.13615695126973493, 0.1816535516631439, 0.15169982426432138, 0.16669024225613416, 0.1976137281868845, 0.1725505277757866, 0.23600766422378405, 0.12061822603947825, 0.16723763318503393, 0.18113062841189054, 0.17263250687098186, 0.2190921213668624, 0.17566772429451827, 0.1865756764338533, 0.1767632658428855, 0.17956235521229758, 0.1794962244396675, 0.1885461748726155, 0.1871349822065036, 0.18377413135883525, 0.049004424995335305, 0.052874179146493394, 0.05762937145177094, 0.04096887827099727, 0.040251728445910295, 0.042958369193995316, 0.05058790616032294, 0.04568037357489152, 0.04193231306032863]}, "mutation_prompt": null}
{"id": "a7da64da-29ba-497a-b7e8-cf96effb8fc4", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.convergence_history = []\n        self.refine_strategy = False\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Store the convergence history\n            self.convergence_history.append(np.abs(func_value))\n            if len(self.convergence_history) > 10:\n                self.convergence_history.pop(0)\n            # Non-Local Search\n            for k in range(self.dim):\n                for l in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[k] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[l] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        if self.refine_strategy:\n            # Refine the strategy by changing the individual lines\n            # Increase the budget to 5000\n            self.budget = 5000\n            # Increase the number of dimensions to 3\n            self.dim = 3\n            # Increase the alpha value to 0.7\n            self.alpha = 0.7\n            # Decrease the convergence threshold to 0.8\n            self.convergence_threshold = 0.8\n            # Increase the number of convergence history entries to 20\n            self.convergence_history = []\n            # Update the convergence rate\n            self.convergence_rate *= 0.8\n            # Update the convergence threshold\n            self.convergence_threshold *= 0.8\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# NonLocalDABU is a novel metaheuristic algorithm that uses Non-Local Search with Adaptation to Convergence Rate to optimize black box functions.\n# The algorithm refines its strategy by changing the individual lines of the selected solution, which improves its convergence rate.\n# The probability of refinement is 0.3, and the individual lines are changed when the convergence rate or threshold is exceeded.", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 98, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ea3f0b5a-b22c-4c8f-ab9a-73cd32b120f1", "metadata": {"aucs": [0.17103494619483806, 0.20337184348587378, 0.20616253647542115, 0.17306771440460578, 0.1758804055363169, 0.14706482234262963, 0.16028797449257093, 0.17858258653207082, 0.170197464955278, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04654172574596227, 0.044599904547448554, 0.03557551377911228, 0.04117746400669697, 0.03623051505889585, 0.03972899496636506, 0.04834852809265755, 0.07128396748515697, 0.07250921249152398, 0.02133807838245705, 0.07009366185369548, 0.029871168075455312, 0.025682538382036713, 0.024265845332836267, 0.03634107724093705, 0.031100734848785616, 0.039707363380740435, 0.032779740081691155, 0.07540549792518703, 0.07225541761349685, 0.07718202158383647, 0.08779543203779472, 0.07808203193629537, 0.08476574336400466, 0.09079381396367392, 0.07062371162258518, 0.07132078746472958, 0.08053814192194042, 0.06571578383190158, 0.08090281433769664, 0.06861399313955441, 0.12989032626703445, 0.04835075480917128, 0.06489894129943563, 0.08846185187745448, 0.043915730685255894, 0.10337823110928546, 0.12229105854169808, 0.1012622836113658, 0.10285912528904395, 0.09619581210522632, 0.11383134593125943, 0.11131353183308024, 0.14018235998564665, 0.09701439313185034, 0.009152401474250116, 0.0028140138396134384, 0.019222399547697, 9.999999999998899e-05, 0.05940918347209967, 0.004184792210524257, 9.999999999998899e-05, 9.999999999998899e-05, 0.02585968462399746, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0215798444223414, 0.000900873356806775, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10608911175035096, 0.02242861524230122, 0.03379109925134438, 0.04719073787032069, 0.05366158348857841, 0.08415800780440263, 0.07142672841263942, 0.049878469582578466, 0.03289695705789086, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001703192968604883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1854925812469772, 0.20449482803142205, 0.21453795555594124, 0.18533302808555963, 0.2463258771576402, 0.18406281833176608, 0.20548790335370126, 0.22599733675561406, 0.17481044762276776, 0.040762372510397826, 0.06304089496148735, 0.05740133516185175, 0.035008593735472604, 0.06409242774855561, 0.038127652697462544, 0.030352752878950784, 0.04581722938209243, 0.04903820507392431, 0.13731658756426368, 0.1402774683027428, 0.1491138423984084, 0.13037656576554835, 0.14352624347090992, 0.11548286991399748, 0.12296840648168073, 0.18947712581810505, 0.14073019554739497, 0.17939499800206526, 0.16863043606301076, 0.17037014820682694, 0.17498484729380492, 0.15910954807338473, 0.1538671365650458, 0.17750009128226718, 0.16028791265682263, 0.15235167667753158, 0.11054636947178986, 0.09699397019286993, 0.11469299135213928, 0.11232133585966908, 0.11267393981149576, 0.11436928737218388, 0.11206754634322136, 0.10737520064693673, 0.09546946883816676, 0.143610864271716, 0.1630260530144948, 0.15696017284153874, 0.18551085913261445, 0.14073215457316546, 0.15353214362983458, 0.1568771553226005, 0.16134220635327712, 0.14706066446248733, 0.14246111447967447, 0.16672154392229166, 0.14276653110740212, 0.15316069325613768, 0.15527213084470226, 0.15741762330296127, 0.13761021578448074, 0.128623081178189, 0.12778626049719077, 0.19985474221488975, 0.15871901758336737, 0.1646951313372057, 0.16885161641413615, 0.1770831132962023, 0.1628490039507291, 0.15060784629092527, 0.13615695126973493, 0.1816535516631439, 0.15169982426432138, 0.16669024225613416, 0.1976137281868845, 0.1725505277757866, 0.23600766422378405, 0.12061822603947825, 0.16723763318503393, 0.18113062841189054, 0.17263250687098186, 0.2190921213668624, 0.17566772429451827, 0.1865756764338533, 0.1767632658428855, 0.17956235521229758, 0.1794962244396675, 0.1885461748726155, 0.1871349822065036, 0.18377413135883525, 0.049004424995335305, 0.052874179146493394, 0.05762937145177094, 0.04096887827099727, 0.040251728445910295, 0.042958369193995316, 0.05058790616032294, 0.04568037357489152, 0.04193231306032863]}, "mutation_prompt": null}
{"id": "e62ee349-be11-4197-ba86-9eccc8c09e8c", "solution": "import numpy as np\nimport random\n\nclass NonLocalDABU:\n    def __init__(self, budget, dim, alpha=0.5, beta=0.8, min_alpha=0.01, max_alpha=0.9, min_beta=0.01, max_beta=0.1):\n        self.budget = budget\n        self.dim = dim\n        self.search_space = np.linspace(-5.0, 5.0, dim)\n        self.func_evaluations = 0\n        self.alpha = alpha\n        self.beta = beta\n        self.min_alpha = min_alpha\n        self.max_alpha = max_alpha\n        self.min_beta = min_beta\n        self.max_beta = max_beta\n        self.current_alpha = alpha\n        self.current_beta = beta\n        self.convergence_rate = 0.8\n        self.convergence_threshold = 0.9\n        self.search_space_size = 100\n        self.convergence_history = []\n        self.refine_strategy = False\n\n    def __call__(self, func):\n        while self.func_evaluations < self.budget:\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            if self.func_evaluations / self.budget > self.convergence_rate:\n                self.alpha *= self.beta\n                if self.alpha < self.min_alpha:\n                    self.alpha = self.min_alpha\n                if self.alpha > self.max_alpha:\n                    self.alpha = self.max_alpha\n            if self.func_evaluations / self.budget > self.convergence_threshold:\n                self.beta *= self.alpha\n                if self.beta < self.min_beta:\n                    self.beta = self.min_beta\n                if self.beta > self.max_beta:\n                    self.beta = self.max_beta\n            # Non-Local Search\n            for i in range(self.dim):\n                for j in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[i] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[j] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n            # Store the convergence history\n            self.convergence_history.append(np.abs(func_value))\n            if len(self.convergence_history) > 10:\n                self.convergence_history.pop(0)\n            # Non-Local Search\n            for k in range(self.dim):\n                for l in range(self.dim):\n                    if random.random() < self.alpha:\n                        self.search_space[k] = np.random.uniform(-5.0, 5.0)\n                        self.search_space[l] = np.random.uniform(-5.0, 5.0)\n            # Evaluate the function with the new search space\n            func_value = func(self.search_space)\n            if np.abs(func_value) < 1e-6:  # stop if the function value is close to zero\n                break\n            self.func_evaluations += 1\n        if self.refine_strategy:\n            # Refine the strategy by changing the individual lines\n            # Increase the budget to 5000\n            self.budget = 5000\n            # Increase the number of dimensions to 3\n            self.dim = 3\n            # Increase the alpha value to 0.7\n            self.alpha = 0.7\n            # Decrease the convergence threshold to 0.8\n            self.convergence_threshold = 0.8\n            # Increase the number of convergence history entries to 20\n            self.convergence_history = []\n            # Update the convergence rate\n            self.convergence_rate *= 0.8\n            # Update the convergence threshold\n            self.convergence_threshold *= 0.8\n        return func_value\n\n# Example usage:\ndef test_function(x):\n    return np.exp(-x[0]**2 - x[1]**2)\n\nnonlocal_dabu = NonLocalDABU(1000, 2)  # 1000 function evaluations, 2 dimensions\nprint(nonlocal_dabu(test_function))  # prints a random value between -10 and 10\n\n# Description: Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate\n# Code: \n# ```python\n# NonLocalDABU is a novel metaheuristic algorithm that uses Non-Local Search with Adaptation to Convergence Rate to optimize black box functions.\n# The algorithm refines its strategy by changing the individual lines of the selected solution, which improves its convergence rate.\n# The probability of refinement is 0.3, and the individual lines are changed when the convergence rate or threshold is exceeded.", "name": "NonLocalDABU", "description": "Novel metaheuristic algorithm using Non-Local Search with Adaptation to Convergence Rate", "configspace": "", "generation": 98, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "ea3f0b5a-b22c-4c8f-ab9a-73cd32b120f1", "metadata": {"aucs": [0.17103494619483806, 0.20337184348587378, 0.20616253647542115, 0.17306771440460578, 0.1758804055363169, 0.14706482234262963, 0.16028797449257093, 0.17858258653207082, 0.170197464955278, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04654172574596227, 0.044599904547448554, 0.03557551377911228, 0.04117746400669697, 0.03623051505889585, 0.03972899496636506, 0.04834852809265755, 0.07128396748515697, 0.07250921249152398, 0.02133807838245705, 0.07009366185369548, 0.029871168075455312, 0.025682538382036713, 0.024265845332836267, 0.03634107724093705, 0.031100734848785616, 0.039707363380740435, 0.032779740081691155, 0.07540549792518703, 0.07225541761349685, 0.07718202158383647, 0.08779543203779472, 0.07808203193629537, 0.08476574336400466, 0.09079381396367392, 0.07062371162258518, 0.07132078746472958, 0.08053814192194042, 0.06571578383190158, 0.08090281433769664, 0.06861399313955441, 0.12989032626703445, 0.04835075480917128, 0.06489894129943563, 0.08846185187745448, 0.043915730685255894, 0.10337823110928546, 0.12229105854169808, 0.1012622836113658, 0.10285912528904395, 0.09619581210522632, 0.11383134593125943, 0.11131353183308024, 0.14018235998564665, 0.09701439313185034, 0.009152401474250116, 0.0028140138396134384, 0.019222399547697, 9.999999999998899e-05, 0.05940918347209967, 0.004184792210524257, 9.999999999998899e-05, 9.999999999998899e-05, 0.02585968462399746, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0215798444223414, 0.000900873356806775, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10608911175035096, 0.02242861524230122, 0.03379109925134438, 0.04719073787032069, 0.05366158348857841, 0.08415800780440263, 0.07142672841263942, 0.049878469582578466, 0.03289695705789086, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001703192968604883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1854925812469772, 0.20449482803142205, 0.21453795555594124, 0.18533302808555963, 0.2463258771576402, 0.18406281833176608, 0.20548790335370126, 0.22599733675561406, 0.17481044762276776, 0.040762372510397826, 0.06304089496148735, 0.05740133516185175, 0.035008593735472604, 0.06409242774855561, 0.038127652697462544, 0.030352752878950784, 0.04581722938209243, 0.04903820507392431, 0.13731658756426368, 0.1402774683027428, 0.1491138423984084, 0.13037656576554835, 0.14352624347090992, 0.11548286991399748, 0.12296840648168073, 0.18947712581810505, 0.14073019554739497, 0.17939499800206526, 0.16863043606301076, 0.17037014820682694, 0.17498484729380492, 0.15910954807338473, 0.1538671365650458, 0.17750009128226718, 0.16028791265682263, 0.15235167667753158, 0.11054636947178986, 0.09699397019286993, 0.11469299135213928, 0.11232133585966908, 0.11267393981149576, 0.11436928737218388, 0.11206754634322136, 0.10737520064693673, 0.09546946883816676, 0.143610864271716, 0.1630260530144948, 0.15696017284153874, 0.18551085913261445, 0.14073215457316546, 0.15353214362983458, 0.1568771553226005, 0.16134220635327712, 0.14706066446248733, 0.14246111447967447, 0.16672154392229166, 0.14276653110740212, 0.15316069325613768, 0.15527213084470226, 0.15741762330296127, 0.13761021578448074, 0.128623081178189, 0.12778626049719077, 0.19985474221488975, 0.15871901758336737, 0.1646951313372057, 0.16885161641413615, 0.1770831132962023, 0.1628490039507291, 0.15060784629092527, 0.13615695126973493, 0.1816535516631439, 0.15169982426432138, 0.16669024225613416, 0.1976137281868845, 0.1725505277757866, 0.23600766422378405, 0.12061822603947825, 0.16723763318503393, 0.18113062841189054, 0.17263250687098186, 0.2190921213668624, 0.17566772429451827, 0.1865756764338533, 0.1767632658428855, 0.17956235521229758, 0.1794962244396675, 0.1885461748726155, 0.1871349822065036, 0.18377413135883525, 0.049004424995335305, 0.052874179146493394, 0.05762937145177094, 0.04096887827099727, 0.040251728445910295, 0.042958369193995316, 0.05058790616032294, 0.04568037357489152, 0.04193231306032863]}, "mutation_prompt": null}

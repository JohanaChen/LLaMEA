{"id": "08c9ccc3-a4cc-4890-8986-aeaa052de9a4", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.min_bound = -5.0\n        self.max_bound = 5.0\n        self.F = 0.5  # differential evolution scaling factor\n        self.CR = 0.9  # crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.min_bound, self.max_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, self.min_bound, self.max_bound)\n\n            # Evaluate PSO positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n            improved = scores < personal_best_scores\n            personal_best_positions[improved] = positions[improved]\n            personal_best_scores[improved] = scores[improved]\n\n            if np.min(scores) < global_best_score:\n                global_best_position = positions[np.argmin(scores)]\n                global_best_score = np.min(scores)\n\n            # DE Update\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = positions[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.F * (b - c), self.min_bound, self.max_bound)\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant_vector, positions[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial_vector\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A hybrid particle swarm optimization with adaptive differential evolution to balance exploration and exploitation.", "configspace": "", "generation": 0, "fitness": 0.21458885324826313, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": null, "metadata": {"aucs": [0.39712887885076875, 0.39712887885076875, 0.39712887885076875, 0.9392608853865323, 0.9392608853865323, 0.9392608853865323, 0.9447148316808145, 0.9447148316808145, 0.9447148316808145, 0.028792382451166332, 0.028792382451166332, 0.028792382451166332, 0.1009351199984907, 0.1009351199984907, 0.1009351199984907, 0.1430506425957383, 0.1430506425957383, 0.1430506425957383, 0.1389080290134791, 0.1389080290134791, 0.1389080290134791, 0.11907872565189537, 0.11907872565189537, 0.11907872565189537, 0.12097957910475166, 0.12097957910475166, 0.12097957910475166, 0.09323925280257861, 0.09323925280257861, 0.09323925280257861, 0.08423166241709568, 0.08423166241709568, 0.08423166241709568, 0.16560897253537077, 0.16560897253537077, 0.16560897253537077, 0.1569292008876091, 0.1569292008876091, 0.1569292008876091, 0.986701382393906, 0.986701382393906, 0.986701382393906, 0.22921073650379675, 0.22921073650379675, 0.22921073650379675, 0.7152190098184298, 0.7152190098184298, 0.7152190098184298, 0.14682330187732462, 0.14682330187732462, 0.14682330187732462, 0.17062499230538597, 0.17062499230538597, 0.17062499230538597, 0.17289888386197438, 0.17289888386197438, 0.17289888386197438, 0.16296510256108454, 0.16296510256108454, 0.16296510256108454, 0.22372347356299893, 0.22372347356299893, 0.22372347356299893, 0.13815739814132755, 0.13815739814132755, 0.13815739814132755, 0.1628571520815424, 0.1628571520815424, 0.1628571520815424, 0.07500309716985376, 0.07500309716985376, 0.07500309716985376, 0.15288070449686908, 0.15288070449686908, 0.15288070449686908, 0.15286606853579465, 0.15286606853579465, 0.15286606853579465, 0.13783602808943574, 0.13783602808943574, 0.13783602808943574, 0.01809705027407016, 0.01809705027407016, 0.01809705027407016, 0.011213555172999268, 0.011213555172999268, 0.011213555172999268, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15188807390674608, 0.15188807390674608, 0.15188807390674608, 0.04513764527761999, 0.04513764527761999, 0.04513764527761999, 0.09587655233290882, 0.09587655233290882, 0.09587655233290882, 0.19701351519139731, 0.19701351519139731, 0.19701351519139731, 0.1467681466263393, 0.1467681466263393, 0.1467681466263393, 0.21879673330699723, 0.21879673330699723, 0.21879673330699723, 0.13266085342380718, 0.13266085342380718, 0.13266085342380718, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5021745159494003, 0.5021745159494003, 0.5021745159494003, 0.26791554812722307, 0.26791554812722307, 0.26791554812722307, 0.4034031679207458, 0.4034031679207458, 0.4034031679207458, 0.07912983070662738, 0.07912983070662738, 0.07912983070662738, 0.10890157698744929, 0.10890157698744929, 0.10890157698744929, 0.07790850416404904, 0.07790850416404904, 0.07790850416404904, 0.17793838342635426, 0.17793838342635426, 0.17793838342635426, 0.21146187415422624, 0.21146187415422624, 0.21146187415422624, 0.20801603229642884, 0.20801603229642884, 0.20801603229642884, 0.5042570489570127, 0.5042570489570127, 0.5042570489570127, 0.43911133305186345, 0.43911133305186345, 0.43911133305186345, 0.17672942670168834, 0.17672942670168834, 0.17672942670168834, 0.20087677551783245, 0.20087677551783245, 0.20087677551783245, 0.27206400122291374, 0.27206400122291374, 0.27206400122291374, 0.15760741436928694, 0.15760741436928694, 0.15760741436928694, 0.2147211716330205, 0.2147211716330205, 0.2147211716330205, 0.2358635608978069, 0.2358635608978069, 0.2358635608978069, 0.21101825937973473, 0.21101825937973473, 0.21101825937973473, 0.21393156671765268, 0.21393156671765268, 0.21393156671765268, 0.19890931799085132, 0.19890931799085132, 0.19890931799085132, 0.18023087717828856, 0.18023087717828856, 0.18023087717828856, 0.6378141874184067, 0.6378141874184067, 0.6378141874184067, 0.18897147642551293, 0.18897147642551293, 0.18897147642551293, 0.16672924726552685, 0.16672924726552685, 0.16672924726552685, 0.16995128948968852, 0.16995128948968852, 0.16995128948968852, 0.16989663507815544, 0.16989663507815544, 0.16989663507815544, 0.16755371257063834, 0.16755371257063834, 0.16755371257063834, 0.17909819032542162, 0.17909819032542162, 0.17909819032542162, 0.1852133671546029, 0.1852133671546029, 0.1852133671546029, 0.19330726827627032, 0.19330726827627032, 0.19330726827627032, 0.09197430504235948, 0.09197430504235948, 0.09197430504235948, 0.10703734828107936, 0.10703734828107936, 0.10703734828107936, 0.0723025989079269, 0.0723025989079269, 0.0723025989079269]}, "mutation_prompt": null}
{"id": "35e8ef95-ec39-4251-9d62-8caef0306f5e", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.min_bound = -5.0\n        self.max_bound = 5.0\n        self.F = 0.5  # differential evolution scaling factor\n        self.CR = 0.9  # crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.min_bound, self.max_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, self.min_bound, self.max_bound)\n\n            # Evaluate PSO positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n            improved = scores < personal_best_scores\n            personal_best_positions[improved] = positions[improved]\n            personal_best_scores[improved] = scores[improved]\n\n            if np.min(scores) < global_best_score:\n                global_best_position = positions[np.argmin(scores)]\n                global_best_score = np.min(scores)\n\n            # DE Update\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = positions[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.F * (b - c), self.min_bound, self.max_bound)\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant_vector, positions[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial_vector\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A hybrid particle swarm optimization with adaptive differential evolution to balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "08c9ccc3-a4cc-4890-8986-aeaa052de9a4", "metadata": {"aucs": [0.39712887885076875, 0.39712887885076875, 0.39712887885076875, 0.9392608853865323, 0.9392608853865323, 0.9392608853865323, 0.9447148316808145, 0.9447148316808145, 0.9447148316808145, 0.028792382451166332, 0.028792382451166332, 0.028792382451166332, 0.1009351199984907, 0.1009351199984907, 0.1009351199984907, 0.1430506425957383, 0.1430506425957383, 0.1430506425957383, 0.1389080290134791, 0.1389080290134791, 0.1389080290134791, 0.11907872565189537, 0.11907872565189537, 0.11907872565189537, 0.12097957910475166, 0.12097957910475166, 0.12097957910475166, 0.09323925280257861, 0.09323925280257861, 0.09323925280257861, 0.08423166241709568, 0.08423166241709568, 0.08423166241709568, 0.16560897253537077, 0.16560897253537077, 0.16560897253537077, 0.1569292008876091, 0.1569292008876091, 0.1569292008876091, 0.986701382393906, 0.986701382393906, 0.986701382393906, 0.22921073650379675, 0.22921073650379675, 0.22921073650379675, 0.7152190098184298, 0.7152190098184298, 0.7152190098184298, 0.14682330187732462, 0.14682330187732462, 0.14682330187732462, 0.17062499230538597, 0.17062499230538597, 0.17062499230538597, 0.17289888386197438, 0.17289888386197438, 0.17289888386197438, 0.16296510256108454, 0.16296510256108454, 0.16296510256108454, 0.22372347356299893, 0.22372347356299893, 0.22372347356299893, 0.13815739814132755, 0.13815739814132755, 0.13815739814132755, 0.1628571520815424, 0.1628571520815424, 0.1628571520815424, 0.07500309716985376, 0.07500309716985376, 0.07500309716985376, 0.15288070449686908, 0.15288070449686908, 0.15288070449686908, 0.15286606853579465, 0.15286606853579465, 0.15286606853579465, 0.13783602808943574, 0.13783602808943574, 0.13783602808943574, 0.01809705027407016, 0.01809705027407016, 0.01809705027407016, 0.011213555172999268, 0.011213555172999268, 0.011213555172999268, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15188807390674608, 0.15188807390674608, 0.15188807390674608, 0.04513764527761999, 0.04513764527761999, 0.04513764527761999, 0.09587655233290882, 0.09587655233290882, 0.09587655233290882, 0.19701351519139731, 0.19701351519139731, 0.19701351519139731, 0.1467681466263393, 0.1467681466263393, 0.1467681466263393, 0.21879673330699723, 0.21879673330699723, 0.21879673330699723, 0.13266085342380718, 0.13266085342380718, 0.13266085342380718, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5021745159494003, 0.5021745159494003, 0.5021745159494003, 0.26791554812722307, 0.26791554812722307, 0.26791554812722307, 0.4034031679207458, 0.4034031679207458, 0.4034031679207458, 0.07912983070662738, 0.07912983070662738, 0.07912983070662738, 0.10890157698744929, 0.10890157698744929, 0.10890157698744929, 0.07790850416404904, 0.07790850416404904, 0.07790850416404904, 0.17793838342635426, 0.17793838342635426, 0.17793838342635426, 0.21146187415422624, 0.21146187415422624, 0.21146187415422624, 0.20801603229642884, 0.20801603229642884, 0.20801603229642884, 0.5042570489570127, 0.5042570489570127, 0.5042570489570127, 0.43911133305186345, 0.43911133305186345, 0.43911133305186345, 0.17672942670168834, 0.17672942670168834, 0.17672942670168834, 0.20087677551783245, 0.20087677551783245, 0.20087677551783245, 0.27206400122291374, 0.27206400122291374, 0.27206400122291374, 0.15760741436928694, 0.15760741436928694, 0.15760741436928694, 0.2147211716330205, 0.2147211716330205, 0.2147211716330205, 0.2358635608978069, 0.2358635608978069, 0.2358635608978069, 0.21101825937973473, 0.21101825937973473, 0.21101825937973473, 0.21393156671765268, 0.21393156671765268, 0.21393156671765268, 0.19890931799085132, 0.19890931799085132, 0.19890931799085132, 0.18023087717828856, 0.18023087717828856, 0.18023087717828856, 0.6378141874184067, 0.6378141874184067, 0.6378141874184067, 0.18897147642551293, 0.18897147642551293, 0.18897147642551293, 0.16672924726552685, 0.16672924726552685, 0.16672924726552685, 0.16995128948968852, 0.16995128948968852, 0.16995128948968852, 0.16989663507815544, 0.16989663507815544, 0.16989663507815544, 0.16755371257063834, 0.16755371257063834, 0.16755371257063834, 0.17909819032542162, 0.17909819032542162, 0.17909819032542162, 0.1852133671546029, 0.1852133671546029, 0.1852133671546029, 0.19330726827627032, 0.19330726827627032, 0.19330726827627032, 0.09197430504235948, 0.09197430504235948, 0.09197430504235948, 0.10703734828107936, 0.10703734828107936, 0.10703734828107936, 0.0723025989079269, 0.0723025989079269, 0.0723025989079269]}, "mutation_prompt": null}
{"id": "a8ed9ab0-9497-41a0-a7d8-c64a152fbbca", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.min_bound = -5.0\n        self.max_bound = 5.0\n        self.F = 0.5  # differential evolution scaling factor\n        self.CR = 0.9  # crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.min_bound, self.max_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, self.min_bound, self.max_bound)\n\n            # Evaluate PSO positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n            improved = scores < personal_best_scores\n            personal_best_positions[improved] = positions[improved]\n            personal_best_scores[improved] = scores[improved]\n\n            if np.min(scores) < global_best_score:\n                global_best_position = positions[np.argmin(scores)]\n                global_best_score = np.min(scores)\n\n            # DE Update\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = positions[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.F * (b - c), self.min_bound, self.max_bound)\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant_vector, positions[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial_vector\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A hybrid particle swarm optimization with adaptive differential evolution to balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "08c9ccc3-a4cc-4890-8986-aeaa052de9a4", "metadata": {"aucs": [0.39712887885076875, 0.39712887885076875, 0.39712887885076875, 0.9392608853865323, 0.9392608853865323, 0.9392608853865323, 0.9447148316808145, 0.9447148316808145, 0.9447148316808145, 0.028792382451166332, 0.028792382451166332, 0.028792382451166332, 0.1009351199984907, 0.1009351199984907, 0.1009351199984907, 0.1430506425957383, 0.1430506425957383, 0.1430506425957383, 0.1389080290134791, 0.1389080290134791, 0.1389080290134791, 0.11907872565189537, 0.11907872565189537, 0.11907872565189537, 0.12097957910475166, 0.12097957910475166, 0.12097957910475166, 0.09323925280257861, 0.09323925280257861, 0.09323925280257861, 0.08423166241709568, 0.08423166241709568, 0.08423166241709568, 0.16560897253537077, 0.16560897253537077, 0.16560897253537077, 0.1569292008876091, 0.1569292008876091, 0.1569292008876091, 0.986701382393906, 0.986701382393906, 0.986701382393906, 0.22921073650379675, 0.22921073650379675, 0.22921073650379675, 0.7152190098184298, 0.7152190098184298, 0.7152190098184298, 0.14682330187732462, 0.14682330187732462, 0.14682330187732462, 0.17062499230538597, 0.17062499230538597, 0.17062499230538597, 0.17289888386197438, 0.17289888386197438, 0.17289888386197438, 0.16296510256108454, 0.16296510256108454, 0.16296510256108454, 0.22372347356299893, 0.22372347356299893, 0.22372347356299893, 0.13815739814132755, 0.13815739814132755, 0.13815739814132755, 0.1628571520815424, 0.1628571520815424, 0.1628571520815424, 0.07500309716985376, 0.07500309716985376, 0.07500309716985376, 0.15288070449686908, 0.15288070449686908, 0.15288070449686908, 0.15286606853579465, 0.15286606853579465, 0.15286606853579465, 0.13783602808943574, 0.13783602808943574, 0.13783602808943574, 0.01809705027407016, 0.01809705027407016, 0.01809705027407016, 0.011213555172999268, 0.011213555172999268, 0.011213555172999268, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15188807390674608, 0.15188807390674608, 0.15188807390674608, 0.04513764527761999, 0.04513764527761999, 0.04513764527761999, 0.09587655233290882, 0.09587655233290882, 0.09587655233290882, 0.19701351519139731, 0.19701351519139731, 0.19701351519139731, 0.1467681466263393, 0.1467681466263393, 0.1467681466263393, 0.21879673330699723, 0.21879673330699723, 0.21879673330699723, 0.13266085342380718, 0.13266085342380718, 0.13266085342380718, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5021745159494003, 0.5021745159494003, 0.5021745159494003, 0.26791554812722307, 0.26791554812722307, 0.26791554812722307, 0.4034031679207458, 0.4034031679207458, 0.4034031679207458, 0.07912983070662738, 0.07912983070662738, 0.07912983070662738, 0.10890157698744929, 0.10890157698744929, 0.10890157698744929, 0.07790850416404904, 0.07790850416404904, 0.07790850416404904, 0.17793838342635426, 0.17793838342635426, 0.17793838342635426, 0.21146187415422624, 0.21146187415422624, 0.21146187415422624, 0.20801603229642884, 0.20801603229642884, 0.20801603229642884, 0.5042570489570127, 0.5042570489570127, 0.5042570489570127, 0.43911133305186345, 0.43911133305186345, 0.43911133305186345, 0.17672942670168834, 0.17672942670168834, 0.17672942670168834, 0.20087677551783245, 0.20087677551783245, 0.20087677551783245, 0.27206400122291374, 0.27206400122291374, 0.27206400122291374, 0.15760741436928694, 0.15760741436928694, 0.15760741436928694, 0.2147211716330205, 0.2147211716330205, 0.2147211716330205, 0.2358635608978069, 0.2358635608978069, 0.2358635608978069, 0.21101825937973473, 0.21101825937973473, 0.21101825937973473, 0.21393156671765268, 0.21393156671765268, 0.21393156671765268, 0.19890931799085132, 0.19890931799085132, 0.19890931799085132, 0.18023087717828856, 0.18023087717828856, 0.18023087717828856, 0.6378141874184067, 0.6378141874184067, 0.6378141874184067, 0.18897147642551293, 0.18897147642551293, 0.18897147642551293, 0.16672924726552685, 0.16672924726552685, 0.16672924726552685, 0.16995128948968852, 0.16995128948968852, 0.16995128948968852, 0.16989663507815544, 0.16989663507815544, 0.16989663507815544, 0.16755371257063834, 0.16755371257063834, 0.16755371257063834, 0.17909819032542162, 0.17909819032542162, 0.17909819032542162, 0.1852133671546029, 0.1852133671546029, 0.1852133671546029, 0.19330726827627032, 0.19330726827627032, 0.19330726827627032, 0.09197430504235948, 0.09197430504235948, 0.09197430504235948, 0.10703734828107936, 0.10703734828107936, 0.10703734828107936, 0.0723025989079269, 0.0723025989079269, 0.0723025989079269]}, "mutation_prompt": null}
{"id": "7e180372-ff68-406f-83c0-7440d256a236", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.min_bound = -5.0\n        self.max_bound = 5.0\n        self.F = 0.5  # differential evolution scaling factor\n        self.CR = 0.9  # crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.min_bound, self.max_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(2)\n            velocities = (self.w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, self.min_bound, self.max_bound)\n\n            # Evaluate PSO positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n            improved = scores < personal_best_scores\n            personal_best_positions[improved] = positions[improved]\n            personal_best_scores[improved] = scores[improved]\n\n            if np.min(scores) < global_best_score:\n                global_best_position = positions[np.argmin(scores)]\n                global_best_score = np.min(scores)\n\n            # DE Update\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = positions[np.random.choice(indices, 3, replace=False)]\n                mutant_vector = np.clip(a + self.F * (b - c), self.min_bound, self.max_bound)\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant_vector, positions[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial_vector\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "A hybrid particle swarm optimization with adaptive differential evolution to balance exploration and exploitation.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "No code was extracted. The code should be encapsulated with ``` in your response.", "error": "The code should be encapsulated with ``` in your response.", "parent_id": "08c9ccc3-a4cc-4890-8986-aeaa052de9a4", "metadata": {"aucs": [0.39712887885076875, 0.39712887885076875, 0.39712887885076875, 0.9392608853865323, 0.9392608853865323, 0.9392608853865323, 0.9447148316808145, 0.9447148316808145, 0.9447148316808145, 0.028792382451166332, 0.028792382451166332, 0.028792382451166332, 0.1009351199984907, 0.1009351199984907, 0.1009351199984907, 0.1430506425957383, 0.1430506425957383, 0.1430506425957383, 0.1389080290134791, 0.1389080290134791, 0.1389080290134791, 0.11907872565189537, 0.11907872565189537, 0.11907872565189537, 0.12097957910475166, 0.12097957910475166, 0.12097957910475166, 0.09323925280257861, 0.09323925280257861, 0.09323925280257861, 0.08423166241709568, 0.08423166241709568, 0.08423166241709568, 0.16560897253537077, 0.16560897253537077, 0.16560897253537077, 0.1569292008876091, 0.1569292008876091, 0.1569292008876091, 0.986701382393906, 0.986701382393906, 0.986701382393906, 0.22921073650379675, 0.22921073650379675, 0.22921073650379675, 0.7152190098184298, 0.7152190098184298, 0.7152190098184298, 0.14682330187732462, 0.14682330187732462, 0.14682330187732462, 0.17062499230538597, 0.17062499230538597, 0.17062499230538597, 0.17289888386197438, 0.17289888386197438, 0.17289888386197438, 0.16296510256108454, 0.16296510256108454, 0.16296510256108454, 0.22372347356299893, 0.22372347356299893, 0.22372347356299893, 0.13815739814132755, 0.13815739814132755, 0.13815739814132755, 0.1628571520815424, 0.1628571520815424, 0.1628571520815424, 0.07500309716985376, 0.07500309716985376, 0.07500309716985376, 0.15288070449686908, 0.15288070449686908, 0.15288070449686908, 0.15286606853579465, 0.15286606853579465, 0.15286606853579465, 0.13783602808943574, 0.13783602808943574, 0.13783602808943574, 0.01809705027407016, 0.01809705027407016, 0.01809705027407016, 0.011213555172999268, 0.011213555172999268, 0.011213555172999268, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15188807390674608, 0.15188807390674608, 0.15188807390674608, 0.04513764527761999, 0.04513764527761999, 0.04513764527761999, 0.09587655233290882, 0.09587655233290882, 0.09587655233290882, 0.19701351519139731, 0.19701351519139731, 0.19701351519139731, 0.1467681466263393, 0.1467681466263393, 0.1467681466263393, 0.21879673330699723, 0.21879673330699723, 0.21879673330699723, 0.13266085342380718, 0.13266085342380718, 0.13266085342380718, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.5021745159494003, 0.5021745159494003, 0.5021745159494003, 0.26791554812722307, 0.26791554812722307, 0.26791554812722307, 0.4034031679207458, 0.4034031679207458, 0.4034031679207458, 0.07912983070662738, 0.07912983070662738, 0.07912983070662738, 0.10890157698744929, 0.10890157698744929, 0.10890157698744929, 0.07790850416404904, 0.07790850416404904, 0.07790850416404904, 0.17793838342635426, 0.17793838342635426, 0.17793838342635426, 0.21146187415422624, 0.21146187415422624, 0.21146187415422624, 0.20801603229642884, 0.20801603229642884, 0.20801603229642884, 0.5042570489570127, 0.5042570489570127, 0.5042570489570127, 0.43911133305186345, 0.43911133305186345, 0.43911133305186345, 0.17672942670168834, 0.17672942670168834, 0.17672942670168834, 0.20087677551783245, 0.20087677551783245, 0.20087677551783245, 0.27206400122291374, 0.27206400122291374, 0.27206400122291374, 0.15760741436928694, 0.15760741436928694, 0.15760741436928694, 0.2147211716330205, 0.2147211716330205, 0.2147211716330205, 0.2358635608978069, 0.2358635608978069, 0.2358635608978069, 0.21101825937973473, 0.21101825937973473, 0.21101825937973473, 0.21393156671765268, 0.21393156671765268, 0.21393156671765268, 0.19890931799085132, 0.19890931799085132, 0.19890931799085132, 0.18023087717828856, 0.18023087717828856, 0.18023087717828856, 0.6378141874184067, 0.6378141874184067, 0.6378141874184067, 0.18897147642551293, 0.18897147642551293, 0.18897147642551293, 0.16672924726552685, 0.16672924726552685, 0.16672924726552685, 0.16995128948968852, 0.16995128948968852, 0.16995128948968852, 0.16989663507815544, 0.16989663507815544, 0.16989663507815544, 0.16755371257063834, 0.16755371257063834, 0.16755371257063834, 0.17909819032542162, 0.17909819032542162, 0.17909819032542162, 0.1852133671546029, 0.1852133671546029, 0.1852133671546029, 0.19330726827627032, 0.19330726827627032, 0.19330726827627032, 0.09197430504235948, 0.09197430504235948, 0.09197430504235948, 0.10703734828107936, 0.10703734828107936, 0.10703734828107936, 0.0723025989079269, 0.0723025989079269, 0.0723025989079269]}, "mutation_prompt": null}
{"id": "ec0a644b-840c-4702-aeec-f5e09aa0e334", "solution": "import numpy as np\n\nclass HybridPSODE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.population_size = 10 + 2 * int(np.sqrt(dim))\n        self.min_bound = -5.0\n        self.max_bound = 5.0\n        self.F = 0.5  # DE scaling factor\n        self.CR = 0.9  # crossover probability\n        self.w = 0.5  # inertia weight for PSO\n        self.c1 = 1.5  # cognitive component\n        self.c2 = 1.5  # social component\n\n    def __call__(self, func):\n        np.random.seed(42)\n        positions = np.random.uniform(self.min_bound, self.max_bound, (self.population_size, self.dim))\n        velocities = np.random.uniform(-1, 1, (self.population_size, self.dim))\n        personal_best_positions = np.copy(positions)\n        personal_best_scores = np.array([func(x) for x in positions])\n        global_best_position = personal_best_positions[np.argmin(personal_best_scores)]\n        global_best_score = np.min(personal_best_scores)\n\n        evaluations = self.population_size\n\n        while evaluations < self.budget:\n            # PSO Update\n            r1, r2 = np.random.rand(2)\n            adaptive_w = 0.4 + 0.5 * np.random.random()  # Adaptive inertia weight\n            velocities = (adaptive_w * velocities +\n                          self.c1 * r1 * (personal_best_positions - positions) +\n                          self.c2 * r2 * (global_best_position - positions))\n            positions += velocities\n            positions = np.clip(positions, self.min_bound, self.max_bound)\n\n            # Evaluate PSO positions\n            scores = np.array([func(x) for x in positions])\n            evaluations += self.population_size\n            improved = scores < personal_best_scores\n            personal_best_positions[improved] = positions[improved]\n            personal_best_scores[improved] = scores[improved]\n\n            if np.min(scores) < global_best_score:\n                global_best_position = positions[np.argmin(scores)]\n                global_best_score = np.min(scores)\n\n            # DE Update\n            for i in range(self.population_size):\n                indices = [idx for idx in range(self.population_size) if idx != i]\n                a, b, c = positions[np.random.choice(indices, 3, replace=False)]\n                F_dynamic = 0.4 + 0.6 * np.random.random()  # Dynamic scaling factor\n                mutant_vector = np.clip(a + F_dynamic * (b - c), self.min_bound, self.max_bound)\n                crossover_mask = np.random.rand(self.dim) < self.CR\n                trial_vector = np.where(crossover_mask, mutant_vector, positions[i])\n                trial_score = func(trial_vector)\n                evaluations += 1\n                if trial_score < scores[i]:\n                    positions[i] = trial_vector\n                    scores[i] = trial_score\n                    if trial_score < personal_best_scores[i]:\n                        personal_best_scores[i] = trial_score\n                        personal_best_positions[i] = trial_vector\n\n                if trial_score < global_best_score:\n                    global_best_position = trial_vector\n                    global_best_score = trial_score\n\n        return global_best_position, global_best_score", "name": "HybridPSODE", "description": "Enhanced HybridPSODE with adaptive velocity update and dynamic DE parameters for improved convergence.", "configspace": "", "generation": 4, "fitness": 0.27123507962272364, "feedback": "The algorithm HybridPSODE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.27 with standard deviation 0.26.", "error": "", "parent_id": "08c9ccc3-a4cc-4890-8986-aeaa052de9a4", "metadata": {"aucs": [0.7088466979050652, 0.7088466979050652, 0.7088466979050652, 0.7716727160864145, 0.7716727160864145, 0.7716727160864145, 0.8213962208037371, 0.8213962208037371, 0.8213962208037371, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.6348197936407443, 0.6348197936407443, 0.6348197936407443, 0.12270222500039851, 0.12270222500039851, 0.12270222500039851, 0.07949645523138826, 0.07949645523138826, 0.07949645523138826, 0.10111488994089146, 0.10111488994089146, 0.10111488994089146, 0.07927669639120027, 0.07927669639120027, 0.07927669639120027, 0.10209560097569625, 0.10209560097569625, 0.10209560097569625, 0.12066696510367869, 0.12066696510367869, 0.12066696510367869, 0.9859933936969779, 0.9859933936969779, 0.9859933936969779, 0.9834751201755124, 0.9834751201755124, 0.9834751201755124, 0.9838229492094559, 0.9838229492094559, 0.9838229492094559, 0.36561922421440995, 0.36561922421440995, 0.36561922421440995, 0.1503216489647673, 0.1503216489647673, 0.1503216489647673, 0.08768398466611216, 0.08768398466611216, 0.08768398466611216, 0.6388896938941981, 0.6388896938941981, 0.6388896938941981, 0.15948924770312622, 0.15948924770312622, 0.15948924770312622, 0.48756144601694373, 0.48756144601694373, 0.48756144601694373, 0.676498464355017, 0.676498464355017, 0.676498464355017, 0.22759826432707353, 0.22759826432707353, 0.22759826432707353, 0.6648168716970604, 0.6648168716970604, 0.6648168716970604, 0.204123106455244, 0.204123106455244, 0.204123106455244, 0.2070434391944973, 0.2070434391944973, 0.2070434391944973, 0.2775609032294789, 0.2775609032294789, 0.2775609032294789, 0.09167890728542116, 0.09167890728542116, 0.09167890728542116, 0.05727756355920899, 0.05727756355920899, 0.05727756355920899, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07012027754343686, 0.07012027754343686, 0.07012027754343686, 0.11644049183148275, 0.11644049183148275, 0.11644049183148275, 0.050226082387908044, 0.050226082387908044, 0.050226082387908044, 0.045136234169967815, 0.045136234169967815, 0.045136234169967815, 0.05690449649142082, 0.05690449649142082, 0.05690449649142082, 0.16026343511425034, 0.16026343511425034, 0.16026343511425034, 0.5056937670746404, 0.5056937670746404, 0.5056937670746404, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08279555155990004, 0.08279555155990004, 0.08279555155990004, 0.7218087447909175, 0.7218087447909175, 0.7218087447909175, 0.5817152958214491, 0.5817152958214491, 0.5817152958214491, 0.5346599182173627, 0.5346599182173627, 0.5346599182173627, 0.08332084708293441, 0.08332084708293441, 0.08332084708293441, 0.09818319640677287, 0.09818319640677287, 0.09818319640677287, 0.04627954276951329, 0.04627954276951329, 0.04627954276951329, 0.1395144346209719, 0.1395144346209719, 0.1395144346209719, 0.1939320396500409, 0.1939320396500409, 0.1939320396500409, 0.16314250970452993, 0.16314250970452993, 0.16314250970452993, 0.31552415479709595, 0.31552415479709595, 0.31552415479709595, 0.1926486934451992, 0.1926486934451992, 0.1926486934451992, 0.3219636258796019, 0.3219636258796019, 0.3219636258796019, 0.2645471228592482, 0.2645471228592482, 0.2645471228592482, 0.18722067900195238, 0.18722067900195238, 0.18722067900195238, 0.1151690352168574, 0.1151690352168574, 0.1151690352168574, 0.1908090063911605, 0.1908090063911605, 0.1908090063911605, 0.1835402619990455, 0.1835402619990455, 0.1835402619990455, 0.18954077288289628, 0.18954077288289628, 0.18954077288289628, 0.20599268301303075, 0.20599268301303075, 0.20599268301303075, 0.20929892108136616, 0.20929892108136616, 0.20929892108136616, 0.19548689052505674, 0.19548689052505674, 0.19548689052505674, 0.7812829783522514, 0.7812829783522514, 0.7812829783522514, 0.15239071209406996, 0.15239071209406996, 0.15239071209406996, 0.1767420808913508, 0.1767420808913508, 0.1767420808913508, 0.2118724791884964, 0.2118724791884964, 0.2118724791884964, 0.21010164965515665, 0.21010164965515665, 0.21010164965515665, 0.1860744612992311, 0.1860744612992311, 0.1860744612992311, 0.1794444355486463, 0.1794444355486463, 0.1794444355486463, 0.18200923180998152, 0.18200923180998152, 0.18200923180998152, 0.19079232748695485, 0.19079232748695485, 0.19079232748695485, 0.08097511055638384, 0.08097511055638384, 0.08097511055638384, 0.09022965301771602, 0.09022965301771602, 0.09022965301771602, 0.07318941088213193, 0.07318941088213193, 0.07318941088213193]}, "mutation_prompt": null}

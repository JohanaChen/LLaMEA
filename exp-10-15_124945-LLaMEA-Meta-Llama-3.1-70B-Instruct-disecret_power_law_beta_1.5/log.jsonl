{"id": "cfac9a65-9054-4f30-8d59-2874c2169068", "solution": "import numpy as np\n\nclass HybridSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] += 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n            # Modified simulated annealing\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizer(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizer", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer\" (HSO), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm.", "configspace": "", "generation": 0, "fitness": 0.17330235347516407, "feedback": "The algorithm HybridSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": null, "metadata": {"aucs": [0.2862431840291877, 0.31857076645060034, 0.3161363886826052, 0.31117948102579385, 0.3006050084356936, 0.3027054926928854, 0.3191970598358618, 0.2996052943577173, 0.31470126892903827, 9.999999999998899e-05, 0.0006696223862602269, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0803500966418289, 0.07939539445476163, 0.09434540676908942, 0.0823858613145354, 0.07925655672415488, 0.08056213683851365, 0.10567546099603564, 0.09017193728926887, 0.09547166845217359, 0.06101848510808017, 0.07269642891720829, 0.0751836645496784, 0.07673256741396872, 0.06922143922738944, 0.06860109975264062, 0.07499929962828067, 0.06550181992065085, 0.06947901606178586, 0.9009049927467812, 0.9292352672100812, 0.8911507200511113, 0.8746525675270668, 0.888883210663366, 0.8731138511760403, 0.9293431951027967, 0.926034303623854, 0.9246957932613258, 0.18835040145353765, 0.18896639927994852, 0.22636260574583644, 0.18976791282168792, 0.1941137115862871, 0.1911034322236863, 0.1880135749173415, 0.20204831777056365, 0.195015778555779, 0.21290745726621185, 0.2217515578121123, 0.21568376299391545, 0.2188247287576255, 0.25532414370007495, 0.18884912783720276, 0.22877994399658752, 0.21167018723418507, 0.23326170161247317, 0.09139054204023922, 0.05186407029348261, 0.08952370607846061, 0.06975594865494461, 0.1119661526662118, 0.10728689844106176, 0.10164338755394697, 0.10175846246984133, 0.1066540655800523, 0.1073348475136996, 0.0703266777835383, 0.10726784669443312, 0.12021124079540335, 0.1039002029314895, 0.11351504230284393, 0.10991922623451011, 0.11597712623825396, 0.0674592356713174, 0.0015108101440121091, 9.999999999998899e-05, 9.999999999998899e-05, 0.02181722711102252, 0.0002349413802162914, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10755900570676968, 0.05711124968869552, 0.10274170669085125, 0.0792828353687306, 0.055753413986717515, 0.02124661647304671, 0.1454192951635943, 0.0963600905182197, 0.07511980877531332, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05179795156089406, 0.039600354090042256, 0.0426421863389258, 0.06667134933460461, 0.044059943603071194, 0.06036366786377201, 0.05097536176689588, 0.03418563597985891, 0.03755128339809066, 0.30246565015610527, 0.30868442234015137, 0.30878871619717607, 0.2898077433532119, 0.3586985374861974, 0.3061484191022533, 0.29995418738819035, 0.31369924820000483, 0.3009076530846946, 0.06705035454855002, 0.09589361068323288, 0.08515879905647339, 0.08234890001822825, 0.09173438125394118, 0.10705471886090001, 0.09263337502196523, 0.07661365788445584, 0.11343419935188614, 0.1277248752284741, 0.20304178548565255, 0.14179759878442855, 0.17825311332820404, 0.17099560477116593, 0.18348167681223637, 0.12234166275818004, 0.13613618858179577, 0.15194692370135165, 0.22922636875634916, 0.21357252172012353, 0.23343197985740993, 0.2173398607917667, 0.23112525174299037, 0.22341513029694626, 0.22567262551292355, 0.22467800905060364, 0.22241310531528957, 0.16811116796467485, 0.17959586444544562, 0.1842635456507412, 0.1700548345654357, 0.17712842355615432, 0.17065647827075048, 0.16261528324344876, 0.1811374132651289, 0.14171988115099343, 0.20226484175337922, 0.21120731900744294, 0.197105656916436, 0.2094155396814371, 0.20950818510426739, 0.20600091538746035, 0.2102294582952956, 0.19900690251310005, 0.2002847799297004, 0.2076039160186237, 0.1804523129872152, 0.18091279167724128, 0.1809214588766317, 0.1819286915735624, 0.17663842229829885, 0.17178027079834535, 0.17590222377237164, 0.17322587985169868, 0.17557061508254046, 0.17831181144439778, 0.18206133184585516, 0.15366385295899088, 0.19171694306031273, 0.16571302839572288, 0.2463447799002566, 0.4010776954696509, 0.3901902630388715, 0.3769416930842926, 0.20330980697730971, 0.09166462860491142, 0.16702631262775414, 0.16652424669039667, 0.16580611373016674, 0.16428756321971083, 0.10194656182321782, 0.4170730759730873, 0.1777006550472352, 0.18005631991747872, 0.17911882146632374, 0.19406455937957967, 0.17711325428257263, 0.18794665246796116, 0.1926035786227478, 0.1855958984838031, 0.19535228367458535, 0.08096960093921357, 0.08681477308665286, 0.08528338842124616, 0.07968323032646818, 0.09237488592131882, 0.08553169930445115, 0.08190985401651374, 0.07512596464233323, 0.08795932296846698]}, "mutation_prompt": null}
{"id": "bed50f5c-e4fb-47f6-aa14-6382e3f1c649", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACD:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.999\n        self.dynamic_swarm_size = True\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] += 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n            # Modified simulated annealing\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic swarm size adjustment\n            if self.dynamic_swarm_size and evaluations > (self.budget // 2):\n                self.swarm_size = int(np.sqrt(self.budget - evaluations))\n                self.particles = self.particles[:self.swarm_size]\n                self.velocities = self.velocities[:self.swarm_size]\n                self.best_positions = self.best_positions[:self.swarm_size]\n                self.best_fitness = self.best_fitness[:self.swarm_size]\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACD(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACD", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling and Dynamic Swarm Size\" (HSO-ACD), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm and adaptive cooling rate, and dynamically adjusts the swarm size based on the optimization progress.", "configspace": "", "generation": 1, "fitness": -Infinity, "feedback": "An exception occurred: ZeroDivisionError('integer division or modulo by zero').", "error": "ZeroDivisionError('integer division or modulo by zero')", "parent_id": "cfac9a65-9054-4f30-8d59-2874c2169068", "metadata": {}, "mutation_prompt": null}
{"id": "c9d0720d-0738-4b72-8cd6-9b09ddb38e97", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerAC:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] += 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerAC(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerAC", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling\" (HSO-AC), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm and an adaptive cooling schedule.", "configspace": "", "generation": 2, "fitness": 0.1737265569302595, "feedback": "The algorithm HybridSwarmOptimizerAC got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": "cfac9a65-9054-4f30-8d59-2874c2169068", "metadata": {"aucs": [0.3037444899485411, 0.3085094562943026, 0.2823804386305103, 0.31890950474503343, 0.3333054544431945, 0.3044141095687346, 0.2897797223848251, 0.3244749783308638, 0.31706831769935184, 9.999999999998899e-05, 0.0006696223862602269, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0923944223794253, 0.09124338018667766, 0.07922745422906663, 0.08408566568836118, 0.08223701663269856, 0.07656433237777238, 0.08431660634653215, 0.10367315943540056, 0.09276060312554746, 0.061106170799549164, 0.07803714472131684, 0.0804866992886456, 0.08505035607954126, 0.0862941073596648, 0.0895804946271439, 0.0848353450741457, 0.06408385388665139, 0.07355326053161737, 0.9009051850473684, 0.9315893847244843, 0.8928129167705626, 0.8778988677728632, 0.8882348077927966, 0.88044324486559, 0.9293558039981009, 0.926034303623854, 0.9246957932613258, 0.17515835985927375, 0.19680661405135869, 0.17190474051164872, 0.20135978387557285, 0.17740654522687038, 0.2020547635663119, 0.1746867966729646, 0.1888570759820586, 0.1966427024666465, 0.23814862683398463, 0.2640401083304912, 0.21960680437774072, 0.20485598875295907, 0.2562622208617876, 0.1873548845941404, 0.22324667545834675, 0.24260494281091882, 0.25353667138545777, 0.08188449439475476, 0.07123130693202606, 0.09715940297331127, 0.06257355035911438, 0.1023636485212368, 0.10637593912920307, 0.10699130634054399, 0.11404893092747093, 0.11994501777379118, 0.10591666179699588, 0.06661801018162183, 0.09647204250375563, 0.10609246538121153, 0.10358926003108992, 0.10973025373438339, 0.12048438976313225, 0.11730336939043173, 0.0988621846435912, 0.0015108101440121091, 9.999999999998899e-05, 9.999999999998899e-05, 0.02181722711102252, 0.0002349413802162914, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10755900570676968, 0.05711124968869552, 0.10274170669085125, 0.07787751169541024, 0.055753413986717515, 0.02124661647304671, 0.1454192951635943, 0.09461398291180789, 0.07511980877531332, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.051795259501305035, 0.03352706981943121, 0.05158217891042716, 0.045498333053872964, 0.041312272914598935, 0.057021449018089476, 0.03614443621775587, 0.03265966179715707, 0.06415552057785023, 0.31562184790525694, 0.29870204169945214, 0.30368407359003036, 0.29442813862022954, 0.29325217466751274, 0.30170087807621515, 0.32077999653828515, 0.3108965556765294, 0.3088181556573848, 0.07845190430991822, 0.09028606111557258, 0.07921925613371694, 0.07664401761437989, 0.0902168596498748, 0.12086075110571615, 0.10462803965374023, 0.08397706478532085, 0.08589429138489646, 0.14038933902454842, 0.16526836840227244, 0.1252235758243312, 0.15597168916969295, 0.1683563830794561, 0.19161338913253312, 0.16562225854400114, 0.16472651597533094, 0.18979952530075173, 0.22849802455556645, 0.22707939831009027, 0.22840657980873014, 0.2103054179273245, 0.22863967473888147, 0.2253796460424533, 0.22878700168650512, 0.24037822816691556, 0.22455252310918217, 0.16778017785726274, 0.13890619485450784, 0.18351607223672117, 0.1914258683496729, 0.18648996428321407, 0.16013125156673502, 0.15950162888025277, 0.17866935581494947, 0.14979994267037833, 0.21706487655311646, 0.18583463294392155, 0.19629952084593594, 0.2327248732676851, 0.22621946858922126, 0.21450678585955196, 0.2245471540340298, 0.21143532179640578, 0.22961488393180784, 0.2076039160186237, 0.18219319178451365, 0.18134769625231306, 0.18781250442299402, 0.1812174377272041, 0.18760275408790117, 0.17851628582701085, 0.17755249506939597, 0.17312296609455735, 0.17453045131081313, 0.18009892493534296, 0.18065832901443557, 0.1168096824860313, 0.1888072283313128, 0.16486690348732302, 0.13762437567486108, 0.3759400015853117, 0.4440617065272682, 0.36189044028417494, 0.20103196296584802, 0.09166462860491142, 0.16687368341445508, 0.16678355465238526, 0.17079280405734065, 0.16349976643147623, 0.10191788010227087, 0.37255568734070765, 0.2001528148083559, 0.1971573763499589, 0.17686421155669685, 0.17841498823318636, 0.17562741545596905, 0.17280099043570718, 0.18361610177344856, 0.18465285686271748, 0.17834410843807058, 0.08640079701672498, 0.08786016700561827, 0.09112432168627527, 0.08118497152371185, 0.08426533271046921, 0.0912686924772399, 0.08266634015381424, 0.081735840678402, 0.08795932296846698]}, "mutation_prompt": null}
{"id": "2bd9c767-c03e-45af-9636-06addb085209", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] += 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACL(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACL", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling and Levy Flight\" (HSO-ACL), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, and Levy flight for enhanced global search.", "configspace": "", "generation": 3, "fitness": 0.17807278864017764, "feedback": "The algorithm HybridSwarmOptimizerACL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "c9d0720d-0738-4b72-8cd6-9b09ddb38e97", "metadata": {"aucs": [0.32211198214145875, 0.29570310520112286, 0.2961807073029171, 0.31579764915185937, 0.3036014241567565, 0.3065130429770012, 0.3122357387265894, 0.28736742933559223, 0.31091290115799486, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.040858323186554246, 9.999999999998899e-05, 0.0808824056431735, 0.09357111437749666, 0.08560017545166543, 0.08013710776359817, 0.07955284963515186, 0.07681640217761654, 0.10174926219842906, 0.0922242539599436, 0.08411863252934948, 0.07942493174672072, 0.08427959762925652, 0.07658867974209771, 0.08244292509001117, 0.07078223667805827, 0.0629785772107061, 0.08293130026449147, 0.0716968260901143, 0.07539913233858009, 0.8963471109875898, 0.9304907615961833, 0.9025216007492755, 0.8631824176395857, 0.8770871810814598, 0.9121885557218445, 0.9281812848425637, 0.9169606448480375, 0.9235806139327318, 0.17539568833932795, 0.20054549421540924, 0.18836986919122367, 0.1947885841294249, 0.21934099671574037, 0.17766928720799224, 0.19221008221665514, 0.15957449121212341, 0.17343873192770842, 0.2419699916154997, 0.21842016417411425, 0.24525419968318163, 0.2017198736719411, 0.2354396836073871, 0.18633186551771264, 0.22559509876044515, 0.22752525288016967, 0.21966490926535642, 0.10229750299932405, 0.10145557884692957, 0.09762048736834117, 0.06732803834920797, 0.12233319139942689, 0.10644222168422002, 0.09547173760890615, 0.1299345489796946, 0.1127670038427967, 0.11304135592089148, 0.11715141603963752, 0.10182433715049322, 0.09834592703966993, 0.12770407473211076, 0.11458693265930686, 0.10439389874474525, 0.08755277675934048, 0.07988123692490645, 9.999999999998899e-05, 0.004257751166280244, 9.999999999998899e-05, 0.0026076223190629744, 9.999999999998899e-05, 0.0011276209035601115, 0.01127897234284303, 9.999999999998899e-05, 9.999999999998899e-05, 0.09297765622153398, 0.03326581746026569, 0.10402216759167382, 0.07938119963947754, 0.06526464791842668, 0.01841465049370694, 0.10274069699297339, 0.07414432255956416, 0.11488142387957445, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.039074760356926475, 0.0451026237798029, 0.04075540294057933, 0.05039954575679817, 0.04549878295473264, 0.03766817350286711, 0.04216180168472783, 0.043414407786201425, 0.04016361264175905, 0.325995744169322, 0.3092902625558036, 0.29526265419722497, 0.3097180280773857, 0.29482243648101325, 0.3229747913930139, 0.3045677531772709, 0.3190648113274762, 0.3463409159809525, 0.08444997706234503, 0.09021084379089461, 0.0911092744477503, 0.10818824283741346, 0.08918081803196565, 0.07946728909568723, 0.083455493072498, 0.09246690325688378, 0.09890069615139951, 0.17209867152712688, 0.17220949345110492, 0.18354274651430547, 0.14498644987581122, 0.27357466497537897, 0.17421788258271953, 0.18954036008613484, 0.14890451027434315, 0.14263682699927016, 0.22426127083112057, 0.1922821968253362, 0.23525845953643776, 0.22574125087892882, 0.21832279516857456, 0.23154107173133098, 0.24316856375420692, 0.2332429919672424, 0.2265424463521395, 0.17901545010096265, 0.17059638838750835, 0.18198163597761097, 0.1899603673356156, 0.1719560075121206, 0.1710954434217976, 0.16204586961433143, 0.1901159811132619, 0.14886932108002315, 0.2313013729156066, 0.20346611027805095, 0.1766742586819342, 0.2162628319732125, 0.264959555224777, 0.21445858928363415, 0.20469035897168208, 0.20409150629778627, 0.1857340802182742, 0.17226440152616618, 0.1760104769637605, 0.1718828402947301, 0.1789662196226518, 0.18127597274542095, 0.16916150996808832, 0.1733312325756602, 0.1722549544941212, 0.17165401165617167, 0.3587730503833183, 0.17547487908156056, 0.17910734546000406, 0.2177951637170712, 0.19115220539713174, 0.18733104346600749, 0.16754796729454535, 0.3988823627151631, 0.38610726770514225, 0.3489947606344391, 0.19905569872238227, 0.2500685488096315, 0.3691654942783146, 0.31281071108916114, 0.16552207089348325, 0.2653811511849933, 0.10781208921809082, 0.35544368769731394, 0.19344860796899832, 0.18786504739992516, 0.1843338840047437, 0.19541739205845166, 0.18797904930327514, 0.20218388189179637, 0.2015712107226928, 0.18117433772748615, 0.181676605353016, 0.08412117040173361, 0.08171570659031946, 0.08484550620772302, 0.0754162357183088, 0.08087103693707831, 0.09071544767090145, 0.0829226862228144, 0.08582257766544443, 0.0764110504748523]}, "mutation_prompt": null}
{"id": "1a86ba09-19a8-478f-b3c9-f15d0fd48dab", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACL_RDM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.mutation_probability = 0.2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] += 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Randomized dimensional mutation for increased diversity\n                if np.random.rand() < self.mutation_probability:\n                    mutated_dim = np.random.randint(0, self.dim)\n                    self.particles[i, mutated_dim] = np.random.uniform(self.lower_bound, self.upper_bound)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACL_RDM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACL_RDM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Randomized Dimensional Mutation\" (HSO-ACL-RDM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, and randomized dimensional mutation for increased diversity.", "configspace": "", "generation": 4, "fitness": 0.172923870664876, "feedback": "The algorithm HybridSwarmOptimizerACL_RDM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": "2bd9c767-c03e-45af-9636-06addb085209", "metadata": {"aucs": [0.3018008943369773, 0.32614547077696365, 0.28543155575268797, 0.30074478906850577, 0.2903959054174924, 0.30034929063090277, 0.29285351052054787, 0.2796657999498948, 0.27935244876163345, 9.999999999998899e-05, 0.01034711177702663, 9.999999999998899e-05, 9.999999999998899e-05, 0.023228773192790375, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09384309205124575, 0.07998432004006284, 0.0897947380897689, 0.07182041622342461, 0.09542575247642926, 0.08375656071540816, 0.08955924279396654, 0.0930818593663354, 0.09706281438061448, 0.06158420633229722, 0.06810235062955095, 0.09213820449515242, 0.084594670204588, 0.08162427728553234, 0.07971681361607641, 0.06523822497509424, 0.08970316331355188, 0.06755231353330216, 0.8979050844816899, 0.9387144603934852, 0.8890588723386503, 0.9001402890426967, 0.8882656647207062, 0.9128727537673662, 0.9136715689538436, 0.9167054528093932, 0.918564520726135, 0.21089924023799955, 0.1685902959088651, 0.20015996573695682, 0.1778582715973256, 0.18446086703943143, 0.1707419323024102, 0.1604119002758343, 0.16568267175458318, 0.1909690493968127, 0.23806709397623538, 0.2383323414424171, 0.22487908914242793, 0.2576144175961329, 0.23362298510851398, 0.20071030373104404, 0.20418057100235654, 0.20322921435137276, 0.225642741174107, 0.10724313883261438, 0.10398542436900193, 0.09449983418710328, 0.11713982682174862, 0.11005911022294657, 0.10518145496350828, 0.12341544337037325, 0.06361238363593491, 0.11348453447641582, 0.10962017569302718, 0.09777594685929503, 0.1343143712264293, 0.09631032577070842, 0.1049300157269536, 0.11421127138888965, 0.11150400725619802, 0.10451524109727994, 0.11176897660844465, 0.00033060771101522946, 0.012866077615976468, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07618540196696577, 0.04780051338392566, 0.12073564468007247, 0.07823991897963878, 0.09889112839475989, 0.024499026876429908, 0.10513241241045923, 0.05860266313083429, 0.10022717212406895, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04613394784039915, 0.04856184737410951, 0.029226753337167954, 0.016504916339022402, 0.04316511718441829, 0.03762406785954353, 0.0548502953457084, 0.03947370575026321, 0.03694603711275779, 0.3226333022784502, 0.3013205148755246, 0.3224211278589121, 0.277401199861144, 0.2913483819698164, 0.2935770328670092, 0.2911338985883166, 0.2892475932998061, 0.30655994273294485, 0.08571656429602659, 0.10010590101525718, 0.09097735882351665, 0.09268869431464732, 0.09287331907093643, 0.09169103856410488, 0.09128086998039853, 0.10131757043357992, 0.08747236546233306, 0.14944909840331788, 0.15243998433186368, 0.14118548632429995, 0.13948194575098116, 0.17037261331684495, 0.1624994287632242, 0.13341406272597345, 0.14522163948442124, 0.14212281628577206, 0.2288524026415294, 0.22346027970416327, 0.23616061766155694, 0.22479864128818072, 0.22546621041349868, 0.2210960122266793, 0.2253606427945153, 0.23599292422359908, 0.23103072038457506, 0.17441014662976395, 0.15247390923978965, 0.16046802688678397, 0.16884229599688005, 0.17371264571101241, 0.18197167809351045, 0.15073875067343667, 0.17797353089527734, 0.1506416149416533, 0.18321736617137807, 0.20289221182649186, 0.20375327945503263, 0.20032246043845492, 0.2401764665116315, 0.19677337082600277, 0.2396873167387784, 0.21492747829805925, 0.19550651816502373, 0.18370721137783108, 0.18546575575541435, 0.17715279845249787, 0.18540686112569416, 0.1851205639968586, 0.17293993894342385, 0.17708520303370312, 0.22820170124957728, 0.17221664129771452, 0.12570352650180172, 0.17655759683036176, 0.17506526431312464, 0.15268453820934247, 0.19141207426068096, 0.1865776831982241, 0.20118811684729676, 0.1533926383803913, 0.4212266490900254, 0.362219831804253, 0.1969220602712095, 0.34364345842245914, 0.3319108115075119, 0.16830388873012359, 0.1651380736167719, 0.16548643089662962, 0.11083629666568617, 0.38392074437791646, 0.1869513240242492, 0.17163346698943682, 0.1960636403246765, 0.17941828905967538, 0.1817333129639379, 0.1749494684120455, 0.1743296630056157, 0.1954465061117857, 0.17613880628668266, 0.0872128275072811, 0.08009781426977791, 0.0837774855582597, 0.08002361895638099, 0.07075915582907566, 0.08033163472088922, 0.08944851357451677, 0.09178356324563486, 0.07659041545906675]}, "mutation_prompt": null}
{"id": "66e9e58d-ea2a-4f43-9891-a635470281ac", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.cauchy_mutation_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        return position + np.random.standard_cauchy(size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] += 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Cauchy mutation for increased diversity\n                if np.random.rand() < self.cauchy_mutation_rate:\n                    self.particles[i] = self.cauchy_mutation(self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLCM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLCM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Cauchy Mutation\" (HSO-ACL-CM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, and Cauchy mutation for increased diversity.", "configspace": "", "generation": 5, "fitness": 0.1751570846739588, "feedback": "The algorithm HybridSwarmOptimizerACLCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "2bd9c767-c03e-45af-9636-06addb085209", "metadata": {"aucs": [0.34275305234195286, 0.3303769746732932, 0.2823239607414624, 0.31555115649128185, 0.2918299434983863, 0.31746875936248786, 0.29477393578785527, 0.29646610332443213, 0.28873002368275114, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08469021870475713, 0.11444387403424683, 0.06942483874569538, 0.09007664379583491, 0.07918187497791462, 0.08117381016907532, 0.0879321375439347, 0.09229894073561085, 0.0850181236658869, 0.07471600529361933, 0.0759547756121437, 0.08344717888242359, 0.08572830335267478, 0.08303520849690449, 0.0688430344997667, 0.08899716178173966, 0.0785314443752464, 0.08344965295948736, 0.8981847751513976, 0.9390594949541251, 0.9134861263593861, 0.9277161445936376, 0.9181929048458003, 0.9227830665915349, 0.9395179805635896, 0.9284797136242712, 0.9001469317238511, 0.18279911859666487, 0.1927005603806744, 0.16001653194778664, 0.18752137984165929, 0.17145088542257014, 0.18033157246904885, 0.16876049935144988, 0.20726570130208322, 0.1931197927539341, 0.2826324096866579, 0.2499537654944719, 0.21811907733979774, 0.23817881996511292, 0.24918201518467398, 0.18141724491073308, 0.22603635098156138, 0.22964273512565625, 0.21781688094268525, 0.08501522865461808, 0.06399271161634057, 0.10319569881615531, 0.09063870788363637, 0.10712246202805942, 0.09052465342087002, 0.11003796734258142, 0.1058429817022597, 0.10848052114304518, 0.11986245776590532, 0.08233227175503033, 0.11665938645151652, 0.11057985539225124, 0.11794182630524663, 0.12508780256421237, 0.09040842850278497, 0.09671071767166028, 0.07592099353142456, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0023757770683334734, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10022806800344863, 0.06536973307535077, 0.10351410222735791, 0.10324578359160297, 0.06124738675928365, 0.01693386086004245, 0.09579475969109463, 0.11008247379951097, 0.07836944426840764, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0375762842330607, 0.03230616485489224, 0.060634449144717606, 0.06928141954501676, 0.05352029472897246, 0.03970625115332582, 0.03466598712647684, 0.03416564578310355, 0.06624403610553387, 0.307280982975375, 0.2837592176065845, 0.29121147391409474, 0.2830025405959775, 0.31027008466846784, 0.2900281205272165, 0.30898461543530875, 0.3020523648899024, 0.3077595996700909, 0.0948598783693052, 0.08537648315612367, 0.06979584850308185, 0.0799227165836226, 0.08787468486511751, 0.07985121827899422, 0.08496295001166998, 0.0781662535294616, 0.0937204846827675, 0.19467716723810713, 0.16114023512496156, 0.16055114758586386, 0.15175856129734033, 0.14796243297560463, 0.16179164978575022, 0.18230647659665078, 0.16268948687789142, 0.17110949204916903, 0.2297826423832875, 0.2401711532544787, 0.22252842298302689, 0.22403477475461941, 0.2315336842569684, 0.24263962581616383, 0.22542931054372917, 0.21557091555629937, 0.2188026999080146, 0.1696075162676587, 0.15778255771152871, 0.17430972148941437, 0.1952140220320343, 0.17589535767519338, 0.16772316324721503, 0.1501276051985626, 0.17217585802872304, 0.1460043945657693, 0.19578909365129626, 0.215847828915385, 0.18518922700167773, 0.19246366561599937, 0.2151055107490264, 0.17909601417150844, 0.2224063870504106, 0.21215643769414583, 0.20463459281260066, 0.16586455728578053, 0.17322849321858336, 0.18511942672791737, 0.1795587249297016, 0.18696580685359954, 0.17517027793903994, 0.1847120494630472, 0.1722515263293819, 0.17670415774878534, 0.1808371011998331, 0.16459121134931343, 0.17854651876348637, 0.13688520807060245, 0.19102255345277053, 0.18646179174134336, 0.3682772168328492, 0.3792165797090682, 0.382499577519276, 0.4293466520251634, 0.16727570253510715, 0.2490223415116659, 0.29414343089352724, 0.1646780469401008, 0.16564712438518858, 0.16455154051321697, 0.1943671592525742, 0.2966445088322832, 0.1759821777870798, 0.20102450745182843, 0.17298511383165172, 0.19171009187124355, 0.19117369292028774, 0.18000094157885071, 0.18586881313596382, 0.18665444342350612, 0.17806110781738083, 0.0843690645599865, 0.0751960010673518, 0.07172400837112258, 0.06954551752860538, 0.07652219995362053, 0.08069080386057303, 0.08747137262458216, 0.07633042063438877, 0.08019616180182243]}, "mutation_prompt": null}
{"id": "bc4d2be0-dee6-4e6b-8bdf-54a67f054477", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACL_CM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.chaotic_map = lambda x: 4 * x * (1 - x)\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def chaotic_mutation(self, x):\n        chaotic_value = self.chaotic_map(np.random.uniform())\n        return x + (self.upper_bound - self.lower_bound) * (chaotic_value - 0.5)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] += 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Chaotic mutation for increased diversity\n                if np.random.rand() < 0.1:\n                    self.particles[i] = self.chaotic_mutation(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACL_CM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACL_CM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Chaotic Mutation\" (HSO-ACL-CM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, and chaotic mutation for increased diversity.", "configspace": "", "generation": 6, "fitness": 0.17450259830346596, "feedback": "The algorithm HybridSwarmOptimizerACL_CM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": "2bd9c767-c03e-45af-9636-06addb085209", "metadata": {"aucs": [0.30079965228782557, 0.3327572692526263, 0.304997853070734, 0.31266651787076716, 0.3119839801876165, 0.30476498580699796, 0.28878562606389546, 0.32673483008330184, 0.29479216002822484, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08313299506302718, 0.06693733871898744, 0.09276540266408406, 0.08874086328786612, 0.08836990882685392, 0.07861044065543632, 0.08630516786927489, 0.08915661853833368, 0.10018918176100056, 0.06321193592330365, 0.09073962710482897, 0.06779503984190705, 0.07293247183547791, 0.07599202550457862, 0.07631574965854815, 0.0681425519262524, 0.07173780127831142, 0.06948800843032954, 0.8987175977968456, 0.9379346599998323, 0.9016034252052392, 0.8538261970129155, 0.8791168921655718, 0.9111543859118505, 0.940072636691243, 0.9275925542076131, 0.9228547904760722, 0.18092789556752675, 0.2117175437459905, 0.1980876631119235, 0.19335623694768433, 0.18932366765004705, 0.1948460733899371, 0.1771916928550138, 0.16435425678443738, 0.17255788416608797, 0.2869182706160698, 0.24828915783069394, 0.26807897831457017, 0.20868394849137062, 0.22982628112296666, 0.196879525501218, 0.2434648348077052, 0.1997778720989717, 0.23093874128111758, 0.11723610232483384, 0.10428546682915352, 0.09618645546539173, 0.04916147849212216, 0.12464773719055577, 0.0942722705094029, 0.10264643169422927, 0.11577951012148824, 0.10895030815547524, 0.10433073541163163, 0.09622121466255906, 0.09855769356064681, 0.11151835068061211, 0.11078591216175049, 0.10915291146063699, 0.13824965118417598, 0.11124228776024048, 0.09803374990646385, 9.999999999998899e-05, 0.010917237393776258, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10267616891600573, 0.08238952821242362, 0.08766833595369494, 0.12161846213423377, 0.08493341822372602, 0.06581670175841103, 0.07346233496671117, 0.02131125266257805, 0.06460728907202262, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.042929440738726954, 0.05105763947238395, 0.0592417375850115, 0.04098730257888905, 0.041478732767297855, 0.02674784401991348, 0.048983709849605095, 0.040258774880664205, 0.04129470212532538, 0.3420419220457821, 0.3003722722011777, 0.30361275867779935, 0.3078833505294315, 0.2878896943523669, 0.29534826736621145, 0.2948838459155231, 0.33380931246745527, 0.3512189358079668, 0.0718210734114395, 0.08161095005934804, 0.08576517366116587, 0.07645343514729408, 0.09397183697808975, 0.10449956164247454, 0.08101398209099175, 0.08460497852921633, 0.09070239142162029, 0.1466292364445939, 0.15038380318272115, 0.17003334974110584, 0.18060191122089742, 0.17723350419386863, 0.14548886059322963, 0.15540914023659858, 0.14845903345598144, 0.14760857340270817, 0.22344730432565163, 0.22082207529089715, 0.24595259425547134, 0.22432994771542702, 0.23058795357602535, 0.2542070169776254, 0.22704349721812178, 0.25646364407481226, 0.22008100558425225, 0.16982270043661918, 0.13670087939435194, 0.17665851576565983, 0.16705428594176663, 0.1741607411667625, 0.1934013265292046, 0.16763754074067816, 0.17841825861182026, 0.15291179536357735, 0.2062164848763005, 0.20359028319028294, 0.20441533320336824, 0.2371417012997652, 0.2046093384208737, 0.18315235955923126, 0.2179544413675153, 0.20440683075178634, 0.2059922001168052, 0.17461527547079603, 0.16678448479803354, 0.17408115324353035, 0.18924262996294616, 0.1871420823757567, 0.18084614133759946, 0.17992474441278394, 0.18429274207802193, 0.17195953704584843, 0.16991908995841254, 0.1813119450712537, 0.17532582968143817, 0.1311838510734218, 0.19116790857887678, 0.1658240003524013, 0.3560428728381606, 0.16008535364714283, 0.3814468969611835, 0.34652506184670295, 0.16726224692613045, 0.31339735277987024, 0.20092246577610362, 0.16530770693422459, 0.16634175934454254, 0.16393263368770128, 0.1512551641134916, 0.38266203196271664, 0.19396937291324012, 0.20136628478971808, 0.19276658242131584, 0.19690657103573528, 0.18827204559895683, 0.18268254228711478, 0.18703603658226808, 0.1822100511757725, 0.17629858058024206, 0.08003471347032376, 0.08991277220050764, 0.07757400454195051, 0.0762598999548536, 0.08876042546211516, 0.08916466156780012, 0.07694654586490757, 0.07779697479758885, 0.08009044733974846]}, "mutation_prompt": null}
{"id": "4bb8c8d8-20d1-49db-9754-180d55847d11", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBL:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] += 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBL(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBL", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning\" (HSO-ACL-OBL), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, and opposition-based learning for improved convergence.", "configspace": "", "generation": 7, "fitness": 0.18328585675998676, "feedback": "The algorithm HybridSwarmOptimizerACLOBL got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.19.", "error": "", "parent_id": "2bd9c767-c03e-45af-9636-06addb085209", "metadata": {"aucs": [0.32544686106256837, 0.3315461379421989, 0.30375616480062584, 0.32221072687427943, 0.30504618965038344, 0.35291077807097004, 0.2906195842392384, 0.2970139820738076, 0.302200497684353, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09605367607534243, 0.08896409374859782, 0.08145404074976725, 0.09340638400100576, 0.07435253088668647, 0.10277343401664729, 0.09528953883235114, 0.10839742922589812, 0.09723631905205932, 0.06955883929566675, 0.08814088381573093, 0.10545697108766139, 0.07611945786714402, 0.07016435004799937, 0.06703823098346873, 0.08479263088877376, 0.07282175300824656, 0.09375647310524127, 0.9251115194512758, 0.9525442436700687, 0.9389353825733113, 0.8999030389139793, 0.9075091913877606, 0.9257805258642096, 0.9432909862112238, 0.9333299502557872, 0.9267641673032739, 0.1963187622811039, 0.18580706359282584, 0.18816171178768726, 0.18780402918430716, 0.17573776954814124, 0.19120559173880602, 0.23443763760461034, 0.17127687920666246, 0.1802224715419044, 0.23190999584248684, 0.240594875400845, 0.24127550390245456, 0.27772926863487724, 0.2581863361129576, 0.20822255499961284, 0.21552005874549773, 0.22903606227550322, 0.22426286893998026, 0.11136641283119264, 0.08718325021150031, 0.0714371518889313, 0.07890558386887259, 0.09510561911216386, 0.12453744449068194, 0.11710836256183443, 0.05555727511581987, 0.10972650412989882, 0.13095524138447434, 0.11029235581670238, 0.12761144360254673, 0.10874783764576823, 0.10792431792580393, 0.10473542162813043, 0.11771169935985981, 0.11465583152631276, 0.10391495272140305, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11531047782895965, 0.09632810051188812, 0.12422520154154448, 0.06473617159948242, 0.06941609788324787, 0.02780607486388431, 0.16067723225471398, 0.1061186696715054, 0.06525274032805883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0672148328349167, 0.060753370421861796, 0.034178145530624926, 0.05355684410382333, 0.05231320546006679, 0.05079497525364385, 0.048378306129393644, 0.05088950195606612, 0.02963475588384734, 0.3174502994467001, 0.3030048167303455, 0.307621852161555, 0.28937198869509395, 0.32199492375216743, 0.3096120861853827, 0.3531188864467969, 0.3052198072463017, 0.3493688730977861, 0.08648918834557173, 0.09823231547892697, 0.08371726717158146, 0.08157976698012992, 0.08932655995724659, 0.09070941601941884, 0.08171641432976195, 0.08751133310599579, 0.08235247121778899, 0.14070064041109687, 0.1570830656340968, 0.13968235788783046, 0.1658466940482658, 0.16702010709468773, 0.17848672142972877, 0.17895270605178992, 0.17255891754371822, 0.17347767839990647, 0.2277007905770242, 0.2283202901194893, 0.224005374816181, 0.22908776289801958, 0.2468817951467196, 0.24391915606140524, 0.23812591753307477, 0.2401408641470757, 0.22944399178807495, 0.18499208070973427, 0.16422439015929013, 0.17684237509637968, 0.17408487941796869, 0.16709904565743672, 0.1783954488580557, 0.17965751123376772, 0.16869624258386906, 0.15098586507639644, 0.21219228016246738, 0.19368349129260365, 0.2087332513514677, 0.22464991030196835, 0.20990449944161527, 0.22304195014770523, 0.24025670237377272, 0.20245742389672838, 0.21324793847042134, 0.19101052755137915, 0.17348660064999144, 0.17111551959843985, 0.2003818514706872, 0.17945892342685343, 0.17260640898244894, 0.18292199401676368, 0.18900661477739145, 0.1741262481518947, 0.17971053313913088, 0.1768179147476281, 0.37758463977425705, 0.42530694712535466, 0.1877878892518403, 0.16533231888473454, 0.1487660997429654, 0.3786265359115003, 0.45458419493732705, 0.3898965263061941, 0.2001700636935676, 0.3872149414077348, 0.3506386950136129, 0.19202871646529185, 0.16605703073126277, 0.16617060718455046, 0.38433927405135926, 0.35156126436589574, 0.18387963863901113, 0.1837501323614048, 0.18697677988458283, 0.18478500090355288, 0.19148141143118314, 0.18007099182119968, 0.17455248149538038, 0.18222075024312767, 0.18728395317346735, 0.0762872167387002, 0.0979420134976452, 0.08484958640831353, 0.09908479114413948, 0.08392347867047123, 0.08494969080560144, 0.08464221787661441, 0.08081642196924055, 0.08739342160777286]}, "mutation_prompt": null}
{"id": "8975bb58-a643-4997-aebd-afcc715cd30e", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIW:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIW(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIW", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight\" (HSO-ACL-OBL-DIW), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, and a dynamic inertia weight for better balance between exploration and exploitation.", "configspace": "", "generation": 8, "fitness": 0.19462174995630702, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIW got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "4bb8c8d8-20d1-49db-9754-180d55847d11", "metadata": {"aucs": [0.3387705556650571, 0.36694467257712027, 0.34352966069304547, 0.3214501886553932, 0.35491266118544107, 0.34941090819577725, 0.3408272330447597, 0.343762417611287, 0.36977836140455655, 0.024808360414493635, 0.005273372183058012, 0.044931174067087354, 9.999999999998899e-05, 0.0077924864926389725, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09765880836983176, 0.08798232256841765, 0.10461454950242022, 0.09904312934617032, 0.07384847267380357, 0.10079804085712751, 0.10789154017352376, 0.10134204102791045, 0.10261394931428947, 0.10169194271802429, 0.09234309114555928, 0.0951138255209234, 0.09052030081113827, 0.08385629622164814, 0.07905320630908585, 0.09206965553090163, 0.09001368883063154, 0.08358235780663814, 0.9186178632738351, 0.9480487769391553, 0.9283828099003468, 0.878470045581347, 0.8942903590654959, 0.9217326887911804, 0.9361623398219554, 0.9318947894845484, 0.9267870469744861, 0.21788000878491365, 0.21003923690714932, 0.22920777977803364, 0.21415428533153713, 0.21960961134981594, 0.21544223636741733, 0.22290040420539758, 0.21160920987376253, 0.20959039883304753, 0.24997573245351834, 0.29464677620049573, 0.2641124946488699, 0.2799699832841175, 0.2678362342166244, 0.2289912457886596, 0.2415626653791315, 0.2565379795936701, 0.27310144863985186, 0.16145559742657134, 0.07808825675617537, 0.09446511699765303, 0.08499581378909093, 0.1267322226799561, 0.1264877742574454, 0.1242965238197028, 0.08321643288113578, 0.1442075340622816, 0.12347999167577217, 0.13384046176919073, 0.1300989302127311, 0.14436485693760082, 0.11877854112774022, 0.14626486069085098, 0.11759555873522876, 0.13388120426759365, 0.1284196857331028, 9.999999999998899e-05, 9.999999999998899e-05, 0.0052906921865752965, 0.025729212322306405, 0.002996280893948655, 9.999999999998899e-05, 9.999999999998899e-05, 0.02143975224955008, 0.05497599892232907, 0.08411999911291879, 0.051640745707347224, 0.16884564757811205, 0.09676318154152852, 0.07258631043623831, 0.046055029172911044, 0.14720446267907916, 0.07338001926183846, 0.06051051265881924, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06276287520170931, 0.07640026239728048, 0.06095433076288004, 0.06573801870996321, 0.0700000687146316, 0.06921351007408516, 0.07045800234019006, 0.06068013361037816, 0.07096662229963002, 0.32643288960963923, 0.34013438970999654, 0.3490575743667903, 0.3202790159579547, 0.32629639076292316, 0.325422736866919, 0.3331186851250333, 0.3538438216791585, 0.3404314665198991, 0.1033702928855702, 0.09767246541335028, 0.10130019772573928, 0.1517499433621038, 0.09402935870131224, 0.09631753637133367, 0.095062511654047, 0.10935460611776593, 0.0971903004499498, 0.1608718925387479, 0.16301605143912679, 0.13332824511696728, 0.16031210793151562, 0.18104169563467487, 0.1810129579519103, 0.17008676286761348, 0.136503482940444, 0.204156488498887, 0.24959942523868106, 0.25439237214502075, 0.24963459445877256, 0.25069211898361976, 0.25926863568010683, 0.24236512099840046, 0.22309224985319287, 0.2451021300530093, 0.23880862039948603, 0.22410306702128857, 0.20744056762310503, 0.18072802746553207, 0.21075669462052338, 0.19026669478313885, 0.174486753484686, 0.18853199743702242, 0.18760844173093172, 0.1773330099417919, 0.21529073846976587, 0.22027588217006955, 0.21262275308287648, 0.21129385588456573, 0.20400913631245987, 0.21883591647711464, 0.22668852192922573, 0.21471085887666008, 0.21755503610825033, 0.17940127465534061, 0.1800544267522315, 0.2015379792633578, 0.19223678532207222, 0.1849637369006133, 0.17585264880250395, 0.19294714593280204, 0.2104717604718953, 0.17666204327102064, 0.1823628303899163, 0.1814190858644975, 0.4629623300981083, 0.48661987602193923, 0.19510470988719197, 0.16620074208341562, 0.1505115436951051, 0.15316681696157208, 0.4420686043903914, 0.41720114959453436, 0.20671172833864337, 0.43840841633118166, 0.4762745447322988, 0.20006156523238627, 0.1655950930031309, 0.16713049372731037, 0.3633611040548681, 0.40101905727572784, 0.1986686354809838, 0.18423094677223906, 0.1901354231318373, 0.2007799797919445, 0.17993008913864084, 0.17840230934329504, 0.17715055122315349, 0.21617928838941836, 0.1776309649623352, 0.08524106220248562, 0.08659841231066656, 0.08136911039442873, 0.08623822652424784, 0.09992570358825015, 0.08199220491791237, 0.11397249390740949, 0.0972123742578247, 0.0964808767023082]}, "mutation_prompt": null}
{"id": "d7ffa841-ac75-48e2-940f-f468c23e2818", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWGM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.gaussian_mutation_rate = 0.1\n        self.gaussian_mutation_stddev = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def gaussian_mutation(self, position):\n        return position + np.random.normal(0, self.gaussian_mutation_stddev, size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Gaussian mutation for increased diversity\n                if np.random.rand() < self.gaussian_mutation_rate:\n                    mutated_position = self.gaussian_mutation(self.particles[i])\n                    mutated_position = np.clip(mutated_position, self.lower_bound, self.upper_bound)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWGM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWGM", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Gaussian Mutation (HSO-ACL-OBL-DIW-GM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and Gaussian mutation for increased diversity.", "configspace": "", "generation": 9, "fitness": 0.19269702749731327, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWGM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {"aucs": [0.3408364024440784, 0.33669527128417154, 0.33290086378853645, 0.3210068091366287, 0.33499150129048094, 0.3404777826953139, 0.32593132413210113, 0.3329825829719879, 0.33383269351113654, 9.999999999998899e-05, 0.00738404064803122, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10756105477379774, 0.09564300789960489, 0.10159605432645535, 0.09869975877496451, 0.09081931719338754, 0.08564182833714973, 0.10491001607019423, 0.10868869719302998, 0.07542854433097146, 0.07022418403156894, 0.08255930929574584, 0.08250455976264603, 0.09199637690060847, 0.09068169714905139, 0.08437412520374743, 0.10619629723569146, 0.0785776177857409, 0.0912125567711839, 0.9098678941961285, 0.9311679893959449, 0.892387801871215, 0.8733939263737636, 0.8924143159534812, 0.8987797451757289, 0.9335513671609409, 0.9072648695225088, 0.9184748855959202, 0.2199419256960753, 0.2351829760874009, 0.2246621049423485, 0.2474060036582979, 0.225096303631798, 0.2206508135819889, 0.2564978714116707, 0.21017165373919366, 0.210077042195999, 0.2567150916343732, 0.29114800887917636, 0.30070322630578683, 0.2259048932819867, 0.27757807822660996, 0.20953894196942624, 0.23836271553728783, 0.1980113981102961, 0.2464966955585105, 0.14275024099487177, 0.08199856232280944, 0.13222446510604546, 0.16507393660299707, 0.11528978509758858, 0.12030230564170119, 0.13844972014608792, 0.12543773104755418, 0.15368836772596928, 0.13139400213092978, 0.14725610829104774, 0.13623513857718628, 0.13010183302588452, 0.12419270997756171, 0.13536324197007454, 0.135143546979554, 0.13448739006544297, 0.09773600844287045, 0.0023280223835921987, 9.999999999998899e-05, 9.999999999998899e-05, 0.019956329943668027, 0.00027686312448493844, 9.999999999998899e-05, 0.0011457975290549705, 0.00016648627896753698, 9.999999999998899e-05, 0.08032436636782603, 0.09427277147763524, 0.1369044947038598, 0.07723797667404675, 0.053043207773122214, 0.03145319870784946, 0.10430789827090592, 0.06465607337725254, 0.09832716240086925, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0622921667562748, 0.06501406003174925, 0.061243023637086336, 0.060976950015253495, 0.06677865103059955, 0.048913301464988734, 0.06283672729341083, 0.06372083416105034, 0.04682113834676527, 0.32850941803897626, 0.32710770527622846, 0.3336191495606933, 0.33335654125406833, 0.3318495190710461, 0.3214396257320469, 0.33850167420893595, 0.3359913794977246, 0.34640247979398386, 0.10244158430119055, 0.09455637324882737, 0.083681004041672, 0.09488451599217662, 0.09243795810668076, 0.08351698963160381, 0.09582623537773693, 0.09705368319080021, 0.10020402453156352, 0.14990148546344084, 0.16537096141412788, 0.13329849888543432, 0.18421381778096524, 0.1738956701863379, 0.18710366959874247, 0.1837718678156569, 0.17852695608868707, 0.1752286379216137, 0.24845310580674995, 0.23905543003875107, 0.24687408045785697, 0.25281403897874577, 0.2398136381395911, 0.2488397946158014, 0.24133819522184807, 0.2631416078559762, 0.24702257429464658, 0.19761599040754652, 0.18749740119856273, 0.19991036022215247, 0.20168723503871278, 0.19351627117979175, 0.18732968241276393, 0.15703831269322122, 0.20029539519748818, 0.17927309090290733, 0.23399309207223173, 0.21440324561214574, 0.23494153648949667, 0.21267730784349337, 0.2150341492965131, 0.2125677932051896, 0.23004970369284183, 0.2344976371426961, 0.22406839114805588, 0.19822726994430728, 0.18045167949553675, 0.18964383446132793, 0.19204138606103138, 0.19272182003954774, 0.1849469777519801, 0.21723466594752583, 0.18622416180458057, 0.17542140091289826, 0.12776088485668147, 0.18206111039231543, 0.4862042206370226, 0.46125360177324637, 0.192535539702113, 0.19128690737511456, 0.1386715634909257, 0.4365373282016971, 0.44368548837366506, 0.4395041037362918, 0.20823268264124473, 0.41994751616353676, 0.3374965898176765, 0.16571953873374445, 0.16587241957323917, 0.16589753025122245, 0.3978491542999111, 0.4117452052986388, 0.1833909515799531, 0.20804250200254137, 0.19422851097026328, 0.17475264322787898, 0.1918573432123135, 0.1716985775313773, 0.18580898233804477, 0.1793066014111977, 0.17906505041899723, 0.082400578034042, 0.0777171747312061, 0.07724794876878072, 0.09376504070392988, 0.0921512255729573, 0.09371186959715327, 0.09135866734750364, 0.1000513637413113, 0.08236242878809485]}, "mutation_prompt": null}
{"id": "5e4bc070-01a1-4a29-8391-74cbbaf8ab79", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWGM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.gaussian_mutation_rate = 0.1\n        self.gaussian_mutation_stddev = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def gaussian_mutation(self, position):\n        return position + np.random.normal(0, self.gaussian_mutation_stddev, size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Gaussian mutation for increased diversity\n                if np.random.rand() < self.gaussian_mutation_rate:\n                    mutated_position = self.gaussian_mutation(self.particles[i])\n                    mutated_position = np.clip(mutated_position, self.lower_bound, self.upper_bound)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWGM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWGM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Gaussian Mutation\" (HSO-ACL-OBL-DIW-GM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and Gaussian mutation for increased diversity.", "configspace": "", "generation": 10, "fitness": 0.19269702749731327, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWGM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {"aucs": [0.3408364024440784, 0.33669527128417154, 0.33290086378853645, 0.3210068091366287, 0.33499150129048094, 0.3404777826953139, 0.32593132413210113, 0.3329825829719879, 0.33383269351113654, 9.999999999998899e-05, 0.00738404064803122, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10756105477379774, 0.09564300789960489, 0.10159605432645535, 0.09869975877496451, 0.09081931719338754, 0.08564182833714973, 0.10491001607019423, 0.10868869719302998, 0.07542854433097146, 0.07022418403156894, 0.08255930929574584, 0.08250455976264603, 0.09199637690060847, 0.09068169714905139, 0.08437412520374743, 0.10619629723569146, 0.0785776177857409, 0.0912125567711839, 0.9098678941961285, 0.9311679893959449, 0.892387801871215, 0.8733939263737636, 0.8924143159534812, 0.8987797451757289, 0.9335513671609409, 0.9072648695225088, 0.9184748855959202, 0.2199419256960753, 0.2351829760874009, 0.2246621049423485, 0.2474060036582979, 0.225096303631798, 0.2206508135819889, 0.2564978714116707, 0.21017165373919366, 0.210077042195999, 0.2567150916343732, 0.29114800887917636, 0.30070322630578683, 0.2259048932819867, 0.27757807822660996, 0.20953894196942624, 0.23836271553728783, 0.1980113981102961, 0.2464966955585105, 0.14275024099487177, 0.08199856232280944, 0.13222446510604546, 0.16507393660299707, 0.11528978509758858, 0.12030230564170119, 0.13844972014608792, 0.12543773104755418, 0.15368836772596928, 0.13139400213092978, 0.14725610829104774, 0.13623513857718628, 0.13010183302588452, 0.12419270997756171, 0.13536324197007454, 0.135143546979554, 0.13448739006544297, 0.09773600844287045, 0.0023280223835921987, 9.999999999998899e-05, 9.999999999998899e-05, 0.019956329943668027, 0.00027686312448493844, 9.999999999998899e-05, 0.0011457975290549705, 0.00016648627896753698, 9.999999999998899e-05, 0.08032436636782603, 0.09427277147763524, 0.1369044947038598, 0.07723797667404675, 0.053043207773122214, 0.03145319870784946, 0.10430789827090592, 0.06465607337725254, 0.09832716240086925, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0622921667562748, 0.06501406003174925, 0.061243023637086336, 0.060976950015253495, 0.06677865103059955, 0.048913301464988734, 0.06283672729341083, 0.06372083416105034, 0.04682113834676527, 0.32850941803897626, 0.32710770527622846, 0.3336191495606933, 0.33335654125406833, 0.3318495190710461, 0.3214396257320469, 0.33850167420893595, 0.3359913794977246, 0.34640247979398386, 0.10244158430119055, 0.09455637324882737, 0.083681004041672, 0.09488451599217662, 0.09243795810668076, 0.08351698963160381, 0.09582623537773693, 0.09705368319080021, 0.10020402453156352, 0.14990148546344084, 0.16537096141412788, 0.13329849888543432, 0.18421381778096524, 0.1738956701863379, 0.18710366959874247, 0.1837718678156569, 0.17852695608868707, 0.1752286379216137, 0.24845310580674995, 0.23905543003875107, 0.24687408045785697, 0.25281403897874577, 0.2398136381395911, 0.2488397946158014, 0.24133819522184807, 0.2631416078559762, 0.24702257429464658, 0.19761599040754652, 0.18749740119856273, 0.19991036022215247, 0.20168723503871278, 0.19351627117979175, 0.18732968241276393, 0.15703831269322122, 0.20029539519748818, 0.17927309090290733, 0.23399309207223173, 0.21440324561214574, 0.23494153648949667, 0.21267730784349337, 0.2150341492965131, 0.2125677932051896, 0.23004970369284183, 0.2344976371426961, 0.22406839114805588, 0.19822726994430728, 0.18045167949553675, 0.18964383446132793, 0.19204138606103138, 0.19272182003954774, 0.1849469777519801, 0.21723466594752583, 0.18622416180458057, 0.17542140091289826, 0.12776088485668147, 0.18206111039231543, 0.4862042206370226, 0.46125360177324637, 0.192535539702113, 0.19128690737511456, 0.1386715634909257, 0.4365373282016971, 0.44368548837366506, 0.4395041037362918, 0.20823268264124473, 0.41994751616353676, 0.3374965898176765, 0.16571953873374445, 0.16587241957323917, 0.16589753025122245, 0.3978491542999111, 0.4117452052986388, 0.1833909515799531, 0.20804250200254137, 0.19422851097026328, 0.17475264322787898, 0.1918573432123135, 0.1716985775313773, 0.18580898233804477, 0.1793066014111977, 0.17906505041899723, 0.082400578034042, 0.0777171747312061, 0.07724794876878072, 0.09376504070392988, 0.0921512255729573, 0.09371186959715327, 0.09135866734750364, 0.1000513637413113, 0.08236242878809485]}, "mutation_prompt": null}
{"id": "44d5e0b8-b8d1-4d22-8ed4-89b4ff0e89ac", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.chaotic_map = np.random.uniform(size=self.swarm_size)\n\n    def logistic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Chaotic maps for increased randomness and diversity\n                self.chaotic_map[i] = self.logistic_map(self.chaotic_map[i])\n                if np.random.rand() < self.chaotic_map[i]:\n                    self.particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWCM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWCM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Chaotic Maps\" (HSO-ACL-OBL-DIW-CM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and chaotic maps for increased randomness and diversity.", "configspace": "", "generation": 11, "fitness": 0.17411272719671397, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {"aucs": [0.3019013894947079, 0.3230327176125325, 0.30973141993627673, 0.2972184343281884, 0.2911784461903929, 0.3103223725821661, 0.3061001037765121, 0.30271033001293335, 0.326460496054895, 0.024465043603139947, 0.006111866583903058, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0958421320910593, 0.08300330390386224, 0.09551712046761673, 0.08056469239748454, 0.08539966903905538, 0.07958290557549441, 0.09468824648499863, 0.08337168033922338, 0.08807902718092431, 0.07364314402168148, 0.07636540577144957, 0.07188070453248308, 0.07496000159037086, 0.0624741208379872, 0.0854849125009447, 0.07104486101627538, 0.06230714790810721, 0.05705686401693855, 0.8931037463326441, 0.9337241377015101, 0.8862503668238896, 0.85952652355235, 0.859765936749377, 0.8995223883424741, 0.925942260741646, 0.9130467084269644, 0.9036629195387483, 0.19697731988549327, 0.18803094055508607, 0.17893365484961488, 0.18400765396995622, 0.17313400748862606, 0.1832052750824188, 0.17122387094323022, 0.16437064935206236, 0.17600872617513086, 0.2075431473703777, 0.23796545050239115, 0.21969602165593605, 0.20905425776578146, 0.18661450989899264, 0.17880716846391387, 0.21522358716047452, 0.2202956309763373, 0.25412374939741744, 0.09183063700898397, 0.1014387099420534, 0.10436589683597086, 0.06165835366713723, 0.11228538009432454, 0.12976291334750167, 0.10267741590579971, 0.05140124496756293, 0.10381247281525452, 0.11973950195934868, 0.12092123585140802, 0.10060383204790069, 0.10659896135393954, 0.10258076484250467, 0.12545764417690208, 0.10352983459726384, 0.10021707509190858, 0.10567707874054444, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.020405221346134206, 9.999999999998899e-05, 9.999999999998899e-05, 0.02011850476601973, 9.999999999998899e-05, 9.999999999998899e-05, 0.08162797003466726, 0.058520429323104306, 0.08776614023433016, 0.09453198827969211, 0.1071343551402737, 0.033746237279576596, 0.0852574368691087, 0.05547892063239035, 0.07616269043274804, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03774400366636743, 0.04916649394258221, 0.03976023189147959, 0.03730695975740561, 0.05509620724343711, 0.06168833776973137, 0.03834705648935055, 0.04238309898602588, 0.03709455715039989, 0.29843500360426567, 0.2973846872784649, 0.3209886902550999, 0.29595618608959084, 0.2997711931980874, 0.3064456897172154, 0.29771604119536965, 0.3170253867910007, 0.3100999318303478, 0.08723471263991489, 0.0790427390719769, 0.08421039142475606, 0.07445667771875819, 0.08282103341230251, 0.09860005144961759, 0.07353309365344263, 0.09397472556465492, 0.08736562270024173, 0.1210759554074059, 0.15538514808293835, 0.15757745858879713, 0.17059803380575778, 0.15662834456440056, 0.13715879759568017, 0.13429467266996908, 0.13174064747225744, 0.17564245886036456, 0.2216582939954218, 0.23075499722214776, 0.22454641489929295, 0.23026481782523733, 0.23808249690519945, 0.23231091215065414, 0.2405407570590613, 0.23311083146442324, 0.22653018043766027, 0.1818490790231514, 0.1686760666346574, 0.1684917653604121, 0.17541554060273612, 0.16312778661654614, 0.16346725483553382, 0.14298101567851895, 0.1792920088085591, 0.1773545757744991, 0.19563951042634575, 0.21348368948395713, 0.21939039502390145, 0.22313017051515305, 0.2017670497945716, 0.20353453212074624, 0.25687372387938645, 0.2167701560128309, 0.2010984935224659, 0.17359165057901027, 0.18480090492751022, 0.1749617335760546, 0.185927326761667, 0.17906095138260258, 0.17403533854879139, 0.17591605340713345, 0.17767775346331605, 0.17046065218708117, 0.1787569215549928, 0.3866830886094301, 0.17709921187714806, 0.19302571422429848, 0.19272493343158237, 0.15141261072084256, 0.26436025488549475, 0.16367846036591982, 0.35174288801172493, 0.3478399911504605, 0.19795722864261955, 0.3330352505812756, 0.2903379758145337, 0.28114253617073415, 0.25381082434182256, 0.2898817892846911, 0.19967795500483254, 0.23137446216776636, 0.1854630347049936, 0.1807336557658431, 0.18717814138864852, 0.18124855784541682, 0.1761296564084165, 0.17583669815916003, 0.18503133694747953, 0.1781284145369908, 0.17618118379637582, 0.08366973315342507, 0.07622375401757508, 0.08019666708899853, 0.07096774346440726, 0.0795876412421963, 0.09178611018527849, 0.08008330538474528, 0.07872057710067659, 0.07844754687492861]}, "mutation_prompt": null}
{"id": "72be079f-5c3d-4951-b862-6a048ebfcf66", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        return position + np.random.normal(0, self.mutation_step_size, size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_position = np.clip(mutated_position, self.lower_bound, self.upper_bound)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Self-Adaptive Mutation\" (HSO-ACL-OBL-DIW-SAM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and self-adaptive mutation for increased diversity.", "configspace": "", "generation": 12, "fitness": 0.19269702749731327, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {"aucs": [0.3408364024440784, 0.33669527128417154, 0.33290086378853645, 0.3210068091366287, 0.33499150129048094, 0.3404777826953139, 0.32593132413210113, 0.3329825829719879, 0.33383269351113654, 9.999999999998899e-05, 0.00738404064803122, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10756105477379774, 0.09564300789960489, 0.10159605432645535, 0.09869975877496451, 0.09081931719338754, 0.08564182833714973, 0.10491001607019423, 0.10868869719302998, 0.07542854433097146, 0.07022418403156894, 0.08255930929574584, 0.08250455976264603, 0.09199637690060847, 0.09068169714905139, 0.08437412520374743, 0.10619629723569146, 0.0785776177857409, 0.0912125567711839, 0.9098678941961285, 0.9311679893959449, 0.892387801871215, 0.8733939263737636, 0.8924143159534812, 0.8987797451757289, 0.9335513671609409, 0.9072648695225088, 0.9184748855959202, 0.2199419256960753, 0.2351829760874009, 0.2246621049423485, 0.2474060036582979, 0.225096303631798, 0.2206508135819889, 0.2564978714116707, 0.21017165373919366, 0.210077042195999, 0.2567150916343732, 0.29114800887917636, 0.30070322630578683, 0.2259048932819867, 0.27757807822660996, 0.20953894196942624, 0.23836271553728783, 0.1980113981102961, 0.2464966955585105, 0.14275024099487177, 0.08199856232280944, 0.13222446510604546, 0.16507393660299707, 0.11528978509758858, 0.12030230564170119, 0.13844972014608792, 0.12543773104755418, 0.15368836772596928, 0.13139400213092978, 0.14725610829104774, 0.13623513857718628, 0.13010183302588452, 0.12419270997756171, 0.13536324197007454, 0.135143546979554, 0.13448739006544297, 0.09773600844287045, 0.0023280223835921987, 9.999999999998899e-05, 9.999999999998899e-05, 0.019956329943668027, 0.00027686312448493844, 9.999999999998899e-05, 0.0011457975290549705, 0.00016648627896753698, 9.999999999998899e-05, 0.08032436636782603, 0.09427277147763524, 0.1369044947038598, 0.07723797667404675, 0.053043207773122214, 0.03145319870784946, 0.10430789827090592, 0.06465607337725254, 0.09832716240086925, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0622921667562748, 0.06501406003174925, 0.061243023637086336, 0.060976950015253495, 0.06677865103059955, 0.048913301464988734, 0.06283672729341083, 0.06372083416105034, 0.04682113834676527, 0.32850941803897626, 0.32710770527622846, 0.3336191495606933, 0.33335654125406833, 0.3318495190710461, 0.3214396257320469, 0.33850167420893595, 0.3359913794977246, 0.34640247979398386, 0.10244158430119055, 0.09455637324882737, 0.083681004041672, 0.09488451599217662, 0.09243795810668076, 0.08351698963160381, 0.09582623537773693, 0.09705368319080021, 0.10020402453156352, 0.14990148546344084, 0.16537096141412788, 0.13329849888543432, 0.18421381778096524, 0.1738956701863379, 0.18710366959874247, 0.1837718678156569, 0.17852695608868707, 0.1752286379216137, 0.24845310580674995, 0.23905543003875107, 0.24687408045785697, 0.25281403897874577, 0.2398136381395911, 0.2488397946158014, 0.24133819522184807, 0.2631416078559762, 0.24702257429464658, 0.19761599040754652, 0.18749740119856273, 0.19991036022215247, 0.20168723503871278, 0.19351627117979175, 0.18732968241276393, 0.15703831269322122, 0.20029539519748818, 0.17927309090290733, 0.23399309207223173, 0.21440324561214574, 0.23494153648949667, 0.21267730784349337, 0.2150341492965131, 0.2125677932051896, 0.23004970369284183, 0.2344976371426961, 0.22406839114805588, 0.19822726994430728, 0.18045167949553675, 0.18964383446132793, 0.19204138606103138, 0.19272182003954774, 0.1849469777519801, 0.21723466594752583, 0.18622416180458057, 0.17542140091289826, 0.12776088485668147, 0.18206111039231543, 0.4862042206370226, 0.46125360177324637, 0.192535539702113, 0.19128690737511456, 0.1386715634909257, 0.4365373282016971, 0.44368548837366506, 0.4395041037362918, 0.20823268264124473, 0.41994751616353676, 0.3374965898176765, 0.16571953873374445, 0.16587241957323917, 0.16589753025122245, 0.3978491542999111, 0.4117452052986388, 0.1833909515799531, 0.20804250200254137, 0.19422851097026328, 0.17475264322787898, 0.1918573432123135, 0.1716985775313773, 0.18580898233804477, 0.1793066014111977, 0.17906505041899723, 0.082400578034042, 0.0777171747312061, 0.07724794876878072, 0.09376504070392988, 0.0921512255729573, 0.09371186959715327, 0.09135866734750364, 0.1000513637413113, 0.08236242878809485]}, "mutation_prompt": null}
{"id": "bbcc22f8-60aa-4aef-a727-ad76e4867fff", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWGM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.gaussian_mutation_rate = 0.1\n        self.gaussian_mutation_stddev = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def gaussian_mutation(self, position):\n        return position + np.random.normal(0, self.gaussian_mutation_stddev, size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Gaussian mutation for increased diversity\n                if np.random.rand() < self.gaussian_mutation_rate:\n                    mutated_position = self.gaussian_mutation(self.particles[i])\n                    mutated_position = np.clip(mutated_position, self.lower_bound, self.upper_bound)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWGM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWGM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Gaussian Mutation\" (HSO-ACL-OBL-DIW-GM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and Gaussian mutation for increased diversity.", "configspace": "", "generation": 13, "fitness": 0.19269702749731327, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWGM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {"aucs": [0.3408364024440784, 0.33669527128417154, 0.33290086378853645, 0.3210068091366287, 0.33499150129048094, 0.3404777826953139, 0.32593132413210113, 0.3329825829719879, 0.33383269351113654, 9.999999999998899e-05, 0.00738404064803122, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10756105477379774, 0.09564300789960489, 0.10159605432645535, 0.09869975877496451, 0.09081931719338754, 0.08564182833714973, 0.10491001607019423, 0.10868869719302998, 0.07542854433097146, 0.07022418403156894, 0.08255930929574584, 0.08250455976264603, 0.09199637690060847, 0.09068169714905139, 0.08437412520374743, 0.10619629723569146, 0.0785776177857409, 0.0912125567711839, 0.9098678941961285, 0.9311679893959449, 0.892387801871215, 0.8733939263737636, 0.8924143159534812, 0.8987797451757289, 0.9335513671609409, 0.9072648695225088, 0.9184748855959202, 0.2199419256960753, 0.2351829760874009, 0.2246621049423485, 0.2474060036582979, 0.225096303631798, 0.2206508135819889, 0.2564978714116707, 0.21017165373919366, 0.210077042195999, 0.2567150916343732, 0.29114800887917636, 0.30070322630578683, 0.2259048932819867, 0.27757807822660996, 0.20953894196942624, 0.23836271553728783, 0.1980113981102961, 0.2464966955585105, 0.14275024099487177, 0.08199856232280944, 0.13222446510604546, 0.16507393660299707, 0.11528978509758858, 0.12030230564170119, 0.13844972014608792, 0.12543773104755418, 0.15368836772596928, 0.13139400213092978, 0.14725610829104774, 0.13623513857718628, 0.13010183302588452, 0.12419270997756171, 0.13536324197007454, 0.135143546979554, 0.13448739006544297, 0.09773600844287045, 0.0023280223835921987, 9.999999999998899e-05, 9.999999999998899e-05, 0.019956329943668027, 0.00027686312448493844, 9.999999999998899e-05, 0.0011457975290549705, 0.00016648627896753698, 9.999999999998899e-05, 0.08032436636782603, 0.09427277147763524, 0.1369044947038598, 0.07723797667404675, 0.053043207773122214, 0.03145319870784946, 0.10430789827090592, 0.06465607337725254, 0.09832716240086925, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0622921667562748, 0.06501406003174925, 0.061243023637086336, 0.060976950015253495, 0.06677865103059955, 0.048913301464988734, 0.06283672729341083, 0.06372083416105034, 0.04682113834676527, 0.32850941803897626, 0.32710770527622846, 0.3336191495606933, 0.33335654125406833, 0.3318495190710461, 0.3214396257320469, 0.33850167420893595, 0.3359913794977246, 0.34640247979398386, 0.10244158430119055, 0.09455637324882737, 0.083681004041672, 0.09488451599217662, 0.09243795810668076, 0.08351698963160381, 0.09582623537773693, 0.09705368319080021, 0.10020402453156352, 0.14990148546344084, 0.16537096141412788, 0.13329849888543432, 0.18421381778096524, 0.1738956701863379, 0.18710366959874247, 0.1837718678156569, 0.17852695608868707, 0.1752286379216137, 0.24845310580674995, 0.23905543003875107, 0.24687408045785697, 0.25281403897874577, 0.2398136381395911, 0.2488397946158014, 0.24133819522184807, 0.2631416078559762, 0.24702257429464658, 0.19761599040754652, 0.18749740119856273, 0.19991036022215247, 0.20168723503871278, 0.19351627117979175, 0.18732968241276393, 0.15703831269322122, 0.20029539519748818, 0.17927309090290733, 0.23399309207223173, 0.21440324561214574, 0.23494153648949667, 0.21267730784349337, 0.2150341492965131, 0.2125677932051896, 0.23004970369284183, 0.2344976371426961, 0.22406839114805588, 0.19822726994430728, 0.18045167949553675, 0.18964383446132793, 0.19204138606103138, 0.19272182003954774, 0.1849469777519801, 0.21723466594752583, 0.18622416180458057, 0.17542140091289826, 0.12776088485668147, 0.18206111039231543, 0.4862042206370226, 0.46125360177324637, 0.192535539702113, 0.19128690737511456, 0.1386715634909257, 0.4365373282016971, 0.44368548837366506, 0.4395041037362918, 0.20823268264124473, 0.41994751616353676, 0.3374965898176765, 0.16571953873374445, 0.16587241957323917, 0.16589753025122245, 0.3978491542999111, 0.4117452052986388, 0.1833909515799531, 0.20804250200254137, 0.19422851097026328, 0.17475264322787898, 0.1918573432123135, 0.1716985775313773, 0.18580898233804477, 0.1793066014111977, 0.17906505041899723, 0.082400578034042, 0.0777171747312061, 0.07724794876878072, 0.09376504070392988, 0.0921512255729573, 0.09371186959715327, 0.09135866734750364, 0.1000513637413113, 0.08236242878809485]}, "mutation_prompt": null}
{"id": "de313fcf-0ecb-43ee-82da-d0867e96a718", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSADE:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.de_scale_factor = 0.5\n        self.de_crossover_probability = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.choice(self.swarm_size, 2, replace=False)\n        mutant = self.particles[r1] + self.de_scale_factor * (self.particles[r2] - position)\n        mutant = np.clip(mutant, self.lower_bound, self.upper_bound)\n        crossover = np.where(np.random.rand(self.dim) < self.de_crossover_probability, mutant, position)\n        return crossover\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive differential evolution for enhanced local search\n                if np.random.rand() < 0.1:\n                    de_position = self.differential_evolution(self.particles[i])\n                    de_fitness = func(de_position)\n                    evaluations += 1\n                    if de_fitness < fitness:\n                        self.particles[i] = de_position\n                        self.best_fitness[i] = de_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSADE(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSADE", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Self-Adaptive Differential Evolution\" (HSO-ACL-OBL-DIW-SADE), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and self-adaptive differential evolution for enhanced local search.", "configspace": "", "generation": 14, "fitness": 0.1902167450494678, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSADE got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {"aucs": [0.34864680232342704, 0.3369793450845746, 0.3323623405110714, 0.3266834306578066, 0.3426714968292377, 0.34136741517204405, 0.334599375524236, 0.32465210265989974, 0.3277724772059828, 9.999999999998899e-05, 0.005446023940666622, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10422534072094891, 0.08998175221140137, 0.09065017218419269, 0.11539564324625662, 0.08752176410509471, 0.0995053460663885, 0.09120938397604861, 0.11683816654462531, 0.10514917863490336, 0.08279008079273986, 0.09627353749808298, 0.08792864649404908, 0.08010269942353987, 0.08146909342708675, 0.09118698316878127, 0.09579784570646044, 0.08560768600878854, 0.09237944389727948, 0.9035054679210428, 0.9429512677147632, 0.8745144062571937, 0.8578534146416827, 0.8966775514867026, 0.9218350023728732, 0.9198800387647795, 0.92678870668532, 0.8962179752396249, 0.22206172413965874, 0.2307815540951318, 0.22149953197602767, 0.2291260844004337, 0.22995825109294288, 0.20285339823358328, 0.22479024660592672, 0.2124959922093853, 0.21449833255497275, 0.25821165245103594, 0.282939383085721, 0.2657431711359667, 0.2742716707452426, 0.3117751616557576, 0.24732698377862183, 0.2716881460393086, 0.2387081142452424, 0.28320342868924564, 0.13911916074670516, 0.11430621334147995, 0.11327343295927295, 0.11137287647057525, 0.12972982239560693, 0.16005303099108992, 0.13217335977010913, 0.12221088318059159, 0.14148609321651928, 0.12383109764521227, 0.13476539692410638, 0.0902984333218434, 0.12559364913702087, 0.14674241345573702, 0.13825583846429235, 0.1214316292080635, 0.1397511006287725, 0.1337564684493151, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007144955218229554, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08485543341927493, 0.08903148288131035, 0.11356060155724812, 0.06525661529531768, 0.04676435897716258, 0.037274608505979856, 0.06964331296956605, 0.07235100412460926, 0.07528633979183175, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.053987249205740606, 0.06425309788772027, 0.05942483329302628, 0.05995750234478159, 0.06297738831978128, 0.05031148491916482, 0.07464148038340068, 0.06808538826523125, 0.06426301787432565, 0.3343287597010133, 0.3466061135989982, 0.32312619703914114, 0.3352197904897831, 0.3253427974624328, 0.3461437427080982, 0.32380703840237324, 0.34046197266075817, 0.34175567580369715, 0.09419146091765762, 0.08896245173396256, 0.105336025883904, 0.09545821143367339, 0.08507700856927203, 0.10171988263755061, 0.09142180250363852, 0.09702485093651791, 0.09829189579058561, 0.14961901434367098, 0.15671839575536173, 0.16179307174392743, 0.1782247196016815, 0.1804631592522986, 0.16365513943396615, 0.18230272129036573, 0.1682259506153969, 0.16621545907235125, 0.24938945772251142, 0.2505482964648782, 0.25243862667486416, 0.26571314933605117, 0.2428687479452889, 0.25327373015441357, 0.2074457370512921, 0.2656274279034203, 0.25080270170961294, 0.1907604436566076, 0.198843408733122, 0.20695196425870932, 0.19511633802422135, 0.1742709003285976, 0.18156135282122832, 0.18207864043389388, 0.19074331226769892, 0.19750767486372356, 0.21494077290186242, 0.2447951585165733, 0.2318039387938685, 0.22553904046818185, 0.2125858202057611, 0.2368142757009879, 0.2289624373506305, 0.21190184309978843, 0.21033485778228822, 0.18453840525566045, 0.18599497093447237, 0.17842245511819343, 0.1893532307395419, 0.18968417369480595, 0.17499648093958953, 0.17159819764699769, 0.18618253750285607, 0.1671363689406029, 0.4754856310384755, 0.18201989185554257, 0.16663171158432177, 0.16945187419004848, 0.19604073115581655, 0.19288575478446723, 0.45520344429149684, 0.4458049412537053, 0.1641198226770092, 0.4188603729761242, 0.20470732220914523, 0.07303066350780663, 0.37598504126381216, 0.16496110581168577, 0.1660723187610753, 0.16683967566338365, 0.4356993021522303, 0.41166212023250315, 0.17766189750129158, 0.18975405579974813, 0.1936221484247529, 0.18495209939645407, 0.18912971427410108, 0.1847965883645476, 0.1809787702805673, 0.19748923322276657, 0.1826151737245434, 0.08956041585830299, 0.08702246136987435, 0.07190707233390425, 0.077789676752832, 0.08983453363345839, 0.07749861847406936, 0.07690752990477034, 0.08929414875128205, 0.0804495941104384]}, "mutation_prompt": null}
{"id": "dda6ffb7-f820-4f24-8395-41536e66c689", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWRDM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.randomized_dimensional_mutation_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def randomized_dimensional_mutation(self, position):\n        mutated_position = np.copy(position)\n        mutated_dimension = np.random.randint(0, self.dim)\n        mutated_position[mutated_dimension] = np.random.uniform(self.lower_bound, self.upper_bound)\n        return mutated_position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Randomized dimensional mutation for increased exploration\n                if np.random.rand() < self.randomized_dimensional_mutation_rate:\n                    mutated_position = self.randomized_dimensional_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWRDM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWRDM", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Randomized Dimensional Mutation (HSO-ACL-OBL-DIW-RDM)", "configspace": "", "generation": 15, "fitness": 0.19048620272989614, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWRDM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {"aucs": [0.3465248302307886, 0.34129630694539415, 0.3389437323063881, 0.3352060784484291, 0.3615785374005349, 0.3351673522714492, 0.37847618506380853, 0.33141141072327684, 0.34432410446645867, 0.014308696551027067, 0.002785395022301018, 0.008929510236023286, 9.999999999998899e-05, 0.0008032324508465694, 0.0037376557613988393, 9.999999999998899e-05, 0.0011880331062713578, 9.999999999998899e-05, 0.10777818576755638, 0.10931391360039855, 0.10050186406447115, 0.09593269228854295, 0.09593025400601873, 0.0888690157003712, 0.10067624634842032, 0.10831971455583589, 0.12265064039805496, 0.08866854571032834, 0.07556661029288447, 0.0976037050098637, 0.07835508452923057, 0.08603151883546833, 0.08587292429332771, 0.08561679935443445, 0.08452654166667872, 0.10326516455198687, 0.9158853667863406, 0.9328985403113486, 0.9125201777541863, 0.8633367437378304, 0.8862918504616843, 0.9066225180126929, 0.9384374925007473, 0.9211814704777085, 0.9185422470753145, 0.22319548734554095, 0.21272530215275343, 0.21008372607612347, 0.22574674564193598, 0.21832970208305114, 0.22065405191245668, 0.22299320914863796, 0.21807896238452984, 0.20265995265913894, 0.26496780044607393, 0.2977071236655785, 0.21621484277099312, 0.2759392796496739, 0.29427623040465145, 0.23625362910064518, 0.27600387821439176, 0.23214580051260614, 0.25539829357559907, 0.12531871787314175, 0.13922764725865278, 0.13498993855054575, 0.08216628720572294, 0.1326701445416102, 0.1328909358291105, 0.11317585761048143, 0.08194067308501674, 0.1325180323955676, 0.12139173458758379, 0.11986353963813123, 0.11864288170454607, 0.15912519231421962, 0.12788043148296568, 0.1329952616788218, 0.12319035365481779, 0.1281050342237373, 0.1189232391246966, 0.0005206864818876333, 9.999999999998899e-05, 0.001025575850089111, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0013281201410969556, 9.999999999998899e-05, 0.010189454085264282, 0.11539188689809465, 0.1012470921068449, 0.15444580972452837, 0.09687214310770398, 0.07813820591945264, 0.022982120665842043, 0.10906986018482989, 0.09222784654084304, 0.1036071000612121, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.055943483721390685, 0.06752612202388841, 0.062400227701560285, 0.06472322977650269, 0.057516520297888785, 0.05742155373355218, 0.07010517430581853, 0.06508515496737566, 0.0740266922920737, 0.33329113834367574, 0.40680416921052165, 0.32533962557064, 0.344596459581639, 0.3404438565645601, 0.3170238159064297, 0.3220810897366111, 0.3520413024185085, 0.3341196972758542, 0.09055993811769258, 0.10023591831235279, 0.09743874890207371, 0.09683696179310375, 0.10265065781769467, 0.1020541063721323, 0.09627017111707514, 0.08226842922736055, 0.08962910662818291, 0.14625356435232317, 0.17622127674074384, 0.16755943214155944, 0.14286753474503544, 0.1639725039537212, 0.18036566267316834, 0.17161429496700586, 0.17043498653797073, 0.13359679245228706, 0.24338222133221987, 0.24349445623061194, 0.24510710109679557, 0.24815580188397257, 0.24659420705121793, 0.24515775420268104, 0.2603905309686133, 0.2538532796327365, 0.2502168281689311, 0.1901301667943669, 0.19448539556761757, 0.19407564661633936, 0.20194986492884537, 0.1896185412601733, 0.18539431778774118, 0.1869647906058448, 0.20320318168874096, 0.16617939585236852, 0.23128594019639181, 0.22545758896230106, 0.21207081272886386, 0.21080466878292858, 0.2256416128453801, 0.2539992001036748, 0.21567299540287854, 0.2373785711883858, 0.23131188772170097, 0.18055680896129667, 0.18050872825785502, 0.1831836686260443, 0.18572123811128471, 0.19769272210007816, 0.20566954727302278, 0.17487596953558715, 0.17941504583065437, 0.17670916991126884, 0.18340560963869268, 0.18343064504959838, 0.14507541788531675, 0.486983862686449, 0.19381879564725035, 0.1449844696965913, 0.13973882488989642, 0.46663139179034674, 0.16339435095101362, 0.44101827517179426, 0.2055205654957255, 0.44066063509758957, 0.19846768595898479, 0.16022717439680034, 0.16528433542032905, 0.16769520466300147, 0.36893604224496357, 0.34490795938517527, 0.17171175175289477, 0.17705238157195513, 0.19944676219534008, 0.18370197527162369, 0.2151170849729972, 0.1818844807923523, 0.1758048292735368, 0.1940321653107583, 0.194031046921201, 0.07739350502489983, 0.07239178365469667, 0.0748967470968317, 0.08295129049312489, 0.08496542763047055, 0.08989007418579953, 0.09349048656444969, 0.08588692941018239, 0.09954805162798397]}, "mutation_prompt": null}
{"id": "a4085573-6fee-4a50-a0b6-ed883d3814f5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWCT:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.chaos_map = np.random.uniform(0, 1, size=self.swarm_size)\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def chaos_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Chaos theory for increased diversity\n                if np.random.rand() < 0.1:\n                    self.chaos_map[i] = self.chaos_map(self.chaos_map[i])\n                    self.particles[i] = self.lower_bound + (self.upper_bound - self.lower_bound) * self.chaos_map[i]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWCT(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWCT", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Chaos Theory\" (HSO-ACL-OBL-DIW-CT), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and chaos theory for increased diversity.", "configspace": "", "generation": 16, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'numpy.ndarray' object is not callable\").", "error": "TypeError(\"'numpy.ndarray' object is not callable\")", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {}, "mutation_prompt": null}
{"id": "59733327-24ab-472e-8474-773e12bd59f3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWGM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.gaussian_mutation_rate = 0.1\n        self.gaussian_mutation_stddev = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def gaussian_mutation(self, position):\n        return position + np.random.normal(0, self.gaussian_mutation_stddev, size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Gaussian mutation for increased diversity\n                if np.random.rand() < self.gaussian_mutation_rate:\n                    mutated_position = self.gaussian_mutation(self.particles[i])\n                    mutated_position = np.clip(mutated_position, self.lower_bound, self.upper_bound)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWGM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWGM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Gaussian Mutation\" (HSO-ACL-OBL-DIW-GM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and Gaussian mutation for increased diversity.", "configspace": "", "generation": 17, "fitness": 0.19269702749731327, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWGM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {"aucs": [0.3408364024440784, 0.33669527128417154, 0.33290086378853645, 0.3210068091366287, 0.33499150129048094, 0.3404777826953139, 0.32593132413210113, 0.3329825829719879, 0.33383269351113654, 9.999999999998899e-05, 0.00738404064803122, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10756105477379774, 0.09564300789960489, 0.10159605432645535, 0.09869975877496451, 0.09081931719338754, 0.08564182833714973, 0.10491001607019423, 0.10868869719302998, 0.07542854433097146, 0.07022418403156894, 0.08255930929574584, 0.08250455976264603, 0.09199637690060847, 0.09068169714905139, 0.08437412520374743, 0.10619629723569146, 0.0785776177857409, 0.0912125567711839, 0.9098678941961285, 0.9311679893959449, 0.892387801871215, 0.8733939263737636, 0.8924143159534812, 0.8987797451757289, 0.9335513671609409, 0.9072648695225088, 0.9184748855959202, 0.2199419256960753, 0.2351829760874009, 0.2246621049423485, 0.2474060036582979, 0.225096303631798, 0.2206508135819889, 0.2564978714116707, 0.21017165373919366, 0.210077042195999, 0.2567150916343732, 0.29114800887917636, 0.30070322630578683, 0.2259048932819867, 0.27757807822660996, 0.20953894196942624, 0.23836271553728783, 0.1980113981102961, 0.2464966955585105, 0.14275024099487177, 0.08199856232280944, 0.13222446510604546, 0.16507393660299707, 0.11528978509758858, 0.12030230564170119, 0.13844972014608792, 0.12543773104755418, 0.15368836772596928, 0.13139400213092978, 0.14725610829104774, 0.13623513857718628, 0.13010183302588452, 0.12419270997756171, 0.13536324197007454, 0.135143546979554, 0.13448739006544297, 0.09773600844287045, 0.0023280223835921987, 9.999999999998899e-05, 9.999999999998899e-05, 0.019956329943668027, 0.00027686312448493844, 9.999999999998899e-05, 0.0011457975290549705, 0.00016648627896753698, 9.999999999998899e-05, 0.08032436636782603, 0.09427277147763524, 0.1369044947038598, 0.07723797667404675, 0.053043207773122214, 0.03145319870784946, 0.10430789827090592, 0.06465607337725254, 0.09832716240086925, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0622921667562748, 0.06501406003174925, 0.061243023637086336, 0.060976950015253495, 0.06677865103059955, 0.048913301464988734, 0.06283672729341083, 0.06372083416105034, 0.04682113834676527, 0.32850941803897626, 0.32710770527622846, 0.3336191495606933, 0.33335654125406833, 0.3318495190710461, 0.3214396257320469, 0.33850167420893595, 0.3359913794977246, 0.34640247979398386, 0.10244158430119055, 0.09455637324882737, 0.083681004041672, 0.09488451599217662, 0.09243795810668076, 0.08351698963160381, 0.09582623537773693, 0.09705368319080021, 0.10020402453156352, 0.14990148546344084, 0.16537096141412788, 0.13329849888543432, 0.18421381778096524, 0.1738956701863379, 0.18710366959874247, 0.1837718678156569, 0.17852695608868707, 0.1752286379216137, 0.24845310580674995, 0.23905543003875107, 0.24687408045785697, 0.25281403897874577, 0.2398136381395911, 0.2488397946158014, 0.24133819522184807, 0.2631416078559762, 0.24702257429464658, 0.19761599040754652, 0.18749740119856273, 0.19991036022215247, 0.20168723503871278, 0.19351627117979175, 0.18732968241276393, 0.15703831269322122, 0.20029539519748818, 0.17927309090290733, 0.23399309207223173, 0.21440324561214574, 0.23494153648949667, 0.21267730784349337, 0.2150341492965131, 0.2125677932051896, 0.23004970369284183, 0.2344976371426961, 0.22406839114805588, 0.19822726994430728, 0.18045167949553675, 0.18964383446132793, 0.19204138606103138, 0.19272182003954774, 0.1849469777519801, 0.21723466594752583, 0.18622416180458057, 0.17542140091289826, 0.12776088485668147, 0.18206111039231543, 0.4862042206370226, 0.46125360177324637, 0.192535539702113, 0.19128690737511456, 0.1386715634909257, 0.4365373282016971, 0.44368548837366506, 0.4395041037362918, 0.20823268264124473, 0.41994751616353676, 0.3374965898176765, 0.16571953873374445, 0.16587241957323917, 0.16589753025122245, 0.3978491542999111, 0.4117452052986388, 0.1833909515799531, 0.20804250200254137, 0.19422851097026328, 0.17475264322787898, 0.1918573432123135, 0.1716985775313773, 0.18580898233804477, 0.1793066014111977, 0.17906505041899723, 0.082400578034042, 0.0777171747312061, 0.07724794876878072, 0.09376504070392988, 0.0921512255729573, 0.09371186959715327, 0.09135866734750364, 0.1000513637413113, 0.08236242878809485]}, "mutation_prompt": null}
{"id": "9e101078-fd0d-4379-8055-484ef07848e1", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Self-Adaptive Mutation\" (HSO-ACL-OBL-DIW-SAM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and a self-adaptive mutation strategy for increased diversity.", "configspace": "", "generation": 18, "fitness": 0.19519787911598113, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "8975bb58-a643-4997-aebd-afcc715cd30e", "metadata": {"aucs": [0.34586637947182064, 0.3393439331007596, 0.34757014024885646, 0.3482876788738235, 0.3376875989586188, 0.3296295202520847, 0.33563166267520683, 0.34159491703168454, 0.3566178498535205, 0.002480067215975046, 0.014452548641350371, 0.0006738999753702624, 9.999999999998899e-05, 0.011462119229441292, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09416538378994721, 0.12136159168129856, 0.08293289778501745, 0.10237209985856821, 0.09096489155022591, 0.09386891714722456, 0.11228226209930703, 0.10013112133071422, 0.07844404782750602, 0.08030930831792116, 0.08951637703199489, 0.09501113259670124, 0.07629361798256562, 0.06909009725986359, 0.10011805696749143, 0.08012737155606442, 0.08365977486313947, 0.09676234890398538, 0.9076467325844689, 0.9436289072961669, 0.9206918974886313, 0.8624792044806572, 0.8744238280794214, 0.879773460890343, 0.9311933377121485, 0.9278949708948651, 0.9127505029655163, 0.20895970082865756, 0.20299554616608118, 0.2263552825872699, 0.25022696163322566, 0.21831112823837906, 0.21023202252031825, 0.23326963745172846, 0.2067169225212282, 0.2378665901598772, 0.27797479763586097, 0.24257146440304367, 0.2534474435833983, 0.26818716275726706, 0.2624775443924563, 0.19652652886318678, 0.2742556150698877, 0.22211109771936466, 0.28663688876877835, 0.11612679608646015, 0.07373047856719983, 0.11595715429603426, 0.07553042286321943, 0.1258284369046181, 0.12542300023992015, 0.12009283085784794, 0.0971390754878626, 0.14839177354585664, 0.12512536365574056, 0.12447405270240375, 0.11133787562296549, 0.1717313206587785, 0.13692355111804133, 0.1307174005746068, 0.10355913862660804, 0.12973219921935775, 0.12214645626777854, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.032116123723131884, 0.001357364386244675, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010070744139724419, 0.08252107890596527, 0.03977963878780466, 0.12868526606355335, 0.08078643168063604, 0.05891816375131298, 0.05690190893087643, 0.08862070000255551, 0.0701031222670272, 0.12790415787686182, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06291757068160131, 0.05811303127540268, 0.06808560832396038, 0.07228610599511665, 0.062129177479978925, 0.07847771389641767, 0.08849644882546237, 0.06128068331621084, 0.0631657077228791, 0.32441990377788466, 0.3335960787853611, 0.33379370345956905, 0.33719559530702903, 0.3481513547507429, 0.32251196335007526, 0.3517013262957872, 0.34357095070415333, 0.33667863599754744, 0.0923641250117031, 0.0891080672423159, 0.10977749957779337, 0.1100620531780403, 0.08905276247446103, 0.10566133251402776, 0.09871087189533811, 0.10518716053940702, 0.10204728679876407, 0.1717172764826873, 0.1378738581972493, 0.17372355947987594, 0.17844098508761108, 0.19741019191108178, 0.21412471766157726, 0.18353689106442972, 0.13513864362120875, 0.22385041741453282, 0.24078983378711005, 0.2495211195730327, 0.2470469209351952, 0.2383192463092687, 0.24610290152222836, 0.24381527916097456, 0.24150593186922364, 0.25354167830729624, 0.25265735468490924, 0.16153448123656577, 0.19228270365714273, 0.19833990739591778, 0.19640355077313065, 0.18695951029419677, 0.1829518658756134, 0.17584538812254924, 0.18612995471918203, 0.16781451794151014, 0.24306088127557646, 0.21663082056544247, 0.23384085627897233, 0.25194824922186565, 0.22718348426325063, 0.23087790167065636, 0.209754161242529, 0.21930718808863647, 0.2249557048756502, 0.17112269175184847, 0.1768341516147811, 0.1778244183186145, 0.19179519764888975, 0.19018385765536439, 0.18615912576036053, 0.20036340690991605, 0.19103830514927533, 0.17255172775803362, 0.4472341181562447, 0.18216048652213424, 0.46701432623741457, 0.497255813183078, 0.1951830757187658, 0.1924166748376407, 0.14013830851883302, 0.43394824694271106, 0.4442522029984578, 0.4243139629289613, 0.20655990888028386, 0.3567678703855136, 0.3051856379565382, 0.3394114948833893, 0.16673122361421955, 0.16615749882320308, 0.5036646725140181, 0.4224597414290078, 0.18066274969476925, 0.17885698538294892, 0.18577856065569587, 0.18153050905162726, 0.17517670665801777, 0.19948955856717754, 0.1767127238845927, 0.17729763678277344, 0.18622824903793578, 0.09566404121376126, 0.07757964529656003, 0.07809852848915977, 0.0866132947294096, 0.08164147811195366, 0.08313716340024746, 0.07633405003234672, 0.08877803268530282, 0.08890635495396015]}, "mutation_prompt": null}
{"id": "04ee5870-23c6-4deb-9aef-f0f9232afcac", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.chaotic_map = np.random.uniform(0, 1, size=self.dim)\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def chaotic_map(self, x):\n        return 4 * x * (1 - x)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Chaotic map for enhanced exploration\n                if np.random.rand() < 0.1:\n                    self.chaotic_map = self.chaotic_map(self.chaotic_map)\n                    self.particles[i] += self.chaotic_map * np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMCM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMCM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Chaotic Maps\" (HSO-ACL-OBL-DIW-SAM-CM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, a self-adaptive mutation strategy for increased diversity, and chaotic maps for enhanced exploration.", "configspace": "", "generation": 19, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'numpy.ndarray' object is not callable\").", "error": "TypeError(\"'numpy.ndarray' object is not callable\")", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {}, "mutation_prompt": null}
{"id": "94ac8563-3589-4215-ba6d-bfcc7271f6ef", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.chaotic_map_lambda = 4.0\n        self.chaotic_map_mu = 0.9\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def chaotic_map(self, x):\n        return self.chaotic_map_lambda * x * (1 - x)\n\n    def __call__(self, func):\n        evaluations = 0\n        chaotic_map_values = np.random.uniform(size=self.swarm_size)\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Chaotic map for enhanced exploration and exploitation\n                chaotic_map_values[i] = self.chaotic_map(chaotic_map_values[i])\n                self.particles[i] += chaotic_map_values[i] * (self.upper_bound - self.lower_bound) / 4.0\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMCM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMCM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Chaotic Maps\" (HSO-ACL-OBL-DIW-SAM-CM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, a self-adaptive mutation strategy for increased diversity, and chaotic maps for enhanced exploration and exploitation.", "configspace": "", "generation": 20, "fitness": 0.16549190632121824, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.15.", "error": "", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {"aucs": [0.32520448002325064, 0.3136911108064785, 0.29022526961535156, 0.31007825161344693, 0.31141221948022946, 0.33197795532123786, 0.3725267146989678, 0.31810817754704024, 0.32510718919806103, 9.999999999998899e-05, 9.999999999998899e-05, 0.0007872926892185106, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07655195372915136, 0.07025610916938962, 0.08672974255263288, 0.09043436777804414, 0.09414353549235088, 0.09385563915290662, 0.11010162067937912, 0.08647934189132489, 0.09148124100140576, 0.08480095941190835, 0.08045853666542857, 0.08031699790710589, 0.07178989747173414, 0.06814248151618851, 0.0853757450257866, 0.07944547011900016, 0.0677683190179067, 0.06429575418960254, 0.8635695439396758, 0.9570949000151445, 0.7631209278868102, 0.16572569698668704, 0.13349281869860807, 0.13430802686583243, 0.8745771800652524, 0.8769220489596768, 0.8800975983980344, 0.22737247362957158, 0.16664772149777252, 0.20618620516773867, 0.2120906177731653, 0.1782007267991581, 0.1716425032325677, 0.17312139117410785, 0.1690577211231843, 0.1743051948935983, 0.27417266292302855, 0.282064425380982, 0.2675909850492795, 0.2471189375486752, 0.23092866036325554, 0.18784986314259755, 0.17865743468097695, 0.172727235165827, 0.19147397397782528, 0.06518181605337581, 0.09053676545150868, 0.07920707142200756, 0.009504451867454411, 0.1015607580273854, 0.11523226116154694, 0.12755342552562832, 0.07869081240023568, 0.13901679673728262, 0.1127248677069409, 0.11038022241544931, 0.09386198683139213, 0.1250908790028341, 0.12765886420639194, 0.11098538649735723, 0.12565363104209515, 0.1331392796594033, 0.119162171785962, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010124843702585373, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0655565404433448, 0.039838916457483164, 0.0581153614118044, 0.08362272178090258, 0.07764224702621692, 0.05003113585269825, 0.05098969989289159, 0.046072411690862514, 0.09268565910791693, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.048193877424537956, 0.04983535202201006, 0.048719963723814375, 0.04162316613372752, 0.062471297454910424, 0.06079988809715231, 0.04557454952033457, 0.0640495214880149, 0.05970894286995043, 0.3471775012432219, 0.3147968808976259, 0.325721404565415, 0.32200937903340165, 0.3287089587917671, 0.3290549631732892, 0.33931725202613894, 0.3070201405841876, 0.32927029038784283, 0.08405809491093119, 0.08287839095189409, 0.07613662816449229, 0.09187823582818877, 0.06818907327691937, 0.08940166932430016, 0.09229364288069486, 0.09262795617604114, 0.09287040608330754, 0.1490822626957895, 0.14086603331237857, 0.15953903771702171, 0.15008718348541283, 0.16380046423068706, 0.13209561258876001, 0.13479231504133027, 0.13457867839485282, 0.17937599581340868, 0.24774106451772837, 0.24700784822512611, 0.24270659260628058, 0.22215858304101033, 0.2352413692741152, 0.2162477058130634, 0.1956644055570954, 0.23836401065988344, 0.2206758667774147, 0.18418617846187768, 0.1808448683005367, 0.15423926115293873, 0.18601432605572255, 0.1871085039232948, 0.17490493665893614, 0.15815387208638565, 0.18633987310812306, 0.13892404043622664, 0.23945770098799424, 0.23712969664650363, 0.2412318997119124, 0.23572773644026157, 0.19565561554794075, 0.2292777227255811, 0.241809606472128, 0.22402612258332066, 0.21936182203601762, 0.18339286629413942, 0.18479479743587124, 0.179613170242376, 0.16895664332112903, 0.17367369884740014, 0.17691681234448753, 0.1740128510732517, 0.1696831661216076, 0.18780105635551037, 0.16833194550395836, 0.16450757007548777, 0.18132302327467542, 0.17024230486465808, 0.1898379503611891, 0.14151431389495395, 0.13806221216988945, 0.14161788518508234, 0.16140798441517235, 0.35463449803910596, 0.16712064183250164, 0.27022223599466755, 0.3932382202140823, 0.3443038892187821, 0.16536693970186866, 0.35410307756603265, 0.4541548893213767, 0.346976182557716, 0.1812573745923004, 0.17747102295919615, 0.18084047010379445, 0.19588464278975937, 0.20797631411827577, 0.17559612540243275, 0.17917969136988499, 0.18135219961147853, 0.18609814328354346, 0.09575351601596338, 0.08193482013299724, 0.08215321978860102, 0.08564077819957161, 0.07562749960265991, 0.10111227260595934, 0.08135816798086615, 0.0866335063202256, 0.08178009989296375]}, "mutation_prompt": null}
{"id": "b9e69bde-1223-400e-b6ab-01b445957e20", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.cauchy_mutation_rate = 0.05\n        self.cauchy_mutation_scale = 1.0\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim) * self.cauchy_mutation_scale\n        return position + mutation_vector * mutation_mask\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Cauchy mutation for further exploration\n                if np.random.rand() < self.cauchy_mutation_rate:\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMCM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMCM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Cauchy Mutation\" (HSO-ACL-OBL-DIW-SAM-CM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, a self-adaptive mutation strategy for increased diversity, and Cauchy mutation for further exploration.", "configspace": "", "generation": 21, "fitness": 0.19273172708734926, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.19.", "error": "", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {"aucs": [0.35242566638903317, 0.3450919729617494, 0.34092078481758437, 0.34091466468684795, 0.3547241935701285, 0.33976108855958087, 0.34009272677160407, 0.3239601308847043, 0.3322242050922044, 9.999999999998899e-05, 0.01743549042221426, 0.011707549990205512, 0.0066212150845677, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11200884802442723, 0.09143143947128318, 0.09788232556518595, 0.10271280591169452, 0.0975169458011631, 0.1130887745702317, 0.0809394836182239, 0.12512012474707956, 0.12695113784537138, 0.08681554926360002, 0.06971953253377228, 0.07406908231725517, 0.08127022438307685, 0.09181188095721937, 0.07890862502441376, 0.08148016736889296, 0.05225371458896222, 0.08825780191798316, 0.9105082617060927, 0.9430143192049926, 0.9092491729942246, 0.868832329368341, 0.8646198565855485, 0.9238523754350283, 0.9396929749664222, 0.9371518816281892, 0.9137972136982968, 0.22301455747083243, 0.20986437812302194, 0.23031962062882672, 0.21159168076356705, 0.21428522075144718, 0.21369378140619677, 0.22253546909497235, 0.2452577202055639, 0.1965606000445398, 0.2615625449754574, 0.25462952350104906, 0.2669647404540647, 0.264737931347645, 0.25464293778044866, 0.23619127582073374, 0.2540547371795613, 0.265595947704389, 0.3042433905701052, 0.12808137106850315, 0.13330869128772815, 0.11640686148852997, 0.12587430666698152, 0.14003697149582328, 0.11596911859812375, 0.1273279481190862, 0.11831905898514428, 0.13556812188711187, 0.12612176693819488, 0.12027500242520106, 0.14845275701142724, 0.12314997618034307, 0.1239460974814508, 0.12865783184438373, 0.1383911883349156, 0.14496939324251545, 0.12589751792098614, 0.008640113706744001, 0.0005622533324882717, 9.999999999998899e-05, 0.005982554890103686, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11877197835773456, 0.0636678007394188, 0.09947919810581751, 0.05522397193595985, 0.03269733266259156, 0.022207757364102743, 0.09659278603443944, 0.05516899555581589, 0.08737889531891363, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07165197904986564, 0.06084244891828494, 0.06822892919922052, 0.05504114720452147, 0.06140324453175139, 0.04903338179162764, 0.054184494355980495, 0.06349192535007564, 0.059979402705387486, 0.34616749713194817, 0.3332169596036554, 0.35503149018497393, 0.3270610539888128, 0.3720688267728448, 0.3362628691489946, 0.32765192995288706, 0.3259055436766438, 0.3484181725034161, 0.0849563385842983, 0.10394897352131593, 0.10685512101639727, 0.09238178620980342, 0.1028472614481365, 0.09485500964443017, 0.10021218976938595, 0.10222456578430594, 0.08896171008066978, 0.14382553044213242, 0.17566513555847563, 0.12506460109711992, 0.16764128496809605, 0.1734230584474662, 0.2044544077258863, 0.16958745750854454, 0.1652597995553411, 0.1509022026815492, 0.26331325685871565, 0.2414287445443607, 0.2429653333654035, 0.24270725855036046, 0.2607206985431796, 0.24863583186284466, 0.2071751426392483, 0.2640624298169266, 0.2612161833052892, 0.20011274256044875, 0.18367541809699173, 0.18680791458752988, 0.20060236093631667, 0.1952038388660572, 0.1911627347613406, 0.17527650631464875, 0.18445806815311216, 0.1655065149051126, 0.228673600445486, 0.22071067509578068, 0.21929854270438742, 0.22951096886169087, 0.2303134120227548, 0.2367789709718381, 0.22059127634466114, 0.21345760968110594, 0.22033045168221765, 0.18451996415823746, 0.1870421941957764, 0.18165397206285794, 0.18917330620505668, 0.18835383495728397, 0.17197742459428467, 0.19280006618556667, 0.17120872429477763, 0.17327217270564066, 0.12679124197198222, 0.18268233912824883, 0.18118440655559176, 0.49635439368254675, 0.19515954575279304, 0.16567497572523537, 0.1393871181205203, 0.5916514307642353, 0.450726635974812, 0.4483905353064903, 0.20599767325455287, 0.4949192741250539, 0.4356760905341991, 0.16536553506158125, 0.16490923365641297, 0.16630548276693202, 0.36206491183526246, 0.4791212787761253, 0.17760171612920206, 0.18415203702560956, 0.1739256435419022, 0.17840436974226237, 0.19375286912685774, 0.18886376933734705, 0.185155938411251, 0.1727390795469146, 0.16997746259286706, 0.0854017712463101, 0.09039242757627985, 0.08141889052622409, 0.07702237507139598, 0.07466067306481194, 0.08384904947633698, 0.08085800011349453, 0.07802595513951416, 0.0902728287243455]}, "mutation_prompt": null}
{"id": "17658329-c8fb-4561-a42d-b75b6d64346a", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.995  # refined inertia weight damping ratio\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.mutation_rate_adaptation = 0.01  # new mutation rate adaptation parameter\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.mutation_rate += self.mutation_rate_adaptation * (1 - self.mutation_rate)  # adapt mutation rate\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2", "description": "HybridSwarmOptimizerACLOBLDIWSAMV2, a novel metaheuristic algorithm that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and a self-adaptive mutation strategy for increased diversity, with refined strategies for inertia weight damping, mutation rate adaptation, and adaptive cooling.", "configspace": "", "generation": 22, "fitness": 0.1657564327656035, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.16.", "error": "", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {"aucs": [0.3166950897736731, 0.29903072646811046, 0.32833235358512125, 0.3077125897161064, 0.3030870553202598, 0.30806665657608967, 0.32507162629023056, 0.3167232350943854, 0.34118533348037583, 9.999999999998899e-05, 0.00589989959619619, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0912982824730818, 0.11738314902582248, 0.07382988999975693, 0.09588065444403093, 0.06932956706738713, 0.08722050030688877, 0.08415101281640458, 0.06792394065634744, 0.07444933531955045, 0.0696271238898718, 0.08333828777526686, 0.07129687614687663, 0.09513410467846095, 0.0459929214621958, 0.06794759671518258, 0.06252879852440107, 0.053513813424925005, 0.06068461549597304, 0.7239095378692186, 0.9149114474021349, 0.8409237102731836, 0.5754515816200281, 0.7685557376819605, 0.6897688824276047, 0.8713680871521635, 0.8963153845357902, 0.880821250259193, 0.1871289942950478, 0.1638645818053548, 0.15580921589005647, 0.18424042525379924, 0.1494925352403227, 0.18020624425134446, 0.17877549645566893, 0.14248012726271586, 0.20789616618127493, 0.23027285078116166, 0.2690583514633972, 0.2434978866146723, 0.24836501367811825, 0.24281825627171605, 0.2147766219010664, 0.2002355321534074, 0.14949520018461093, 0.23625944859786263, 0.13025901440156362, 0.0642831556851986, 9.999999999998899e-05, 9.999999999998899e-05, 0.10733039981412928, 0.11400008721801991, 0.10947681330272696, 0.009651620278645856, 0.09401562432438804, 0.10514974730047033, 0.09099727527042611, 0.06045570477326434, 0.08912942927386047, 0.12380354257944515, 0.116721431860898, 0.10756488233022521, 0.1063716089238349, 0.10573908005475918, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08976610246704986, 0.04395565420692382, 0.05916243180160763, 0.04030845043739151, 0.052436053346089695, 0.048006523487516106, 0.07927576721661667, 0.034193279657142694, 0.05702443557310366, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0543150868497938, 0.04087440987785662, 0.03665738843506294, 0.041447988636745814, 0.03541650110292738, 0.04091459020303134, 0.03897140099803453, 0.05167036998314145, 0.04505171169731548, 0.3265508454748841, 0.30372810824022967, 0.309698452844956, 0.2973315284050386, 0.31335178198108826, 0.3223883864870587, 0.3202141690046033, 0.30891542549012696, 0.3477326484003671, 0.0634289532866229, 0.09664852740201335, 0.07480391871026681, 0.08417307004398211, 0.06709047080603248, 0.10158853667614387, 0.0805247519884208, 0.09054956632561095, 0.0856846784960108, 0.15157227151122987, 0.1662012103381496, 0.14540497319499301, 0.16211956688974238, 0.184750463982721, 0.16092927585264338, 0.15697449802426633, 0.1320946177988166, 0.17560879883395042, 0.22239196906811098, 0.22527383584102534, 0.24131750907751226, 0.23649802044610257, 0.22600883757307788, 0.2184209487680694, 0.24056974147915455, 0.2336432826325442, 0.18528865574233266, 0.18173844076845425, 0.17376306722733226, 0.17478737129828226, 0.1715623269964741, 0.17442158517656248, 0.17806277814988714, 0.15971270010819005, 0.18288908686349326, 0.1595929091398568, 0.19903789872611044, 0.19702728093025768, 0.20411043191180767, 0.21244051971574962, 0.21541491947276004, 0.22134803429016314, 0.21299385152897132, 0.1996173355020514, 0.24010858877453, 0.1740666770994661, 0.17724884328516455, 0.1710879721552654, 0.19151852005920678, 0.1905798298884993, 0.17081770261024298, 0.1802540315722304, 0.20773276292462217, 0.16767794685242965, 0.12646412827466902, 0.17676568662863124, 0.1830447709119709, 0.31929720452743304, 0.19224795087373847, 0.18213609684063536, 0.13730961350331983, 0.1457832885642507, 0.39967377677105453, 0.31299898039564333, 0.19717977380967344, 0.1292216111305674, 0.1982433541554336, 0.26838577727027313, 0.16524365544615338, 0.16479657806126213, 0.10306234953624427, 0.46678309187252576, 0.21025613822500988, 0.17737764832141945, 0.1784559349435445, 0.1907749881210048, 0.1887716072627097, 0.1879925804099991, 0.17662570448118076, 0.16520542110242842, 0.17160395700963527, 0.09141612002645416, 0.059509867056483756, 0.09061987850800546, 0.06602321488236962, 0.08337545150946768, 0.07459243503802082, 0.09527266409227708, 0.08851206315284255, 0.09204923751301264]}, "mutation_prompt": null}
{"id": "6a7f34aa-6c78-4db5-a567-9f4cb35a90a3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # changed from 0.5 to 0.4\n        self.levy_flight_alpha = 1.2  # changed from 1.5 to 1.2\n        self.levy_flight_beta = 1.6  # changed from 1.8 to 1.6\n        self.opposition_based_learning_rate = 0.25  # changed from 0.2 to 0.25\n        self.inertia_weight = 0.85  # changed from 0.9 to 0.85\n        self.inertia_weight_damping_ratio = 0.995  # changed from 0.99 to 0.995\n        self.mutation_rate = 0.12  # changed from 0.1 to 0.12\n        self.mutation_step_size = 0.12  # changed from 0.1 to 0.12\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.22:  # changed from 0.2 to 0.22\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMRefined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMRefined", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Self-Adaptive Mutation\" (HSO-ACL-OBL-DIW-SAM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, and a self-adaptive mutation strategy for increased diversity, with refined strategy.", "configspace": "", "generation": 23, "fitness": 0.1858422307378071, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {"aucs": [0.3341472742839652, 0.34967896626393036, 0.3474777573827672, 0.3259000566305358, 0.3177362899557449, 0.3609424739309973, 0.3357633443381688, 0.33854623251003524, 0.3264932379915185, 9.999999999998899e-05, 0.0016261454281398802, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09286539575687836, 0.08846555087531616, 0.09176436397994236, 0.08278130088779945, 0.08637314725858358, 0.08801557068830057, 0.09042783521728581, 0.0974270653385807, 0.11572982111524655, 0.07931185550468522, 0.0973109534478086, 0.08959238150935367, 0.08520054020227197, 0.05840195167916573, 0.08809027897304755, 0.09357240350060547, 0.08102175021513447, 0.07388577981040412, 0.8978728123408397, 0.9378376449293817, 0.8744854206950469, 0.8527416818292227, 0.8371071416316573, 0.8623765567489663, 0.9201774253636519, 0.926983101588538, 0.9030172688654781, 0.225078617302908, 0.22546044421630795, 0.20983442487256143, 0.20719849211695285, 0.20362125353701388, 0.22350057517591693, 0.20837255385941333, 0.21903660756929388, 0.2133943555291824, 0.2594949725586285, 0.28313405459343544, 0.27942451719623407, 0.27262916436040363, 0.25913275583459705, 0.2514332214831553, 0.22949921232391235, 0.23173761872083887, 0.2536985582000002, 0.12886458105374854, 0.10451313374432791, 0.1169020604943184, 0.09101020185748643, 0.1141257980738919, 0.11643252714448227, 0.1208970839224619, 0.1150582830615351, 0.1335336475221669, 0.12278687409058398, 0.12202110684803724, 0.12873607758558625, 0.13023995634622465, 0.1541961317952868, 0.11798211218648635, 0.11346012620894708, 0.13033903104607125, 0.09549214409283047, 0.008871492822009719, 9.999999999998899e-05, 0.0002543772942357192, 0.018478314173416943, 0.006957399485957638, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10583997025819936, 0.05474155485066601, 0.11673305266357803, 0.0652772966333236, 0.0949290107596178, 0.0501345129378451, 0.12938950666647975, 0.05636227790482551, 0.0556274887871403, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06123415647793429, 0.06145671138594788, 0.06948919889374972, 0.062075701654999094, 0.05362894577759958, 0.05567435016222222, 0.05471543203748952, 0.05933677199751142, 0.04611409482055895, 0.3260766694026903, 0.3290681762302684, 0.3309461118586351, 0.3203046593585104, 0.3247514238963498, 0.3570917879435941, 0.31662455363375164, 0.32612963664194317, 0.334509581830862, 0.08295149618711872, 0.09863852238827897, 0.10922217206363816, 0.09118505453139347, 0.10482711535102829, 0.11392271313367164, 0.09918427122117368, 0.09747136004487655, 0.10647375757491484, 0.16134730853196655, 0.1899867975445806, 0.1398515600568202, 0.16694856361343502, 0.1921390782869069, 0.18114753305206055, 0.15665590731299017, 0.16918205739396475, 0.1517566626910073, 0.24620023550941694, 0.2529438706291567, 0.24357500656881959, 0.24695862938414903, 0.23875046302124892, 0.2521988018329948, 0.2567503424245072, 0.24693318347237625, 0.2248076300359102, 0.17541987846296214, 0.18997227892246937, 0.20462711349440843, 0.20979589657855513, 0.20161831954799359, 0.19209113898622965, 0.19845483529303953, 0.1873714682535662, 0.1816715690149615, 0.21810791271026475, 0.20644257763353657, 0.2171846578918607, 0.22552650978062527, 0.22646011894988982, 0.2374532422393374, 0.2271985005587831, 0.2292564665906176, 0.22413475876822264, 0.18736449350151518, 0.16991848040365098, 0.1877736149690611, 0.17719768745176756, 0.20542194505823796, 0.1994608502408286, 0.19554490629390608, 0.19416723729369245, 0.1699619782584756, 0.18012159675583894, 0.18017046536072445, 0.14357115455313452, 0.5017758374778694, 0.19256631421075643, 0.19220733828291903, 0.13908399328425058, 0.1495833800082128, 0.4722171534288535, 0.43361417517663925, 0.20330773631619603, 0.3821180843107489, 0.20046264576380368, 0.16582309089307512, 0.16570640100771328, 0.16555050378058167, 0.11298338496847504, 0.36500395084791937, 0.16885509387382813, 0.17769985979279956, 0.18203363092066716, 0.19655656844678915, 0.194656164020389, 0.17923738703800396, 0.18907864910300742, 0.17536578452871932, 0.18216386753224345, 0.10835698826479567, 0.0896639756787927, 0.07785917386428698, 0.08684721849399069, 0.0926403276356561, 0.08663109208537867, 0.07575894938028271, 0.08018300594929528, 0.09241309088669203]}, "mutation_prompt": null}
{"id": "deb8a20f-c9bd-461b-8364-f7f3e6213be3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.cauchy_mutation_rate = 0.1\n        self.cauchy_mutation_scale = 1.0\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim) * self.cauchy_mutation_scale\n        return position + mutation_vector * mutation_mask\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Cauchy mutation for enhanced exploration\n                if np.random.rand() < self.cauchy_mutation_rate:\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMCM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMCM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Cauchy Mutation\" (HSO-ACL-OBL-DIW-SAM-CM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, a self-adaptive mutation strategy for increased diversity, and Cauchy mutation for enhanced exploration.", "configspace": "", "generation": 24, "fitness": 0.18943204672439573, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {"aucs": [0.33240493142805605, 0.32294017408225895, 0.3366317943295032, 0.35793740813377384, 0.3365756642560528, 0.3339992704031539, 0.340905602425997, 0.31729193782444753, 0.3427614791229041, 9.999999999998899e-05, 0.005827623499682688, 0.007070272196344374, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11648378153928207, 0.08794861987675306, 0.09243970992679729, 0.1214347971478612, 0.10059030158262516, 0.08657632302412366, 0.10629107647387714, 0.09938350274727803, 0.1095387668545782, 0.08571304939289548, 0.08385316137894516, 0.09379181745882947, 0.0903499696436908, 0.07961140360005359, 0.08565337216661606, 0.09307492811728024, 0.07535224731848666, 0.08666412120537537, 0.8975512767172635, 0.946527860700735, 0.8982645022746453, 0.8639351926528103, 0.8883961069931712, 0.8850652139553865, 0.9135908243029007, 0.9236507276253892, 0.9125523251750264, 0.20649219161820687, 0.22068106346913674, 0.20175822749838035, 0.21340776260404415, 0.24069767932875052, 0.22339125209907662, 0.2301924619344633, 0.20338368615058455, 0.20888974822906603, 0.29314620647965817, 0.29126244963955017, 0.2636017439704669, 0.2049752559670176, 0.25396665113155514, 0.22530050036466864, 0.2810652398546114, 0.2204711707689636, 0.25699849369461814, 0.12228716192814448, 0.11284265805245863, 0.11436001462788259, 0.08717751624862269, 0.11906560137654765, 0.11943310185793576, 0.12741503014515965, 0.0809797979697956, 0.15605199548191362, 0.1275486757887162, 0.1346972336194303, 0.115520413843889, 0.13382790983724135, 0.12639153808610448, 0.11550009129635852, 0.12246503883123439, 0.11850457999891095, 0.12004393044978934, 0.012152276915976423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002898963927845055, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08193121188901709, 0.05455837801610308, 0.08385564487617447, 0.06357712106517033, 0.056589761856244536, 0.05443673138068028, 0.06023666264962846, 0.11029566848617867, 0.06897474019659822, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06459653075448712, 0.06100967902616761, 0.07117247942009342, 0.060474947823904945, 0.05512768653218869, 0.06556119633626878, 0.056547012862530055, 0.06123543573256607, 0.04432216459437277, 0.3266411256616242, 0.33538886018916614, 0.3301476634029298, 0.3095170464983642, 0.3170588065054587, 0.3332442821898628, 0.32919307725147195, 0.329883797006291, 0.33414803749029975, 0.10329516129499339, 0.0971881837586368, 0.10574199209666424, 0.12583753723385094, 0.11410097285147713, 0.09534052338857468, 0.08473096984882245, 0.11132522248021415, 0.08765789134886659, 0.1332355545612106, 0.1638919186711133, 0.13535171400515866, 0.16671373587429938, 0.18705637004072817, 0.19322375294705996, 0.1789088609733428, 0.17795716326220756, 0.1788101824974616, 0.25727481426805965, 0.2469718228400326, 0.25031683473433797, 0.24850742837840134, 0.25759858136344616, 0.23788471347744344, 0.21524024555088894, 0.2443405694217039, 0.2360323898572031, 0.1935479404965479, 0.20246428399169536, 0.18789212281356427, 0.18200394436531087, 0.19188556784436528, 0.18329458722911485, 0.188519904816438, 0.19226432260831616, 0.16889127682387317, 0.2136028409987457, 0.22387377601951008, 0.24660803522891606, 0.20800983927687255, 0.22958034586124954, 0.22465033463249962, 0.22102418071287966, 0.22405320817931684, 0.21161645937138562, 0.18457592954387847, 0.18337090592787286, 0.19135622349459513, 0.2070462971622825, 0.18672598058565393, 0.18253965663384464, 0.16994350010352988, 0.18447771712346972, 0.1734705317045031, 0.18079809622743392, 0.18134444816130546, 0.5272082786398211, 0.43431771879912584, 0.1960810708619708, 0.19157127774642502, 0.1392785753712158, 0.1604673598449865, 0.43422597669424623, 0.39886168289836244, 0.20382591661222316, 0.4548445852219778, 0.3118734754545296, 0.3298607990373782, 0.16872270118337473, 0.16782558341062137, 0.3187230730643221, 0.3441586913431979, 0.1657349892102542, 0.17507710596069714, 0.1826050021054576, 0.19354821934896183, 0.22131340830168134, 0.17307825962457624, 0.17342588876843035, 0.17710150373291966, 0.177233698978987, 0.08451404318621758, 0.08774944707857102, 0.07930041888204031, 0.08654894979669625, 0.07559837365438093, 0.0727204870806174, 0.08961471536432508, 0.09672883896596429, 0.08011240894428284]}, "mutation_prompt": null}
{"id": "ba03d71a-8884-44df-bde2-5c7784a67351", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = self.chaotic_mappingInitialization(self.swarm_size, self.dim)\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def chaotic_mappingInitialization(self, swarm_size, dim):\n        particles = np.zeros((swarm_size, dim))\n        for i in range(swarm_size):\n            for j in range(dim):\n                particles[i, j] = self.lower_bound + (self.upper_bound - self.lower_bound) * (np.sin(i) + np.cos(j)) / (np.abs(np.sin(i)) + np.abs(np.cos(j)))\n        return particles\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMCM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMCM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Chaotic Mapping\" (HSO-ACL-OBL-DIW-SAM-CM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, a self-adaptive mutation strategy for increased diversity, and a chaotic mapping for improved initialization.", "configspace": "", "generation": 25, "fitness": 0.17191759983719887, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.17.", "error": "", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {"aucs": [0.32142015531237167, 0.3352843911039005, 0.3386720562828208, 0.30812494575005245, 0.3462626258743038, 0.3182972709455656, 0.33051440518569497, 0.34967777224824104, 0.3022520212285372, 0.032725844476896415, 0.010287871127518833, 0.010701953973740963, 0.002620843757208835, 0.019439292613737003, 9.999999999998899e-05, 0.016241143597427787, 0.014470337780062126, 9.999999999998899e-05, 0.0860886644285851, 0.07232931505572182, 0.0718278931676154, 0.09809896204443902, 0.09538854039979616, 0.1224499956550873, 0.07974184600540124, 0.08970487959723539, 0.07080914331239907, 0.08428985498998265, 0.06912151565259317, 0.07874598418020651, 0.05791550465057538, 0.0772644493277076, 0.0875035527876642, 0.0808544666636708, 0.06859040101617409, 0.0818850689053352, 0.8562910867779141, 0.8323573472610528, 0.8407117107474937, 0.7586221083739048, 0.8282389318534041, 0.782187969893796, 0.8340761635745166, 0.8292108013524229, 0.8438625158468919, 0.16439519630546473, 0.18582791533687304, 0.17520587633065898, 0.1932408026735033, 0.19474172298725967, 0.20865441677838514, 0.21201894203262128, 0.17821591417901872, 0.20810885552438363, 0.282077874601411, 0.2833150345430141, 0.29361110257864675, 0.24189623872913302, 0.2511804844243676, 0.2397672483411447, 0.24463496153550057, 0.24159862075771565, 0.2938116980902342, 0.13053195605672385, 0.1178729821185922, 0.124618649932277, 0.08811198507253792, 0.10998661802381071, 0.09091339300901724, 0.12018347068737856, 0.11728644311703451, 0.11260311910840426, 0.11923772569432645, 0.14000554122477515, 0.11948148402714376, 0.1371790607546518, 0.13903929004029925, 0.14087524796783946, 0.13844029761284204, 0.1483696381695241, 0.13720864993272497, 9.999999999998899e-05, 0.0073294513426884755, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08732843553836522, 0.1376301078185188, 0.03964442261162171, 0.03263168660077154, 0.015725576997941415, 0.007585317403944858, 0.05734075371151559, 0.02850400845578549, 0.018178873309447008, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0517465571826895, 0.04944691496722431, 0.06633374892896393, 0.05043228252506893, 0.0365796140933482, 0.0538536434893222, 0.05281033455229556, 0.04486678029524771, 0.061005093987818504, 0.3236905873648822, 0.31783527229699804, 0.3303312651283522, 0.31091704340999715, 0.302130629719604, 0.3193366586828207, 0.3292698391833828, 0.3298363616175407, 0.34412586808148893, 0.08822318114931349, 0.08529884142097854, 0.09172116484090387, 0.09301905637212604, 0.09825645492669433, 0.09527836618841634, 0.09448716896402021, 0.08255572023437485, 0.09731301279985105, 0.16260177383873597, 0.17080320930352244, 0.16562167502002956, 0.1643519876559878, 0.14084969273983572, 0.14216146190837753, 0.13854243205935723, 0.1355949036998254, 0.1336122557066346, 0.21674223577149154, 0.20923362533269163, 0.24836373918397758, 0.24826604476034597, 0.2506328399928075, 0.23521973636539129, 0.1786690699140756, 0.17814527013659698, 0.18288523677250934, 0.14109689732716546, 0.15594621651101404, 0.14358394519760842, 0.19996258636185793, 0.1951060288797486, 0.18022473448221277, 0.14411909789752209, 0.1443855357434468, 0.1489794817844422, 0.25788582823422734, 0.23767063335112415, 0.23229161689981714, 0.2524912824435659, 0.20806795828262925, 0.23316963662853163, 0.23721526860213182, 0.23458560625361868, 0.22326968910987544, 0.1833421392366461, 0.17302216271475357, 0.1688146747921384, 0.1778836802768441, 0.17841649210170785, 0.17057254420469892, 0.19785632545383647, 0.18934930618016432, 0.18670981581964408, 0.1653709852487687, 0.1760931506821546, 0.16261671116574783, 0.14588940642827852, 0.14448762292384876, 0.1554079857974744, 0.14186619443133675, 0.1427030401923064, 0.142569658481574, 0.10434402606761106, 0.1045593147410877, 0.10201422026179097, 0.10152913032958588, 0.10105893973240543, 0.40701860870023887, 0.11904247996188855, 0.5088192657758543, 0.40322993359717096, 0.18355773225363647, 0.1918294095481511, 0.17042830906422002, 0.1811461492327927, 0.18397367860142044, 0.18976167373780184, 0.17537786244414022, 0.1803439231598455, 0.18426373401788199, 0.08764906380934445, 0.09015386331668274, 0.08838046326725946, 0.08147407708170995, 0.0897288405628438, 0.09537121521626557, 0.07514675297398699, 0.08311789438085793, 0.08164971344058725]}, "mutation_prompt": null}
{"id": "c8456bab-e642-4794-bfc9-5971c882e3e6", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMGP:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.gaussian_perturbation_stddev = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        return position + np.random.normal(0, self.gaussian_perturbation_stddev, size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Gaussian perturbation for improved local search\n                if np.random.rand() < 0.1:\n                    perturbed_position = self.gaussian_perturbation(self.particles[i])\n                    perturbed_position = np.clip(perturbed_position, self.lower_bound, self.upper_bound)\n                    perturbed_fitness = func(perturbed_position)\n                    evaluations += 1\n                    if perturbed_fitness < fitness:\n                        self.particles[i] = perturbed_position\n                        self.best_fitness[i] = perturbed_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMGP(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMGP", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Simulated Annealing with Gaussian Perturbations\" (HSO-ACL-OBL-DIW-SAM-GP), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, a self-adaptive mutation strategy for increased diversity, and Gaussian perturbations for improved local search.", "configspace": "", "generation": 26, "fitness": 0.19031185314081053, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMGP got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {"aucs": [0.3546931635932148, 0.3288719691148818, 0.3215806592912178, 0.3500038154568579, 0.3430799466485349, 0.33775053013944867, 0.3190574470612263, 0.33447803306024404, 0.3418668456638434, 0.0013225916127481696, 0.0031124502995689696, 0.023577285846910545, 0.0003437525939565811, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11832159394720543, 0.09897899599669713, 0.07667096054748601, 0.08958609293628417, 0.09944345129572829, 0.09929097928636943, 0.0871178129122705, 0.09944827351138597, 0.0970123906704139, 0.08427797575703666, 0.08162151591060096, 0.09204163298546186, 0.09431646311333808, 0.07450781931637307, 0.0920286800128457, 0.102619728270123, 0.0849273185386864, 0.07577744368896766, 0.9178758066910426, 0.9426956587318929, 0.8982970400384473, 0.8695885831774304, 0.8770529975655907, 0.8510232276235868, 0.9395513834174722, 0.9389848638630046, 0.9092053479188145, 0.22283375782965864, 0.22573810922391113, 0.20378232913738292, 0.21694117375240307, 0.21314073371622055, 0.23176494711170392, 0.23746667919020548, 0.21335028489927998, 0.20525161521882496, 0.2807134195972546, 0.30258826878975364, 0.2388230725698277, 0.24457107331549433, 0.2780571040116887, 0.2252933887453863, 0.2892197402957344, 0.24792189455130476, 0.25261752921761393, 0.1161795720570743, 0.08596183353209053, 0.11418638236130796, 0.0922530938559526, 0.16002051794519723, 0.12167919725608423, 0.13523892388251335, 0.10799399577292934, 0.1246270504261705, 0.13288739816184592, 0.11412103917505445, 0.10777777295352475, 0.14638820456168466, 0.11990544494982647, 0.1253898055989332, 0.13693603325278436, 0.0811320009873594, 0.12384201060235123, 9.999999999998899e-05, 9.999999999998899e-05, 0.016045774464716667, 0.024219238326000037, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08433423193384193, 0.03775604022103163, 0.12608376816150613, 0.0992567261269598, 0.047770015504846164, 0.01146929282645015, 0.06548244104287437, 0.09937166674621145, 0.07942380922091685, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06373465998242422, 0.06089465957625939, 0.05750643248928822, 0.07109893883937335, 0.07945677505686222, 0.04267352271257363, 0.045059293346883744, 0.06001086903410846, 0.06822834623882923, 0.3280017102906738, 0.32600206545826305, 0.32595555141871, 0.32170304326525756, 0.33512574265996586, 0.3118111104981288, 0.32671652056517586, 0.3511633228561438, 0.34137106780269233, 0.09000155532567644, 0.0898646353589454, 0.09004414007299943, 0.09952116754378726, 0.09951513176177307, 0.09824553725527896, 0.09721162580922171, 0.10351379529801674, 0.08486349983856001, 0.14355598948286585, 0.1633423056460157, 0.15259994816030653, 0.15625482637243526, 0.1928934844735508, 0.2011878352756833, 0.21667506805201742, 0.18850791853111282, 0.16971204397604545, 0.25094942811905774, 0.2554311909532547, 0.24623604748606454, 0.24960736634008618, 0.25901730335649376, 0.2665886017156066, 0.25087927689916056, 0.26336186941055295, 0.24139809774361942, 0.17417041322639504, 0.18916622095882885, 0.2009625925904417, 0.19906362488062113, 0.19119581696148802, 0.18243177375041963, 0.18385653328663898, 0.198033418431376, 0.16985694336796298, 0.2250611626671618, 0.21478500705015546, 0.2413661900064048, 0.22375004832808187, 0.2372178112664557, 0.23145936434590797, 0.2475158665290378, 0.22007252192607074, 0.24265533537078354, 0.17538684663633208, 0.186974069647446, 0.17166712161129527, 0.19722385839203083, 0.1827511378139295, 0.1867724919988628, 0.18763289971971087, 0.1782108713006908, 0.17015633951846432, 0.17757332112599744, 0.12377339622565964, 0.45139780006397046, 0.16985523968848681, 0.1935316243529318, 0.19042927612616445, 0.13827418658251733, 0.2368515222644907, 0.4359437541136507, 0.4131695005190661, 0.20426251461862677, 0.40768915738250266, 0.3361232481625618, 0.43081164482085355, 0.1688363403215617, 0.16746859737970043, 0.32588479668436654, 0.41159941505911224, 0.17876092527798204, 0.1776620950461122, 0.17975926606161452, 0.18819359354128917, 0.20318701050383847, 0.18253693155715378, 0.23004838599005129, 0.18572949273193118, 0.17596963836641266, 0.07913176742297123, 0.08087198606376678, 0.07087592809495147, 0.10135409040944487, 0.08597755208587587, 0.08581761231622387, 0.08780550497950512, 0.08241433868519621, 0.07898828866683527]}, "mutation_prompt": null}
{"id": "f9af3cef-304d-4b20-a3ca-5dc378423c21", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMCM:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.cauchy_mutation_rate = 0.05\n        self.cauchy_mutation_scale = 1.0\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim) * self.cauchy_mutation_scale\n        return position + mutation_vector * mutation_mask\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Cauchy mutation for enhanced exploration\n                if np.random.rand() < self.cauchy_mutation_rate:\n                    cauchy_mutated_position = self.cauchy_mutation(self.particles[i])\n                    cauchy_mutated_fitness = func(cauchy_mutated_position)\n                    evaluations += 1\n                    if cauchy_mutated_fitness < fitness:\n                        self.particles[i] = cauchy_mutated_position\n                        self.best_fitness[i] = cauchy_mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMCM(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMCM", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Cauchy Mutation\" (HSO-ACL-OBL-DIW-SAM-CM), that combines the exploration capabilities of particle swarm optimization with the exploitation capabilities of a modified simulated annealing algorithm, an adaptive cooling schedule, Levy flight for enhanced global search, opposition-based learning for improved convergence, a dynamic inertia weight for better balance between exploration and exploitation, self-adaptive mutation for increased diversity, and Cauchy mutation for enhanced exploration.", "configspace": "", "generation": 27, "fitness": 0.19273172708734926, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMCM got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.19.", "error": "", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {"aucs": [0.35242566638903317, 0.3450919729617494, 0.34092078481758437, 0.34091466468684795, 0.3547241935701285, 0.33976108855958087, 0.34009272677160407, 0.3239601308847043, 0.3322242050922044, 9.999999999998899e-05, 0.01743549042221426, 0.011707549990205512, 0.0066212150845677, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11200884802442723, 0.09143143947128318, 0.09788232556518595, 0.10271280591169452, 0.0975169458011631, 0.1130887745702317, 0.0809394836182239, 0.12512012474707956, 0.12695113784537138, 0.08681554926360002, 0.06971953253377228, 0.07406908231725517, 0.08127022438307685, 0.09181188095721937, 0.07890862502441376, 0.08148016736889296, 0.05225371458896222, 0.08825780191798316, 0.9105082617060927, 0.9430143192049926, 0.9092491729942246, 0.868832329368341, 0.8646198565855485, 0.9238523754350283, 0.9396929749664222, 0.9371518816281892, 0.9137972136982968, 0.22301455747083243, 0.20986437812302194, 0.23031962062882672, 0.21159168076356705, 0.21428522075144718, 0.21369378140619677, 0.22253546909497235, 0.2452577202055639, 0.1965606000445398, 0.2615625449754574, 0.25462952350104906, 0.2669647404540647, 0.264737931347645, 0.25464293778044866, 0.23619127582073374, 0.2540547371795613, 0.265595947704389, 0.3042433905701052, 0.12808137106850315, 0.13330869128772815, 0.11640686148852997, 0.12587430666698152, 0.14003697149582328, 0.11596911859812375, 0.1273279481190862, 0.11831905898514428, 0.13556812188711187, 0.12612176693819488, 0.12027500242520106, 0.14845275701142724, 0.12314997618034307, 0.1239460974814508, 0.12865783184438373, 0.1383911883349156, 0.14496939324251545, 0.12589751792098614, 0.008640113706744001, 0.0005622533324882717, 9.999999999998899e-05, 0.005982554890103686, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11877197835773456, 0.0636678007394188, 0.09947919810581751, 0.05522397193595985, 0.03269733266259156, 0.022207757364102743, 0.09659278603443944, 0.05516899555581589, 0.08737889531891363, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07165197904986564, 0.06084244891828494, 0.06822892919922052, 0.05504114720452147, 0.06140324453175139, 0.04903338179162764, 0.054184494355980495, 0.06349192535007564, 0.059979402705387486, 0.34616749713194817, 0.3332169596036554, 0.35503149018497393, 0.3270610539888128, 0.3720688267728448, 0.3362628691489946, 0.32765192995288706, 0.3259055436766438, 0.3484181725034161, 0.0849563385842983, 0.10394897352131593, 0.10685512101639727, 0.09238178620980342, 0.1028472614481365, 0.09485500964443017, 0.10021218976938595, 0.10222456578430594, 0.08896171008066978, 0.14382553044213242, 0.17566513555847563, 0.12506460109711992, 0.16764128496809605, 0.1734230584474662, 0.2044544077258863, 0.16958745750854454, 0.1652597995553411, 0.1509022026815492, 0.26331325685871565, 0.2414287445443607, 0.2429653333654035, 0.24270725855036046, 0.2607206985431796, 0.24863583186284466, 0.2071751426392483, 0.2640624298169266, 0.2612161833052892, 0.20011274256044875, 0.18367541809699173, 0.18680791458752988, 0.20060236093631667, 0.1952038388660572, 0.1911627347613406, 0.17527650631464875, 0.18445806815311216, 0.1655065149051126, 0.228673600445486, 0.22071067509578068, 0.21929854270438742, 0.22951096886169087, 0.2303134120227548, 0.2367789709718381, 0.22059127634466114, 0.21345760968110594, 0.22033045168221765, 0.18451996415823746, 0.1870421941957764, 0.18165397206285794, 0.18917330620505668, 0.18835383495728397, 0.17197742459428467, 0.19280006618556667, 0.17120872429477763, 0.17327217270564066, 0.12679124197198222, 0.18268233912824883, 0.18118440655559176, 0.49635439368254675, 0.19515954575279304, 0.16567497572523537, 0.1393871181205203, 0.5916514307642353, 0.450726635974812, 0.4483905353064903, 0.20599767325455287, 0.4949192741250539, 0.4356760905341991, 0.16536553506158125, 0.16490923365641297, 0.16630548276693202, 0.36206491183526246, 0.4791212787761253, 0.17760171612920206, 0.18415203702560956, 0.1739256435419022, 0.17840436974226237, 0.19375286912685774, 0.18886376933734705, 0.185155938411251, 0.1727390795469146, 0.16997746259286706, 0.0854017712463101, 0.09039242757627985, 0.08141889052622409, 0.07702237507139598, 0.07466067306481194, 0.08384904947633698, 0.08085800011349453, 0.07802595513951416, 0.0902728287243455]}, "mutation_prompt": null}
{"id": "cd45f918-bfe1-4298-8498-cff5835f5e3b", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight and Self-Adaptive Mutation\" (HSO-ACL-OBL-DIW-SAM) that incorporates a new \"Velocity Clustering\" strategy to enhance the convergence speed and diversity of the swarm.", "configspace": "", "generation": 28, "fitness": 0.19552492464578564, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "9e101078-fd0d-4379-8055-484ef07848e1", "metadata": {"aucs": [0.33245762640896503, 0.3331776313798904, 0.3434592525523199, 0.3242984799437706, 0.36791707867748524, 0.38151320793789534, 0.3540898512442415, 0.39108043332523934, 0.32639762519030513, 9.999999999998899e-05, 0.010553265380115806, 9.999999999998899e-05, 9.999999999998899e-05, 0.004632277591584577, 0.0009380493196488038, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08949496910421895, 0.12199630356127855, 0.11423445456563386, 0.10872462931386562, 0.09867286020573829, 0.08996358343313116, 0.10332879468408684, 0.09253338425810054, 0.10060258296854918, 0.0880450670637829, 0.07874565190436733, 0.07739518335843054, 0.09132698340129541, 0.07727756528587892, 0.07092844818430877, 0.0914470999138135, 0.08948700622319139, 0.08121889653980341, 0.9170863316127524, 0.9485973470278739, 0.9077277429232746, 0.8735602490206024, 0.9073768177592764, 0.8776725221608022, 0.9410319765016097, 0.9247162078864329, 0.9197361378878481, 0.22840227255681067, 0.2094787309533367, 0.2271398837517724, 0.20177857820856682, 0.20092196162395248, 0.20963623014047728, 0.2152046704774333, 0.22745513885649504, 0.20330740515868517, 0.26413812786897584, 0.2636473260805491, 0.26377100149980726, 0.28124438882649716, 0.2267924535721857, 0.25606413903173886, 0.26409324269574286, 0.2205451231182718, 0.2771497139750113, 0.1232453445914018, 0.09078482214234551, 0.10960179156982908, 0.08159040756462432, 0.1472761550918149, 0.12568320464135452, 0.15567891200792605, 0.12775339346031211, 0.128571521045862, 0.15299759156447568, 0.12659888454298485, 0.11545275500837959, 0.12394446769292211, 0.12130501123985193, 0.13150829926541008, 0.13103272632666207, 0.07367272213163956, 0.10713827468768, 0.014754522893416278, 9.999999999998899e-05, 9.999999999998899e-05, 0.031868859867205, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0151358936898639, 0.09672292317227471, 0.04254371034736637, 0.055423095724659976, 0.11737004330485912, 0.1093267065527529, 0.03597363776719098, 0.11487539254814838, 0.07487437284664333, 0.06027115068361677, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06054598076025397, 0.06105087246701535, 0.055963293976221795, 0.07913283699884255, 0.05824996979400787, 0.07573981703453214, 0.06409702063547995, 0.061449307613933746, 0.05398364617939111, 0.33300545549143135, 0.34657274581036923, 0.35239091649155363, 0.3147351772683442, 0.33243316338025763, 0.3229889308668066, 0.34479704879706696, 0.3676171687081562, 0.3561559122518302, 0.11513863479402953, 0.09996523837158988, 0.08724988698398883, 0.08743298958788659, 0.07723409901157063, 0.11233918571969881, 0.1005262546612179, 0.1114357324809041, 0.08059693491200703, 0.17574587326268976, 0.1698337498678928, 0.12769739323483864, 0.19859685750004374, 0.20472890002284538, 0.17449427462292766, 0.17054480627280322, 0.15575580442901404, 0.17582070299854202, 0.23989927799357302, 0.2584081055311189, 0.2584033953729711, 0.24970712072010226, 0.24701650633456862, 0.2584158638011982, 0.25103754548676227, 0.24558335047782875, 0.25237757839016917, 0.188741983389073, 0.19222993311285552, 0.19427161958430827, 0.17937439968088342, 0.19676078919427675, 0.18699732527971558, 0.17192472421909477, 0.2049443032152105, 0.1515778123412601, 0.2314101623369319, 0.21445714824177264, 0.2200217967107756, 0.22841150204929805, 0.21075155635352816, 0.24287854381441576, 0.19782636935716602, 0.22113110469806674, 0.23827412117128421, 0.1748409005773437, 0.19444969407365442, 0.17085104729286904, 0.19625619665785554, 0.1853177457509554, 0.17944325660419636, 0.201107386688262, 0.17995370108962216, 0.17826475430483646, 0.4948491441090639, 0.18238373476943903, 0.45620825500815176, 0.511923328556787, 0.19072978608347313, 0.19379243588216644, 0.13956984409018425, 0.4935071576417901, 0.46440015228696563, 0.3733968791139811, 0.20242657283299448, 0.40890727716758235, 0.41785259038343947, 0.37063908849809546, 0.16685822042902054, 0.16794197708016312, 0.27529537520216496, 0.42874868131518573, 0.18209558058953068, 0.17159095538508895, 0.1802828545614117, 0.18255814990965247, 0.18952861213756655, 0.16955680659392725, 0.18097835653969763, 0.18547926933373815, 0.18682939297576617, 0.08720865796955146, 0.080591854694261, 0.07410542146651156, 0.09780025916895296, 0.08557083496652718, 0.08676692007052189, 0.08098517926485982, 0.0794413335957308, 0.09392702058675972]}, "mutation_prompt": null}
{"id": "ebcfdd98-be63-4d18-8304-750bbd4927cc", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2Refined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.centroid_velocity_clustering_rate = 0.2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def centroid_velocity_clustering(self, velocities, positions):\n        centroid = np.mean(positions, axis=0)\n        distance_to_centroid = np.linalg.norm(velocities - centroid, axis=1)\n        closest_particles = np.argsort(distance_to_centroid)[:int(self.swarm_size * 0.2)]\n        closest_velocities = velocities[closest_particles]\n        return np.mean(closest_velocities, axis=0)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                centroid_velocity = self.centroid_velocity_clustering(self.velocities, self.particles)\n                if np.random.rand() < self.centroid_velocity_clustering_rate:\n                    self.velocities[i] = centroid_velocity\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2Refined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2Refined", "description": "A novel metaheuristic algorithm, \"Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering\" (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Centroid-Based Velocity Clustering\" strategy to enhance the convergence speed and diversity of the swarm.", "configspace": "", "generation": 29, "fitness": 0.185370130004503, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2Refined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "cd45f918-bfe1-4298-8498-cff5835f5e3b", "metadata": {"aucs": [0.3367896898743785, 0.32169685485861277, 0.3262966078106424, 0.32785920572632454, 0.3201831723022247, 0.31146845851608307, 0.31559327059557785, 0.3266872687945058, 0.32714547694294216, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0877536472293512, 0.08080695746798994, 0.08669338033716412, 0.1047619348924016, 0.08988283169541578, 0.08486886545315153, 0.1019243005595376, 0.09996854963910862, 0.1002003449444131, 0.08547528076422528, 0.07568796913073583, 0.08528173024226071, 0.08113944135856999, 0.08357309086688236, 0.08355865340454238, 0.0766546716692974, 0.0786358366025861, 0.0957308158500606, 0.9143957976163324, 0.9531722422520053, 0.9265740575383377, 0.8398410051029898, 0.8511129721695029, 0.8758466058186156, 0.9017649548945785, 0.9406535843881635, 0.929248062996206, 0.2125073970592315, 0.1954058120648997, 0.20740989520325415, 0.2011659805720757, 0.20281523518841726, 0.21038894852680312, 0.25255821703473647, 0.22077033776610155, 0.19715859398774427, 0.23722959960232415, 0.2647082041025458, 0.2635586230472453, 0.24013368263912338, 0.27021452734398355, 0.20750604274992035, 0.27016588532852615, 0.24638981591829368, 0.26622330179883147, 0.1256887720054385, 0.06000533108565065, 0.09099917826973014, 0.04411785138165503, 0.10816483825874224, 0.11995722354788085, 0.1392307694743269, 0.09098982579781445, 0.1361857183639288, 0.1230004162289502, 0.14783340497283515, 0.13018932183797238, 0.1422814229269752, 0.11998944153640045, 0.12528051528218875, 0.12518951807091727, 0.11846332618116762, 0.16110380074785824, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0026971912921198715, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005209736362258965, 0.06766888658403025, 0.061136087048145105, 0.09260412388579786, 0.08446794714419414, 0.06027797818115954, 0.019757689433411496, 0.1142471151374439, 0.05580770446272365, 0.06341731220072233, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06440629669351672, 0.06771782569264484, 0.09545309611095942, 0.058634514311600494, 0.06881266793734253, 0.06548154421463914, 0.05503116545470421, 0.06817528429168251, 0.05157621805348811, 0.33776706873086937, 0.3232673959591672, 0.3388121086845848, 0.32032659183417045, 0.31097802011697573, 0.3258315442264169, 0.31690458131531607, 0.33378055881604873, 0.3255286764370475, 0.08757837154183401, 0.09217323652535636, 0.06438224637740986, 0.07591201541100823, 0.10859147242904765, 0.09781594605336286, 0.07335149238056715, 0.09971451788167396, 0.09983821460726083, 0.14430616670294438, 0.17972291360857962, 0.13491480607597928, 0.14880154421442804, 0.17266988069252653, 0.18432259521166594, 0.18872681144071635, 0.13471455944561272, 0.15499484880242564, 0.24860455529274417, 0.2594661939271691, 0.24642586334551086, 0.24400824854372294, 0.27965721350006134, 0.23493874072974275, 0.2524317922396435, 0.25232268897802, 0.2421511801998959, 0.18353172893901415, 0.17526287660883022, 0.20405846698014718, 0.18757035086761442, 0.18452980488461335, 0.1874858916640787, 0.1885504161863394, 0.19990557731815461, 0.1771758561543686, 0.21528593779972027, 0.21524218915754068, 0.21674560586450953, 0.2159029319160355, 0.23568670593387964, 0.23719092110993611, 0.222161180926008, 0.22355366210670724, 0.21790915135134759, 0.1991854784702095, 0.2056754591530443, 0.17267457691713572, 0.18359288589944078, 0.17900293780669163, 0.1938856002717131, 0.17774152716432856, 0.1768520859174565, 0.16787397121005831, 0.1806514575714887, 0.1808731981599614, 0.1795419133068652, 0.4166022122370938, 0.19291064524176083, 0.19436820089236018, 0.137812965469861, 0.4969658433229577, 0.16174391770825491, 0.35611002320667706, 0.16765019081090882, 0.4398821915410608, 0.19280765835601021, 0.332359629953196, 0.1649558797581343, 0.16415818802085835, 0.3138697101093638, 0.3712783632195693, 0.1989138545466842, 0.1750301119315214, 0.1905292733485232, 0.1886780972758927, 0.18639634401189997, 0.18241274741899494, 0.19132717223729567, 0.17511793602769798, 0.17911483593738975, 0.09784941440602868, 0.09446906679711442, 0.09194261025958617, 0.10066037557157814, 0.07759621883078704, 0.08330337752861672, 0.08907636329695923, 0.08998853838144116, 0.09404236271703337]}, "mutation_prompt": null}
{"id": "8cee53ee-f4a3-42fa-931a-b74322a7bd39", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PF:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PF(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PF", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm.", "configspace": "", "generation": 30, "fitness": 0.20505512053677463, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PF got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "cd45f918-bfe1-4298-8498-cff5835f5e3b", "metadata": {"aucs": [0.4568515066791925, 0.49052183301953967, 0.49358636326789485, 0.4285671283986293, 0.4481202839036236, 0.45976705761742565, 0.4625090311250506, 0.43562195479136645, 0.4652804392367146, 9.999999999998899e-05, 0.023804661015440653, 0.0008855658909869835, 9.999999999998899e-05, 0.10743250348160349, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10621831848543262, 0.10817635477090282, 0.12280900575643405, 0.11280020622950726, 0.08233787301074458, 0.08558812471953348, 0.09304024833684632, 0.13781639961506986, 0.10401482994440958, 0.08681319511359176, 0.08845212876593012, 0.1132363508276456, 0.08987805968060292, 0.10150499196517726, 0.08109189428711483, 0.10056997542999202, 0.08971756883172888, 0.051853471293234366, 0.8852112828383112, 0.9451142330630633, 0.913101395848823, 0.8812006603988715, 0.8941972270814091, 0.8797246103442246, 0.9379859863979558, 0.915166056275755, 0.9214545707390434, 0.26452640083482415, 0.25437408950690776, 0.26423464309884925, 0.2259839546095529, 0.22084300679049007, 0.26821007853588597, 0.2331140613509678, 0.2390244546996645, 0.24600891533967773, 0.23625597494300832, 0.3346168773033854, 0.24853567527180964, 0.2558710100500623, 0.3348521519404757, 0.24514112420950684, 0.2198070403823389, 0.22991916594995698, 0.3257712904270067, 0.16880064956747032, 0.12964617651279042, 0.13700722629532847, 0.10386081984413797, 0.12663961694006898, 0.123161401369287, 0.15767814879198594, 0.15624452821050816, 0.14547789642684916, 0.1522247501509033, 0.14645653320170482, 0.12326459822675229, 0.14648330204057036, 0.14414740988120034, 0.12661416154924898, 0.12923753493071066, 0.15408626417618, 0.14816425652117182, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.022266110516270032, 0.007211942580810371, 0.00012745083795284717, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10605566185140036, 0.0684365255815137, 0.12463199784885692, 0.06291930609038432, 0.07670014555639515, 0.030455989570876807, 0.11118288686052691, 0.05226807891480534, 0.09620953939654031, 0.004357245863876424, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007962162513172721, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0016600955649300753, 0.1424890303488442, 0.12149699483054832, 0.09102959320223103, 0.12432702037980148, 0.07066625713176822, 0.11270297307488386, 0.11924576341474147, 0.09448117684476398, 0.07482413297184498, 0.4213142192814101, 0.46883564920724907, 0.4093687414449191, 0.3978931884192066, 0.4073145536197458, 0.44861957303277866, 0.42138291460762745, 0.43469407485541545, 0.41647925260665575, 0.10289163562087256, 0.08789947122270236, 0.1327496865362605, 0.10516675889302074, 0.0995206883258839, 0.10598483555515159, 0.09385759436319718, 0.12426317858429325, 0.07835056766158466, 0.15302665004773786, 0.2230910010021543, 0.18478411719045518, 0.1669639437508016, 0.1870313194481309, 0.15297041794419963, 0.1811232031140767, 0.183458729907379, 0.19062155532451597, 0.29042658914267006, 0.30777794669582625, 0.29630416199910115, 0.3232984803656923, 0.27897871645384154, 0.2605847467897593, 0.2622312905555375, 0.2739852136895141, 0.2800626697335852, 0.22079887894723926, 0.23111211869328752, 0.2635126444827338, 0.20920272498686898, 0.21012174905800007, 0.22198841821922366, 0.20276228172359223, 0.20767748198819547, 0.19545166549924253, 0.2430082555895442, 0.23341775395029696, 0.2236270438093988, 0.22698754182459413, 0.2383017769740282, 0.22183375628669189, 0.25284806223987033, 0.2365084788032854, 0.2332772762648887, 0.1702424015012326, 0.1765181981714664, 0.1895236706540211, 0.26796446893588877, 0.1796824882917143, 0.18797587034401275, 0.1981639374913321, 0.18058463450722917, 0.17983793056846065, 0.12861221287041358, 0.18614405378570942, 0.18525648179608856, 0.17096742702440892, 0.1974293862544737, 0.16679545153058462, 0.14178701925327464, 0.16776081368196427, 0.1643667685725504, 0.4640037273392088, 0.1682220755262135, 0.4442318789896653, 0.4188973986868719, 0.16603464568934323, 0.16473870008854208, 0.16755749311699275, 0.28202411752459755, 0.16223930624218552, 0.17526030260606873, 0.18065394897515596, 0.1852198954651686, 0.1775805132237378, 0.17616439997622024, 0.19155374422044213, 0.19015389397771654, 0.19570977313095295, 0.1894854006466843, 0.08686021590010662, 0.12295686690450858, 0.09867284823513234, 0.09528684078062033, 0.07954797143862291, 0.08311557051819696, 0.10169696133284867, 0.08336895321773441, 0.08149351051322229]}, "mutation_prompt": null}
{"id": "2c1dd782-95cd-454a-88a3-6e1b48ca645c", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.swarm_restructuring_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def swarm_restructuring(self, particles):\n        restructuring_mask = np.random.rand(self.swarm_size) < self.swarm_restructuring_rate\n        restructuring_particles = particles[restructuring_mask]\n        if len(restructuring_particles) > 0:\n            restructuring_centroid = np.mean(restructuring_particles, axis=0)\n            restructuring_directions = np.random.uniform(-1, 1, size=(len(restructuring_particles), self.dim))\n            restructuring_distances = np.linalg.norm(restructuring_directions, axis=1)\n            restructuring_distances = restructuring_distances[:, np.newaxis]\n            restructuring_particles = restructuring_centroid + restructuring_directions / restructuring_distances * np.random.uniform(0, 1, size=(len(restructuring_particles), 1))\n            particles[restructuring_mask] = restructuring_particles\n        return particles\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Swarm restructuring for improved exploration\n                if np.random.rand() < self.swarm_restructuring_rate:\n                    self.particles = self.swarm_restructuring(self.particles)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, and a novel \"Swarm Restructuring\" mechanism to improve exploration.", "configspace": "", "generation": 31, "fitness": 0.20048402688004863, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.18.", "error": "", "parent_id": "8cee53ee-f4a3-42fa-931a-b74322a7bd39", "metadata": {"aucs": [0.45173584029566016, 0.4388177388077238, 0.45006296481529107, 0.4475944234938346, 0.4437806661704089, 0.44749378804339357, 0.44707851919518415, 0.46101632441470397, 0.43784982271494344, 0.0009478593490366283, 0.0005497453740074265, 9.999999999998899e-05, 9.999999999998899e-05, 0.0012337452189272735, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.094260151675996, 0.12353913349313439, 0.09113010893505069, 0.09962883218795415, 0.11711548505263236, 0.07560931460476805, 0.09728462210470823, 0.14297276352658828, 0.10710791668641373, 0.09586696095234115, 0.07656118618289443, 0.07096109062630074, 0.08726627497551909, 0.045585599573735425, 0.10573706755623058, 0.08854515175617839, 0.08358470251218808, 0.07698999543206175, 0.8910898485349378, 0.744634763417153, 0.8964554381954409, 0.824549495019917, 0.8013256918772264, 0.7739648352492169, 0.9078250809008434, 0.816521234014631, 0.9207664827822226, 0.27111391401693474, 0.2626609506463563, 0.24239055290306522, 0.25749640773469196, 0.2595280428719333, 0.26164318767381367, 0.25421186972925314, 0.24356257836131456, 0.24096406016728855, 0.22910375879890665, 0.22846171600063048, 0.20725465587437597, 0.2280820705158313, 0.23856617286988824, 0.2554033171841429, 0.3182869481144277, 0.2014311028726279, 0.2133372198148762, 0.12459135921008124, 0.11745506525702931, 0.14399168596201684, 0.15286906406853795, 0.18477326598380572, 0.21568379796494186, 0.14833107409040003, 0.18470539035364886, 0.14492501813840386, 0.16726523110228264, 0.17002383897466955, 0.17718362438483415, 0.1797832669418753, 0.15943648444449188, 0.16632095018617055, 0.16289592131926678, 0.1380987901993358, 0.14502022591940822, 9.999999999998899e-05, 9.999999999998899e-05, 0.03524586960661835, 0.007576867678007471, 9.999999999998899e-05, 0.012907503704758683, 0.0019141309909662674, 0.0003407574579723516, 0.014838977146437338, 0.10225181365123115, 0.05164768789312457, 0.11509024044956206, 0.07254255008979893, 0.054149725517257496, 0.025695496823465835, 0.045758189318863884, 0.062051728602003586, 0.038555148403881856, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1211954858431058, 0.0808146451977444, 0.07397786499848358, 0.0790621657132391, 0.11580553529377047, 0.07637615987296631, 0.11947068156690166, 0.11968513736861841, 0.10345038400310913, 0.40454798606380504, 0.4142363291707849, 0.41359344591819247, 0.3958806791793438, 0.3995795214490656, 0.3849265944633651, 0.3995596460508877, 0.42231591098565413, 0.41736515623753134, 0.07808146553072948, 0.08012741565537274, 0.06946665672822583, 0.07780041585000941, 0.08976020979578392, 0.10399565279113598, 0.09124581940891818, 0.13158281107074477, 0.0694046954531603, 0.15651604779787376, 0.2973703252503841, 0.11836790123490815, 0.14155343505427576, 0.15204524711813405, 0.248599296936714, 0.19537219144443274, 0.23019897710784476, 0.20082232833021973, 0.30681630714173225, 0.28024700965929794, 0.28843270873134574, 0.27134912848056925, 0.3271685963075176, 0.2585025940675183, 0.23814363907805025, 0.3140805936333052, 0.2268751208799662, 0.20668780555430832, 0.19024934526566517, 0.2583713489550403, 0.21131642264798578, 0.21961474454686625, 0.19892445168933814, 0.18046989490476084, 0.21136085377984304, 0.17060266528839096, 0.24383721784942003, 0.2522746964243511, 0.25843843100704067, 0.2627517929877877, 0.2594559894848216, 0.2616922611803665, 0.2753318401073134, 0.251958118661336, 0.24738999199305745, 0.19196547429949196, 0.18236695426462524, 0.18381408930599452, 0.20140169913783246, 0.21056801181080098, 0.17880159867807, 0.17482596194126054, 0.1899077930175317, 0.17204616583080856, 0.1868171845248897, 0.18640331512902963, 0.1856237371736259, 0.5914184866796784, 0.1986918847288951, 0.14764724813211882, 0.14060495043352406, 0.14773403864347168, 0.5958182541486615, 0.5417174458177005, 0.20551440073024196, 0.10646349365665886, 0.2032023539711978, 0.16314879806807225, 0.16383837148961067, 0.1634420840069588, 0.16525896196928969, 0.1636731935293727, 0.18631111733771044, 0.1815897777259563, 0.18079282223416138, 0.18717747899881365, 0.18503364826415358, 0.18126146737713877, 0.18302570860199463, 0.18100695042186754, 0.1836743991536468, 0.09232123211793719, 0.08777854124588469, 0.0719872734821283, 0.0923232889917448, 0.09318709084936128, 0.07044693143449399, 0.07426157673527001, 0.08934297331480445, 0.06955385073667819]}, "mutation_prompt": null}
{"id": "2a195867-4f02-4d70-a399-58542b304a3c", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.dynamic_particle_filtering_rate = 0.05\n        self.velocity_reinitialization_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def velocity_reinitialization(self, velocities):\n        reinitialized_velocities = np.zeros((self.swarm_size, self.dim))\n        for i in range(self.swarm_size):\n            if np.random.rand() < self.velocity_reinitialization_rate:\n                reinitialized_velocities[i] = np.random.uniform(-1, 1, size=self.dim)\n        return reinitialized_velocities\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate + self.dynamic_particle_filtering_rate * (evaluations / self.budget):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Velocity reinitialization for preventing stagnation\n                self.velocities[i] = self.velocity_reinitialization(self.velocities)[i]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy with an enhanced exploration-exploitation balance using a dynamic particle filtering rate and a novel \"Velocity Reinitialization\" mechanism to prevent stagnation.", "configspace": "", "generation": 32, "fitness": 0.19171463552451684, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.15.", "error": "", "parent_id": "8cee53ee-f4a3-42fa-931a-b74322a7bd39", "metadata": {"aucs": [0.5135591594035388, 0.47029453036227065, 0.5005741107866146, 0.494901905072777, 0.46655080244990854, 0.5197689868089659, 0.461481551904536, 0.4027115125111561, 0.4397152087137495, 9.999999999998899e-05, 0.010251835501555617, 0.0009630938456531846, 9.999999999998899e-05, 0.0034402376294939696, 9.999999999998899e-05, 9.999999999998899e-05, 0.0003215073707393268, 9.999999999998899e-05, 0.09927964240044562, 0.08454245395170434, 0.140050340888766, 0.08664538134601574, 0.09472446510368338, 0.10942021056335305, 0.1487217236497339, 0.10352775437426476, 0.0977550444789731, 0.08936901718714685, 0.10400893896494767, 0.08631959043074988, 0.08959713389016233, 0.08485520257728263, 0.09365899111311815, 0.09296337630496676, 0.0807377705104545, 0.08020604647258045, 0.5326958804099158, 0.7850922974380431, 0.4406367459878414, 0.30036432439259775, 0.3709184753099717, 0.21096752290539966, 0.7266228049973882, 0.6127926823315237, 0.5300777082886191, 0.22819706365974068, 0.24192032160549637, 0.22710462120218422, 0.25824335099495477, 0.2452200307366852, 0.24276918340267883, 0.23553123564801304, 0.23853767862460262, 0.23532951080980724, 0.29269618735206326, 0.2966714679544381, 0.223602144244185, 0.268354679806207, 0.31657771021220604, 0.20780984526719037, 0.19732184421694643, 0.2196274019431308, 0.2974887620220684, 0.15735643590041037, 0.10966317100071465, 0.11396788320291451, 9.999999999998899e-05, 0.13762891300457591, 0.22598020203942393, 0.14278708898031833, 0.10235126314143239, 0.14926788258398227, 0.14023212379345873, 0.1813303891863689, 0.16809506165555466, 0.1543027759274166, 0.15059719753202339, 0.16008569509675474, 0.14519618689214586, 0.1656171859540524, 0.18270355146545558, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007234281034959489, 9.999999999998899e-05, 0.0025621395508708122, 9.999999999998899e-05, 0.008269299098620841, 9.999999999998899e-05, 0.12501436793590492, 0.14524904594760335, 0.08070761867693277, 0.06016438420629033, 0.0682801189128659, 0.020792577302884307, 0.10905159121731955, 0.07663309714174105, 0.06546784040173026, 0.011681715195136722, 9.999999999998899e-05, 9.999999999998899e-05, 0.00032811350291972463, 0.0016136566851521206, 9.999999999998899e-05, 9.999999999998899e-05, 0.001162236829283958, 0.04103350465728217, 0.0817993976251804, 0.12072447614777626, 0.06464478357691428, 0.11964487631429199, 0.0993526695829452, 0.09117214919018146, 0.12201214702505692, 0.08358663297134827, 0.09735806442312966, 0.42839127971738455, 0.4413925471124932, 0.4007940456351533, 0.4043354677499458, 0.3979783727064785, 0.3851928769234362, 0.4199141099701722, 0.4461391270859776, 0.43065315526081294, 0.09217975704386061, 0.10880483203132807, 0.0993502845992803, 0.09278287941150498, 0.07179941711994764, 0.11344424676682707, 0.1092425080165742, 0.06888214633105982, 0.08488624188213123, 0.15669833333003358, 0.19051828286163397, 0.1930899113914747, 0.18645943351677619, 0.2644389331822765, 0.20360258876960047, 0.1435065098646996, 0.17113234240477704, 0.18793457544422898, 0.270467815100881, 0.27197105016268186, 0.326089190358132, 0.2911389442313106, 0.30388517896853573, 0.27743487536854283, 0.2379650808867233, 0.29284817870181856, 0.2196870110691017, 0.20597406879246072, 0.19260629981197464, 0.22996261676228424, 0.21344854443740224, 0.24347768796072122, 0.25160876364329354, 0.19544244521490928, 0.2077479404963083, 0.22058561566892376, 0.23613971043323678, 0.23275911692796336, 0.23926973530375362, 0.24002910825875745, 0.23229228823964687, 0.23452583943010719, 0.25001812001500845, 0.23278345983055837, 0.22591105937213873, 0.16982302229727098, 0.1807595639116486, 0.17520461659299835, 0.1783475224717498, 0.1891780091968548, 0.18491546077829846, 0.18419619321577807, 0.17527606889428493, 0.1894472376265569, 0.18543750314147245, 0.18543416100715404, 0.18632577945445972, 0.4820359922197395, 0.19860437741054515, 0.14941217279574026, 0.14010531622600486, 0.15554986475886112, 0.5342543827583097, 0.4529215964594553, 0.20736356502561615, 0.41901008624674396, 0.43353701492941055, 0.3686864950254184, 0.3638740785749207, 0.16697601539742046, 0.16428439876451106, 0.38379814691529623, 0.1967535810493498, 0.19796951135937957, 0.17148447300337122, 0.17151007733744916, 0.1733013844980651, 0.18077338561615075, 0.18646000139394647, 0.18968184092543394, 0.17594307509187257, 0.07742399090641972, 0.09229739279798832, 0.08694248312145425, 0.09102513506640186, 0.09224428135847662, 0.06675632924373154, 0.09840484904157543, 0.08111759469716928, 0.07750649226929562]}, "mutation_prompt": null}
{"id": "25e490a1-f0c7-487f-bdd4-f1ddab81c185", "solution": "import numpy as np\n\nclass NovelSwarmOptimizerACLOBLDIWSAMV2PF:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.probabilistic_velocity_update_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                if np.random.rand() < self.probabilistic_velocity_update_rate:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                else:\n                    self.velocities[i] = np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = NovelSwarmOptimizerACLOBLDIWSAMV2PF(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "NovelSwarmOptimizerACLOBLDIWSAMV2PF", "description": "Novel Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering that incorporates a new \"Particle Filtering\" strategy and enhanced exploration-exploitation balance through probabilistic velocity updates.", "configspace": "", "generation": 33, "fitness": 0.19607472491630742, "feedback": "The algorithm NovelSwarmOptimizerACLOBLDIWSAMV2PF got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.18.", "error": "", "parent_id": "8cee53ee-f4a3-42fa-931a-b74322a7bd39", "metadata": {"aucs": [0.40366651846895063, 0.42940400660984834, 0.38945342553694684, 0.44341090123892124, 0.37486823078122367, 0.4145658703370182, 0.40340131788499545, 0.4105144509420867, 0.40000425868699985, 0.0011069046423083373, 0.00036599626351130343, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.040876457267180366, 9.999999999998899e-05, 0.10671265979526745, 0.10796941692447404, 0.07634703272886234, 0.09618486518204772, 0.09642988712553324, 0.10990150496601947, 0.12177827409990039, 0.09244696690837295, 0.08698247908963508, 0.10272833428671657, 0.07340590620387011, 0.09534810654421566, 0.10210112497271295, 0.10240012662836939, 0.08285370696732275, 0.09477549682607511, 0.08145760017065495, 0.10401521188663554, 0.8764888265618558, 0.9166443214923312, 0.7958529211738368, 0.7848978739235903, 0.65953739821127, 0.7802510527782031, 0.9352684283752684, 0.8976599167311008, 0.8818700888653486, 0.220096616581809, 0.2319359353043574, 0.206999883607749, 0.24818522135535526, 0.2275452384941058, 0.20042197390961614, 0.24390504346981456, 0.21471552928193705, 0.2026459098093425, 0.21728685873535947, 0.23136434978792897, 0.22982812899155647, 0.20579594646809862, 0.2619200565464206, 0.19024121512107128, 0.224410753603969, 0.23879919324043963, 0.24262645379656966, 0.11381646842436277, 0.13627190823065227, 0.1186095311574411, 0.10239670270178414, 0.1325099479265206, 0.144140867262614, 0.13409909263351238, 0.1672758188405996, 0.12403799061004794, 0.13203458625614384, 0.12819470635810903, 0.12374111603053517, 0.13046780769730337, 0.12253985835879044, 0.129375117316333, 0.13347269578788057, 0.12252748984018325, 0.14538551646967868, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004473692321186218, 0.007779312544007877, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11271589197258258, 0.08014873095110309, 0.06723877258139765, 0.08277171916704662, 0.0690463552239482, 0.06069740649009636, 0.1161113931865726, 0.1176936025912173, 0.08385360737931713, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00020333822806584134, 9.999999999998899e-05, 9.999999999998899e-05, 0.09303647679961746, 0.059045835561401194, 0.07190368487801513, 0.08895284376367674, 0.12569311178881815, 0.08027483808212532, 0.06457777220008831, 0.04971970313453489, 0.07234872257967817, 0.3735024417367977, 0.39414018475563617, 0.3868061803780224, 0.36827893109570586, 0.3943370091454811, 0.3759890979563072, 0.3706404680283637, 0.390521803109665, 0.4068617320427744, 0.10389810496505048, 0.09779674673340955, 0.08732164176143165, 0.12205893567494464, 0.11474103469428887, 0.11642236222820301, 0.10789425414120724, 0.09671588647994467, 0.08489085364043458, 0.16240635063961217, 0.16566853320611807, 0.1361035603199542, 0.14372854930984735, 0.1542333622850378, 0.1541755025303273, 0.147978045293658, 0.1663774470859889, 0.18625810659175124, 0.26366562938587046, 0.30991132659531284, 0.2788428482883073, 0.2651982886146914, 0.2700871758995801, 0.2611801076070144, 0.2861178583787295, 0.2496547583425518, 0.22547911432353818, 0.19537870676885716, 0.21581382687770112, 0.22008512295520555, 0.2185360511211536, 0.20917651641283597, 0.24658735758368988, 0.19379922697108398, 0.1947934540013111, 0.20096139124212953, 0.20890916037242147, 0.23376715556897143, 0.257921626149341, 0.222721514274264, 0.22314253202636813, 0.21616531538394923, 0.2073849433155135, 0.22568264163077567, 0.2064804544512343, 0.19223630648062706, 0.16580537096294068, 0.16973900389688512, 0.180711182071146, 0.17399952652840966, 0.1640484038568586, 0.16616237493310893, 0.18087347027748435, 0.17149665971476624, 0.1841850962186825, 0.1832647750149763, 0.43122809895227643, 0.4015595050577223, 0.1945597917219818, 0.41081897263930234, 0.1394512746028549, 0.5619758792275846, 0.5531701934269753, 0.3258367559030707, 0.15112378193621845, 0.413025942885621, 0.3141619735724479, 0.1647603561212494, 0.1649563966358948, 0.16293392520449057, 0.16079524492923936, 0.37605931170812346, 0.20237062014839557, 0.22611937257159154, 0.18908220728159963, 0.18174686154979913, 0.16515607469954408, 0.21165091006176062, 0.1904805640608218, 0.18426105492836053, 0.17317298340557885, 0.08437931490722517, 0.0916489898843671, 0.07523564429815965, 0.0971276127667623, 0.08364368615160567, 0.08398413397465232, 0.10146778648375332, 0.09174887788140984, 0.07877687250174292]}, "mutation_prompt": null}
{"id": "12b53625-dd7a-4f49-921a-6d3aa29a24a9", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.evaluations_per_inertia_weight_adjustment = self.budget // 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight adjustment based on evaluations\n            if evaluations % self.evaluations_per_inertia_weight_adjustment == 0:\n                self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering that incorporates a new \"Particle Filtering\" strategy and a modified simulated annealing with adaptive cooling and dynamic inertia weight adjustment based on evaluations.", "configspace": "", "generation": 34, "fitness": 0.19950510855651873, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "8cee53ee-f4a3-42fa-931a-b74322a7bd39", "metadata": {"aucs": [0.4023612161356134, 0.42962356581689265, 0.4975397506669734, 0.4123157422592574, 0.45391379506450324, 0.4496461946162421, 0.4397389096223342, 0.41458292663165497, 0.41804265919344985, 9.999999999998899e-05, 0.030198776334981248, 9.999999999998899e-05, 9.999999999998899e-05, 0.08327860900503892, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12033296160643236, 0.10747070813279147, 0.12248650908029302, 0.10037648033012647, 0.1032050491690698, 0.11667245770028345, 0.11526953808640195, 0.11575011364585475, 0.09776372128172439, 0.07684446974935366, 0.09730993027518076, 0.07806675176481148, 0.09511959495820443, 0.10913805781573171, 0.1071924669926777, 0.08883459404006477, 0.08175660201936918, 0.07513965642158948, 0.8856725895448101, 0.9451638137747685, 0.9206515668335284, 0.8878947668544637, 0.8946692029487239, 0.8907439477759321, 0.9380971036734408, 0.9246449583217747, 0.9222644067884107, 0.24145677555623046, 0.24280747303796368, 0.22347752014445732, 0.22265285121780676, 0.22074269737691732, 0.2237322730797051, 0.23445385069020408, 0.21238625142127654, 0.2197857803599801, 0.2786420913302008, 0.32697485850030894, 0.2155185655820453, 0.22570593246128823, 0.35815927564345107, 0.20303054729590342, 0.29285946019367126, 0.2294544840408551, 0.322830353491101, 0.1426158328611924, 0.13274054226403842, 0.13942665574016955, 0.09453229646371164, 0.12777208573994903, 0.12108810551526805, 0.1475836161055527, 0.12349537395624643, 0.12433342009449388, 0.14718158833091388, 0.14121724670324964, 0.11614887433040944, 0.14786227542660468, 0.13095780639900423, 0.134559528594816, 0.12777717259634136, 0.14997523413298675, 0.15032552221817952, 9.999999999998899e-05, 9.999999999998899e-05, 0.013382418412029806, 0.04908447083283174, 0.011183402348466376, 0.0375255550424608, 9.999999999998899e-05, 9.999999999998899e-05, 0.0018042932082998897, 0.11915478809064517, 0.10591982255990573, 0.14682903824114368, 0.08908417535633473, 0.0708015527136362, 0.03767787992853899, 0.15900185713522152, 0.02818030308979924, 0.10608531325242077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11153770566916588, 0.10964095372466509, 0.08179915232924162, 0.08993860987248115, 0.07292680215372671, 0.08233726672611297, 0.06341486845942523, 0.06664629956119772, 0.07324160341336428, 0.37937371370898465, 0.41149356664492354, 0.3921648221309234, 0.3823608171022358, 0.39143084621176727, 0.37776655959956607, 0.4230837093923018, 0.39088940939673034, 0.40609310427045364, 0.10206482595620714, 0.08427308103714948, 0.06724108258906913, 0.11437529023343973, 0.08656619247812758, 0.0887959184429572, 0.08054950798468585, 0.10199944926391058, 0.08829904064559502, 0.16062241257680288, 0.2249198630503273, 0.16441381795156995, 0.14087436440885082, 0.17348060735820814, 0.164990778790428, 0.17755441294477547, 0.2032588010050751, 0.14744900185711196, 0.25644894890743786, 0.29041814583771286, 0.2861225845263856, 0.28403617519954627, 0.2935059364009448, 0.299052242706472, 0.2383117035908896, 0.26141222393219254, 0.27687974845485774, 0.23680039609302916, 0.23361960988832342, 0.2429164135184646, 0.2045407889195261, 0.21118845527011199, 0.21637622968281622, 0.1832856885272205, 0.23491540957526902, 0.18630355411308663, 0.1966665229625928, 0.24845650387860385, 0.2360445144736767, 0.23957578367388455, 0.21972355696368462, 0.21649465978341986, 0.2316196725534293, 0.23133589461059945, 0.2323953046570627, 0.17873952532081416, 0.19928110853374748, 0.18300414959897193, 0.19375291115471516, 0.1849106026808024, 0.18871619706316567, 0.23380279027702056, 0.17453593345616736, 0.1796829880534031, 0.12836242144973098, 0.1862405325775931, 0.18448399968650286, 0.17093170892815435, 0.19737344898968, 0.16694435153789655, 0.1418644982764572, 0.1680222686218089, 0.16447218869075164, 0.3607612289224742, 0.168215290599398, 0.5007489238041255, 0.34989098434453825, 0.16598114490844307, 0.16465759156504423, 0.16750205115105743, 0.25952995991639294, 0.16201624546491133, 0.17331482575910673, 0.18316377654685345, 0.1758747088642273, 0.20203146657730908, 0.17828992379404462, 0.1737063332301837, 0.18013156914174755, 0.1931883507397929, 0.177469127300654, 0.08802170473889859, 0.07926202613632172, 0.08482743314779384, 0.0903712757972005, 0.09205028513044566, 0.09612301810566792, 0.09537618496834821, 0.08909775816027832, 0.12831045281161946]}, "mutation_prompt": null}
{"id": "af913b57-d5f1-4bd9-9187-43425af0c951", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.probability_7_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_7_strategy(self, position):\n        if np.random.rand() < self.probability_7_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Apply probability 7 strategy\n                self.particles[i] = self.probability_7_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 7.", "configspace": "", "generation": 35, "fitness": 0.20715479594919065, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "8cee53ee-f4a3-42fa-931a-b74322a7bd39", "metadata": {"aucs": [0.425993039867553, 0.46804418549469784, 0.42456511294887933, 0.42743208549231515, 0.39400183563927516, 0.4166014966534334, 0.431333341971749, 0.3986324099494186, 0.4156197580274428, 0.016650683546122647, 0.0013049524013711844, 0.003382415690385443, 0.004573329856219388, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09497539753547424, 0.11154780064436476, 0.10160914492614026, 0.1065347101458376, 0.1029046586825183, 0.10113757808340684, 0.12075785467494826, 0.1220730299732864, 0.11928076926330833, 0.10752543628442601, 0.10750283905259239, 0.08631544668587376, 0.10183731982091326, 0.08833954086497087, 0.10203927607324825, 0.1122958534496471, 0.07342541620946463, 0.07336970125237607, 0.9052502871680005, 0.94414998703743, 0.8758322832878428, 0.9130434842640027, 0.8737362125378675, 0.888495279380789, 0.9294035172752377, 0.9004190646399993, 0.9101305614043775, 0.23007747023552105, 0.20560146585331884, 0.23125553621885908, 0.25587011444442653, 0.22559934635705714, 0.22236654088568386, 0.23407553109006596, 0.19546625698005227, 0.20617532360588897, 0.3211242905645144, 0.23726381497471472, 0.22312293939941696, 0.2734314879880356, 0.22792168119763279, 0.21483051304262746, 0.2618641052191416, 0.24429482157902283, 0.30094746938003003, 0.16112769227668666, 0.13494022729662192, 0.09649680335137656, 0.14120232290900625, 0.17058456182407933, 0.15964269412836385, 0.14971911790813008, 0.15785023381276808, 0.13719021886036098, 0.1226953297454173, 0.11760411351188871, 0.12319602052475676, 0.1574463518072582, 0.13437221691051215, 0.1275647227253397, 0.13439332516771518, 0.1292341059858525, 0.1438285753632612, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06845232745543184, 0.0021142945297492055, 0.032595383076371, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14152021750577592, 0.03516892204995925, 0.0881107958578885, 0.09898100534670629, 0.07163934711061015, 0.03500263652203828, 0.12020043099478661, 0.09093692275733334, 0.08520672129855411, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09420926963263032, 0.08566919258988348, 0.07904581734256566, 0.09762741451168822, 0.10704717995771407, 0.08484530204126983, 0.08847939243816239, 0.08658333911869465, 0.07965055157888967, 0.4263453078260815, 0.4138981818326418, 0.4073042662791113, 0.38432342096446626, 0.40117109243212523, 0.39743011227263714, 0.3881249956367395, 0.3820931612846833, 0.3929545120848106, 0.11031259415453809, 0.10728308918401419, 0.10034444577059476, 0.12155309402884906, 0.1325290340935682, 0.09651821245999148, 0.11829386076418091, 0.08606493465056009, 0.09403980322330285, 0.16537235713648113, 0.19062668467044386, 0.1401506731452773, 0.1616018776425453, 0.16756435697651817, 0.14899246162427449, 0.1711488828205634, 0.15992145024734838, 0.156961899592985, 0.2670577962763653, 0.24266463886930634, 0.3086197720811418, 0.29280710538749644, 0.2751348497291978, 0.2805218380590443, 0.21665958328949975, 0.2763561139495082, 0.25315572516638696, 0.21538807270261007, 0.172176348201038, 0.21571119273985073, 0.2269442450589686, 0.23600389827410329, 0.20480218254894644, 0.18797287381552608, 0.19767231953119413, 0.17701634951010237, 0.2164312486953177, 0.21675831162579096, 0.23050320807659086, 0.2183992261008465, 0.21182437881053517, 0.22333085605956327, 0.22930361814080302, 0.2468514189039518, 0.20789312072631605, 0.17386190879135388, 0.17450300361617754, 0.17755663330037785, 0.1912848280190539, 0.19567770922016092, 0.19101849918483804, 0.1948369969388727, 0.18622463519070098, 0.1790087050379816, 0.5677095936640548, 0.18472611743302847, 0.18601582039054942, 0.4542787838376682, 0.19542661737870715, 0.1145001233130657, 0.25156637087403755, 0.5667218220695545, 0.5275163770045215, 0.4843777505386433, 0.1684715044696461, 0.43530030366919303, 0.35611828630681464, 0.36055210240609037, 0.3162712661290028, 0.16579513937858226, 0.3489242089403124, 0.33556530430464304, 0.17612232030049668, 0.189360829832398, 0.18753461642068736, 0.17449779646275676, 0.19973433629249415, 0.190671813187826, 0.20388354507991457, 0.19152480247197845, 0.1827375178136802, 0.08507078583391503, 0.09741502486466158, 0.07861088453123666, 0.0778494239658527, 0.10307221245557341, 0.08658292736278794, 0.104441599602206, 0.0839845452024307, 0.0901145718079962]}, "mutation_prompt": null}
{"id": "d0f95aef-85e7-474c-9c49-089963365a19", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.probability_1_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_1_strategy(self, position):\n        if np.random.rand() < self.probability_1_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Apply probability 1 strategy\n                self.particles[i] = self.probability_1_strategy(self.particles[i])\n                # Apply a new perturbation strategy to further enhance exploration\n                if np.random.rand() < 0.1:\n                    self.particles[i] += np.random.uniform(-0.1, 0.1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1.", "configspace": "", "generation": 36, "fitness": 0.2058986723933595, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {"aucs": [0.42397217995100267, 0.40790800337546185, 0.4653927763467973, 0.40417473665015125, 0.3983764129943944, 0.39668448713966475, 0.4369709870916748, 0.4121423523489559, 0.4256196363918747, 0.03302774500568917, 0.011342712631275398, 9.999999999998899e-05, 0.010117577666172828, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.073184450209826, 0.11170000698361748, 0.09310686084183051, 0.0894189125907866, 0.0848122310187005, 0.11646107854743892, 0.116085704205099, 0.11923639495238658, 0.11121611482801141, 0.07041864708527501, 0.10028296657433822, 0.0972454791055758, 0.09989497320021035, 0.0741030113651846, 0.056356247660329095, 0.08950763442409138, 0.08129064277244491, 0.07978569690004456, 0.918983248755148, 0.9471385932906559, 0.8808092558287898, 0.8485178902057983, 0.8705182605644219, 0.8971622200227388, 0.921802992315089, 0.9260441507319682, 0.9105845904572308, 0.22885439985949407, 0.22348284129246743, 0.23126627778438325, 0.21771987355498623, 0.24229686171700904, 0.23381108971092046, 0.2230383654363164, 0.22897690361501144, 0.22364966326536628, 0.24946235986743426, 0.29122718475009146, 0.27400693665914, 0.21044804350180268, 0.23521638477581308, 0.20525999380138882, 0.23589814595542558, 0.22663866110034547, 0.2533562999289337, 0.132530217561037, 0.1324899680170385, 0.12795593387425963, 0.1278220434480969, 0.18231068430287245, 0.1605142699954638, 0.14983894284466115, 0.13904029923566052, 0.12792907319415847, 0.13589165902119038, 0.14964906202604378, 0.1274092987375658, 0.12517657083286882, 0.12875796627009417, 0.135607372971704, 0.12810872682148966, 0.13447854001082282, 0.1244629432480775, 9.999999999998899e-05, 0.012954443421252515, 0.0043428172652202335, 0.02007434002535846, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.023782812710556156, 0.13082694078891777, 0.06874898470075896, 0.10183629476887401, 0.1034434342851055, 0.06123506616943564, 0.04085816933324371, 0.1310444148998422, 0.10189962117718165, 0.04863522901253181, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08115335086163755, 0.09681288883768469, 0.095807599280059, 0.08487273096500048, 0.08855805322534138, 0.08982222614022572, 0.10244231084907895, 0.09710903803522253, 0.0914677294362839, 0.3895421157469515, 0.461782079793405, 0.42314416059073834, 0.4032325731576296, 0.3739528442823603, 0.40348569062176654, 0.3995150368278131, 0.3869347921052554, 0.4160312848327692, 0.10000218036960684, 0.10644240137233141, 0.11788429859854821, 0.10157371538954885, 0.12283145318536426, 0.10609506304195204, 0.09706965016521096, 0.08982385308396845, 0.09470832073294655, 0.17122870914402832, 0.15791168723428595, 0.11877956615871843, 0.14594858569117475, 0.19440875833127946, 0.17145357517169924, 0.21415428850068208, 0.20275140359539034, 0.1934820983556046, 0.25352570927226115, 0.2825677752819755, 0.29408579176468697, 0.28350156787810477, 0.2898618556119793, 0.28977117162893506, 0.24050966755414316, 0.29428146221093876, 0.2581858237229817, 0.20647293796990351, 0.19187338166729162, 0.20485202795636692, 0.22041176043842736, 0.20377620131402407, 0.2302579752173206, 0.16104395971056706, 0.22128857233551236, 0.16635724159555554, 0.2235407301408504, 0.23246744652530593, 0.2251101919244879, 0.20030877928802826, 0.21932701022325685, 0.2384719447568181, 0.22250827348817015, 0.22160220115981344, 0.2123497085235012, 0.17961295820271972, 0.17786657691338592, 0.17588657467566027, 0.18836167240875656, 0.19808988355437585, 0.17866504925433224, 0.17172805235354516, 0.18296883786143592, 0.17551209533652712, 0.548303643088967, 0.18558563102705028, 0.18523367984303063, 0.5484120938801591, 0.19682549960939888, 0.5431799126221033, 0.4777194286734333, 0.14967689765003755, 0.472956696232009, 0.37630736253863395, 0.2054213281592967, 0.35660899150869496, 0.2044010450055319, 0.30110531119625217, 0.16598760988193118, 0.19706745901716338, 0.3405607916869112, 0.43547919042281924, 0.1804201666507237, 0.1860955413972658, 0.18676011837860307, 0.1799679315606012, 0.1826890622912518, 0.19721569614577616, 0.18633268588811047, 0.18234133612473613, 0.18860516066528388, 0.09799041400948372, 0.08981273354292729, 0.09147561012785899, 0.08382077799163201, 0.08410701515282903, 0.08544138259862355, 0.10416496584026758, 0.09697811033016823, 0.1021786822147096]}, "mutation_prompt": null}
{"id": "b32e1f98-66a5-4e46-8867-858e8a25d7bb", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.98\n        self.adaptive_cooling_rate = 0.6\n        self.levy_flight_alpha = 1.2\n        self.levy_flight_beta = 1.5\n        self.opposition_based_learning_rate = 0.3\n        self.inertia_weight = 0.85\n        self.inertia_weight_damping_ratio = 0.995\n        self.mutation_rate = 0.15\n        self.mutation_step_size = 0.15\n        self.velocity_clustering_rate = 0.15\n        self.particle_filtering_rate = 0.25\n        self.probability_2_rate = 0.2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.02 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_2_strategy(self, position):\n        if np.random.rand() < self.probability_2_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.6 * np.random.uniform(-1, 1, size=self.dim) + 0.6 * (self.best_positions[i] - self.particles[i]) + 0.6 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.25:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Apply probability 2 strategy\n                self.particles[i] = self.probability_2_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2.", "configspace": "", "generation": 37, "fitness": 0.1879017345389272, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {"aucs": [0.36313580891459074, 0.4217929045772214, 0.38183510591080216, 0.37208438704364477, 0.3916357534034032, 0.41021022093378545, 0.395428913308428, 0.3646207688874632, 0.38304006489350273, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10136558551383967, 0.07110771239685287, 0.08865118587104504, 0.07455408661561491, 0.08769478780046669, 0.07861352647449726, 0.11401832186754834, 0.10709568685872894, 0.1286115224943415, 0.07613216897997865, 0.08191647812853009, 0.085650457263858, 0.07996735609874928, 0.07558354614379037, 0.0808281956178526, 0.06926748245539038, 0.07769374117590144, 0.08410199684366293, 0.9215626681081653, 0.947949117118046, 0.8975458042372134, 0.8704342687445767, 0.8635026982500855, 0.8898178798787683, 0.9220080173021946, 0.9299898832188246, 0.9317926139935788, 0.1946699702839243, 0.18676216962671044, 0.20127646699179735, 0.1873660118217536, 0.19789675818255614, 0.19409790167772067, 0.2056153545024766, 0.19071255728401348, 0.2137846674630598, 0.26366182377017733, 0.21012872210375677, 0.2169653066817555, 0.2605029937267762, 0.25865019269538836, 0.19935473494230882, 0.21935946196526068, 0.20463397734876365, 0.1966117794672213, 0.10699534398548072, 0.10997534553789734, 0.1241326834967893, 0.12036819254351194, 0.15179231020925854, 0.1333167786490672, 0.1366482654007366, 0.12901397452986585, 0.13329547354689986, 0.11452320774708169, 0.11378144777187515, 0.10971930560214571, 0.1341659519912286, 0.10852413975410569, 0.12016691449692318, 0.10923701333571478, 0.13650648577728297, 0.11354202298258076, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.017780949318252026, 0.0239788061151901, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09337690593422954, 0.059237870564140205, 0.1325998848140496, 0.07336729320809032, 0.05545570651649867, 0.038997561601401665, 0.061244260653146365, 0.04345388746047285, 0.08317870184991005, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08349817784828106, 0.08993300664477788, 0.07112718712649968, 0.07628913754520306, 0.0741265268788951, 0.06681107377568074, 0.05557179541627244, 0.06597092235195101, 0.07734460507149166, 0.3858347494886152, 0.36661180084016665, 0.3989766055755223, 0.37767511338762316, 0.36074775615627297, 0.36894390869457716, 0.38263720515745814, 0.3834919134332233, 0.3661178696717493, 0.10807953190965724, 0.09153364692778809, 0.07294607851801105, 0.09595781963242933, 0.10579009096137992, 0.1091830267941315, 0.09041864090161544, 0.11270749479952302, 0.08546031978699542, 0.13491087741573393, 0.1446685201849628, 0.12872770087142815, 0.15989363776834764, 0.15753115828960818, 0.14370999464431589, 0.13452426269423212, 0.14219505076183048, 0.1504341345441631, 0.26871785877747034, 0.26314059349589014, 0.2743434695397934, 0.24480947166932787, 0.26467943042345576, 0.2622623676831184, 0.20635203758587095, 0.2644750495633007, 0.2357955364330654, 0.19580533134175648, 0.18234646203704763, 0.18981402160267002, 0.19305233732823035, 0.20514209080751233, 0.23384592151180572, 0.17781813480609376, 0.1978488528280815, 0.14682172117571168, 0.221163809375583, 0.22359101635281797, 0.2363093833310681, 0.22750946038041697, 0.21562286926007546, 0.2060199288397615, 0.24526840926483662, 0.21465858556068795, 0.21401157779408875, 0.16870784640500547, 0.1796529855926441, 0.1770273298832009, 0.2110006921366121, 0.18646535286947952, 0.17911548153011647, 0.19071187144764679, 0.1798637533609896, 0.1851463092547383, 0.4660633897856795, 0.1847005799945508, 0.18578172151837868, 0.4413187328303282, 0.19090189859710294, 0.16481792313126753, 0.16441635671735677, 0.15974098521813362, 0.1607016727780045, 0.3538437672366588, 0.2506004544737914, 0.41049810146504784, 0.18147532819544454, 0.1646060265702507, 0.16659807256161308, 0.16557504812526547, 0.16328284239418878, 0.3717315441516378, 0.1900360800278471, 0.18780861301791563, 0.187118984106446, 0.17763716692196196, 0.17929336921050054, 0.17437816664762507, 0.1884208168094874, 0.19325567306650981, 0.1882056250603822, 0.08201249769090246, 0.08400146162589639, 0.07979762120277178, 0.07501338847976535, 0.11258095969595994, 0.07652961923049117, 0.08285482230440666, 0.08772326750879544, 0.08998513508133132]}, "mutation_prompt": null}
{"id": "24ca0850-002e-481f-a834-c5f0ab993837", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.adaptive_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.adaptive_mutation_step_size = 0.05\n        self.velocity_clustering_rate = 0.1\n        self.dynamic_velocity_clustering_rate = 0.05\n        self.particle_filtering_rate = 0.2\n        self.probability_2_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_2_strategy(self, position):\n        if np.random.rand() < self.probability_2_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate + self.dynamic_velocity_clustering_rate * (evaluations / self.budget):\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate + self.adaptive_opposition_based_learning_rate * (evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.mutation_step_size += self.adaptive_mutation_step_size * (1 - evaluations / self.budget)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Apply probability 2 strategy\n                self.particles[i] = self.probability_2_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2 using adaptive opposition-based learning rate, self-adaptive mutation step size, and dynamic velocity clustering rate.", "configspace": "", "generation": 38, "fitness": 0.20594681453194055, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {"aucs": [0.43604150760531857, 0.42809948868607295, 0.4131498635892735, 0.4045880977742693, 0.402764016868417, 0.46164965415930903, 0.4107596067728896, 0.4217784031999784, 0.4238708154989915, 9.999999999998899e-05, 0.0010607099920248997, 9.999999999998899e-05, 9.999999999998899e-05, 0.0018009132804123196, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09323159029242345, 0.10589727558364193, 0.10060498765801695, 0.10141007839146621, 0.12609562978692468, 0.0770589963173186, 0.0957709229303284, 0.11331982332982338, 0.11008579732676826, 0.07636409836702862, 0.08837076561217416, 0.07295053192694867, 0.0962232938085239, 0.07454688171165147, 0.09924638350915627, 0.10918942448000579, 0.08150461922849206, 0.07823597670359472, 0.907678567766074, 0.9445062044721003, 0.8892858160338604, 0.9121452724813133, 0.8732429261511712, 0.8896998019987994, 0.9287488259162986, 0.9230269226609149, 0.9111024832513485, 0.2223971980563233, 0.20552038552342078, 0.21787894243540773, 0.2171462366017034, 0.221003401219525, 0.2249480463450031, 0.21427682218531796, 0.19784185723057712, 0.2237140892039846, 0.2844340030392064, 0.29572226406519486, 0.23352678916792724, 0.26885076575460354, 0.2613190672142387, 0.22859068733888832, 0.31180168223053295, 0.21534405498937081, 0.2971987395672804, 0.13851255385085715, 0.13958237326583445, 0.09969598584985329, 0.12512450792003216, 0.17849109378075778, 0.13586461855717558, 0.13204762390462077, 0.14106225556706864, 0.12832503777830317, 0.11873888157561319, 0.10992990977657469, 0.14153631003714506, 0.13712760925785372, 0.12757432761347298, 0.1367585846539663, 0.12145172291806317, 0.11969927190408214, 0.12456166465503815, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03425259114613399, 0.030263097140205697, 0.006327870056050178, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10841865955061458, 0.07520684554163615, 0.08940011147873805, 0.11343957657193882, 0.06293805084031212, 0.012466768177803345, 0.15377022264528806, 0.07619325315748193, 0.09235630607346834, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08863701181314154, 0.07952324731868798, 0.09187001852606647, 0.08463020476861771, 0.0937401558554809, 0.09033728249544526, 0.10032390271099212, 0.092032420960514, 0.0869740211410408, 0.40502494003665823, 0.4229033477441483, 0.42632165807717215, 0.3515004662005906, 0.4075441280894839, 0.42503371195647544, 0.4196896504670874, 0.4061572022504766, 0.39579622417662585, 0.10436757504426863, 0.10943764335254058, 0.10195250768210407, 0.10191597449512502, 0.11730282716451623, 0.10569487400067934, 0.11784876237167574, 0.09281660633470856, 0.09492928469119577, 0.15844805864716816, 0.184188652502824, 0.1445746585512696, 0.16151639045991084, 0.18520891518959204, 0.16423869594088758, 0.17285440439666677, 0.17053603050456223, 0.16656787710551202, 0.2550262945388494, 0.2433337187495056, 0.2884877193751806, 0.27610069346067745, 0.2899661830914657, 0.28197658391556446, 0.22144593111756772, 0.28969074177290266, 0.24422910710091594, 0.20235462726192277, 0.20040874773014816, 0.22769711020665873, 0.2000309990280129, 0.2260404587034981, 0.185002948656377, 0.18001876975714026, 0.20226396328288276, 0.13689769241646843, 0.2286570377039323, 0.22932669997127086, 0.22291670008467168, 0.23888867474085596, 0.23194159607072706, 0.23629796002765857, 0.2487663136401137, 0.22911735981096681, 0.22085100740559627, 0.1718239022378093, 0.18208889898586944, 0.1782390455285029, 0.19497773063611756, 0.18349377818942725, 0.20080412747844234, 0.19582352951327098, 0.18152007842404994, 0.1772870153811682, 0.5222384060248213, 0.1849313723526821, 0.18599264625905554, 0.47927076105223354, 0.19393246710702994, 0.11438908442854678, 0.2771635492713487, 0.5415166734584345, 0.513628953868289, 0.42331441170158945, 0.1684402797907536, 0.42913996142466737, 0.4068637175398826, 0.36754993773971745, 0.3220902129903047, 0.1659524208016948, 0.27826085252414123, 0.3772315494629006, 0.1779002163786112, 0.18603263380243973, 0.17707019763513887, 0.17596495775457188, 0.18536247363700908, 0.1744356434393245, 0.2045531518184308, 0.18856623166102737, 0.1811002968546256, 0.08040713115156217, 0.09256326283263061, 0.07519099415515407, 0.08300302871314724, 0.11836468772471931, 0.08467737768448458, 0.08990546242567321, 0.089146943981263, 0.10218721789354313]}, "mutation_prompt": null}
{"id": "c73ef220-ee82-4939-9073-fddbc192766e", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.98\n        self.adaptive_cooling_rate = 0.4\n        self.levy_flight_alpha = 1.2\n        self.levy_flight_beta = 1.6\n        self.opposition_based_learning_rate = 0.25\n        self.inertia_weight = 0.85\n        self.inertia_weight_damping_ratio = 0.995\n        self.mutation_rate = 0.12\n        self.mutation_step_size = 0.12\n        self.velocity_clustering_rate = 0.12\n        self.particle_filtering_rate = 0.22\n        self.probability_10_rate = 0.12\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_10_strategy(self, position):\n        if np.random.rand() < self.probability_10_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Apply probability 10 strategy\n                self.particles[i] = self.probability_10_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 10.", "configspace": "", "generation": 39, "fitness": 0.20040571749081035, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {"aucs": [0.4229413390195984, 0.4225014731378557, 0.42894851002625023, 0.3891317844257429, 0.39388927264530516, 0.4077176002969898, 0.47717076589692575, 0.3897954089231487, 0.4337561125428344, 0.04416981847988333, 0.003558287641833857, 0.0016505293259891918, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0034799474091647964, 9.999999999998899e-05, 0.10575988764405797, 0.08169411443588537, 0.08861479318516796, 0.08277948879567198, 0.10303510869816923, 0.09709303424444715, 0.11138157670948312, 0.11070236116327437, 0.10151300805213526, 0.070195211667608, 0.10151892837260112, 0.07163132529825522, 0.08932934078495125, 0.0679020596908072, 0.10141846654107978, 0.09836585066848424, 0.097684542668104, 0.07659479499495792, 0.90738687867722, 0.9450945196475423, 0.8684035983033574, 0.8194904044885265, 0.8714499854029261, 0.9276644821943282, 0.9117902320530253, 0.9199214644910888, 0.9198048882628727, 0.2104366848421968, 0.21455559809549563, 0.23529991781124981, 0.2150049652412922, 0.20475742086916204, 0.2074397819969388, 0.24370662029410328, 0.1987345454035646, 0.21650947045464186, 0.2755769345024829, 0.33373302922581993, 0.26701404599227063, 0.24603034869479423, 0.20923877350670816, 0.3346274748765544, 0.19849962904099627, 0.26771677400823446, 0.24088151135589142, 0.10909496512043193, 0.11410569066060994, 0.1289472411459085, 0.12443991951987043, 0.1314601153604399, 0.13256246211391431, 0.14098862493277298, 0.10216301924437066, 0.13582023952045275, 0.11910356081335105, 0.12707138825025577, 0.13304838908668248, 0.1254985833767578, 0.14515455765395235, 0.12550720068332843, 0.12436283364118628, 0.1517395730223825, 0.14357440942457145, 0.009129081069376266, 0.002620174225606786, 0.0041373752969288136, 0.04400985060879048, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11028472667723677, 0.088671417058802, 0.09833019866957127, 0.10114862163591443, 0.09075602011272366, 0.031473105864529116, 0.14763698248744372, 0.08156735244927782, 0.13148316442363706, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08078036530393473, 0.07717675651685352, 0.08584793227052556, 0.061674612755660885, 0.08163455402389841, 0.06881283606347466, 0.10648031814491465, 0.06387971511425439, 0.06746899890083458, 0.39103170264409126, 0.3864957231739836, 0.4023311642972097, 0.3878142364738394, 0.3779961613531907, 0.3934296161827794, 0.3963484112500808, 0.389611957367761, 0.37532509872759734, 0.09751561656925223, 0.1033940693685037, 0.079660910393336, 0.09528431663157277, 0.08517177379686058, 0.13911888760247926, 0.10165397147328636, 0.11402846945662493, 0.08620531403416731, 0.13311361785578613, 0.147315099832658, 0.15238803447597693, 0.1579007414812178, 0.17631824293822707, 0.16465900255501253, 0.17282591378705214, 0.14255613516089982, 0.1663259120285009, 0.27363076080768156, 0.24390160702056107, 0.27741884760273794, 0.26984274524724927, 0.27326118264182664, 0.2761465332243247, 0.21667858216430447, 0.27202294385825876, 0.24307426065883442, 0.19429599739281, 0.20210887531944632, 0.23223201644632407, 0.23453497156339598, 0.17642801174581924, 0.22992693249895269, 0.20100352754723028, 0.20448739385918346, 0.17105167395757215, 0.21364524522227046, 0.2362329282144151, 0.2265762811521087, 0.23174910582686814, 0.2243259091112113, 0.24422445022715766, 0.2208630592628964, 0.21491699463110137, 0.23648807400141325, 0.19328678066263294, 0.16948674578380074, 0.20899272515982692, 0.18153053208121106, 0.1758755907778592, 0.18425725924155567, 0.17651690534163278, 0.17167500238383493, 0.1771017948249679, 0.535121615083399, 0.18595273759272068, 0.18574346801292152, 0.2894041242804942, 0.19633764956744792, 0.14299084231904946, 0.14038867661109766, 0.5790811438994083, 0.4807456751173399, 0.38548276832840145, 0.20370955808901647, 0.47037227189221886, 0.35547362764027024, 0.16556128024709638, 0.1670983959672292, 0.16430720865779203, 0.37708318298937826, 0.268811414651823, 0.1776410433182275, 0.1862551571079747, 0.19295134843226502, 0.1680171876070462, 0.1811937652150486, 0.1829689924763669, 0.17870792492881193, 0.18409491557928892, 0.18418284842988542, 0.07198882057137523, 0.11361082743034279, 0.08763947420661733, 0.0921737781575912, 0.09267788786582676, 0.08793498434569169, 0.08388152512184965, 0.09540363317982958, 0.09879121835328719]}, "mutation_prompt": null}
{"id": "7e9c8abe-b50a-4416-b068-9e81b1492cc6", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.probability_1_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_1_strategy(self, position):\n        if np.random.rand() < self.probability_1_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Cauchy mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Apply probability 1 strategy\n                self.particles[i] = self.probability_1_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget)) ** 2\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, using Cauchy mutation and a novel adaptive cooling schedule.", "configspace": "", "generation": 40, "fitness": 0.20461746832890804, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {"aucs": [0.425982494011206, 0.44062892321773994, 0.4908113252244686, 0.4182409154641522, 0.3962873513751495, 0.4115226324952187, 0.40297753718445406, 0.43160801980850616, 0.4342756755818341, 0.010269990128131234, 0.019545217080989108, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11537127179424223, 0.10587931106534487, 0.1166050321065002, 0.10357093254823924, 0.09256500467954887, 0.09416464993543672, 0.12203733075701928, 0.12804699516624585, 0.09935112494346099, 0.0751517518660697, 0.07865737248729687, 0.0747257313398253, 0.09026040643502165, 0.101161071660271, 0.08908141205731224, 0.09457570395422676, 0.08700290187470294, 0.08523323928513149, 0.9151144204435582, 0.9370477253537365, 0.8832976851679104, 0.8499586907932071, 0.9005274552013485, 0.92227405168193, 0.9349824710844702, 0.9544039595818052, 0.9123201924604952, 0.20905313648976898, 0.21872896625418947, 0.20769812118200015, 0.2134947391884402, 0.21841544605487362, 0.21724105089485657, 0.2114988338482181, 0.226333322997739, 0.2114689595277398, 0.2316820127213698, 0.3121717739233909, 0.22514463143337704, 0.29573779012981805, 0.27103444817831535, 0.2036008678711213, 0.30803103278959665, 0.3024188126789942, 0.26528662924020074, 0.19161689311284824, 0.11596854808185308, 0.13807506261199853, 0.09813605755528465, 0.1496466017569884, 0.13073575569319895, 0.15398879616726413, 0.14017440283704252, 0.14845888516822436, 0.11834563035573686, 0.13937483412392426, 0.12930920258281298, 0.13913298853526557, 0.12806572254724724, 0.15010393262861377, 0.13130289944971552, 0.12543702596027584, 0.12964910661529416, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0024843159488402433, 0.0008554481576596995, 0.019506379499591775, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1681719142337459, 0.08041538169070772, 0.09967544931355876, 0.07237311283067416, 0.03649839409593081, 0.03468060858483257, 0.08780549205205812, 0.08728764617936235, 0.11124636315957126, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09578685587449565, 0.10061097938890073, 0.07512113464154224, 0.06956618979348428, 0.09761585692503483, 0.06152881282558287, 0.1045391757728974, 0.07648814038430596, 0.10575271875928594, 0.3839778260539559, 0.40348383977102986, 0.40886635234685975, 0.40581022781813403, 0.38177232342702994, 0.4026109418276814, 0.407510487199506, 0.3892202967805918, 0.41580266532812193, 0.11197193120736704, 0.08907851835068537, 0.08210329418987439, 0.09030214381916613, 0.11039046177515177, 0.10348129243109527, 0.12847579811031407, 0.09199101262578202, 0.09888928672118413, 0.17261344503371767, 0.21241520286793925, 0.13226585487730957, 0.15053198075233287, 0.15688429090234934, 0.1577364373841842, 0.15772225615954139, 0.14793449096284583, 0.14790837698276904, 0.30086707939804336, 0.2916662829024904, 0.27185151109591554, 0.2800908423780274, 0.28677015488387747, 0.25113095918437145, 0.24943715789884402, 0.2694129350574228, 0.23550520497464222, 0.19934592381262162, 0.2012229904230357, 0.23764228001590904, 0.221374992905226, 0.1978251425963683, 0.22852831525894668, 0.18926950030940792, 0.22403321102907803, 0.17067722549465125, 0.21897252753333685, 0.22648999242931367, 0.2520198398529996, 0.21952536247065224, 0.22613719996022397, 0.22021302291168365, 0.22413266122727937, 0.22258738557355373, 0.2419759935471889, 0.18791767928239111, 0.17319341335935767, 0.18900642611157514, 0.18282302716632892, 0.1741327121015882, 0.18313927977085187, 0.17559970089198673, 0.18632474743236394, 0.1716185852833907, 0.183974047383628, 0.18455461881897295, 0.18541563419579865, 0.17104289618149982, 0.1973050944374778, 0.19398971016468192, 0.4296732555057623, 0.5572259618846405, 0.5050741845528739, 0.3908818823537813, 0.5366212516119135, 0.46598028151026993, 0.3332695896582961, 0.1647887837605433, 0.1656624667800648, 0.1657521939881531, 0.27313792011473625, 0.5127476974558585, 0.1785028080389489, 0.17542511344834744, 0.18115826715099526, 0.18895151170508384, 0.19055692822056036, 0.17336712375327823, 0.1928940319747885, 0.18436082180656754, 0.1793358019181276, 0.08337016619519633, 0.08164151362218797, 0.07802692168840353, 0.08699842657944323, 0.08036199107348041, 0.09475099350313998, 0.09433628142147099, 0.07724020169749524, 0.09249321406033484]}, "mutation_prompt": null}
{"id": "7076e3f9-149e-4aa2-8bf3-2321dd0ab61d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.3  # Changed from 0.5 to 0.3\n        self.levy_flight_alpha = 1.2  # Changed from 1.5 to 1.2\n        self.levy_flight_beta = 1.6  # Changed from 1.8 to 1.6\n        self.opposition_based_learning_rate = 0.3  # Changed from 0.2 to 0.3\n        self.inertia_weight = 0.8  # Changed from 0.9 to 0.8\n        self.inertia_weight_damping_ratio = 0.98  # Changed from 0.99 to 0.98\n        self.mutation_rate = 0.2  # Changed from 0.1 to 0.2\n        self.mutation_step_size = 0.2  # Changed from 0.1 to 0.2\n        self.velocity_clustering_rate = 0.2  # Changed from 0.1 to 0.2\n        self.particle_filtering_rate = 0.3  # Changed from 0.2 to 0.3\n        self.probability_7_rate = 0.2  # Changed from 0.1 to 0.2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_7_strategy(self, position):\n        if np.random.rand() < self.probability_7_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Apply probability 7 strategy\n                self.particles[i] = self.probability_7_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 3.", "configspace": "", "generation": 41, "fitness": 0.1879870884485435, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {"aucs": [0.4283437503761396, 0.3573472031367221, 0.36591932307325703, 0.35300194095741666, 0.3679144461338315, 0.38243757603013084, 0.34843343889714107, 0.3755436058014314, 0.4024498661053887, 9.999999999998899e-05, 9.999999999998899e-05, 0.03507236427966198, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10538325865095033, 0.08593742445732755, 0.09206275216264881, 0.0919691740223163, 0.07256547933791568, 0.09856624438811634, 0.08781153603782188, 0.08935451889599522, 0.08194132828813927, 0.08676823486991836, 0.0811288822026941, 0.0813359684660323, 0.09730691109849454, 0.051219265892336496, 0.07433060553844972, 0.08722460349743522, 0.07465457188918967, 0.11710606432519421, 0.8851840225109291, 0.9214698507341441, 0.8385731526909448, 0.7879586507594522, 0.7794166467713992, 0.7574882808030543, 0.9171609537972876, 0.8833121018935883, 0.8851966088809199, 0.20847407059946932, 0.19309879666284913, 0.2072644067410303, 0.22007438850586636, 0.21332514875625097, 0.21653997524581148, 0.21522408837363294, 0.22190731803653752, 0.21140908071888065, 0.22241929086288903, 0.2983882384630838, 0.20715099281458083, 0.23731371562087689, 0.22040626024072185, 0.27722581812719094, 0.22791773210809285, 0.23286070460586206, 0.19733639742361897, 0.11753265738206042, 0.11045974665007374, 0.0845295539492561, 0.0757984590643902, 0.15165155680928177, 0.12517272976896654, 0.13976588345057028, 0.10654007967872381, 0.155629569864983, 0.12807296872305085, 0.1252724214875801, 0.12294986809239639, 0.11757618194373298, 0.13445222151038394, 0.1271890575351614, 0.11801365123851792, 0.11810379994777431, 0.11587977075713751, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.018267046954353883, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13508568201367777, 0.06283382421324535, 0.1134601430339901, 0.10797806458051129, 0.05009454994127116, 0.03770611589180184, 0.08205256899351276, 0.07729011916785389, 0.053211237417476354, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06571850990143391, 0.06346933052242532, 0.07381130270077574, 0.06058704117577962, 0.08280406734737789, 0.049344433219403405, 0.07486233543525345, 0.058575952092358774, 0.059315857112352766, 0.34324884003150313, 0.3625788803381109, 0.3455085508860546, 0.34038906331628993, 0.3299647087215992, 0.3386063729704524, 0.3592879548474319, 0.38967324602740117, 0.3985410350235884, 0.08484631902201889, 0.09949019014726035, 0.08101576044041048, 0.10097771255978205, 0.07082772970646656, 0.09764649737264297, 0.09223899861930929, 0.10211520158810983, 0.1112955018870998, 0.17641815568240204, 0.1547340421585366, 0.12330951057988004, 0.14021415040598117, 0.15625447675048476, 0.15617323303722952, 0.16282208261539022, 0.1702290843947012, 0.2080115113019354, 0.24135018818167797, 0.2618172597557966, 0.24377530047320073, 0.27099175710321266, 0.2594949963258225, 0.23800078146634562, 0.2619001617306115, 0.2506676307526243, 0.2759986229470772, 0.1728409128272793, 0.1762035843422436, 0.1978899398733428, 0.1980852447116931, 0.22861645807720032, 0.20104423174560504, 0.19781952818427495, 0.20650505796887453, 0.18007800187060496, 0.21699562495401792, 0.21704459690853062, 0.20500436637261688, 0.2286399018616586, 0.21723262170460855, 0.259539469506051, 0.23922640260893235, 0.21126557560301695, 0.26020723618800956, 0.1789190136787493, 0.18930898065098334, 0.17787288005779356, 0.20354928125123373, 0.2024681260507487, 0.17050307515985974, 0.18946890532705885, 0.17039100946002161, 0.17485027062505032, 0.4513625478122243, 0.18483983678875593, 0.5110333682347559, 0.18849262280686785, 0.19594997546602855, 0.4351796838795834, 0.164911290398832, 0.1793835254363232, 0.16609060004719778, 0.385108677500951, 0.20123958866966873, 0.39243772551303435, 0.19828246319598164, 0.20422857466938793, 0.1973027029505655, 0.16587076659233702, 0.3415815101129738, 0.16539218560287172, 0.17751293600022455, 0.18429259353069527, 0.19041282325538245, 0.17762807074477083, 0.181151633042549, 0.17894521775299577, 0.1797494171991062, 0.17997830144965987, 0.17291269794473174, 0.08777491855290642, 0.09274821275784761, 0.0930923865511799, 0.08992586663207347, 0.10856902058708107, 0.07962510301496406, 0.07889115790547929, 0.10128669649709665, 0.08925520791985564]}, "mutation_prompt": null}
{"id": "d25c034f-be07-483b-8edb-d55b0901c99d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.probability_2_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_2_strategy(self, position):\n        if np.random.rand() < self.probability_2_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Apply probability 2 strategy\n                self.particles[i] = self.probability_2_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2.", "configspace": "", "generation": 42, "fitness": 0.20684135992736868, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {"aucs": [0.4756949339110622, 0.4333912591949779, 0.46566355847561636, 0.4355248314377903, 0.461946736740388, 0.42053560963789816, 0.448156418823384, 0.41386583348065364, 0.4402979120449142, 0.02010450603674563, 0.018857090926141296, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09703064924053484, 0.12656451739278674, 0.10213052570861203, 0.11338063116006591, 0.11609272267965265, 0.09253663188454064, 0.10701887187439352, 0.10063422442648695, 0.08111689930363042, 0.08261046776638503, 0.08882341656390613, 0.08820405494335737, 0.08091146888203893, 0.07032324884338192, 0.07629101055355225, 0.09709679668184801, 0.11577648086892567, 0.09571483495197941, 0.9114577212565125, 0.9316817660436431, 0.9213643535347626, 0.9039680932333743, 0.8712586630260706, 0.831347275015313, 0.9257510329589483, 0.9243599662105001, 0.918040653369932, 0.22733071013064032, 0.22456086778045714, 0.2241946593693832, 0.23502989185236622, 0.23370234632417586, 0.21564788162857162, 0.2587439082492219, 0.20883235711001757, 0.22971460750586858, 0.3374851160834633, 0.3269803542255644, 0.23562997167776445, 0.26120831469448824, 0.25392416082180336, 0.2496430583420869, 0.26224563075627416, 0.2597530762913224, 0.28734223105064616, 0.14167883874009657, 0.1349369384411352, 0.12561245851918024, 0.11363761305987885, 0.16246251972656578, 0.14814896081928042, 0.14788608588009444, 0.1589404509300517, 0.18284587763960802, 0.13406581948869933, 0.12909216929150913, 0.12490883620121951, 0.13718663559979027, 0.12929106877448227, 0.14040784059274725, 0.15777578536250436, 0.15310098039534548, 0.13759082142604107, 9.999999999998899e-05, 9.999999999998899e-05, 0.000648484574568231, 0.057478329731000866, 0.0014199336192787237, 0.0008881104430985554, 0.0007056011859043476, 0.00010303581323167776, 0.0005093501133929257, 0.11561872306130039, 0.05761353453740958, 0.09025629810533609, 0.10453636517061782, 0.07032892493092313, 0.019613107649635975, 0.16096794525355784, 0.11396748025748471, 0.11592448443225845, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007849376966457933, 9.999999999998899e-05, 0.11560745283832163, 0.11517615454109653, 0.08804168037919258, 0.08373926201003612, 0.08078944530193855, 0.07321483119790828, 0.10085237163515992, 0.12095451891661635, 0.08728738914279077, 0.4264954038896317, 0.42485656315459974, 0.410924928463806, 0.39333255538005163, 0.3913629891994099, 0.40774561437136936, 0.4155922079914658, 0.4328509934808077, 0.42681741966005016, 0.10238357319437452, 0.08746965477574453, 0.10987621850242302, 0.09614813133349764, 0.09097816205090026, 0.13101981219253833, 0.113511714708458, 0.11045277333414782, 0.1250477976938581, 0.13500881108898943, 0.15289033302247312, 0.17702917304181487, 0.15101860525602295, 0.16448047104554575, 0.14680122468341483, 0.18601640321476032, 0.1652618839731953, 0.13444074281213347, 0.30162945622559323, 0.302433361161465, 0.3056066509429385, 0.297491610036388, 0.30673878776829544, 0.29789393400535435, 0.23796496737610118, 0.30112683533431617, 0.281603194623116, 0.2157943481868645, 0.18797909487072118, 0.22282883435508516, 0.20303350557801658, 0.19627283971379106, 0.20364223925483937, 0.1972422540767771, 0.19399477240154628, 0.1752877811850636, 0.2274817297301701, 0.22836268445136576, 0.23017289620292825, 0.2647035825472278, 0.22969474933306033, 0.22693751752358338, 0.21670268729007314, 0.2160719569936218, 0.22116164787490744, 0.1894573431715778, 0.18462966421073468, 0.20240557970530393, 0.20655705809624125, 0.19684409149608595, 0.18952313743159188, 0.19211365489593124, 0.17842162826588104, 0.18120375473063255, 0.55243773828959, 0.18568642363434484, 0.18613951928448969, 0.17167674003099143, 0.19892615106129719, 0.11561888420458677, 0.14050732682933853, 0.5461013292514895, 0.15915433657509748, 0.42827336061806665, 0.20932248351519278, 0.49145076943780974, 0.35720420975393063, 0.3642607297982704, 0.17193354169373887, 0.1664220357493823, 0.32761736498459426, 0.33865701553956296, 0.19975770847811336, 0.20533762627078445, 0.18140178543335417, 0.1860784834327711, 0.18052901295476353, 0.18207218942832448, 0.18593760142036486, 0.17754998330315974, 0.17066802140418824, 0.08189152335231575, 0.08822330221211228, 0.09462697067532477, 0.08365318259499288, 0.08785530884140402, 0.07207698637926008, 0.09288062411516618, 0.09330405603749492, 0.09881871948772603]}, "mutation_prompt": null}
{"id": "5ed453ea-feab-400a-9767-2f04a3875880", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.dynamic_velocity_adaptation_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def dynamic_velocity_adaptation(self, velocities):\n        velocity_adaptation_factors = np.random.uniform(0.1, 0.9, size=self.swarm_size)\n        return velocities * velocity_adaptation_factors[:, np.newaxis]\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.velocities[i] = self.dynamic_velocity_adaptation(np.array([self.velocities[i]]))[0]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation for increased diversity\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, utilizing a novel \"Dynamic Velocity Adaptation\" approach to adjust velocity updates.", "configspace": "", "generation": 43, "fitness": 0.19199099464907285, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.15.", "error": "", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {"aucs": [0.4619595615329771, 0.4732177889354824, 0.46807848708258193, 0.46456867759072895, 0.4570905621232809, 0.4748963297628157, 0.44840311172643965, 0.4538554450940936, 0.4547778442758992, 9.999999999998899e-05, 0.050241647479976725, 9.999999999998899e-05, 9.999999999998899e-05, 0.015246800643814118, 9.999999999998899e-05, 9.999999999998899e-05, 0.017339476800349418, 9.999999999998899e-05, 0.08567649293919333, 0.06460478735277575, 0.07976802959826124, 0.09396851745329093, 0.08161622893455645, 0.08941979850586701, 0.10834925217356017, 0.07446020656141938, 0.11807527751584679, 0.07158291587951937, 0.09962959205379796, 0.08332282566442906, 0.08748940218071088, 0.07477318763288054, 0.06909627172416699, 0.10089739887113847, 0.07935234151660353, 0.06042361608706959, 0.6753402888426585, 0.8979578639690031, 0.3154636354285917, 0.12492902602708933, 0.2903353223843578, 0.14742021150414386, 0.6280300879743135, 0.8314049420061744, 0.7792878052598717, 0.2724871301955273, 0.28516207980169106, 0.23353731001501288, 0.29719090285696237, 0.24078018840542248, 0.23947449581133562, 0.2784808095427316, 0.26246582914487127, 0.20969377068312023, 0.22422387898276197, 0.22459442064446034, 0.2181264399008882, 0.2634272022474986, 0.24307446028479296, 0.2066413675298293, 0.22476503096930633, 0.16802977586567525, 0.22489557475540245, 0.29867350478422516, 0.2275952027786423, 0.17650174235687643, 0.044796357386357344, 0.134542080629098, 0.22322784158684383, 0.18276018670347716, 0.17962906740537032, 0.13660320396240133, 0.1625724788413927, 0.15963711721639973, 0.14400031544353165, 0.16926597929584353, 0.14353120971443534, 0.17055019502066138, 0.14595485344284265, 0.16199966263245857, 0.13983671025536637, 9.999999999998899e-05, 9.999999999998899e-05, 0.02763119356007704, 9.999999999998899e-05, 0.009549601008449815, 9.999999999998899e-05, 0.001159026584789169, 0.004783531374389138, 0.000186799598206, 0.11534237816788806, 0.06618760920089284, 0.12887198931890975, 0.06981380048845054, 0.14097673541074618, 0.03023765899186015, 0.08986207087990494, 0.04003624235234149, 0.04120718114659938, 0.005524208317117529, 0.0018111567802152617, 9.999999999998899e-05, 0.011381397104091584, 0.00431772575794187, 0.0013302698853729922, 0.025960190891957113, 9.999999999998899e-05, 0.0032260509197303833, 0.1373856930244206, 0.11128052772789465, 0.06291789518953306, 0.15210589147445075, 0.09679401531631049, 0.11365569820285093, 0.10525949532322831, 0.11331767070015775, 0.08679097299663685, 0.46012803665597735, 0.3838390629004643, 0.43864586522265825, 0.42119829958354627, 0.3999304724263244, 0.36026107634406357, 0.44437144853317545, 0.41597477094873725, 0.4004328061717175, 0.10610223630774673, 0.12168525527843865, 0.07501306123389206, 0.10002127256638993, 0.07048218297953734, 0.12150242223110819, 0.08751700546862229, 0.10511832858559678, 0.08468338375616824, 0.19147814778359573, 0.13325662677104977, 0.15917882213961276, 0.1678287589562144, 0.17131814358172037, 0.15702896413847933, 0.17290515648950222, 0.1609837433609662, 0.20229300366343073, 0.2381329777191621, 0.17543561799001928, 0.2688083852820409, 0.28199826002399364, 0.2831054209112511, 0.3079636428801926, 0.21417792342678565, 0.28010504048363327, 0.22020901123124914, 0.17878185580325734, 0.21760471776037293, 0.21294462066172926, 0.21398735611903053, 0.22023216764723363, 0.2559390656022633, 0.19078521713427055, 0.20832311204364928, 0.19272679603568954, 0.2262436407357834, 0.25973011393967926, 0.23004906564869432, 0.2495962108404105, 0.2352769663270935, 0.25029560677258034, 0.23283388528338267, 0.23432919267126184, 0.21982116617918745, 0.18541183246934712, 0.18554123046932602, 0.17845840687307024, 0.17130700553682054, 0.18027930217370758, 0.1829108353478871, 0.16149769134978575, 0.179390797356355, 0.17905141467380548, 0.18496393298312763, 0.18630923866036053, 0.1856768847510517, 0.5668238542508806, 0.19570150056665225, 0.11389106963862816, 0.13961143539031584, 0.16549904778224622, 0.6132335904180397, 0.45371302409090175, 0.4642612469320998, 0.3334816169449172, 0.46991112180738026, 0.3220929027245304, 0.1657222288989273, 0.16427163469875072, 0.3208352349287801, 0.37867498991579474, 0.19665013354045535, 0.1915855754409267, 0.1802906934946732, 0.19462138188992006, 0.18006867564415951, 0.18086891793320836, 0.17843572454749423, 0.18008868443561876, 0.1748030202899732, 0.09214108470864069, 0.1109101302246347, 0.07386877914317669, 0.08144327711210575, 0.09151799057772236, 0.08658388872368827, 0.08698348081952412, 0.07980307047008028, 0.09706775845895044]}, "mutation_prompt": null}
{"id": "a70c287f-6707-40a0-a842-060a6a2bd810", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.opposition_based_learning_memory = 0.5\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.adaptive_mutation_rate = 0.05\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.probability_2_rate = 0.1\n        self.dynamic_cooling_schedule = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def opposition_based_learning_with_memory(self, position, memory):\n        return memory * position + (1 - memory) * self.opposition_based_learning(position)\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def adaptive_self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.adaptive_mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_2_strategy(self, position):\n        if np.random.rand() < self.probability_2_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        else:\n            return position\n\n    def dynamic_cooling_schedule(self, evaluations):\n        return self.cooling_rate * (1 - self.dynamic_cooling_schedule * (evaluations / self.budget))\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with memory for improved convergence\n                if np.random.rand() < self.opposition_based_learning_rate:\n                    opposition_position = self.opposition_based_learning_with_memory(self.particles[i], self.opposition_based_learning_memory)\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Adaptive self-adaptive mutation for increased diversity\n                if np.random.rand() < self.adaptive_mutation_rate:\n                    mutated_position = self.adaptive_self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Apply probability 2 strategy\n                self.particles[i] = self.probability_2_strategy(self.particles[i])\n            # Modified simulated annealing with dynamic cooling schedule\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / (self.temperature * self.dynamic_cooling_schedule(evaluations))):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2, featuring adaptive mutation rates, opposition-based learning with memory, and dynamic cooling schedules.", "configspace": "", "generation": 44, "fitness": -Infinity, "feedback": "An exception occurred: TypeError(\"'float' object is not callable\").", "error": "TypeError(\"'float' object is not callable\")", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {}, "mutation_prompt": null}
{"id": "652aeb58-35be-4d9d-8c52-452864087a5e", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.probability_3_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_3_strategy(self, position, velocity):\n        if np.random.rand() < self.probability_3_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim), np.random.uniform(-1, 1, size=self.dim)\n        else:\n            return position, velocity\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i], self.velocities[i] = self.probability_3_strategy(self.particles[i], self.velocities[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation with adaptive rate\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 3, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning.", "configspace": "", "generation": 45, "fitness": 0.2089665524718994, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "af913b57-d5f1-4bd9-9187-43425af0c951", "metadata": {"aucs": [0.44301459635738194, 0.40585193604552827, 0.4402735147467527, 0.45425782061304687, 0.407208402918787, 0.42227364013521385, 0.4052427513275413, 0.4440286767362436, 0.4409672322713607, 0.005631538367933953, 0.0022202443914393077, 0.03379995079477416, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01254247984995871, 9.999999999998899e-05, 0.13112043255416006, 0.10986062255390316, 0.0808085336591976, 0.07859077431680761, 0.11137487491138398, 0.10979863924522526, 0.10520082567070499, 0.12839831176577443, 0.12192433483160892, 0.10419063933402628, 0.0985732823377703, 0.08409073093999253, 0.08703918148121226, 0.07136164973751058, 0.09231667276967437, 0.0983583716862273, 0.07276727375252545, 0.09882297151094221, 0.899793538899336, 0.937877004009221, 0.8858559438214422, 0.8202266478867815, 0.8588129697784714, 0.8894754622765353, 0.9383183204336523, 0.9185737372066689, 0.9159823803685321, 0.23059348348657704, 0.24389733292227223, 0.2276034394307248, 0.21726321954331296, 0.22742657947530753, 0.22084753286445913, 0.23830385471636328, 0.21304800368513066, 0.22362557836299546, 0.3481603115135691, 0.26939698012261337, 0.24602812752532965, 0.2590115484355713, 0.2649786963113019, 0.2302327636577427, 0.31444141444782325, 0.20046055711147093, 0.23592341443319842, 0.13597847529253326, 0.13864747097307495, 0.14442926247440735, 0.15392630151178344, 0.19923501666402288, 0.15132394018734374, 0.12292803890203763, 0.1369890375958086, 0.12755912288310323, 0.14460743209139715, 0.14031270506523075, 0.1378997091603158, 0.13553096348972615, 0.12315461005129458, 0.12149292568493164, 0.13222236339153282, 0.12189791828058949, 0.1283995768508276, 9.999999999998899e-05, 0.0038501895680599363, 0.0039062135849499136, 0.01900843413121034, 9.999999999998899e-05, 9.999999999998899e-05, 0.03319010908212916, 9.999999999998899e-05, 0.004303112332490255, 0.1013814157459999, 0.0924809035860158, 0.1549377535554124, 0.10928817082170139, 0.049730396208183425, 0.050703576269837125, 0.10113265814970329, 0.08918154066088757, 0.07979549497275251, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010329913277620784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10716546635089275, 0.1032711360400137, 0.08069464050130992, 0.09832380984461764, 0.0764454163667706, 0.09084833284715133, 0.0908741573640024, 0.09827087550779345, 0.0890837814446308, 0.38445329864469546, 0.39460170881488055, 0.3970851801724168, 0.3891426847760152, 0.36915634870363156, 0.39057994174383237, 0.39797558774019337, 0.4078636319262686, 0.4073916179076288, 0.10811663954166939, 0.10926342310010773, 0.10531002329410588, 0.10246394608734899, 0.10180135707719529, 0.11303908638905069, 0.09982224750258828, 0.10103177245326678, 0.08673818094350061, 0.1453421743741956, 0.19112367645864448, 0.14186437022334664, 0.15742785193730346, 0.16111242340504883, 0.18167050059328727, 0.15635090109189553, 0.15228107977450067, 0.18355423510170887, 0.2029605817822755, 0.2520626884015277, 0.29179944699812477, 0.251500547623436, 0.28159890003905375, 0.2561984542414242, 0.22462393918635704, 0.25972081483485865, 0.27326757738435403, 0.18546696373566185, 0.2237214392165574, 0.22958388672670416, 0.23144680539673446, 0.20565768381373872, 0.21226741382812908, 0.18146077013970263, 0.21375754946025305, 0.19772464910465826, 0.23592193567216213, 0.27015672177883376, 0.23647522309172175, 0.2345061456627876, 0.22297192722957238, 0.2549273498038689, 0.20344916708016814, 0.21426314515220635, 0.21110186240380746, 0.1860890235300029, 0.1901940790809532, 0.16799708826283732, 0.17728864221240404, 0.18220436376516336, 0.18823061848908718, 0.1824902678931979, 0.17235029602808005, 0.18164555821802308, 0.6613083701297587, 0.18508556508891272, 0.1861571162139567, 0.48994353176005656, 0.19619742734323287, 0.19442498927521767, 0.153585494877591, 0.5756488613149618, 0.5919728349008464, 0.5949581769470548, 0.3649774342228046, 0.3862968506547815, 0.20144537977580135, 0.47213915512142135, 0.16563624113125774, 0.33532792116969135, 0.3570310270284647, 0.37821829647936533, 0.17541721028812185, 0.17675654442419564, 0.18423968835207327, 0.17287236016336516, 0.17906229955995645, 0.191867076992849, 0.17488905268578292, 0.18728525294626597, 0.1801122220040997, 0.07842564100627714, 0.09598407582014168, 0.09562919387451385, 0.08167369263761826, 0.08759643905661141, 0.0853943116738719, 0.08678467366499987, 0.08113096510727669, 0.09315042408520624]}, "mutation_prompt": null}
{"id": "36d1f43c-a7b5-447f-af2b-075e573c99a8", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV1:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.probability_1_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def self_adaptive_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.uniform(-self.mutation_step_size, self.mutation_step_size, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def probability_1_strategy(self, position, velocity):\n        if np.random.rand() < self.probability_1_rate:\n            return np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim), np.random.uniform(-1, 1, size=self.dim)\n        else:\n            return position, velocity\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i], self.velocities[i] = self.probability_1_strategy(self.particles[i], self.velocities[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Self-adaptive mutation with adaptive rate\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.self_adaptive_mutation(self.particles[i])\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV1(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV1", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning.", "configspace": "", "generation": 46, "fitness": 0.2089665524718994, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV1 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "652aeb58-35be-4d9d-8c52-452864087a5e", "metadata": {"aucs": [0.44301459635738194, 0.40585193604552827, 0.4402735147467527, 0.45425782061304687, 0.407208402918787, 0.42227364013521385, 0.4052427513275413, 0.4440286767362436, 0.4409672322713607, 0.005631538367933953, 0.0022202443914393077, 0.03379995079477416, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01254247984995871, 9.999999999998899e-05, 0.13112043255416006, 0.10986062255390316, 0.0808085336591976, 0.07859077431680761, 0.11137487491138398, 0.10979863924522526, 0.10520082567070499, 0.12839831176577443, 0.12192433483160892, 0.10419063933402628, 0.0985732823377703, 0.08409073093999253, 0.08703918148121226, 0.07136164973751058, 0.09231667276967437, 0.0983583716862273, 0.07276727375252545, 0.09882297151094221, 0.899793538899336, 0.937877004009221, 0.8858559438214422, 0.8202266478867815, 0.8588129697784714, 0.8894754622765353, 0.9383183204336523, 0.9185737372066689, 0.9159823803685321, 0.23059348348657704, 0.24389733292227223, 0.2276034394307248, 0.21726321954331296, 0.22742657947530753, 0.22084753286445913, 0.23830385471636328, 0.21304800368513066, 0.22362557836299546, 0.3481603115135691, 0.26939698012261337, 0.24602812752532965, 0.2590115484355713, 0.2649786963113019, 0.2302327636577427, 0.31444141444782325, 0.20046055711147093, 0.23592341443319842, 0.13597847529253326, 0.13864747097307495, 0.14442926247440735, 0.15392630151178344, 0.19923501666402288, 0.15132394018734374, 0.12292803890203763, 0.1369890375958086, 0.12755912288310323, 0.14460743209139715, 0.14031270506523075, 0.1378997091603158, 0.13553096348972615, 0.12315461005129458, 0.12149292568493164, 0.13222236339153282, 0.12189791828058949, 0.1283995768508276, 9.999999999998899e-05, 0.0038501895680599363, 0.0039062135849499136, 0.01900843413121034, 9.999999999998899e-05, 9.999999999998899e-05, 0.03319010908212916, 9.999999999998899e-05, 0.004303112332490255, 0.1013814157459999, 0.0924809035860158, 0.1549377535554124, 0.10928817082170139, 0.049730396208183425, 0.050703576269837125, 0.10113265814970329, 0.08918154066088757, 0.07979549497275251, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010329913277620784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10716546635089275, 0.1032711360400137, 0.08069464050130992, 0.09832380984461764, 0.0764454163667706, 0.09084833284715133, 0.0908741573640024, 0.09827087550779345, 0.0890837814446308, 0.38445329864469546, 0.39460170881488055, 0.3970851801724168, 0.3891426847760152, 0.36915634870363156, 0.39057994174383237, 0.39797558774019337, 0.4078636319262686, 0.4073916179076288, 0.10811663954166939, 0.10926342310010773, 0.10531002329410588, 0.10246394608734899, 0.10180135707719529, 0.11303908638905069, 0.09982224750258828, 0.10103177245326678, 0.08673818094350061, 0.1453421743741956, 0.19112367645864448, 0.14186437022334664, 0.15742785193730346, 0.16111242340504883, 0.18167050059328727, 0.15635090109189553, 0.15228107977450067, 0.18355423510170887, 0.2029605817822755, 0.2520626884015277, 0.29179944699812477, 0.251500547623436, 0.28159890003905375, 0.2561984542414242, 0.22462393918635704, 0.25972081483485865, 0.27326757738435403, 0.18546696373566185, 0.2237214392165574, 0.22958388672670416, 0.23144680539673446, 0.20565768381373872, 0.21226741382812908, 0.18146077013970263, 0.21375754946025305, 0.19772464910465826, 0.23592193567216213, 0.27015672177883376, 0.23647522309172175, 0.2345061456627876, 0.22297192722957238, 0.2549273498038689, 0.20344916708016814, 0.21426314515220635, 0.21110186240380746, 0.1860890235300029, 0.1901940790809532, 0.16799708826283732, 0.17728864221240404, 0.18220436376516336, 0.18823061848908718, 0.1824902678931979, 0.17235029602808005, 0.18164555821802308, 0.6613083701297587, 0.18508556508891272, 0.1861571162139567, 0.48994353176005656, 0.19619742734323287, 0.19442498927521767, 0.153585494877591, 0.5756488613149618, 0.5919728349008464, 0.5949581769470548, 0.3649774342228046, 0.3862968506547815, 0.20144537977580135, 0.47213915512142135, 0.16563624113125774, 0.33532792116969135, 0.3570310270284647, 0.37821829647936533, 0.17541721028812185, 0.17675654442419564, 0.18423968835207327, 0.17287236016336516, 0.17906229955995645, 0.191867076992849, 0.17488905268578292, 0.18728525294626597, 0.1801122220040997, 0.07842564100627714, 0.09598407582014168, 0.09562919387451385, 0.08167369263761826, 0.08759643905661141, 0.0853943116738719, 0.08678467366499987, 0.08113096510727669, 0.09315042408520624]}, "mutation_prompt": null}
{"id": "1464fe24-db3f-4c53-8526-1b73c2125906", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation.", "configspace": "", "generation": 47, "fitness": 0.2091965277832529, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefined got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "652aeb58-35be-4d9d-8c52-452864087a5e", "metadata": {"aucs": [0.48062003160336686, 0.49097607473030236, 0.4839047319397649, 0.46940686183467417, 0.43230250316874985, 0.4992736466512001, 0.43421533948400104, 0.41337125225460336, 0.44146161989924915, 0.04464822376254873, 0.0005014961690538167, 0.0005929790770428101, 9.999999999998899e-05, 0.017833070872851353, 9.999999999998899e-05, 9.999999999998899e-05, 0.00418882831675127, 9.999999999998899e-05, 0.11809528970718297, 0.10486896753012065, 0.1107148841962966, 0.09903843634779275, 0.11912531568802809, 0.06642916245824493, 0.10319728488241686, 0.1190677372131258, 0.13297738619852573, 0.1104742076222246, 0.10359183101011726, 0.09157957886379664, 0.08093787359003035, 0.08107186595685978, 0.09315727915137317, 0.08891292566062059, 0.09609870113807828, 0.09807431217137341, 0.9156659550140471, 0.949121673878814, 0.9024784153583556, 0.8455302048582279, 0.8661795703729719, 0.8309180122494718, 0.9026421290753599, 0.9198920953271243, 0.9159994373552381, 0.27745561065329727, 0.24543379075612481, 0.2611090985946808, 0.2666442233148455, 0.25359748586035946, 0.2307083427960901, 0.24918229773687428, 0.2620989995196916, 0.23946551746016376, 0.26932501620162996, 0.3057126780328193, 0.3123048869215036, 0.26041804458441575, 0.34523776623922964, 0.2571212820714821, 0.2281886971803262, 0.265915919658981, 0.2304776597540179, 0.13003046805473606, 0.12543195807981666, 0.1316422920981829, 0.09888766316964337, 0.11841080670776027, 0.12079415731843168, 0.13251148941684188, 0.12698994294722232, 0.1580789728679427, 0.17206293863496702, 0.13177461687168923, 0.13545387461780933, 0.14771726723990009, 0.18803862720788678, 0.14618977179636294, 0.12343813804099424, 0.134431970464846, 0.1512173154809614, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01590764541404277, 0.011116614104991984, 9.999999999998899e-05, 0.007270083552814666, 0.00040673347794140113, 9.999999999998899e-05, 0.13303404741933522, 0.09277735927861963, 0.11566985920309525, 0.09487226854906072, 0.10511688034582112, 0.04094174953790786, 0.09013795524297441, 0.05844931420535382, 0.07759532172459915, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002910812121414308, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012940189693225301, 0.1041529077878871, 0.10819714465011254, 0.0955393889909848, 0.06231608546467815, 0.0817321612265145, 0.09904171345771773, 0.0998001424184275, 0.0942142814533905, 0.11086419568888795, 0.42499563088846726, 0.4105279621409279, 0.4599401790148475, 0.36222015569748534, 0.3999683509733277, 0.4393606418597287, 0.41670284186873774, 0.41195481870807926, 0.4093900108748836, 0.09147188263813566, 0.12018112382338697, 0.09181929087186491, 0.07727635204664751, 0.10576316326114588, 0.1359149554120449, 0.0949299633420877, 0.1133285438322047, 0.10112755580679655, 0.19022095049952037, 0.25637130935006647, 0.19896803523559203, 0.1603116703430687, 0.1715292211477517, 0.16578132406560087, 0.20282453444361415, 0.18946085961553094, 0.23865315278126276, 0.27895988766932145, 0.30382896522874736, 0.3048343088133709, 0.30939036505260453, 0.27283556286433586, 0.2663300870129687, 0.2435891089149509, 0.2898046868196349, 0.2558768146192655, 0.21917715651777592, 0.2037467599211613, 0.2391348281297886, 0.2205539977942519, 0.2341537542459189, 0.20397745017408675, 0.17317572923808677, 0.23038556403036203, 0.16213178390989746, 0.23006305438048436, 0.22427409716686508, 0.23930855606665713, 0.22109286938987338, 0.2249653030554124, 0.23720922718620296, 0.21993393231392167, 0.32405691375331536, 0.2347316836764849, 0.17165315191886366, 0.1853930769079125, 0.1915942420754263, 0.1886078245938756, 0.2104472622570034, 0.1793535522326669, 0.17939032245032305, 0.1826241694470475, 0.18994543061145752, 0.7127828837989674, 0.18536421658533064, 0.18521775146927066, 0.5650082811116457, 0.19823165832141898, 0.11399853869838339, 0.140658746825995, 0.15382333464154596, 0.16057024441669987, 0.46286489100152606, 0.21055308079733537, 0.4632876282789472, 0.37280156500379413, 0.16914446071114309, 0.3511164033396569, 0.1657007010207635, 0.16572649576662302, 0.26381179448218184, 0.17400695241411923, 0.19067823490668356, 0.17838140900889543, 0.18065274348432592, 0.17187633498231336, 0.17899120356047793, 0.19730315391015196, 0.17600986085278214, 0.18147567906903772, 0.08322002297735054, 0.08673769957267019, 0.08773494970888829, 0.08695406364547875, 0.08958347787824328, 0.0885760582393208, 0.0934484433589221, 0.09856462989328174, 0.08482481046301671]}, "mutation_prompt": null}
{"id": "0a9bbe32-7cb3-4081-963f-6f0198a1292d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.2:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.1:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 4, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far.", "configspace": "", "generation": 48, "fitness": 0.2113594474081232, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "1464fe24-db3f-4c53-8526-1b73c2125906", "metadata": {"aucs": [0.45247871244991333, 0.4553525104493674, 0.45213388579257796, 0.4447729547457817, 0.44887630644674126, 0.413870437500953, 0.440697930115584, 0.40863619197380185, 0.4459867229758633, 0.018960187234637882, 0.02657979336835381, 9.999999999998899e-05, 9.999999999998899e-05, 0.034962186403044826, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12344782094362983, 0.1042686377987162, 0.106455594563299, 0.09618407718762778, 0.08852538785341824, 0.09949155021276457, 0.12413271073676024, 0.1038162261308695, 0.09513909559751321, 0.09088173670416833, 0.09927996996219823, 0.09508620946525648, 0.09606693562663282, 0.08215658862028064, 0.10668994999940518, 0.12204499526432433, 0.08514243881208627, 0.09425608232704163, 0.909963770829828, 0.9421165394696984, 0.8934798437016095, 0.8935045480495297, 0.852962803912783, 0.9239375336346443, 0.9310509169255442, 0.9318536246254512, 0.9135670713581808, 0.2644747004673714, 0.2649325847131434, 0.25222507323370047, 0.2511518840668878, 0.2514348664176058, 0.23085608101180766, 0.2451098321169054, 0.24089408691062875, 0.24717714822510461, 0.23550515235833536, 0.6290948207096247, 0.30438632578018043, 0.2924346854351264, 0.2022113320152733, 0.2031704193627787, 0.2691352390159133, 0.22539655781388868, 0.2950980743402497, 0.11270419277289401, 0.17281767214909305, 0.11591787999211445, 0.1057259742759119, 0.15462504831339452, 0.1189381248438991, 0.1326903264886823, 0.1238661089449834, 0.13105864755648977, 0.13463784655366418, 0.15400335957025568, 0.17153259186706638, 0.15594157614904014, 0.15056519302420568, 0.13497036410414676, 0.1353750304279553, 0.16052189600794464, 0.12693548364455853, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05223287724035364, 9.999999999998899e-05, 0.0031746558167853323, 9.999999999998899e-05, 9.999999999998899e-05, 0.015164104515081767, 0.1285813610768448, 0.05105501860814654, 0.12147649982097641, 0.09157942882149905, 0.03212904439628361, 0.027353511182302448, 0.16243200780305922, 0.04990443610477524, 0.08448457191417058, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006969866972138528, 9.999999999998899e-05, 0.0015812642541088717, 9.999999999998899e-05, 0.10828784994509932, 0.1063159749379411, 0.0768784817148539, 0.06924612471297875, 0.12404091835604958, 0.06965422841787405, 0.0925983678787945, 0.0878182363960528, 0.0813974145698354, 0.4363200488722877, 0.4088699479561887, 0.40495000875570475, 0.39746396672248296, 0.4084854829266171, 0.43266869471472547, 0.42748499669307705, 0.4251836204086583, 0.404472172915754, 0.0948588903148071, 0.11639238441785149, 0.0899325122628768, 0.0952373560633063, 0.10913928466889866, 0.12616385951224474, 0.09212442316786473, 0.1362495423823319, 0.08521685495523346, 0.19062378470669872, 0.25303606959457514, 0.13561182287646767, 0.17856037559455107, 0.2542153823508966, 0.1480230499511206, 0.19709048473903334, 0.16121464579338773, 0.1617385080962338, 0.255391233785762, 0.28463335389208266, 0.28501510832462473, 0.3121865861789439, 0.29027645767609356, 0.2827491696009198, 0.22156770983873275, 0.3051556007474385, 0.2834617934866811, 0.24326145749572448, 0.23214545513165663, 0.18915070103503018, 0.20499962166517494, 0.22184503410226197, 0.23784816173513623, 0.1876249813410521, 0.21558277059629216, 0.17003293023106003, 0.26371370736868094, 0.21422970710459144, 0.2544655202464955, 0.21784003372085692, 0.2292371684935428, 0.22341558154766472, 0.23281666798676137, 0.23056588854901683, 0.23824212152325086, 0.20509351840700174, 0.18385211615734953, 0.17481972185740924, 0.21490598012986017, 0.17954616311411353, 0.17952776299404583, 0.19020180231908357, 0.20146577726580694, 0.18099775774983173, 0.12798426867928936, 0.18620942800972196, 0.18579012369580838, 0.5827143678970677, 0.1982953806030654, 0.16388684944481124, 0.14111349373304805, 0.5085815909422459, 0.5462707147466151, 0.38926459049569684, 0.16840739173972286, 0.39676533043459905, 0.42727159825212657, 0.2004394156992696, 0.16658872878301467, 0.3258251394769761, 0.2904821907259786, 0.3968933734964941, 0.20286978212721973, 0.18607798644724027, 0.18232984173411226, 0.1982751122131312, 0.18520239386726622, 0.19763075362780824, 0.19846988931043308, 0.1849148179350898, 0.17694274749198013, 0.08861677929428458, 0.08757825314494183, 0.07065355891748948, 0.09769765860717727, 0.11065295654929519, 0.08153399050421539, 0.10777825931362384, 0.09386653528929234, 0.10426202647876448]}, "mutation_prompt": null}
{"id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV1:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV1(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV1", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 49, "fitness": 0.21839453189541005, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV1 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "0a9bbe32-7cb3-4081-963f-6f0198a1292d", "metadata": {"aucs": [0.5161665562055474, 0.46863754195075047, 0.45686086387716884, 0.49643964797520734, 0.4315166841061766, 0.4463537736575277, 0.4496693691406971, 0.4554736267806634, 0.4248831292984153, 0.004996650854338092, 9.999999999998899e-05, 9.999999999998899e-05, 0.012896683461991798, 0.00386242523487923, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1314262657220292, 0.10349911568779657, 0.10701401924105791, 0.11325285247684713, 0.10895030370487546, 0.11105080485389007, 0.1199423743379201, 0.11082829971608898, 0.10835161606385102, 0.06812524466401282, 0.10396893689007525, 0.09590489013554326, 0.08384017889595485, 0.07793515059729783, 0.09039411309799872, 0.09448593441836106, 0.08127790697845216, 0.09354696977290111, 0.9149437159038689, 0.9463388479092292, 0.9108893139050334, 0.8969920244089592, 0.8950541175293093, 0.900342531086881, 0.9275784881873064, 0.928751963941111, 0.9156287233669277, 0.23953076011221064, 0.23843008141702426, 0.24238509076837522, 0.2487991344659568, 0.25718683020020605, 0.23384254485983458, 0.2538639946863792, 0.230898883660127, 0.24699672667467454, 0.34718347933433524, 0.5620882322612071, 0.3188607378266364, 0.26703628686669056, 0.5669831037903761, 0.2003174553443342, 0.32265442278633394, 0.22159257778049657, 0.34323837006394775, 0.12633107658741882, 0.11775727184740936, 0.1219455635683957, 0.15370240559454906, 0.19478386007495319, 0.1752652400456225, 0.2095662360297892, 0.1945944178763801, 0.1296016797541797, 0.15040927278604654, 0.15939601729046315, 0.14726989361253295, 0.15106261494300965, 0.13094747891514147, 0.14928307363484616, 0.13942849685452274, 0.14993500134283877, 0.17091464547089874, 9.999999999998899e-05, 9.999999999998899e-05, 0.0012883290007943415, 0.038772674189703316, 9.999999999998899e-05, 9.999999999998899e-05, 0.024860245703190564, 0.0059993218546611216, 9.999999999998899e-05, 0.17294596243341565, 0.04334270476019886, 0.12039701793598212, 0.06842739471425552, 0.0724790421596404, 0.008010654468166511, 0.14082663297287945, 0.08609158104856507, 0.027724534758409747, 9.999999999998899e-05, 0.0019041304058730057, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0016300196988678906, 9.999999999998899e-05, 0.10306238773447984, 0.13640264059954021, 0.095116314162486, 0.07776311133195246, 0.11148381500604154, 0.09290302531644479, 0.11112461682253105, 0.10860408182431225, 0.12101996516164926, 0.4702425975644683, 0.4342864478496944, 0.42184368652632465, 0.4087485366177336, 0.4157787217995912, 0.40039747656557667, 0.4428398148394139, 0.43278248890715165, 0.3933062447462814, 0.12376727292636513, 0.1104207526338209, 0.09008600339087736, 0.08940601391046543, 0.10548075063669127, 0.09847752232086937, 0.10382837830311287, 0.13787555053702671, 0.10371149747944819, 0.1464609151097941, 0.2471315581421546, 0.1301924556941274, 0.1752734914938323, 0.18305714766003756, 0.19604618874051138, 0.17180286184771754, 0.14039362638510777, 0.18943444043613988, 0.2805592982962185, 0.3146128285991272, 0.3076468466003597, 0.2806600132288273, 0.2652824930249973, 0.29532169317493306, 0.29428369945558097, 0.29905724623901797, 0.27890401803805265, 0.20191842740513755, 0.2206934528999549, 0.2010551004885549, 0.22828781954723376, 0.2120810622503806, 0.23264969032131488, 0.19357491884086686, 0.2233239195032216, 0.17088789018808204, 0.22656433312006719, 0.24376289347299218, 0.2615811191601396, 0.28598625631646246, 0.2444659000490802, 0.26495452009176956, 0.22551057173720312, 0.2201260443005697, 0.20335547304146062, 0.18818233954969688, 0.18830803559355547, 0.18746919832629183, 0.18494089832133975, 0.1895485426180915, 0.18299821010092743, 0.22462223841510431, 0.2642964937036125, 0.17744376377944993, 0.18445692975113526, 0.1863874209495643, 0.18638656068666615, 0.11747024595346434, 0.19781932440241856, 0.1454011874861657, 0.14121775269510506, 0.5943487682775936, 0.607378074248494, 0.6180626766097557, 0.45505717626775, 0.39937593592580967, 0.43092084864210023, 0.4430592536642147, 0.16682127380804157, 0.16632441313996604, 0.34793110106826475, 0.3766321383693363, 0.1895858302765414, 0.20577758536257085, 0.19384221685336622, 0.18005388736037764, 0.18471065011035648, 0.18808126837065953, 0.18213404534153754, 0.21214562941366866, 0.1728856302377504, 0.07520755994165751, 0.08638043654742145, 0.08673797564716246, 0.0829196702417998, 0.07622665878481216, 0.0923906643647433, 0.07628001798312323, 0.10600531051356665, 0.09267825801847307]}, "mutation_prompt": null}
{"id": "1592d77b-48c1-4072-bda5-268e43543ccd", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.restart_iterations = 50\n        self.iterations_without_improvement = 0\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def restart_swarm(self):\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.iterations_without_improvement = 0\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                        self.iterations_without_improvement = 0\n                    else:\n                        self.iterations_without_improvement += 1\n                if self.iterations_without_improvement >= self.restart_iterations:\n                    self.restart_swarm()\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and an additional \"Restart\" strategy to reinitialize the swarm when the global best fitness does not improve for a certain number of iterations.", "configspace": "", "generation": 50, "fitness": 0.09847850227242226, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.10 with standard deviation 0.07.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.19420901404154645, 0.2386973649179196, 0.20283716434443688, 0.2189248700023264, 0.16860826714143862, 0.1934018748341335, 0.18715960812384314, 0.1736084807457844, 0.17290238824699733, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07542185270481772, 0.050717833448093, 0.06927770681276468, 0.04543448678934514, 0.03756876635090134, 0.046131431957587066, 0.05218910065761351, 0.04629170706970709, 0.055812884820992115, 0.03837157524746149, 0.05042166934661363, 0.05985843685945669, 0.04189780110497088, 0.036209452458254576, 0.0464009714397966, 0.037289507456389814, 0.030902940128203604, 0.02853054686028933, 0.09754528553078345, 0.08495531389435895, 0.08340495424451089, 0.07809625291806666, 0.08478902371471508, 0.06829041282165405, 0.07431451094639996, 0.07992300854994594, 0.08584860770419489, 0.07929646157595394, 0.09136628819249504, 0.11038665430653072, 0.10865497240007171, 0.09052973203684489, 0.0919014741262254, 0.10290536921988092, 0.08084981082744092, 0.10307032407981265, 0.14275400180504016, 0.12983127216685975, 0.14607175544468387, 0.147756451394211, 0.1169843078066295, 0.11902434315902444, 0.13240248025728885, 0.10781378141937226, 0.15031253912243114, 0.0017913671885914084, 0.06461022919692483, 0.013464841389155713, 0.002207090415962787, 0.006592866345040416, 0.03571773872375994, 0.022788485991489194, 0.0029166364831105795, 0.018007029238797045, 0.021831060866757235, 0.02102940312935353, 0.007283489802524801, 0.04489647932521823, 0.015038119137908534, 0.051337437585124435, 0.03936135535761609, 0.054192345344363124, 0.009081846885956701, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07613946419741369, 0.03810383811040541, 0.05281777215859107, 0.07136872887290424, 0.058841113763054675, 0.049882018183596166, 0.05460705838852187, 0.049897309121210265, 0.03802056167386869, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013419488622358089, 9.999999999998899e-05, 0.0020504594769393814, 0.2479640989780013, 0.24963259700222573, 0.22329159722547565, 0.2000196653224261, 0.2000938703927504, 0.2200979440629478, 0.1957130752443471, 0.21234991993041752, 0.22452735752226338, 0.06343323735102935, 0.04852110935081477, 0.059138586204359855, 0.044967223324007155, 0.05735299748644107, 0.04104210509401984, 0.04986997611427668, 0.04745910429050182, 0.05659750228859961, 0.11874690151911305, 0.1299805032728476, 0.13651101422550405, 0.14403817994196, 0.14825392762956924, 0.1487688304577861, 0.1445293327125461, 0.1382370607330633, 0.14741554865891848, 0.16597372399137234, 0.17025773126102706, 0.17860146958784806, 0.19282689103495498, 0.17760548502039053, 0.16859692689966888, 0.1840422547764191, 0.1872603958284792, 0.17643013015050635, 0.12499616000130631, 0.11183913192931139, 0.11303276979855836, 0.14503977312688754, 0.11465137842683237, 0.15777667729839906, 0.12886649046771637, 0.11476892775152159, 0.13171911605647624, 0.15133919541083474, 0.18440654187732974, 0.1714464771775278, 0.17721467692039683, 0.16996631559905906, 0.17769368699788324, 0.16791017924263318, 0.18265711962798192, 0.17166348492449124, 0.15622605406986823, 0.15176369152857172, 0.1421886057869175, 0.16288072998558345, 0.15394383101002207, 0.15116067115274745, 0.1490494008144817, 0.15439514415578837, 0.1616698594322814, 0.1854971345703681, 0.19339716982969424, 0.18580889755778385, 0.16516840526658838, 0.16569346796039408, 0.16885424824641848, 0.219223714213297, 0.15971190951801018, 0.19210838075572323, 0.1927622020528329, 0.15561285769407873, 0.17381636778216125, 0.20705201751021052, 0.2747164383199443, 0.1503865849587479, 0.14908920229144518, 0.22145415741394137, 0.21923053819636817, 0.17878902745554992, 0.1704654777416179, 0.17387710574349824, 0.18818616387073694, 0.19357672791796454, 0.1866310533760943, 0.17607928542064344, 0.18784744876928694, 0.17509878399837686, 0.06093798151528751, 0.060484758646553005, 0.06445401462554423, 0.06278862155796783, 0.05348490243207993, 0.06590577253077812, 0.07028537297527349, 0.05301396978961803, 0.0605992343264099]}, "mutation_prompt": null}
{"id": "2de102f7-ca89-4ca0-9917-65ce5fd50e66", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.memory = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.memory_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def update_memory(self, position):\n        if len(self.memory) < self.memory_size:\n            self.memory.append(position)\n        else:\n            self.memory[np.random.randint(len(self.memory))] = position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    self.update_memory(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                        self.update_memory(self.particles[i])\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                        self.update_memory(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Memory-based position update\n                if np.random.rand() < 0.05:\n                    memory_index = np.random.randint(len(self.memory))\n                    self.particles[i] = self.memory[memory_index]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                        self.update_memory(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a new \"Memory-Based\" strategy to store and retrieve the best positions found so far.", "configspace": "", "generation": 51, "fitness": 0.20884653417483956, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.45084135146560467, 0.4467905055514807, 0.43630970399853786, 0.4388224448454443, 0.43699781601229093, 0.4730403333959756, 0.44963751340168867, 0.4609962832722373, 0.48057296809027816, 0.015116171790651944, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003138479271527439, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09593086711043475, 0.1221579882762237, 0.11390049657248669, 0.09912965299335796, 0.10174047670243813, 0.09659071639537342, 0.103568984289654, 0.1401628113317389, 0.1202306849717315, 0.08893763475747996, 0.08716832242885941, 0.07882912808980913, 0.08995964455592997, 0.08061484549737707, 0.0738639431467567, 0.1092090920622355, 0.09208439942505242, 0.08205704516192402, 0.9144293312921354, 0.9432194780049891, 0.9077235764910845, 0.8582844051728765, 0.877087777742078, 0.8734543450802479, 0.9344728816966578, 0.9203343687040271, 0.9108476100173772, 0.25273664801091267, 0.23067677037298495, 0.25584409404286024, 0.24227250151307733, 0.23905858602543117, 0.2195118927894817, 0.23963761439674625, 0.23190881691488308, 0.24387084764278222, 0.33037819945592806, 0.22118289830732163, 0.2227638631536485, 0.2645324999669404, 0.5389029859248102, 0.3506283662404529, 0.2846080168551509, 0.2253519000423897, 0.2618199727423801, 0.15113267266504193, 0.13065632862107668, 0.13753151425635757, 0.0022501652550045437, 0.12615201248895047, 0.12624730302523335, 0.1492942836715545, 0.16556801685750577, 0.12271234937818243, 0.20724883768058522, 0.17881898818267694, 0.12572312148513898, 0.143900668373939, 0.13638246607274318, 0.1261740726111873, 0.1391668699765738, 0.15148632093993075, 0.1656547800487802, 9.999999999998899e-05, 0.006083659550638165, 9.999999999998899e-05, 0.02960932824074103, 0.00011151443704415787, 9.999999999998899e-05, 0.00011792495930529334, 9.999999999998899e-05, 9.999999999998899e-05, 0.10754945291203444, 0.03810353337339434, 0.11430023804467415, 0.06731687807247566, 0.09090221322507785, 0.051077444399191485, 0.09083728912594413, 0.048165179795261026, 0.09538883828835465, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004215955852712061, 0.002524877284352245, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09283755011123362, 0.12281412030226146, 0.08070475973117952, 0.11116549798670516, 0.07897586851677474, 0.11051423251035064, 0.09600958973945617, 0.10340708067162219, 0.09521783673242312, 0.36138205716278904, 0.4041364884423122, 0.3859781892314441, 0.38400753775553975, 0.4017686193253768, 0.44544364970317596, 0.419811870356228, 0.4431944471116471, 0.40864088907481955, 0.10330264554843527, 0.0871241575959475, 0.1083562238484701, 0.08821084352906872, 0.10009432904872373, 0.129771753455032, 0.10683064575819756, 0.09632104690435916, 0.0840404963457746, 0.17091839866102787, 0.16813096234962122, 0.1372645978624739, 0.2531994218752268, 0.17451894413850277, 0.16902520850832736, 0.139616522478763, 0.1591861737838688, 0.14859922461995723, 0.31260894465704725, 0.2849346258839338, 0.3073773033231021, 0.2647851719225317, 0.30241895142104036, 0.28120316515237453, 0.26634908573719696, 0.30202247669892035, 0.25401344639667334, 0.23765122147369955, 0.20003135108914571, 0.19927080806635344, 0.23431856354129255, 0.21982836563795638, 0.2006383597084419, 0.21372894230470485, 0.24412373584443592, 0.1931204153170727, 0.23230315009104208, 0.2271440993741054, 0.23734363063896435, 0.24152529883331686, 0.21296977306887732, 0.22751242268895233, 0.2412369164657815, 0.22509220121178675, 0.21689697913852612, 0.17679721272524962, 0.17982889912351618, 0.18382734095854736, 0.20083765726749092, 0.21190533251482635, 0.17992299656690447, 0.18536631204063037, 0.19883361506127928, 0.17735216258038544, 0.6413214542820376, 0.1857941755033955, 0.18573535348858194, 0.17083325120077242, 0.19877570927122856, 0.19459509552023457, 0.14925885519118187, 0.5565720985156549, 0.5996115264608444, 0.4862761943586734, 0.2087754211694678, 0.3546914837095665, 0.34578993121959256, 0.20478522836112611, 0.16718694808082457, 0.16729921678865578, 0.1592230795309828, 0.2719278149072146, 0.17094223729373192, 0.16701170215669736, 0.1920705017397678, 0.1850470330629892, 0.17682213629058063, 0.17997150283075403, 0.1927406276942487, 0.1815915274863149, 0.1822870902404753, 0.0923302452031588, 0.09410026483523293, 0.1234628123964796, 0.09836208227067944, 0.1040299802491953, 0.09864486155599239, 0.09606788270574884, 0.092525670436441, 0.09050191783770101]}, "mutation_prompt": null}
{"id": "6ce6821c-6983-4a08-a16c-834c6d853a6e", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.probability = 0.25  # probability 4\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with probability 4\n                if np.random.rand() < self.probability:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 4, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 52, "fitness": 0.1838240251224797, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.34350624681669806, 0.34822519983405353, 0.39067549626181497, 0.3045237644580516, 0.31742371330823893, 0.3273550867245958, 0.31952055880490826, 0.35045797650430466, 0.318670243840395, 9.999999999998899e-05, 0.0006575387420277856, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001466926038816041, 9.999999999998899e-05, 0.08860767534039493, 0.08431144718170547, 0.0814346555415113, 0.079596970499342, 0.0950350620560968, 0.08961684080149646, 0.10601547841513914, 0.09960354100851654, 0.12078807087961563, 0.06957297888838676, 0.0914110232635501, 0.07826920612087196, 0.07837122019810927, 0.07537695613568829, 0.06090763251733611, 0.08283594776382819, 0.0810041294913344, 0.07420248713758304, 0.8552159410165812, 0.8958196789481787, 0.8810593087614011, 0.8487840052545466, 0.8311886281702578, 0.8007908215947295, 0.9047921007691151, 0.8709061125281211, 0.8931057654031693, 0.20392899175765833, 0.18146708224113528, 0.17672668657567991, 0.20225474051602488, 0.1793586190522799, 0.17883982814454902, 0.18272389721703086, 0.17921353120438366, 0.2247027754785419, 0.2738479957490425, 0.27159502138507796, 0.20826419780789407, 0.2879780010213032, 0.23605114120508575, 0.24699140167698097, 0.2078218371776024, 0.2033815199708664, 0.2373836901791031, 0.11900501517135131, 0.10958480583634389, 0.1353532045511865, 0.11904331976930116, 0.08718096632934436, 0.11700575314133221, 0.14924468394410684, 0.08509910474894422, 0.1265717297956378, 0.11550007593174683, 0.09968155075651575, 0.09703947870630014, 0.09760305786568624, 0.1047686032601075, 0.1221956953533263, 0.10809428794662068, 0.1069822275910447, 0.10976868201564538, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00661043819042384, 0.00015063861889796915, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12285752879173384, 0.09366558850837992, 0.1186098506716049, 0.07843949113078363, 0.07332784218884936, 0.06592127478747967, 0.07410910375141888, 0.10942475700659904, 0.07902565598534728, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.065513300304191, 0.059533752167038934, 0.06476147238683438, 0.0471886555236275, 0.07420198134933198, 0.07766806551069116, 0.05901673824439713, 0.059953560025709174, 0.04718181214942174, 0.3569338329375118, 0.3484332032622274, 0.34542986814354404, 0.329352391005182, 0.3182460483071966, 0.3839456159503597, 0.35538669573428616, 0.3359232873716619, 0.3397281029347893, 0.09538291164256296, 0.07684576088318884, 0.10680584316107145, 0.08797657963065808, 0.0852725216233865, 0.08701053974139628, 0.09025491825650589, 0.0858739465714281, 0.10436012847441611, 0.1390199212907557, 0.1483899155474242, 0.1399013954284115, 0.15829049288901864, 0.15292750732835103, 0.1240247125766264, 0.13640702590494225, 0.16705869000168783, 0.14978897703651983, 0.22999850337072836, 0.21072017802813214, 0.2777288448300532, 0.2326099838083645, 0.246680913093553, 0.26113133144750256, 0.23605302925248828, 0.257708691233713, 0.23829610162048154, 0.19023005338589516, 0.1719072499374743, 0.19932927939138945, 0.17212574849811224, 0.19724196028981733, 0.17895555201379842, 0.16359993003405304, 0.17471491401456352, 0.14409933426229748, 0.18566455122269565, 0.20221177835547433, 0.21589740717011496, 0.22365258019222023, 0.24018178230783582, 0.21090642682430538, 0.2212526672312427, 0.2215349114392383, 0.2177687691764022, 0.1669713092121412, 0.17444052814335176, 0.17371942875008795, 0.18721955562636872, 0.17727297221897576, 0.17309429127082598, 0.17796711447407088, 0.17055314915551567, 0.17185548005730744, 0.17105896309872715, 0.17770430072120036, 0.2912733333556602, 0.430698531127807, 0.4019280315136765, 0.18483982407300992, 0.16724789232503845, 0.1668327949608014, 0.43908168739872044, 0.38879765114191067, 0.3659996370202978, 0.3689528409783486, 0.3308056152777228, 0.2723262885613167, 0.17154992389733148, 0.3096841291268152, 0.26479775484407586, 0.2742050419547801, 0.1714474124911065, 0.189158429302128, 0.18440606341050303, 0.1758826392265832, 0.1876097851593831, 0.17218284210618362, 0.17861217472222013, 0.18891899968460868, 0.18272922815525083, 0.075680367603842, 0.07541694661716847, 0.08607606269085788, 0.08540791587560148, 0.08783951335313755, 0.08494522504190916, 0.08259502615500425, 0.07699646786277914, 0.08521180525635141]}, "mutation_prompt": null}
{"id": "7e505539-4e33-4829-bb9e-3a02f3093abb", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.crossover_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def crossover(self, position1, position2):\n        crossover_mask = np.random.rand(self.dim) < self.crossover_rate\n        return position1 * crossover_mask + position2 * (1 - crossover_mask)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Crossover for enhanced exploration\n                if np.random.rand() < self.crossover_rate:\n                    crossover_index = np.random.randint(self.swarm_size)\n                    self.particles[i] = self.crossover(self.particles[i], self.particles[crossover_index])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and also incorporating a new \"Crossover\" strategy to enhance the exploration of the swarm.", "configspace": "", "generation": 53, "fitness": 0.21089092432640008, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.469256609760788, 0.44733692588467733, 0.4694632756302338, 0.43548742868165546, 0.44828363954236805, 0.4355775048312098, 0.43155855589744174, 0.44504531472449194, 0.45483607036593143, 0.0002880994073768406, 0.025287967387117027, 0.002644108766472364, 0.024346833707485138, 0.03335411493247997, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11459248100608399, 0.11938542594487922, 0.12406427044737534, 0.1158738409271286, 0.07708073166169183, 0.0766663704817716, 0.1279169743151326, 0.1922455573460231, 0.1141944847614017, 0.08624986009544777, 0.07063749253080964, 0.09342146742842328, 0.08731861150439435, 0.09155126672168934, 0.09217975361555786, 0.1084249137152905, 0.0900016035765624, 0.12114614493250808, 0.9079531053286631, 0.9360532582728225, 0.9129930037877115, 0.8603873569457734, 0.8927714115276933, 0.8898306114522616, 0.9351891210975732, 0.9240908558379307, 0.9155256446301464, 0.2639635912286623, 0.24801588383563777, 0.25112876521698, 0.2606916348751215, 0.24412668396216775, 0.26195564142906036, 0.22826285274335878, 0.24418992853714017, 0.26377210629744763, 0.22734735861304745, 0.643627258822167, 0.3336625867684726, 0.2362566723965821, 0.3554950727982511, 0.2502962413621803, 0.23610006999664068, 0.23309034031272902, 0.22532227004231986, 0.139888710764292, 0.11889389410274365, 0.12078844738770422, 9.999999999998899e-05, 0.13535313788551817, 0.10900479873077307, 0.15751074237021911, 0.1648087218707922, 0.14192715968565794, 0.13155681702105815, 0.1443832439041033, 0.13627570105433517, 0.12068390852718436, 0.1474103280797655, 0.14594748157201398, 0.13480092609912186, 0.17891517238513766, 0.14533687571547182, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006665246633852373, 9.999999999998899e-05, 9.999999999998899e-05, 0.0011239276172539947, 0.08766168949583297, 0.05016687486228488, 0.1698687087168086, 0.0871352098656254, 0.08368903147558471, 0.04739393987732232, 0.09365503503908734, 0.06389510975161516, 0.06817393039498343, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004606594556779253, 9.999999999998899e-05, 9.999999999998899e-05, 0.12092149040967293, 0.098213742358367, 0.08555097013057478, 0.11325510624291169, 0.11599544105060555, 0.09791169567983193, 0.1147094884897899, 0.10632304648036406, 0.07855460777971657, 0.42624006266168, 0.42747954449379444, 0.39944468305959613, 0.3928012844958604, 0.41680144862209245, 0.39795390425501387, 0.3975693523345841, 0.39960702440286533, 0.3897061376841183, 0.09801280983551064, 0.11666877613249849, 0.12286260773147029, 0.10489740496387145, 0.11628385080191694, 0.12839620880704317, 0.11132454375008383, 0.1097543320244233, 0.07806994654416122, 0.151455664563241, 0.1714630149869023, 0.13131736871360844, 0.1822990120538157, 0.1637771424324168, 0.14764378755337837, 0.15546086731552855, 0.1865400869439966, 0.17755871583599914, 0.29904551518645983, 0.2980986314675782, 0.3027201481476486, 0.277348744366103, 0.2607915353799487, 0.2979575765522565, 0.26472528694196285, 0.3083944747101285, 0.2921067265898344, 0.22411354103635484, 0.1870840594758718, 0.26429843335993497, 0.2295567707382059, 0.222899151215611, 0.22225755010663428, 0.2037239425511045, 0.24151669540850818, 0.19354471524933337, 0.24065848541690615, 0.23546768649385985, 0.23538662838694602, 0.24449183233743121, 0.24660516331689364, 0.24093078678605584, 0.2336858397357906, 0.22143016590204, 0.23799518337417036, 0.18059830328204085, 0.18136950928902174, 0.19780178671244342, 0.199949805715242, 0.211579378034066, 0.19612051873140768, 0.20582816257759662, 0.17775454925766443, 0.1774305830542695, 0.18462318379574805, 0.17438227130416495, 0.18441142707629998, 0.11751574829915612, 0.19821251649899252, 0.1669140876351537, 0.14102956363192165, 0.5034569615007987, 0.5665608745586787, 0.5303829630304462, 0.21061496679513658, 0.5469367847874449, 0.20619755812522822, 0.4054941655972649, 0.16809268386330367, 0.16575227229271228, 0.3829758154700582, 0.36409209525058484, 0.19796332285965523, 0.20353607810598262, 0.18036290132367971, 0.1827095492641776, 0.17487838786871468, 0.19404511623972243, 0.18040610110690491, 0.18049911481004277, 0.1825321509068184, 0.09724352279183368, 0.09360610080276632, 0.10059818199213, 0.08830576186444128, 0.08902337841282804, 0.09328752097580872, 0.0810543797463954, 0.09610699812864953, 0.08920243715724463]}, "mutation_prompt": null}
{"id": "9ff2d43a-bf30-4fa1-b44b-253e6ba992bd", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with probability 0.8\n                if np.random.rand() < 0.8:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 8, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 54, "fitness": 0.20993487839212915, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.48750400346732303, 0.46173581276167186, 0.4807082395831461, 0.5096651422599217, 0.43677602623912737, 0.50845536508513, 0.4745448635191004, 0.464089512523735, 0.4998613113148783, 0.018993203750317655, 0.003941782454655929, 0.014169588104560926, 0.0011243171073125335, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12923425641237207, 0.11304060349080447, 0.16134030469652172, 0.09294205848546899, 0.11243700654460154, 0.12200415856604141, 0.0852920863153096, 0.10466949815961546, 0.10811739702003087, 0.0736288595109631, 0.08726082571472749, 0.10328328803112674, 0.09820498282140488, 0.0898159788608558, 0.09660973835099007, 0.08578323212438466, 0.09130009482301171, 0.08833356062403475, 0.9139919720784135, 0.9299162270239842, 0.8843607621260159, 0.8509234158633354, 0.8895988649395496, 0.8561048102692037, 0.9102681739921535, 0.9230589887026595, 0.9086034248030312, 0.2599677625714829, 0.2568951966152482, 0.24082599751578626, 0.24395236940046217, 0.25230509989006356, 0.24804043159352007, 0.26540547502407996, 0.22073461708177333, 0.23654317109142786, 0.7021537218410483, 0.3110186529203339, 0.2988227987585953, 0.27212470738160854, 0.25947827949875724, 0.20763855706808865, 0.22052053382388948, 0.2318174201556471, 0.3398081859890474, 0.11939553605875886, 0.11736899491477193, 0.13678681488646616, 0.09359530350864098, 0.13905825330372112, 0.13952520730008, 0.12548603257864976, 0.14322843833569165, 0.1698212490007276, 0.1590286058721595, 0.16550413492325933, 0.16099253303494188, 0.12530252972165457, 0.1746691723877144, 0.14287069581584633, 0.16991973031512675, 0.1247953579367258, 0.15576977761166777, 9.999999999998899e-05, 0.010983107931082148, 9.999999999998899e-05, 9.999999999998899e-05, 0.004750697087650191, 0.002940680656513539, 0.03210787551105532, 9.999999999998899e-05, 9.999999999998899e-05, 0.10968776100681021, 0.03925513829838945, 0.1237374969039855, 0.0821894083683039, 0.07988607021217375, 0.022216659744510925, 0.08913066055895291, 0.07186687049026264, 0.12804205805438995, 9.999999999998899e-05, 0.004579145469911561, 9.999999999998899e-05, 0.022251242764695367, 9.999999999998899e-05, 0.00034879441564061864, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006495185460058117, 0.12332084114524622, 0.09634123624165258, 0.1366871523620593, 0.1139304099129198, 0.10840193035569223, 0.09296772640979767, 0.1140418912990443, 0.10633401445931046, 0.06687025108346811, 0.4246119738492493, 0.4183003651322029, 0.4201297928201331, 0.40880913875808655, 0.4173820977900943, 0.3986375106618478, 0.4276059567616577, 0.4193843552605342, 0.42240532791136465, 0.09909942817369011, 0.09085508464118153, 0.08352616097782373, 0.12220450901672686, 0.1271708496393138, 0.13306292009683962, 0.13656072897375215, 0.13095250656935564, 0.09658205519278873, 0.14907974090990683, 0.17058533167772838, 0.14243160333742222, 0.16767176086956515, 0.1892274221349044, 0.18602737580476236, 0.1635990070328247, 0.17374559003224554, 0.19012609296857452, 0.29352882250782464, 0.27009058033642586, 0.29167749710383983, 0.2821033943453033, 0.29773280194773455, 0.29155576348485124, 0.26280445547483977, 0.27799460445152924, 0.2550493611313662, 0.21330944568916843, 0.17989258936106456, 0.2536677374792573, 0.239663345160672, 0.23196564179166812, 0.20774643660647196, 0.18682140105085987, 0.20349504370605564, 0.1875417786656569, 0.22844411645302576, 0.23716827309471733, 0.21866475271965113, 0.2247810513337548, 0.2442858988669222, 0.2617615287852346, 0.23322499817127884, 0.24806021317156346, 0.22728760790764813, 0.1848375321886382, 0.18588075742724453, 0.17950815728333214, 0.18315816260478834, 0.23791296519677563, 0.2099589141864897, 0.2058792357504542, 0.1787636398967294, 0.1912283013965308, 0.1281212789801368, 0.1855439018292887, 0.18693758313217534, 0.15189394447758875, 0.19773527626326426, 0.19537656045742935, 0.1414132863466795, 0.15395331746110474, 0.7217174082855263, 0.4316714596386517, 0.21045409309060492, 0.5295699032382533, 0.3987198597523969, 0.16531961271331275, 0.16683517180248875, 0.1652085877452264, 0.32705072383347156, 0.16782055167312593, 0.1975618308299919, 0.18181165532508714, 0.18186068634990193, 0.1917997603684699, 0.17411771059806846, 0.18230767856525265, 0.18260939033850676, 0.17801475234362807, 0.18587541139636066, 0.081808758871737, 0.06415259974654941, 0.08824697680543381, 0.08929020961481715, 0.08388933384902575, 0.08231923873050018, 0.08578880797943511, 0.08968666048447027, 0.09434453251951214]}, "mutation_prompt": null}
{"id": "260d1c45-37dc-49b5-85ec-c91cc6b7887c", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.multi_explorer_prob = 0.3\n        self.multi_explorer_num = 3\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_explorer(self, particles):\n        explorers = np.random.uniform(-1, 1, size=(self.multi_explorer_num, self.dim))\n        explorer_prob = np.random.rand(self.swarm_size)\n        for i in range(self.swarm_size):\n            if explorer_prob[i] < self.multi_explorer_prob:\n                particles[i] = explorers[np.random.randint(self.multi_explorer_num)]\n        return particles\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Multi-explorer strategy\n                self.particles = self.multi_explorer(self.particles)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a novel \"Multi-Explorer\" strategy to utilize multiple explorers with different exploration-exploitation trade-offs.", "configspace": "", "generation": 55, "fitness": 0.0931936911699918, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.09 with standard deviation 0.08.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.24993897818514543, 0.2215803240196852, 0.21905191451619355, 0.11082126844547169, 0.12506885433265602, 0.1217994237384511, 0.12061690849105888, 0.1386698407733209, 0.12765465541064713, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0431703123407422, 0.04832315148463184, 0.045614756720620764, 0.05802225744399925, 0.04636884683672182, 0.04210622010251719, 0.03473034660127983, 0.025082588246164605, 0.014207325606492627, 0.04046361411911348, 0.05448096190154961, 0.05582957626161755, 0.034119004945679654, 0.04579653614640988, 0.046091876014651145, 0.030007222871439976, 0.030482054227716104, 0.03467581700363975, 0.0942073851890658, 0.04283549450955926, 0.0320108920017419, 0.09321590085564058, 0.03215933885147282, 0.05887547792350378, 0.06834737947011926, 0.04957217285241966, 0.05087501084799584, 0.08471903707505712, 0.04913160175761222, 0.0534607397406347, 0.02485138242309326, 0.03685905658276456, 0.03332129317581789, 0.05977215830780791, 0.013526531207016523, 9.999999999998899e-05, 0.17514753064689814, 0.1723918874760464, 0.19730491144319318, 0.09093265239031356, 0.18502575767007057, 0.15537459345654459, 0.07885077856204448, 0.07405972018499962, 0.07988054015880552, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00367015794749348, 9.999999999998899e-05, 9.999999999998899e-05, 0.02467917356883431, 9.999999999998899e-05, 0.12337805524361756, 0.11683052149565998, 0.11804591865727998, 0.1158664878855672, 0.1269212114332937, 0.11673248851777551, 0.11755235217544124, 0.13266284089110103, 0.10846586396522961, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05626900518351918, 0.04396445564044693, 0.044358270313283765, 0.04783418693197805, 0.0505586739777254, 0.020752996400178914, 0.011056248646616362, 0.01537977927714107, 0.06580643904456829, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.2286057175451579, 0.21028385169704666, 0.1968707556941377, 0.1774699872495128, 0.15308892088239678, 0.15818146887531725, 0.2614881177131022, 0.2563423459943134, 0.2729555443329338, 0.02799718373082105, 0.02175037492163634, 0.02973002665634561, 0.04336502253137475, 0.04065212935862361, 0.0491347141661187, 0.04933552712209255, 0.05627928338662891, 0.04483199529908122, 0.14182741306001678, 0.11758212590341044, 0.12357912378159586, 0.12086113235011986, 0.11536676478415941, 0.13668714477107224, 0.15569272120288535, 0.15495883458801418, 0.13802785036344234, 0.14714830904974552, 0.1487005959270855, 0.13860830163485005, 0.19198501351682307, 0.19458483182713937, 0.20624853413334476, 0.14878210866534503, 0.14825907689886753, 0.14037718381065512, 0.12573154230523065, 0.08729960519876878, 0.09708772027046997, 0.14561250445907148, 0.142191306720868, 0.1669578342978877, 0.07808451329278154, 0.08804753362073348, 0.08711511942648575, 0.23093009332627756, 0.23660968253227566, 0.22448947956909993, 0.21986111157749633, 0.24826954701478166, 0.22493317547975644, 0.25679941266872, 0.2502634025516439, 0.25101015974365715, 0.15982328971193183, 0.16382176191853925, 0.16034084200622734, 0.156974699247591, 0.1613077039403692, 0.15764164072261488, 0.15437276291172786, 0.16011103891359357, 0.15687019503751087, 0.1825966337745124, 0.1778093848426845, 0.1754823532129347, 0.10803679851838133, 0.11384759125552113, 0.11933799397778588, 0.09229667273205722, 0.11977215244069994, 0.09467377677635036, 0.21082688474918676, 0.23594190239510682, 0.20389637902899538, 0.10351352366664213, 0.10139806726917577, 0.11377067659540285, 0.15568053082120148, 0.13890148813823566, 0.1448114806288704, 0.18812344466983644, 0.18746660521340797, 0.18126634118341833, 0.1832623055742738, 0.17515562382821048, 0.17674795139554766, 0.18746178803499347, 0.18120811983253649, 0.17647077684556356, 0.07366789429115328, 0.07477493279935554, 0.07388551562056056, 0.07206629836200795, 0.07537494897816577, 0.07047198570958624, 0.06737657476546155, 0.06729451389511454, 0.06830068025935598]}, "mutation_prompt": null}
{"id": "1ff61b09-f5dd-479b-a2e3-2e7fb315408d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.multi_explorer_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_explorer(self, particles):\n        explorer_particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        explorer_velocities = np.zeros((self.swarm_size, self.dim))\n        explorer_best_positions = np.copy(explorer_particles)\n        explorer_best_fitness = np.inf * np.ones(self.swarm_size)\n        for i in range(self.swarm_size):\n            explorer_fitness = self.global_best_fitness\n            if np.random.rand() < self.multi_explorer_rate:\n                explorer_fitness = np.inf\n                for j in range(self.swarm_size):\n                    if np.linalg.norm(particles[j] - explorer_particles[i]) > 1e-6:\n                        explorer_fitness = min(explorer_fitness, self.best_fitness[j])\n            if explorer_fitness < explorer_best_fitness[i]:\n                explorer_best_fitness[i] = explorer_fitness\n                explorer_best_positions[i] = np.copy(explorer_particles[i])\n        return explorer_particles, explorer_velocities, explorer_best_positions, explorer_best_fitness\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Multi-explorer for balancing exploration and exploitation\n                if np.random.rand() < self.multi_explorer_rate:\n                    explorer_particles, explorer_velocities, explorer_best_positions, explorer_best_fitness = self.multi_explorer(self.particles)\n                    self.particles[i] = explorer_particles[i]\n                    self.velocities[i] = explorer_velocities[i]\n                    self.best_positions[i] = explorer_best_positions[i]\n                    self.best_fitness[i] = explorer_best_fitness[i]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a new \"Multi-Explorer\" strategy to balance exploration and exploitation.", "configspace": "", "generation": 56, "fitness": 0.18485717492469889, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.18 with standard deviation 0.18.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.3814842462237017, 0.3395496266753095, 0.31905217776065975, 0.29635495040978, 0.3003583557313535, 0.3246117962757997, 0.31648692241361154, 0.31477990173415826, 0.31676496261883835, 9.999999999998899e-05, 0.009613024589199104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09141280417352993, 0.08410793358004465, 0.0811974003378042, 0.08525461105881382, 0.07439406955291228, 0.09693021921086731, 0.07846239203382832, 0.07709336578240145, 0.10266387556474288, 0.08119173528710366, 0.07229664933396585, 0.07177351509248109, 0.09249906316336942, 0.07308902598738076, 0.08602801582315456, 0.06934206174725877, 0.07199559145148182, 0.07465271073893687, 0.9145473367762778, 0.9415721499871422, 0.8973703374974807, 0.9066943975130746, 0.8777639764132169, 0.8878712959833754, 0.928731831748883, 0.9302145858160789, 0.9145842003305179, 0.19217414668003563, 0.18994631711019427, 0.18497282573607343, 0.1932947051025552, 0.18168630237050698, 0.18586336892035715, 0.18147815458079475, 0.19505430097344356, 0.18064515802763348, 0.2576935711936842, 0.34067533127955596, 0.2302756043242573, 0.25547414087544174, 0.2509854795121891, 0.1960671249983852, 0.2264642986137385, 0.17144439747519014, 0.20955618225670813, 0.11995589845594201, 0.08154727328926203, 0.1049453997076305, 0.10305012546344294, 0.11499333200469153, 0.10602843899395886, 0.12655203304040974, 0.11050810458618254, 0.11548177886948885, 0.13092418901916714, 0.11357105988973981, 0.1221636989814382, 0.13378478446883013, 0.12479293959375193, 0.11165535423764883, 0.11400381026340545, 0.11560878788257922, 0.09191904758532077, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12966078527515823, 0.07625703168407838, 0.11297167972170241, 0.12192108148659486, 0.0592379968224217, 0.05480945911464952, 0.12467855607286604, 0.09698175375396989, 0.07736688197998043, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04963558017086378, 0.05050258854062539, 0.0402927721419184, 0.05917023725416348, 0.04378179856102693, 0.0351858326391159, 0.04430422455418559, 0.03795821604077987, 0.03798447217800238, 0.3154204343571697, 0.3027859008692123, 0.34535095189392173, 0.33016751128302635, 0.3121377552203457, 0.2947392836038254, 0.3448039864844946, 0.33957457453610984, 0.38191433085090376, 0.08442965398880731, 0.07426310339708853, 0.08171008343669306, 0.06778049440597422, 0.07648526916783882, 0.11821519478403897, 0.09520915385446693, 0.09885795620284721, 0.08551934208892542, 0.15885280225572274, 0.1251840220967615, 0.14192195549195985, 0.15424060189459743, 0.20125007466799516, 0.1726898090900344, 0.14977031486789583, 0.19378318304616227, 0.16913921060003556, 0.2358651501026433, 0.2259713598121551, 0.24352556588958474, 0.26704036223898286, 0.2489293047705856, 0.24266633450687403, 0.23515983177629196, 0.2619911251546114, 0.1930713621216461, 0.18192000577169742, 0.17813921937934207, 0.1793786844587204, 0.1872645406908754, 0.18236515299613398, 0.21032726959276593, 0.15288126989386197, 0.18904061869645994, 0.161378987897014, 0.2187603472638764, 0.219400108292355, 0.2339424739253746, 0.22044547811944049, 0.22274806055113294, 0.22718340319577224, 0.21719827413708925, 0.23260302510351494, 0.21166787879807303, 0.1767193809717783, 0.19658937647669839, 0.17034772666829634, 0.19220150011956916, 0.17256737112171072, 0.170812291020782, 0.16937735368860396, 0.18690672257241514, 0.16454255627336534, 0.18322096309479152, 0.18481567457044834, 0.18583010854208137, 0.18262426034160928, 0.35618839893517285, 0.1836155747810635, 0.4371802240600563, 0.3616718853515666, 0.37716254600801524, 0.4040147052728208, 0.37964169432020656, 0.29325281026159056, 0.3052577872207397, 0.16942820192297148, 0.16600185256390154, 0.2828134911669111, 0.44606917912904487, 0.26169265535616737, 0.182322554804489, 0.18529792595675842, 0.18931435950741415, 0.1899779626919189, 0.198644427993531, 0.1879122183474755, 0.1910412041836954, 0.20688693974270211, 0.1799776704009799, 0.08559584653432917, 0.08360838423653805, 0.08248137904694708, 0.07287891246514933, 0.0863810082081583, 0.08919063285459083, 0.08064153524094275, 0.08905738864049595, 0.08700146071845427]}, "mutation_prompt": null}
{"id": "3c9027cc-58a8-41ee-b425-ff5155d2a57f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.98\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.archive_update_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < self.archive_update_rate:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Archive-based Position Update\" strategy and modified simulated annealing with adaptive cooling rate, using Cauchy mutation and Gaussian perturbation, and a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm.", "configspace": "", "generation": 57, "fitness": 0.21833280243053202, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.4269539956693157, 0.460230599492794, 0.46346841595775023, 0.4821594053991798, 0.4775509697480844, 0.4534412674116972, 0.45218434740677826, 0.4446175904123083, 0.48195415560810806, 0.0026389698331524825, 9.999999999998899e-05, 9.999999999998899e-05, 0.00029249015402932343, 0.00042895727394676175, 9.999999999998899e-05, 9.999999999998899e-05, 0.02764049359219589, 9.999999999998899e-05, 0.11479368964346814, 0.09482915985972173, 0.07841204671608881, 0.10914741559935626, 0.10479491667962171, 0.10988959654279695, 0.12263682322188452, 0.10926361630577008, 0.10639187476589962, 0.09229548373802299, 0.09426161338591887, 0.09389863521355091, 0.08623855852383133, 0.06611845440992214, 0.0947600222300391, 0.08363142550037139, 0.0859606877396153, 0.10349488791395234, 0.9156940071464299, 0.9461656415254367, 0.8992645050619752, 0.8855231071342965, 0.8846448824576153, 0.8922484608214919, 0.9269541519864443, 0.9287165578500403, 0.9149520437065584, 0.27799271561785077, 0.2485191100831563, 0.2616731763184815, 0.25300711372572615, 0.29621482030427315, 0.25695430431682953, 0.2778065398557553, 0.24337582905962118, 0.2275462581966331, 0.6148652911324645, 0.3149385238491226, 0.24638936675329648, 0.26562252577356316, 0.3497843787214864, 0.20106805758283686, 0.26684063644334777, 0.21967220695117984, 0.3081589213316265, 0.12484582466340999, 0.14286939675764387, 0.1167134896244515, 0.1379825538330539, 0.12852296677081554, 0.17705622761735618, 0.12485404920442911, 0.1838990472950769, 0.12261559644002318, 0.136121062072029, 0.12361884443872517, 0.16639248577168086, 0.14262123923863346, 0.12731570986687057, 0.15183286781621552, 0.1556436321888217, 0.1894978265588233, 0.16659037571873447, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0027047093520995436, 0.0014338552795208903, 9.999999999998899e-05, 0.0011606025403049225, 0.003034575768317338, 0.010120662309211381, 0.13614173338482127, 0.05939753091205169, 0.14404835144999195, 0.07118320250906762, 0.054092880584074354, 0.028801284989408815, 0.1510597041287396, 0.06636915894286033, 0.07276164363584414, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00805095395756783, 0.027682547436515437, 0.011914144900659673, 0.007757293424873524, 9.999999999998899e-05, 9.999999999998899e-05, 0.10302092710720023, 0.1363921618506303, 0.11574021169824211, 0.09341081161126707, 0.1372440312532477, 0.11959206726364169, 0.10655349328515296, 0.10082201000757918, 0.11614313523761777, 0.43480445815684643, 0.40300743999592015, 0.4405289234301528, 0.43145656114623343, 0.4036225597970964, 0.41049164399274674, 0.4205134347364018, 0.40735473329253713, 0.40037166370137367, 0.0915096879816023, 0.10721412870245461, 0.09378198241391833, 0.131991318722675, 0.10667044316091634, 0.11583832100675195, 0.07531676505674145, 0.15430544781884725, 0.0933937111553067, 0.20888621912026717, 0.26456702344889005, 0.13435322414763018, 0.20132251020091585, 0.19756863387536117, 0.24799599534905692, 0.19330565988493698, 0.13535917293156674, 0.17508611970912702, 0.29416297395686963, 0.30702208707389067, 0.2895982280875331, 0.26599773460813325, 0.31175341788234623, 0.3040703379019384, 0.2469965873917388, 0.2966357182084204, 0.2925808632885947, 0.19115311081040354, 0.20950485647804307, 0.20320416828372, 0.22317161094235827, 0.25829333651995734, 0.2316966325079911, 0.21588350394816547, 0.21723932132839407, 0.16916642164857076, 0.2515509473570099, 0.24500758120419164, 0.24648892461057204, 0.24234480552950521, 0.2711175589222936, 0.21619569608759248, 0.24561360465673487, 0.22678142586372774, 0.23104131141692774, 0.19267679063073606, 0.18322578380105436, 0.18035557835289706, 0.1850399443995735, 0.1851993249265198, 0.19167833964744907, 0.2002049013874796, 0.26445975188733684, 0.1808143831591431, 0.18457206187143826, 0.18632794679857434, 0.18639846551539296, 0.1174624502663777, 0.19788115570863551, 0.145396772404624, 0.14105121311081925, 0.5231559125152376, 0.6249725604301192, 0.5898966849101848, 0.4519196801778279, 0.6284387111513323, 0.4811303894644663, 0.3501543768229862, 0.16649364642619857, 0.1664023714672952, 0.4200637607832043, 0.361285845132851, 0.18857400656163903, 0.1902711683354681, 0.1756483885553607, 0.18811830173198418, 0.17234332432128263, 0.18197178261997804, 0.18310098344935444, 0.21214562941366866, 0.17583637735344493, 0.09356048294781194, 0.0949472591906666, 0.10039908584137502, 0.09993032709047178, 0.08956006219024548, 0.08675862897353526, 0.1130608512508341, 0.0991918970916682, 0.08691683512046222]}, "mutation_prompt": null}
{"id": "959ea757-1ca7-4df4-b0a0-0888727ba0b3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            # Introduce a new random particle\n            if np.random.rand() < 0.05:\n                new_particle = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n                new_fitness = func(new_particle)\n                evaluations += 1\n                if new_fitness < self.global_best_fitness:\n                    self.global_best_fitness = new_fitness\n                    self.global_best_position = new_particle\n                    self.particles[np.argmax(self.best_fitness)] = new_particle\n                    self.best_fitness[np.argmax(self.best_fitness)] = new_fitness\n                    self.best_positions[np.argmax(self.best_fitness)] = new_particle\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 4, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 58, "fitness": 0.21775361947401858, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.4776127103908119, 0.4478246781974622, 0.4631548592113416, 0.44674084589829344, 0.4717112412028701, 0.4491415656734806, 0.43422708845767655, 0.4475151377644355, 0.4534880096435985, 0.005224977180052326, 0.01029804296839354, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013095219507622824, 9.999999999998899e-05, 0.1267837412311723, 0.11082023165397203, 0.0838318694406075, 0.08113342462924489, 0.11091817409182092, 0.09692199829499937, 0.11060467390444373, 0.1347643194981425, 0.10171616248583193, 0.08292824681952515, 0.09409077230202434, 0.09432299914426479, 0.10525725853353851, 0.08380971771272194, 0.09427519174955756, 0.10145750843926848, 0.08780598737705081, 0.09065549672787132, 0.9149185365843612, 0.9528475656721036, 0.9019599952738571, 0.8590307485187099, 0.8922575248175727, 0.887229440003112, 0.9400928966172807, 0.9274045226928455, 0.9152445442680793, 0.24571331683776343, 0.23623816873406034, 0.25129590519834144, 0.26225835007628606, 0.2883024449316183, 0.2560652237202128, 0.2581571269784355, 0.2548019730012726, 0.2616153468494926, 0.35830296228249403, 0.35887942079919577, 0.2944328563099903, 0.3240141141774907, 0.267382031811103, 0.20440000371804823, 0.2805481153879734, 0.28507383609564885, 0.30757531142740613, 0.143114421430229, 0.20302068679211593, 0.13587991004025812, 0.14536555671767293, 0.1327662689844099, 0.14364293607372458, 0.1427352951022849, 0.2078649458819869, 0.1515082963578891, 0.13779550866315438, 0.13472385216692417, 0.14272395888482337, 0.12273481978217038, 0.1462364675597979, 0.14770362213693256, 0.13443699688258293, 0.14061436562930407, 0.13938608467221658, 9.999999999998899e-05, 9.999999999998899e-05, 0.0011604875910523615, 0.022014674609741047, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1273584898019049, 0.058076611469501604, 0.08719113213121543, 0.09650977797693083, 0.0688440289921507, 0.015210840319275443, 0.13051085016280972, 0.08818575407039864, 0.045229610352893856, 9.999999999998899e-05, 0.0031961086480627454, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12278417431736466, 0.10981606708245784, 0.1012726966143962, 0.10823895910890113, 0.10548112672459187, 0.12165543879430263, 0.07733486014181568, 0.11806272552450958, 0.127749090917465, 0.4255475516668472, 0.4116764170736745, 0.4173976799671558, 0.4133202673340466, 0.42071020363199774, 0.42881049591845066, 0.4234779678345454, 0.38007977662525994, 0.4332759224808369, 0.09547303944404173, 0.12390917581998673, 0.07810503542733982, 0.08954326719336114, 0.09418483587413462, 0.11167186556218534, 0.08655288754098056, 0.1290526744184839, 0.10778693663161287, 0.17684450320934342, 0.21515529407864598, 0.1510146448870564, 0.19622472084995146, 0.18845017734323877, 0.16029774052584977, 0.17978180561978008, 0.20482154155541876, 0.2184742144558791, 0.3055113885767845, 0.2733034944425793, 0.31610191262123577, 0.27099648771383933, 0.26454362561885714, 0.29998514989353575, 0.2916169883171711, 0.28438711430310704, 0.23880325862974316, 0.19711165281901266, 0.19186480227873504, 0.23951648211871213, 0.24638595910569006, 0.22777498945473373, 0.21472137648634082, 0.20160593173620978, 0.23573480125422308, 0.17519479733800414, 0.23737762118164818, 0.23041304294528064, 0.2199778400993727, 0.25064762372368043, 0.22609231060576884, 0.2129735196551794, 0.23616210234214252, 0.2620305025663291, 0.20853194962697674, 0.18408206266523974, 0.1834487132601701, 0.18599944336730811, 0.18834350438756298, 0.183113252086458, 0.17746214884734146, 0.18012204112147157, 0.18162134739869296, 0.182196335639073, 0.18500328713933356, 0.18612735309077855, 0.18516145456508415, 0.11839680125887408, 0.1973959390588328, 0.6213944249760698, 0.14911587373868262, 0.6331627361839787, 0.5984323994866273, 0.5922106953907339, 0.5077995148642723, 0.4876987769646298, 0.5538964093328094, 0.16975624616252938, 0.16761988791447602, 0.1653386456355962, 0.4199613908197777, 0.49877304952016743, 0.17839744806026758, 0.19918298190721584, 0.18483564453538315, 0.19592010826885775, 0.19915751784381797, 0.1845958038357478, 0.1837224065619386, 0.21218189657304443, 0.18810895381874393, 0.09405891422110235, 0.08358873676362366, 0.08406875195623631, 0.11123423460283288, 0.11281921355109092, 0.07801911649196824, 0.08536257812919412, 0.0860364349382764, 0.08043802900003016]}, "mutation_prompt": null}
{"id": "0a525702-c879-48e1-932d-c28aaf48b6de", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.multi_local_search_rate = 0.05\n        self.multi_local_search_step_size = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_local_search(self, position):\n        new_position = np.copy(position)\n        new_position += np.random.uniform(-1, 1, size=self.dim) * self.multi_local_search_step_size\n        new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n        return new_position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Multi-local search\n                if np.random.rand() < self.multi_local_search_rate:\n                    new_position = self.multi_local_search(self.particles[i])\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < fitness:\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a new \"Multi-Local Search\" strategy to escape local optima.", "configspace": "", "generation": 59, "fitness": 0.21104419904796692, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.4293351169042672, 0.4901451164297329, 0.44233801625689917, 0.4482645609154965, 0.45318316524385305, 0.44867534955448285, 0.42649666693694843, 0.43960183408223286, 0.4499551879194622, 9.999999999998899e-05, 0.020889555600571486, 9.999999999998899e-05, 9.999999999998899e-05, 0.013842959408721822, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09399397964586953, 0.12824751037503024, 0.10799406668064859, 0.08919116871170096, 0.09087983788105392, 0.09222178572864015, 0.1150257997568257, 0.11455807634012527, 0.10660255637191896, 0.09683967181389286, 0.10049934613459433, 0.07788031764736991, 0.1111627252402646, 0.08259034492547124, 0.07433787850217888, 0.09790725477125328, 0.0852730373160091, 0.09491411543248252, 0.9056913178417456, 0.9316079742494991, 0.8891232294789698, 0.8400279610573919, 0.8751605917227802, 0.8766406982518563, 0.9219630062280222, 0.9158596775822921, 0.9114771422567586, 0.26044890106684015, 0.25258638579476234, 0.23125749656058303, 0.2695010692491381, 0.25219862629263523, 0.22474059518367795, 0.24986009415026444, 0.24888169801374083, 0.22576954592943077, 0.22897868322622295, 0.36726075072927256, 0.27040923526571636, 0.3246437580853462, 0.24581987329018407, 0.22617258791448025, 0.25160357725040017, 0.22960386690526602, 0.31574192378148214, 0.15935211426008788, 0.13198339982473373, 0.12089857641249868, 0.1344422638308015, 0.12906833682373364, 0.14309502325447554, 0.1434007342282575, 0.13597420002901506, 0.14018647295292908, 0.18613021250219175, 0.15902617758086435, 0.13168437323010296, 0.1831170728693743, 0.14404726284617697, 0.12516760885192157, 0.14682564280318333, 0.1322687476684551, 0.15402681967521747, 9.999999999998899e-05, 9.999999999998899e-05, 0.014069758598052817, 0.11126514657425124, 9.999999999998899e-05, 9.999999999998899e-05, 0.00010194105497107753, 9.999999999998899e-05, 0.025358267596734874, 0.10280236320035585, 0.049755503629472675, 0.09823054130779907, 0.09935813394022919, 0.10742192641121984, 0.04537312194980092, 0.14250367767998073, 0.06125114651027075, 0.05429453528933048, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00011032129703703042, 9.999999999998899e-05, 9.999999999998899e-05, 0.009136655502032798, 9.999999999998899e-05, 0.0952574752330333, 0.15417274920591117, 0.08383037679725636, 0.10169245769000312, 0.1219848861478986, 0.07655269844273427, 0.09596774622315352, 0.1065931570874985, 0.10640766493378429, 0.41514366242176903, 0.4062287955239444, 0.406435942680788, 0.4129398728930499, 0.39331402190612696, 0.40843164399723697, 0.3931428878817268, 0.4018712100830797, 0.3998606036255383, 0.09888572260265505, 0.1327046850620176, 0.11742352409424073, 0.13122218346085823, 0.10621937558563, 0.12052112655802227, 0.10337713507089608, 0.09074174500127741, 0.0803731210021319, 0.18570625526983386, 0.20781337184055793, 0.13218683980163426, 0.21257776202937206, 0.1853335334285876, 0.18972649056067825, 0.16895723915714822, 0.17402306401522272, 0.1978777177170037, 0.2977939393710243, 0.2856016376550672, 0.27359131446336804, 0.28507613089855, 0.2866908935180682, 0.25707332088848467, 0.2944895962606011, 0.282693945008753, 0.28503569726057165, 0.19979395002590195, 0.19350620194357093, 0.22835726228952802, 0.2364042388240576, 0.22212635170026607, 0.22551516088597023, 0.21129717467616216, 0.21395350505552013, 0.20424753258081507, 0.21519965353362946, 0.22879232523055593, 0.22068782674034415, 0.2222282302436286, 0.24123042423017327, 0.2210293707229284, 0.22169216016261994, 0.24025602727866902, 0.21005395470377874, 0.18247749339301267, 0.1799622118541434, 0.18310016492502323, 0.2046532977536233, 0.2065622239628514, 0.1907421674486276, 0.18547232850115147, 0.18283296691269224, 0.18037461368356633, 0.18567123491794446, 0.17420654566511462, 0.18639595044713897, 0.1714215999039811, 0.19766157100610804, 0.2082636780064091, 0.14101497372034577, 0.7642376806785653, 0.5909762130549083, 0.4797932965923646, 0.21074949037376378, 0.4687680330163836, 0.20448487104958246, 0.20439406674083516, 0.41389592012215237, 0.16712226372203365, 0.4525851130467786, 0.34581382305762887, 0.18065442761212602, 0.18219665193815648, 0.18101818110218115, 0.1908649233722296, 0.1785556139141038, 0.19682022906140106, 0.186666929063515, 0.1804650028942415, 0.19257176593099978, 0.11064099245177583, 0.07095540542110135, 0.08280423510993007, 0.10813553565188927, 0.10121079449440218, 0.08275231282138573, 0.09098461862177498, 0.09428293527290266, 0.10091072481277974]}, "mutation_prompt": null}
{"id": "91cc5200-7266-4824-8f84-55b351ffa08f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.differential_evolution_rate = 0.1\n        self.differential_evolution_step_size = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        while r1 == r2:\n            r2 = np.random.randint(0, self.swarm_size)\n        mutant_position = self.particles[r1] + self.differential_evolution_step_size * (self.particles[r2] - self.particles[r1])\n        mutant_position = np.clip(mutant_position, self.lower_bound, self.upper_bound)\n        return mutant_position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Differential evolution for local search\n                if np.random.rand() < self.differential_evolution_rate:\n                    mutant_position = self.differential_evolution(self.particles[i])\n                    mutant_fitness = func(mutant_position)\n                    evaluations += 1\n                    if mutant_fitness < fitness:\n                        self.particles[i] = mutant_position\n                        self.best_fitness[i] = mutant_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutant_fitness)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and incorporating a new \"Differential Evolution\" strategy to enhance the local search capabilities.", "configspace": "", "generation": 60, "fitness": 0.21110997564866504, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.4680816315652243, 0.45429265395434393, 0.454703886056977, 0.4684562828888391, 0.44491903012163514, 0.4440699781834687, 0.4557554301340908, 0.4249319162639781, 0.4618347872520482, 9.999999999998899e-05, 0.017282662922446068, 0.03622690774815218, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1034435984321872, 0.08747896513175879, 0.11045759150154177, 0.09816648780510417, 0.10804359732523006, 0.12002182459719224, 0.1100943111149223, 0.14617745665257809, 0.10024558714956677, 0.10127658852934851, 0.07154715592766292, 0.10146833033149905, 0.08300085430829662, 0.0801230932316086, 0.09330103294460601, 0.08392612407808542, 0.08714138623586054, 0.07794858122205117, 0.900594661668544, 0.9402403222413667, 0.9059325036433402, 0.9014704594439225, 0.8332508669319609, 0.8672925538776464, 0.9107807965429597, 0.9247610490538097, 0.9047112132852503, 0.2609250877765559, 0.2579315681155834, 0.2429887814081283, 0.2302459190743601, 0.22771987252038883, 0.21813603388267888, 0.22242967970297167, 0.22662939233685275, 0.2213122018912167, 0.31113442282325854, 0.5083165833202465, 0.26756404251519617, 0.2577871795089458, 0.20612780712601908, 0.25564096121007307, 0.20050591200155965, 0.2266090578106218, 0.28211502986533266, 0.16749554222249807, 0.13420848639817817, 0.12626996525606793, 0.1369058499707595, 0.1347890640049444, 0.16405199996289088, 0.1362532405857403, 0.17122737648440522, 0.16296619940626733, 0.13839349994080818, 0.13259195847002503, 0.12620818117847976, 0.16092438606086512, 0.14873658483973307, 0.1297925418546172, 0.12295548091086272, 0.13700764558894518, 0.1293878127516509, 0.05770439052446852, 0.03596843696445662, 9.999999999998899e-05, 0.041774673067212054, 0.018664570451897844, 0.023702649591904268, 0.0004629473519763838, 9.999999999998899e-05, 0.00987128159747186, 0.12812021496611103, 0.07267725904345557, 0.11057566858273715, 0.07133121237334983, 0.036726231792152064, 0.012402561009952628, 0.08077434373732462, 0.08386919410051685, 0.056831686708720186, 9.999999999998899e-05, 0.0033533556616653915, 9.999999999998899e-05, 9.999999999998899e-05, 0.02170246366699391, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.113754874371917, 0.09160775373723995, 0.078341816771754, 0.08711201678819469, 0.12439649105996864, 0.13088617778816747, 0.08250104511301526, 0.12129614915225517, 0.12337778068556471, 0.39603799326235944, 0.41848072017882765, 0.4427916007311795, 0.39824603818744286, 0.3871816779784163, 0.3740767237534416, 0.40773092218747076, 0.4014319880535244, 0.4176987103829639, 0.0885348982256543, 0.16175067095274775, 0.07769029052144727, 0.08219875339119642, 0.1346386317625482, 0.09019682516191929, 0.09832984119126409, 0.11676277277263147, 0.12050540451084557, 0.2095203053907333, 0.1929895540720471, 0.14104086501782642, 0.2003020276851758, 0.1912135597012079, 0.21863477144368693, 0.19096237412003336, 0.20115589922711508, 0.17000212468854348, 0.3029168232827798, 0.2627610829427449, 0.30290533635796124, 0.2546909878885324, 0.310667833536027, 0.2795964155269818, 0.28866805358484326, 0.30031186483104355, 0.2655902632151197, 0.18074096686361718, 0.2060873057039, 0.22879068278222747, 0.19755542298303952, 0.19934550752511027, 0.2159278100208205, 0.16736487634663322, 0.21563936560936126, 0.19586601672429682, 0.22009022341840456, 0.2323189070692857, 0.29431814756430963, 0.2345952055862579, 0.24932179990358028, 0.20098050166230663, 0.2457885393467638, 0.2367626176738591, 0.2283333346233558, 0.1994791656066397, 0.186785219110702, 0.1871640800954375, 0.20390698369042015, 0.1842279417223427, 0.1897975315751198, 0.19456019181832884, 0.17111260203120238, 0.17967563512931561, 0.6767079658485171, 0.18474119368734165, 0.18509405370780607, 0.5694008364462921, 0.19693986160083155, 0.19409331806452068, 0.14050497153426966, 0.2054324627424422, 0.6461099445519918, 0.4790544776051405, 0.15235868146352272, 0.332247284685787, 0.16682516237427225, 0.42864374985536546, 0.16722258167282633, 0.16409584798122245, 0.3841041355368521, 0.3209394067611081, 0.17121405448912352, 0.17224982505987407, 0.1884184990495521, 0.18692480211576068, 0.18813473878195075, 0.1827443127172511, 0.17828997485822984, 0.18371529774169615, 0.18543734619083807, 0.09777820393577508, 0.08732604880488748, 0.07920821887161378, 0.08381673039362991, 0.09193998294891204, 0.09576701535312371, 0.09683106301946376, 0.11387565741308558, 0.0876910886045762]}, "mutation_prompt": null}
{"id": "88c0a2a9-fe3b-4d10-a9fb-d007b906edfc", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.archive_update_rate = 0.05\n        self.probability_change = 0.2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.probability_change:\n                    fitness = func(self.particles[i])\n                    evaluations += 1\n                    if fitness < self.best_fitness[i]:\n                        self.best_fitness[i] = fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], fitness)\n                        if fitness < self.global_best_fitness:\n                            self.global_best_fitness = fitness\n                            self.global_best_position = np.copy(self.particles[i])\n                    # Modified velocity update\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                    velocity_centroids = self.velocity_clustering(self.velocities)\n                    if np.random.rand() < self.velocity_clustering_rate:\n                        self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                    self.particles[i] += self.velocities[i]\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    # Levy flight for enhanced global search\n                    if np.random.rand() < 0.1:\n                        self.particles[i] += self.levy_flight(self.dim)\n                        self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                    # Opposition-based learning with adaptive rate\n                    if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                        opposition_position = self.opposition_based_learning(self.particles[i])\n                        opposition_fitness = func(opposition_position)\n                        evaluations += 1\n                        if opposition_fitness < fitness:\n                            self.particles[i] = opposition_position\n                            self.best_fitness[i] = opposition_fitness\n                            self.best_positions[i] = np.copy(self.particles[i])\n                            self.update_archive(self.particles[i], opposition_fitness)\n                    # Cauchy mutation and Gaussian perturbation\n                    if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                        mutated_position = self.cauchy_mutation(self.particles[i])\n                        mutated_position = self.gaussian_perturbation(mutated_position)\n                        mutated_fitness = func(mutated_position)\n                        evaluations += 1\n                        if mutated_fitness < fitness:\n                            self.particles[i] = mutated_position\n                            self.best_fitness[i] = mutated_fitness\n                            self.best_positions[i] = np.copy(self.particles[i])\n                            self.update_archive(self.particles[i], mutated_fitness)\n                    # Particle filtering for enhanced exploration\n                    if np.random.rand() < self.particle_filtering_rate:\n                        particle_centroids = self.particle_filtering(self.particles)\n                        self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                    # Archive-based position update\n                    if np.random.rand() < self.archive_update_rate:\n                        archive_index = np.random.randint(len(self.archive))\n                        self.particles[i] = self.archive[archive_index][0]\n                else:\n                    self.particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy and a novel \"Archive-based Position Update\" with adaptive probability.", "configspace": "", "generation": 61, "fitness": 0.17138209951695257, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.17 with standard deviation 0.18.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.2963688445212369, 0.3172308677904322, 0.29337959274933223, 0.3008893283761217, 0.3038442286725298, 0.28476402049303573, 0.3118949901224345, 0.3096979722274704, 0.3381481665878374, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05490901338122345, 0.08450436280727358, 0.06972534538852537, 0.12908185999203792, 0.06630480222081658, 0.07183292299788668, 0.06940860852631214, 0.08372967264939357, 0.07931684136603456, 0.06504046159273913, 0.058045072365109585, 0.05736207423258621, 0.06349110138739, 0.07372831015968018, 0.049502837500063124, 0.06016083151656404, 0.07191564906105374, 0.06423594304446001, 0.9105922783204788, 0.9131784860403509, 0.938503464472325, 0.870369601762603, 0.9579446738781585, 0.9475343954842669, 0.9380086901405827, 0.813917594301644, 0.9335206672147377, 0.15654487884126977, 0.15476264285556696, 0.1852892381012966, 0.15445133769173136, 0.16229805914663542, 0.16453886912700633, 0.15405756127576675, 0.1634047107646187, 0.16964364037128832, 0.19093226381425488, 0.20134579578372302, 0.1683519333208755, 0.2563558583476353, 0.2109631975864863, 0.2019469823139386, 0.21701542535842355, 0.2229050889493719, 0.18037485637196626, 0.025095079466893377, 0.0877918958221311, 0.05384257793748515, 0.0790275434479456, 0.07619214160247068, 0.10247718111323634, 0.1080994042494342, 0.09749465478422914, 0.08873150002873631, 0.10595105200607502, 0.10224752360921541, 0.10491423383016829, 0.10645108136388848, 0.10963401841869158, 0.0933003079499547, 0.11648369903303923, 0.11603896527727975, 0.11467079239617906, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.012551439507546447, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13261036288406558, 0.07547890288809866, 0.09022877729179435, 0.07087121402489971, 0.049762977318845714, 0.05547943532554522, 0.08347851936255157, 0.06381387476392175, 0.05833834928825732, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.037952389951492305, 0.02737782524177057, 0.031089343197548303, 0.029142202469480627, 0.03261844366743649, 0.03907258019310811, 0.026121520675507215, 0.03800445251540774, 0.03727588275453131, 0.30426006705346986, 0.272884733141352, 0.3114505669959976, 0.32856525218655874, 0.28972501350617275, 0.3089145293621556, 0.2897411628850918, 0.2963933074060302, 0.29684871126769885, 0.08360936758684945, 0.09909072759347304, 0.08695882777209696, 0.07920643835340946, 0.06701509666341776, 0.08224186146797241, 0.08042269077276798, 0.09585149561294404, 0.0790892674921504, 0.1594596021243393, 0.15301151201445573, 0.16980592923202853, 0.140166782694792, 0.1290674261256619, 0.13228570517342175, 0.1599279372920942, 0.12771770347131517, 0.1431023496316437, 0.21625468280979276, 0.21810668993372506, 0.22457858411384746, 0.20471718502266767, 0.21864487823047274, 0.24452938221570386, 0.20418981374965284, 0.2219504581223617, 0.2309864174281694, 0.16962415514804763, 0.15906305129988219, 0.16158387718052614, 0.15440295515459745, 0.17129933201819736, 0.14839400980731698, 0.13957193007875934, 0.14004426528557412, 0.15304463468887264, 0.19264338025517724, 0.196888301281411, 0.21412187497359836, 0.21563009531085298, 0.1914664438084257, 0.21619981433968594, 0.20465918099163738, 0.19810398642503857, 0.20764821035991066, 0.16950209866220045, 0.17230397864516667, 0.16453369867884282, 0.17672783504721978, 0.16403522119217084, 0.1683694590028001, 0.17519718031427534, 0.16889140647991285, 0.16468859394425384, 0.1654210022525413, 0.36725302364083645, 0.28743196862856535, 0.29682852172245044, 0.302009717272974, 0.18842773013126002, 0.3204847639646812, 0.3262328914774444, 0.33393349580791876, 0.22901404037902862, 0.4123036094895851, 0.2896941537492983, 0.290825329502195, 0.18128171219573164, 0.1806949986691585, 0.2756388234007, 0.20722079441418295, 0.2008686684344161, 0.18177135366920538, 0.17462948845500903, 0.18783679863947034, 0.17694944161161819, 0.2002056555331283, 0.1726866365566997, 0.19882468958407162, 0.22831247266516097, 0.19445195026960838, 0.06557915952715321, 0.09452643456769783, 0.069842920857761, 0.07669660559666114, 0.07492921150218823, 0.08227659140274557, 0.07305620345060415, 0.07710441393920686, 0.07429903679524663]}, "mutation_prompt": null}
{"id": "8e182d42-d735-480d-bbf4-1d81336727e5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.differential_evolution_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        return position + 0.5 * (self.particles[r1] - self.particles[r2])\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Differential evolution for enhanced exploration\n                if np.random.rand() < self.differential_evolution_rate:\n                    self.particles[i] = self.differential_evolution(self.particles[i])\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a novel \"Differential Evolution\" strategy to enhance the exploration of the swarm.", "configspace": "", "generation": 62, "fitness": 0.21187431154509845, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.46524718400625775, 0.43444270721883227, 0.4215838562027484, 0.44912664519723944, 0.43912134800240776, 0.4550875345893921, 0.4354452198253346, 0.4357461361726146, 0.44754473995452604, 0.010830980633822263, 0.0016264891957009642, 0.003664540633451563, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02131945139402347, 9.999999999998899e-05, 0.11304410302120049, 0.08900394163846503, 0.09328328502081296, 0.12597326608601556, 0.09994837747716068, 0.09851257381063983, 0.08653243488574391, 0.13159953694590099, 0.11688956986362864, 0.09630840995005818, 0.10389837958181303, 0.07948304732092981, 0.10424484841127213, 0.09813217416545417, 0.1052867464142817, 0.0942722054947146, 0.1010336140819813, 0.09264659986210155, 0.9031158476017178, 0.9520009013503073, 0.9133947982081011, 0.9105666420180851, 0.8690662482469514, 0.8825094817117538, 0.9220090190593677, 0.9343793742421287, 0.9169799853174723, 0.24248933225870228, 0.25630513973987457, 0.22774191992402115, 0.23323210402508698, 0.2530758225830405, 0.228453462295501, 0.23259983307088583, 0.21845686556892085, 0.2396099255198737, 0.6593820920513734, 0.35913802492882074, 0.33770960324369237, 0.2631804224226645, 0.20572610650891898, 0.24969710402270717, 0.22328790039300472, 0.23037352421768476, 0.21271294222962134, 0.1722458312473898, 0.0969842722340607, 0.1403650890301973, 0.13798245723137514, 0.15190558751112582, 0.16299304120331504, 0.12946450787772223, 0.1446947135254959, 0.15330209885522506, 0.13879995929597622, 0.14162739017513992, 0.1402713548300868, 0.13262461474534426, 0.13547285259258057, 0.16294936757392808, 0.13834254740517538, 0.127438770895276, 0.13744089648177327, 0.0023492197510737167, 9.999999999998899e-05, 0.03198965139251064, 0.021794826557752778, 0.078362637418538, 0.004809784592192723, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14533215561667134, 0.05040200521270366, 0.08288266744696615, 0.09815191923762356, 0.055941602155993086, 0.026320434857035058, 0.13686719187544782, 0.06334232266696105, 0.07106132732548887, 9.999999999998899e-05, 0.0035893210026686218, 9.999999999998899e-05, 9.999999999998899e-05, 0.00047531362082642303, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09116302082572325, 0.10148099626781515, 0.07967758740704178, 0.07203671010411505, 0.12924815683145896, 0.11358053000662527, 0.1054945322801828, 0.08431046128310249, 0.08965733548178345, 0.4159016577925373, 0.3912842934098788, 0.40514344117339096, 0.38939490441014235, 0.4025872940589701, 0.40703414735578836, 0.42228772400718995, 0.42375038628433837, 0.42953992963358445, 0.11354171602062268, 0.09052600833679447, 0.08329593943521141, 0.1175567425715599, 0.10593771672033947, 0.09991116198422101, 0.15854014461605803, 0.0983227247163968, 0.09700145949468264, 0.14396015499164916, 0.16699818283339596, 0.136060164059556, 0.17336174179584263, 0.1812380501988502, 0.20951873599622484, 0.16494815582445643, 0.18994045240797763, 0.17491544953296212, 0.30301668348178035, 0.30857488222497664, 0.309875136724736, 0.30162740483889383, 0.29566491777324055, 0.25986960083614963, 0.2584005668108895, 0.30200743742893876, 0.27714051068666945, 0.19745703125124536, 0.17379945023147625, 0.22224346334699085, 0.2080009593401958, 0.22167718951693616, 0.24905908282011346, 0.1976142621646112, 0.22007599210643825, 0.1913058067141451, 0.24016477535018987, 0.21113369437673202, 0.2250908330582433, 0.2439503907351167, 0.22987462611877352, 0.22194082007462812, 0.24869255896464038, 0.25138627106070777, 0.24524289916246234, 0.20692762056689495, 0.1776928743509627, 0.18138408295723318, 0.21456166815013789, 0.20860778319550066, 0.17515463026159195, 0.17437773205752505, 0.17887064841036648, 0.1772588466255094, 0.5779914214959403, 0.18612687758607716, 0.18562771110486698, 0.48194140699958776, 0.1985837627737772, 0.11432654836922596, 0.14027683884172348, 0.6147063286958802, 0.6284503911967698, 0.5001429726406623, 0.15138997811925947, 0.20360666283263873, 0.16658467296832968, 0.34269314537990725, 0.16752946959641435, 0.16556675601739357, 0.29470598920325364, 0.38359179180088465, 0.20791134530341848, 0.19405028119695333, 0.17482574840231568, 0.19530606633507164, 0.1691441091668907, 0.1985059110635159, 0.19315383394653185, 0.18293832527278164, 0.1832877923060494, 0.11241865338214663, 0.09278083337007792, 0.11577197258832495, 0.08701414690015885, 0.0901537616390038, 0.10010236333816924, 0.08034642465609598, 0.07810965722144902, 0.0880642948431607]}, "mutation_prompt": null}
{"id": "ec17ca91-b11f-44ca-ba31-448f2428debc", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.diversity_threshold = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def diversity_based_strategy(self, particles):\n        diversity = np.mean(np.linalg.norm(particles[:, np.newaxis] - particles, axis=2), axis=1)\n        return np.mean(diversity) < self.diversity_threshold\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Diversity-based strategy\n                if self.diversity_based_strategy(self.particles):\n                    self.particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a new \"Diversity-Based\" strategy to balance exploration and exploitation.", "configspace": "", "generation": 63, "fitness": 0.21839453189541005, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.5161665562055474, 0.46863754195075047, 0.45686086387716884, 0.49643964797520734, 0.4315166841061766, 0.4463537736575277, 0.4496693691406971, 0.4554736267806634, 0.4248831292984153, 0.004996650854338092, 9.999999999998899e-05, 9.999999999998899e-05, 0.012896683461991798, 0.00386242523487923, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1314262657220292, 0.10349911568779657, 0.10701401924105791, 0.11325285247684713, 0.10895030370487546, 0.11105080485389007, 0.1199423743379201, 0.11082829971608898, 0.10835161606385102, 0.06812524466401282, 0.10396893689007525, 0.09590489013554326, 0.08384017889595485, 0.07793515059729783, 0.09039411309799872, 0.09448593441836106, 0.08127790697845216, 0.09354696977290111, 0.9149437159038689, 0.9463388479092292, 0.9108893139050334, 0.8969920244089592, 0.8950541175293093, 0.900342531086881, 0.9275784881873064, 0.928751963941111, 0.9156287233669277, 0.23953076011221064, 0.23843008141702426, 0.24238509076837522, 0.2487991344659568, 0.25718683020020605, 0.23384254485983458, 0.2538639946863792, 0.230898883660127, 0.24699672667467454, 0.34718347933433524, 0.5620882322612071, 0.3188607378266364, 0.26703628686669056, 0.5669831037903761, 0.2003174553443342, 0.32265442278633394, 0.22159257778049657, 0.34323837006394775, 0.12633107658741882, 0.11775727184740936, 0.1219455635683957, 0.15370240559454906, 0.19478386007495319, 0.1752652400456225, 0.2095662360297892, 0.1945944178763801, 0.1296016797541797, 0.15040927278604654, 0.15939601729046315, 0.14726989361253295, 0.15106261494300965, 0.13094747891514147, 0.14928307363484616, 0.13942849685452274, 0.14993500134283877, 0.17091464547089874, 9.999999999998899e-05, 9.999999999998899e-05, 0.0012883290007943415, 0.038772674189703316, 9.999999999998899e-05, 9.999999999998899e-05, 0.024860245703190564, 0.0059993218546611216, 9.999999999998899e-05, 0.17294596243341565, 0.04334270476019886, 0.12039701793598212, 0.06842739471425552, 0.0724790421596404, 0.008010654468166511, 0.14082663297287945, 0.08609158104856507, 0.027724534758409747, 9.999999999998899e-05, 0.0019041304058730057, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0016300196988678906, 9.999999999998899e-05, 0.10306238773447984, 0.13640264059954021, 0.095116314162486, 0.07776311133195246, 0.11148381500604154, 0.09290302531644479, 0.11112461682253105, 0.10860408182431225, 0.12101996516164926, 0.4702425975644683, 0.4342864478496944, 0.42184368652632465, 0.4087485366177336, 0.4157787217995912, 0.40039747656557667, 0.4428398148394139, 0.43278248890715165, 0.3933062447462814, 0.12376727292636513, 0.1104207526338209, 0.09008600339087736, 0.08940601391046543, 0.10548075063669127, 0.09847752232086937, 0.10382837830311287, 0.13787555053702671, 0.10371149747944819, 0.1464609151097941, 0.2471315581421546, 0.1301924556941274, 0.1752734914938323, 0.18305714766003756, 0.19604618874051138, 0.17180286184771754, 0.14039362638510777, 0.18943444043613988, 0.2805592982962185, 0.3146128285991272, 0.3076468466003597, 0.2806600132288273, 0.2652824930249973, 0.29532169317493306, 0.29428369945558097, 0.29905724623901797, 0.27890401803805265, 0.20191842740513755, 0.2206934528999549, 0.2010551004885549, 0.22828781954723376, 0.2120810622503806, 0.23264969032131488, 0.19357491884086686, 0.2233239195032216, 0.17088789018808204, 0.22656433312006719, 0.24376289347299218, 0.2615811191601396, 0.28598625631646246, 0.2444659000490802, 0.26495452009176956, 0.22551057173720312, 0.2201260443005697, 0.20335547304146062, 0.18818233954969688, 0.18830803559355547, 0.18746919832629183, 0.18494089832133975, 0.1895485426180915, 0.18299821010092743, 0.22462223841510431, 0.2642964937036125, 0.17744376377944993, 0.18445692975113526, 0.1863874209495643, 0.18638656068666615, 0.11747024595346434, 0.19781932440241856, 0.1454011874861657, 0.14121775269510506, 0.5943487682775936, 0.607378074248494, 0.6180626766097557, 0.45505717626775, 0.39937593592580967, 0.43092084864210023, 0.4430592536642147, 0.16682127380804157, 0.16632441313996604, 0.34793110106826475, 0.3766321383693363, 0.1895858302765414, 0.20577758536257085, 0.19384221685336622, 0.18005388736037764, 0.18471065011035648, 0.18808126837065953, 0.18213404534153754, 0.21214562941366866, 0.1728856302377504, 0.07520755994165751, 0.08638043654742145, 0.08673797564716246, 0.0829196702417998, 0.07622665878481216, 0.0923906643647433, 0.07628001798312323, 0.10600531051356665, 0.09267825801847307]}, "mutation_prompt": null}
{"id": "e17405fb-6274-485c-b532-532cf3fa6742", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.98\n        self.adaptive_cooling_rate = 0.6\n        self.levy_flight_alpha = 1.2\n        self.levy_flight_beta = 1.5\n        self.opposition_based_learning_rate = 0.3\n        self.inertia_weight = 0.85\n        self.inertia_weight_damping_ratio = 0.995\n        self.mutation_rate = 0.15\n        self.mutation_step_size = 0.15\n        self.velocity_clustering_rate = 0.15\n        self.particle_filtering_rate = 0.25\n        self.archive_size = 12\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.12, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(4, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(4):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(4, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(4):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.55 * np.random.uniform(-1, 1, size=self.dim) + 0.55 * (self.best_positions[i] - self.particles[i]) + 0.55 * (self.global_best_position - self.particles[i]) + 0.12 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.12:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.06:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 64, "fitness": 0.21081423313229836, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.44092814072124853, 0.42503631713096834, 0.4249938272859545, 0.4414351154843099, 0.46174299409531117, 0.47032190568473975, 0.4291648206733454, 0.453551888918288, 0.4339535561479201, 9.999999999998899e-05, 0.021228970298007854, 9.999999999998899e-05, 0.00013917933381035752, 0.005236507476362062, 0.002054821878166191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11265342353947527, 0.12503908442645095, 0.11577650144739127, 0.10126756434731488, 0.1035704026778701, 0.08692951060592857, 0.12484390745212326, 0.11599392881405435, 0.11730284076982767, 0.08941020143394796, 0.09393844487703895, 0.09729653959210516, 0.06942928278114613, 0.07818646198548174, 0.09968418107004418, 0.11069374760721751, 0.09062534001995504, 0.08356367188084446, 0.8715869856902504, 0.9326732878832775, 0.8365990640969154, 0.8985547157456499, 0.8799976463082567, 0.9046058225330642, 0.912548599460508, 0.9229744611436277, 0.8993997559381378, 0.2588175998482817, 0.26759864850252, 0.24790916617971437, 0.25973166554899985, 0.2456246817319515, 0.2479504399044391, 0.25524297313913724, 0.24240998154544646, 0.2202119657757018, 0.3321531483564548, 0.29022630340889055, 0.31683213984311964, 0.21816386600754833, 0.2654588381229376, 0.20798735174373273, 0.36594270386141603, 0.17820964097799352, 0.4272541484140092, 0.15151111533899753, 0.2013260056699674, 0.11207028015001941, 0.07272032467379863, 0.13780108307516492, 0.13248511057435608, 0.14104313070188879, 0.19015739086360894, 0.1335593962952325, 0.15241529589277603, 0.13633086100700142, 0.1422907552400282, 0.12260329517936408, 0.1250805450285838, 0.1395489349119431, 0.13752135986040215, 0.14498307698899116, 0.12177593516837515, 9.999999999998899e-05, 0.00819648677275131, 9.999999999998899e-05, 0.05730425085264779, 9.999999999998899e-05, 9.999999999998899e-05, 0.027104837794139858, 9.999999999998899e-05, 0.020688542211585115, 0.1148871034161606, 0.031864347782046054, 0.13966578439836141, 0.10766847676069047, 0.04732776511697534, 0.03184676469816783, 0.11752890604665567, 0.05664151063444001, 0.10532348256724089, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005349752599736024, 0.09737477691423269, 0.10047620998831586, 0.07728810703345845, 0.12154824166180456, 0.10146134887120184, 0.09885497815662025, 0.12469380031589206, 0.10249054720267636, 0.09411818520248094, 0.408262242596387, 0.4294781586878541, 0.41362311063083446, 0.418204559525457, 0.40835420878576456, 0.42648434390631984, 0.3837678670813449, 0.42054091811405037, 0.38516711291866046, 0.1108111233406931, 0.10777011706634765, 0.07235685538193082, 0.0750808922273225, 0.09916740097518573, 0.1328929393038366, 0.10790302631109538, 0.11805906488269446, 0.0903959460291881, 0.14937922935819248, 0.151297358605059, 0.18812979636144678, 0.15117685677806603, 0.16039534380466558, 0.1792081832282706, 0.15779173678114589, 0.24175864478576403, 0.1891767502938133, 0.27679722424568376, 0.28035003096238575, 0.30187842123064623, 0.2665032997936435, 0.29738890073617574, 0.26164107294050076, 0.2605432708123169, 0.2783620932854106, 0.2947035204505275, 0.18666986582779554, 0.20239713425002837, 0.2270203718956445, 0.21370148509508202, 0.2363827261609006, 0.20353677866978925, 0.18615218976949566, 0.21189094752100757, 0.18874449420299488, 0.229113646854197, 0.2773493664524238, 0.22477539097009813, 0.22673499768313155, 0.21991921746583165, 0.23272256796528024, 0.2441598149239489, 0.24370005064127787, 0.22627110887185753, 0.1902479924694851, 0.18137593418077724, 0.18106065487436995, 0.20567600424188526, 0.19058566510415043, 0.1926815376987927, 0.1993540681898508, 0.1856503087368374, 0.17886136970875355, 0.4458598668805386, 0.1853013360892507, 0.18583066760537537, 0.6236039818009482, 0.19624721301340142, 0.19605285740661538, 0.14059397974329846, 0.16726433553497333, 0.6317208603649396, 0.42304670507578623, 0.20843589031840004, 0.4338516376684243, 0.3941799869602862, 0.4027402997348808, 0.16591888096439034, 0.16795016685783815, 0.16472918919119306, 0.47282346302858824, 0.1791982044015198, 0.19287423571286966, 0.19606504675111047, 0.1727313855163093, 0.18840389155323767, 0.20774863323473403, 0.1737331555616609, 0.18650518807097538, 0.1890536035992565, 0.10404088775004694, 0.09238933999002596, 0.08371110817532057, 0.09369199601296319, 0.08432790360234721, 0.09618682390975497, 0.09212007076415774, 0.10112462477985174, 0.09489284051939362]}, "mutation_prompt": null}
{"id": "7a1973df-8cc1-4ef7-a6a3-e43ce476b853", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.exploration_phase = True\n        self.phase_switch_threshold = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def switch_phase(self, evaluations):\n        if evaluations / self.budget > self.phase_switch_threshold:\n            self.exploration_phase = False\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                if self.exploration_phase:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.8 * (self.best_positions[i] - self.particles[i]) + 0.2 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            self.switch_phase(evaluations)\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a novel \"Multi-Phase\" strategy to adaptively switch between exploration and exploitation phases.", "configspace": "", "generation": 65, "fitness": 0.2166025551981099, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.5161665562055474, 0.45488443827555514, 0.46235185924719746, 0.496421665825832, 0.4463835073613336, 0.44863799879205457, 0.4543335770133451, 0.4353601439710766, 0.42725607697563706, 0.0031221539859005443, 9.999999999998899e-05, 9.999999999998899e-05, 0.01382559920038473, 0.005142729297393234, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13008005986296334, 0.10438188083420885, 0.10400439410252327, 0.11276915375597141, 0.10888091549975876, 0.11116624114167917, 0.11980627166695534, 0.10803935300299239, 0.10799108135468538, 0.06588113596900458, 0.0971240118540736, 0.09463100516832679, 0.08211227573645485, 0.07508368154726652, 0.09040571690191068, 0.09026901453655978, 0.08968864342347693, 0.08727886370612448, 0.9149437159038689, 0.9463388479092292, 0.9108893139050334, 0.8969920244089592, 0.8950541175293093, 0.900342531086881, 0.9275784881873064, 0.928751963941111, 0.9156287233669277, 0.23174904718907763, 0.23731475709255534, 0.23103502992390834, 0.24230114390061486, 0.24164880095074925, 0.22237903843954143, 0.2482537679253014, 0.22612389113745812, 0.2334526747379232, 0.3500823425471866, 0.5625175417715249, 0.2952862704185878, 0.26703628686669056, 0.5383976038151403, 0.20028498856560406, 0.3209449374566412, 0.22159257778049657, 0.3382972029993331, 0.12457364881308242, 0.1177726889481997, 0.12158358636109423, 0.15421240309559048, 0.19472089024493866, 0.17470251104018442, 0.21114949449318354, 0.19280945186988296, 0.12927558753188784, 0.14804389441535404, 0.16020130520527853, 0.1468577349443816, 0.1481686170457044, 0.12357156720658458, 0.14985111523666927, 0.13749519213860406, 0.14993500134283877, 0.16912756097299497, 9.999999999998899e-05, 9.999999999998899e-05, 0.004169019288069453, 0.036288374157348535, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005045480245504663, 9.999999999998899e-05, 0.172115973933068, 0.04542556762977967, 0.12099243892949507, 0.06421956671369922, 0.06827275372787445, 0.005344803068517812, 0.13730369506575002, 0.08842850848341854, 0.026787110068769993, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004449835256949863, 9.999999999998899e-05, 0.0020347211280721256, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10570519922486454, 0.14423087799426593, 0.09628130261753287, 0.0828213440266592, 0.10657756227424087, 0.09044356225397499, 0.10605841101272218, 0.11158579609641783, 0.12101996516164926, 0.47210120093075714, 0.40927525136854537, 0.42804460652410325, 0.4130896565844975, 0.40660222336135243, 0.40169728956284734, 0.43666140808389453, 0.42722541685847204, 0.39272906833434695, 0.12351141909398378, 0.10875478752484213, 0.09603762086401835, 0.08929605996316736, 0.09627902896803175, 0.09846618767141446, 0.10402327027368607, 0.13936199588962084, 0.10383149932497782, 0.14348592111696312, 0.2508068437347051, 0.12488403227624312, 0.16519176119326262, 0.18744352357086513, 0.19200739198979933, 0.18545835895286256, 0.12520650246215337, 0.19835267200098794, 0.2785200626234404, 0.31014138334011054, 0.3016419682118331, 0.27950442387283736, 0.2593883532521004, 0.2912785775832367, 0.2885138593462462, 0.2982480104966413, 0.2836827278061522, 0.19792024048188683, 0.22099175712858055, 0.20030035454871176, 0.22948808223885753, 0.21339830278106575, 0.23142437134720706, 0.19537612616555144, 0.22215969524049317, 0.16972274642033625, 0.22656433312006719, 0.24376289347299218, 0.25932017095645943, 0.28598625631646246, 0.2347288528996614, 0.26458997328433775, 0.21867025021417053, 0.2201260443005697, 0.20370587256590578, 0.1875438724535311, 0.18399001312704721, 0.17700635954975064, 0.18486091183334485, 0.18387562252940903, 0.18328434219078948, 0.2223677766215838, 0.26612504694040406, 0.17732035645911204, 0.18445692176871376, 0.1863846698765511, 0.18637278803441426, 0.1174660566136374, 0.19784467378306714, 0.1454011874861657, 0.14121440398330065, 0.6036135353216999, 0.5944892522155033, 0.5968857416315804, 0.43785496381207945, 0.40796886671261745, 0.43116824828110145, 0.4418518732838922, 0.16682166978248192, 0.16630167018660136, 0.33639619241147833, 0.3642980300856101, 0.19174369839560845, 0.20577758536257085, 0.19384221685336622, 0.17746385272247367, 0.18339684470742046, 0.18808126837065953, 0.18213404534153754, 0.21214562941366866, 0.1726813435396818, 0.07836392328607344, 0.0831740729339785, 0.08487495489676145, 0.08588453340770341, 0.07920167726661398, 0.0923906643647433, 0.08435353549220981, 0.09010725992910884, 0.09267825801847307]}, "mutation_prompt": null}
{"id": "0da6718f-e687-4efb-a10c-033614841094", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.probability = 2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                if np.random.rand() < 1 / self.probability:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 66, "fitness": 0.2023352045375877, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.4616437288062868, 0.4291399671214048, 0.4508718194764846, 0.43115866928406243, 0.404379960480691, 0.4483162164033997, 0.44856383430017166, 0.44771831815904595, 0.42320365965198925, 0.007651705571435796, 9.999999999998899e-05, 0.005917539346415146, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.097127046596173, 0.0753739828076101, 0.11176042697816813, 0.10757959141708617, 0.11268673856179778, 0.09835308440908452, 0.08289589740254055, 0.10442257406657263, 0.09496292446748611, 0.08686752416456889, 0.07416677496340196, 0.08909516644917947, 0.08410110202796184, 0.08749293515838985, 0.09197927355686175, 0.07804509449658759, 0.08573231832860329, 0.08812519896548276, 0.8744440933693796, 0.9398586697288358, 0.8640589163582232, 0.7862466512109882, 0.8721862407423462, 0.8736809339363021, 0.9213467702858762, 0.9137881182734492, 0.9002560120759843, 0.23460820188507814, 0.21785817093376658, 0.23675702656711384, 0.2153679038394366, 0.21763458649666345, 0.23741854844536792, 0.21831018213811482, 0.2159557857083374, 0.21598611264663803, 0.2633047937612959, 0.2777664434247604, 0.23605651200761946, 0.25505578511323934, 0.259160322474557, 0.23617894320424504, 0.21633411202297237, 0.20209233468870402, 0.26207106294572946, 0.12602024602236017, 0.1306981825745377, 0.12598821141109384, 0.10012696182246839, 0.12781365954763368, 0.14052815293266396, 0.13412079250683895, 0.12090568559077841, 0.13151289203804373, 0.14749955488903, 0.1381470720843021, 0.1328563269387154, 0.12436567110323249, 0.13663052197360215, 0.15561573325572575, 0.13909015399745217, 0.13347024909376737, 0.12362511437125046, 9.999999999998899e-05, 0.012133455520557779, 9.999999999998899e-05, 9.999999999998899e-05, 0.0048055596377287735, 9.999999999998899e-05, 0.0005298299566486309, 9.999999999998899e-05, 0.004236339288087421, 0.15075179299622687, 0.05103872225182571, 0.1281658526756161, 0.07098978479950546, 0.0624458104878064, 0.0722825875783748, 0.0852737569485178, 0.0883499730338011, 0.060972956054973104, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12650219277964092, 0.05642199911521095, 0.12369883326608155, 0.10870039181490487, 0.11009949332245705, 0.11969251130496539, 0.08979478694567333, 0.07538241691043945, 0.08891538999514392, 0.3904898549342307, 0.39284571654628986, 0.42841554164185414, 0.38893707632603713, 0.3733279923101369, 0.43233011541756095, 0.36138717135043263, 0.4057442494423732, 0.3769295821729669, 0.10612595691330173, 0.09108954994407026, 0.10272957764143265, 0.08499713516435858, 0.09870060791984547, 0.09253902751130283, 0.12268631789758422, 0.10106588648974635, 0.08632224278650191, 0.16608058571766504, 0.1508798191667693, 0.18899037174421662, 0.14097844553495875, 0.18485340238128478, 0.15546618924707944, 0.17500519486211596, 0.16176081179189183, 0.1847686994144303, 0.28891780913305243, 0.2697413678110121, 0.2991255746182322, 0.2700763403753371, 0.30138658660887985, 0.2683068562459333, 0.2530871859215361, 0.27849071877284537, 0.26751402545518665, 0.24344836712662743, 0.22910132528965832, 0.2341888630972474, 0.22193772336242856, 0.22956345761059038, 0.2186797369191671, 0.1881320726986232, 0.21340135527533877, 0.195640320730338, 0.23128302498995013, 0.23983415103076478, 0.22010326875166542, 0.23679012480838557, 0.22160497676954938, 0.22685025779478596, 0.2314956397601663, 0.22568450141108465, 0.21835642046897596, 0.16499245395498785, 0.17918179963104863, 0.17426831418288424, 0.18438276676350795, 0.17984963665108222, 0.18425093253491043, 0.18644875740823985, 0.20559480109421135, 0.19161072052587302, 0.4629076448324506, 0.18479413621431096, 0.18740731713109893, 0.5276270988964988, 0.1958201622004162, 0.1939664768873739, 0.14012823699269772, 0.1678553382311191, 0.635647195503839, 0.4073687821028731, 0.16926364712176545, 0.5216253017153635, 0.398693082711405, 0.16256544471793044, 0.1655262459870862, 0.16190568962791063, 0.21296099949562575, 0.2943364489301109, 0.19933937537290203, 0.19135645191450112, 0.1869265843933514, 0.18600354807790953, 0.20490012695582993, 0.1934225439114874, 0.20334401993932982, 0.18323765869957498, 0.19323799144509735, 0.09543096060859502, 0.08993283423858467, 0.08668457032107513, 0.09038358908195754, 0.08543616283100308, 0.08611995180861065, 0.10072185576774173, 0.09677307353791331, 0.0865683475173975]}, "mutation_prompt": null}
{"id": "51868049-506c-4615-8e03-6778c146318f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.gradient_step_size = 0.01\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def gradient_based_local_search(self, position, func):\n        gradient = np.zeros(self.dim)\n        for i in range(self.dim):\n            eps = 1e-6\n            position_eps = np.copy(position)\n            position_eps[i] += eps\n            gradient[i] = (func(position_eps) - func(position)) / eps\n        return position - self.gradient_step_size * gradient\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Gradient-based local search\n                if np.random.rand() < 0.1:\n                    self.particles[i] = self.gradient_based_local_search(self.particles[i], func)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a new \"Gradient-based\" local search strategy to further refine the solutions.", "configspace": "", "generation": 67, "fitness": 0.18557311805445081, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.3921173866516049, 0.4148134314014069, 0.421383400932843, 0.38562767998255276, 0.38744550772336694, 0.4109736346154186, 0.39692133141106056, 0.39542342537661945, 0.39199686854282656, 9.999999999998899e-05, 0.009586992858898302, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11742085561977023, 0.09657197893975722, 0.08756922276274459, 0.1031260317344902, 0.08753777368220039, 0.09291023004922205, 0.09792184486085587, 0.1127594582078908, 0.0978076365409477, 0.07255912425668798, 0.0722974479843006, 0.09197490676347475, 0.08959919248447801, 0.04800111908102045, 0.08524015049878908, 0.07632487179028846, 0.08004015102935846, 0.08649773249034265, 0.8443815161946637, 0.8967081673036463, 0.85826260247774, 0.7902974665312366, 0.7806779828626449, 0.7871744937336242, 0.8947451104825122, 0.8566528631516567, 0.8565243574556511, 0.19222645706262842, 0.1992542136234735, 0.20543882233141264, 0.18667114431634302, 0.19215306733231396, 0.1711089001893079, 0.18148314521716125, 0.17613797201920622, 0.1697446266114353, 0.23390097331074855, 0.26177922557885924, 0.2006402361363101, 0.242322122530107, 0.2464299049876617, 0.1911213667560846, 0.24565313287103185, 0.2171105358394665, 0.2134822219605479, 0.12055242875821992, 0.0806498715377848, 0.10938296063045239, 0.08475045905940626, 0.12043702917140708, 0.10996169134439748, 0.11689546675400708, 0.09680308235301871, 0.12986972879025183, 0.11128037823506043, 0.13627508349533857, 0.12523493796820384, 0.12894002287792505, 0.1228521558723662, 0.12752080057879522, 0.1151215488979469, 0.09326268811824734, 0.11074848635081747, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10124242747054413, 0.029786543712328806, 0.07238634344203188, 0.06130155513866031, 0.054698644092079696, 0.06431781782755575, 0.08802434804285675, 0.050094100171958034, 0.04053086126579053, 9.999999999998899e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11127209094432, 0.09857529486424188, 0.0965689632957023, 0.14859434366183777, 0.10792458856565501, 0.08289604160186714, 0.07883856312178528, 0.10957678399208148, 0.07317695251075584, 0.40694892326464316, 0.38488047230461897, 0.37835097943006235, 0.3516159259168151, 0.3378291748877629, 0.3249718897648487, 0.382841553361952, 0.3699477694760387, 0.3706794024955764, 0.07671717423712032, 0.10224588143799151, 0.0996483249715635, 0.08006623358314735, 0.08229527176462359, 0.07659414626427641, 0.10271283422604849, 0.1036835250071354, 0.10134800582517256, 0.1328201492671056, 0.13635505267859716, 0.13296586958234602, 0.15130315913450942, 0.17812928749872758, 0.12652653755213328, 0.1264588929702255, 0.11375554741939997, 0.14012377366151652, 0.2508559098122266, 0.2799893483495052, 0.294417503999164, 0.23531728426737886, 0.25500378095019127, 0.2632529381241643, 0.24020460568218827, 0.2832525801596335, 0.21424072866848543, 0.18166188890447033, 0.18780664344243647, 0.19460840686104708, 0.19696746815193444, 0.1946503370006436, 0.19502126260136676, 0.16120119394463128, 0.21877793881709928, 0.1673670490500797, 0.2118305921836645, 0.21098124115567063, 0.20024256193591727, 0.20879242173013512, 0.18986444173440187, 0.1986814708710094, 0.23255589811089628, 0.20658421613176314, 0.2096063126842378, 0.18959438293438124, 0.19369087927457163, 0.17455797645535898, 0.20354887196191662, 0.17650603020642885, 0.18761712299689304, 0.17711623357477146, 0.2045474025183457, 0.18343305172266455, 0.1806616057560525, 0.18281651057608528, 0.18272526286622004, 0.5068604650745215, 0.19461543706727558, 0.1566977086505964, 0.1386143309210569, 0.14576264529652105, 0.4892466634452921, 0.41698158727462886, 0.20656709585158428, 0.3531607121570539, 0.3510546974808967, 0.32990991923605684, 0.16529595497536176, 0.16388920576737875, 0.31602589300307504, 0.2986599334693246, 0.17513056353467327, 0.1818991395798789, 0.18101549487588164, 0.181934109669312, 0.17348361592721562, 0.16935633659988947, 0.18787885340932486, 0.1806101596172468, 0.17919046735860733, 0.07086212529474178, 0.07839786005619176, 0.08527278010924944, 0.09058911293662242, 0.08741202509833257, 0.07812513992410097, 0.0830930740396818, 0.07992766273184682, 0.08722851351957672]}, "mutation_prompt": null}
{"id": "9d4ac76d-e657-4e66-b584-42f2143d3237", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.evolutionary_gradient_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def evolutionary_gradient(self, position):\n        gradient_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + gradient_vector\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Evolutionary gradient for enhanced convergence\n                if np.random.rand() < self.evolutionary_gradient_rate:\n                    self.particles[i] = self.evolutionary_gradient(self.particles[i])\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a new \"Evolutionary Gradient\" strategy to enhance the convergence speed.", "configspace": "", "generation": 68, "fitness": 0.2086229858727055, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.45419990038070723, 0.4848288801306391, 0.4664723274728475, 0.470530284364051, 0.46259345284835096, 0.4276837063953489, 0.439105571571637, 0.45054049041152944, 0.42446705323544587, 0.02264072625202007, 0.008214869123543966, 0.004916614013170562, 9.999999999998899e-05, 0.014860528089764347, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11124925376292272, 0.07503755125503941, 0.1219221057599208, 0.11074626976407631, 0.10741379345770508, 0.09730117891262069, 0.09232498035316161, 0.09614480255500313, 0.1172853200943147, 0.08400046690694785, 0.08823044468177921, 0.10418528317069764, 0.08992801578475751, 0.07331259320119865, 0.07617062969902233, 0.11740646510506336, 0.1040580911605139, 0.08177041193767542, 0.8952666753254124, 0.9449403747523909, 0.9087961031953511, 0.8715886547298645, 0.9149045627888583, 0.9004482800704601, 0.913669159685625, 0.9075110657538836, 0.9147534469220098, 0.267751291772207, 0.2808688256117615, 0.25737883208734536, 0.25584442133019547, 0.2586315185371221, 0.2520553122280188, 0.24580206616969358, 0.2256791324958859, 0.2540404401476616, 0.3312149308027207, 0.2758911083798493, 0.28496407573021654, 0.2708719216454343, 0.2692591038651878, 0.24052772533435396, 0.2504184546407777, 0.1768356831403466, 0.29029159960145634, 0.12411694012128827, 0.12733858190841363, 0.14356729750713015, 0.1470027458799641, 0.12499919556851691, 0.14017857191726346, 0.14198704318844124, 0.15917058700035414, 0.18053311742980582, 0.18832883877648632, 0.13240759528749058, 0.153046314351304, 0.19022725717498912, 0.1338816671473525, 0.14993337848561605, 0.17499068581682498, 0.11624917897503706, 0.179356521809665, 0.016385818534705887, 0.02047895124802801, 9.999999999998899e-05, 0.0036633526130335214, 0.0020784667086208852, 9.999999999998899e-05, 0.0010231988857872798, 9.999999999998899e-05, 0.0058069212419373795, 0.07133864952297575, 0.08382336005733981, 0.10090287607187598, 0.08651307393939367, 0.06676803665643416, 0.02004207576016559, 0.12533093380250104, 0.07616170482666751, 0.08367061153938771, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00046652859980544914, 9.999999999998899e-05, 0.00839464599980655, 9.999999999998899e-05, 0.11680461270151532, 0.10538494879881433, 0.10233085154394972, 0.10186625503324942, 0.09974038104914906, 0.06205819367136978, 0.11326209010295807, 0.07776553903630978, 0.09103948162825604, 0.43329074695199066, 0.3942082882292707, 0.40437421614364144, 0.3984140073337503, 0.4320770561484437, 0.38339063684523345, 0.40883470387613907, 0.4111321315810571, 0.42839185910746524, 0.08552350331689462, 0.15884902584109317, 0.09468176158832942, 0.09574377460034811, 0.09739900052576433, 0.11623304204447249, 0.10328642162492685, 0.10678565644954119, 0.1008901707814952, 0.18101611201308165, 0.13442284546430472, 0.14528266793277234, 0.17630007210302867, 0.27368329800039815, 0.18742644099052574, 0.16934293112000454, 0.17116969692549477, 0.22662646897605643, 0.28324569480270734, 0.29562863967160047, 0.2798769036830513, 0.26471459101659256, 0.31084915840016436, 0.2913838268957495, 0.29419046978321783, 0.29133871363253405, 0.23139130319145074, 0.21255573177390408, 0.2281868897497794, 0.23185595578133367, 0.21877810325500824, 0.21557971183507152, 0.21348752510409041, 0.19718260327489734, 0.24568921293586132, 0.18946583945187856, 0.22654970884892478, 0.2326482368714976, 0.2227864502807152, 0.23876026480559953, 0.23128234560942063, 0.24460593873004466, 0.24002263002731028, 0.2581984268140962, 0.22571166904115247, 0.18869611473080894, 0.17712445531434529, 0.18934310145595146, 0.184170351398233, 0.18588901540971825, 0.24599038145940733, 0.1736063704035885, 0.17289408440495557, 0.17673827162157685, 0.1799074372006476, 0.1858080618326936, 0.18535080464341724, 0.17785656945361583, 0.19861185114603264, 0.19683284683600855, 0.14128796700817925, 0.6150236309146109, 0.5273331882450085, 0.4388739435075356, 0.16856950077043098, 0.44245647374023256, 0.40887583450296694, 0.16570677792231636, 0.16732605015616497, 0.16473870523847656, 0.2609015021614045, 0.2858466039089397, 0.1843863655095841, 0.17753346220103772, 0.1740859134205115, 0.1712041829814499, 0.19586963449084194, 0.18034203813463423, 0.17569358941357238, 0.18236879595874367, 0.1860384031149126, 0.0801454740972889, 0.09503238520536217, 0.07327244582309289, 0.09311633599644553, 0.102314615256616, 0.08034396081314465, 0.10027055777220661, 0.07846750992096385, 0.09991239470798396]}, "mutation_prompt": null}
{"id": "ce4a47e2-42c4-4fcc-9180-f7210db12a1e", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            # Additional exploration with 10% probability\n            if np.random.rand() < 0.1:\n                for i in range(self.swarm_size):\n                    self.particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 4, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 69, "fitness": 0.20562924465322988, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.4381071372232044, 0.40236661705661336, 0.43269639425367024, 0.40812499416291004, 0.3711055186300225, 0.37844367290998193, 0.4215342969544976, 0.39945455512953487, 0.38853839028056514, 0.02320230372175136, 9.999999999998899e-05, 0.006125386795458376, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007210874767755726, 9.999999999998899e-05, 0.11070865250521678, 0.0831347537135041, 0.10702836143171679, 0.09550330294804643, 0.10419057885448146, 0.11306497224323864, 0.10616259519672056, 0.10879257418600319, 0.11320127918494327, 0.06839889391836018, 0.0787483332847021, 0.08774941432177963, 0.1039210575343279, 0.06923155259267044, 0.09300452139684601, 0.08727034796652222, 0.08308211075604854, 0.08592032521232162, 0.89729801319859, 0.9429687382123152, 0.9082738955164736, 0.9032486318214457, 0.8489567013155065, 0.925497985838891, 0.9400928966172807, 0.9124777482711072, 0.9276993302872929, 0.23990773596420434, 0.2447182206614691, 0.19897570644440177, 0.22741445866236498, 0.20624463696523665, 0.23130340102116165, 0.2378075210284264, 0.19533615447414354, 0.20267878315858256, 0.3112821362115238, 0.23318878014769984, 0.27514328921587383, 0.2702783904213969, 0.31443947874586775, 0.2685555035782513, 0.28949783152860153, 0.37102875641032274, 0.231552560792611, 0.13571988591694295, 0.1390264406897963, 0.13742820251576848, 0.1353668887465519, 0.11606296007063233, 0.17766337570806956, 0.13950296857946254, 0.11446183481918304, 0.12109479971469206, 0.1403821057437672, 0.1457297818102512, 0.13429624388552985, 0.12239313601821089, 0.1210008246978872, 0.15289635811157642, 0.16260821560210137, 0.12126714094705915, 0.122265323315072, 9.999999999998899e-05, 9.999999999998899e-05, 0.01496252665302833, 0.024757227023508133, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000497688300420629, 0.12453048189104043, 0.0666845558773641, 0.14581774683621918, 0.14141713566140568, 0.0690087679106215, 0.08789833809108027, 0.11837902353227725, 0.08630088082594212, 0.03883715193441528, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10561126237460938, 0.10597170484519736, 0.06537695268170207, 0.09550044113214662, 0.08854101009699711, 0.09396374095264959, 0.07777598505864602, 0.08996914306723591, 0.09190164163457648, 0.4110909554364134, 0.42512015373169876, 0.39500985667441857, 0.37880258605468775, 0.4394765101258038, 0.3700841954518933, 0.41758358186014, 0.409931479461515, 0.39023183866543576, 0.10760995515351146, 0.09693987522116754, 0.08712932914802984, 0.08645243419556059, 0.10437714909346163, 0.11162723455958434, 0.08387268374749035, 0.10163429646102828, 0.12035898665159495, 0.1407598022324419, 0.1665572421967345, 0.18526936220517176, 0.1759618731175886, 0.17461693850466053, 0.21888443296826832, 0.15896230112337417, 0.19424890936841466, 0.16749245971912274, 0.2906309193683273, 0.2631463572908658, 0.30181623550336767, 0.29074243196271665, 0.2893514708937831, 0.26994566907045425, 0.2443284888489029, 0.25203653695147055, 0.22883776299922964, 0.17931742158745, 0.1745102110182868, 0.21723088331762763, 0.25385249547245226, 0.24059471239746355, 0.2085873699159605, 0.1915498086559424, 0.21833256867099948, 0.17839585387055867, 0.22205554476063172, 0.26172279697418943, 0.20060485272245632, 0.22522166046726777, 0.258550770086574, 0.23351829822615366, 0.22770541850922443, 0.25318939753892533, 0.21140562314479527, 0.19038745985497485, 0.18884609240139272, 0.18943575380090116, 0.18905317794805265, 0.19169963234149123, 0.17444847854675916, 0.1797795869961758, 0.23766252784580055, 0.17284601584472925, 0.18498477578236738, 0.1856644505497954, 0.2997738469264023, 0.15865513678036136, 0.19601629174961077, 0.6215253931278365, 0.14911587373868262, 0.38566391721338467, 0.15795356831817353, 0.583037191911606, 0.4074114741899205, 0.3156766043879753, 0.510368784042195, 0.1693537592648845, 0.20208779554285272, 0.16529229455145744, 0.39904167579719885, 0.19696652701687567, 0.19256744886417732, 0.18752815348567464, 0.19291728572423128, 0.20590628155574664, 0.1949885948870398, 0.1822775477007491, 0.18436403488082753, 0.21218189657304443, 0.19252318469957097, 0.13474197623812856, 0.08482840108365619, 0.07553916779377545, 0.10759435224740688, 0.09422519080225045, 0.08336912691916454, 0.10399134431637447, 0.08551706542118465, 0.08397877315941038]}, "mutation_prompt": null}
{"id": "f106259d-f675-4a22-839b-01f240c29fe5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def exploration_exploitation_trade_off(self, position):\n        if np.random.rand() < self.exploration_rate:\n            return position + np.random.uniform(-1, 1, size=self.dim)\n        else:\n            return position + self.exploitation_rate * (self.global_best_position - position)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Exploration-exploitation trade-off\n                self.particles[i] = self.exploration_exploitation_trade_off(self.particles[i])\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and an additional \"Exploration-Exploitation\" trade-off mechanism.", "configspace": "", "generation": 70, "fitness": 0.21502200209659517, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.4748949169239731, 0.4752529632582848, 0.47623121103898935, 0.5062919320427891, 0.4923483362063562, 0.46730174387497647, 0.480334816835599, 0.4567343139310096, 0.4727146175989453, 9.999999999998899e-05, 0.007930795828311799, 0.0031870394221099607, 0.0006213008443520796, 0.01795993821780628, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09246988107765686, 0.08996561697745786, 0.1677949408802777, 0.08754058386189967, 0.08742042275166473, 0.12767633822887514, 0.08879231300762602, 0.11055223213849752, 0.1342516435315685, 0.10465612897342758, 0.10243924995425657, 0.08682410776717175, 0.10414059305889911, 0.10302436826483541, 0.07643668379280355, 0.10315834645422217, 0.08444013379133453, 0.11952019113799017, 0.8939600891045225, 0.9490217024785429, 0.8423530676696842, 0.8487178651841877, 0.8940051604804349, 0.8609969182437259, 0.9363855388354635, 0.9237623676014821, 0.905416451130509, 0.2808672033736652, 0.26466370194011957, 0.2586246673654857, 0.2901805390643022, 0.29208919744713147, 0.28205453096863575, 0.26932061330026946, 0.2848579863734436, 0.2784254689148147, 0.22847121975649676, 0.3545854550863603, 0.29446224933390974, 0.2654236229458684, 0.26725072113878623, 0.2437895917246652, 0.2316129893368376, 0.3212049465287077, 0.2971954585668283, 0.12545555034625444, 0.18910768357108754, 0.11906303848507926, 9.999999999998899e-05, 0.14169196557835928, 0.12317721519553759, 0.1452185175844254, 0.11430257365488272, 0.14930809418791613, 0.16009259405352916, 0.1443774713921675, 0.12580860697192042, 0.14822708612596835, 0.14720157690601532, 0.1712315801664961, 0.19937579850872567, 0.13244581104594344, 0.15037329375864827, 9.999999999998899e-05, 0.022687906137473735, 0.006221223928400965, 0.03041739005297517, 0.01718904422146661, 0.00037922208084895104, 0.00010577551662349638, 9.999999999998899e-05, 0.004938494603149546, 0.078940921662073, 0.0929496093478106, 0.07217716539660379, 0.08372073760104337, 0.07837997180798406, 0.013903430539659034, 0.101132442301614, 0.038130214646207916, 0.10871099274401697, 9.999999999998899e-05, 0.0029025259379572566, 9.999999999998899e-05, 0.0012935506982734157, 9.999999999998899e-05, 9.999999999998899e-05, 0.0032485211130595104, 0.0011582806987094907, 0.006188483102326114, 0.12348353167334425, 0.10930660836243788, 0.10014142167435314, 0.11529091600587438, 0.12337984283466574, 0.11774753225492407, 0.11761466831292289, 0.10318647220628407, 0.08646274616144545, 0.44059126109843216, 0.4461018368756021, 0.4112051101416482, 0.42670520564327685, 0.43744589285099145, 0.4048041575879556, 0.4221662356991809, 0.44806494969217026, 0.4005487909598964, 0.10514755533263542, 0.14446598771711483, 0.12191285532260832, 0.10439435426310195, 0.10081587774761358, 0.09507556403607464, 0.1148093913325603, 0.1253604980649088, 0.07628091791254155, 0.21168407209986884, 0.15492798331288382, 0.15960949726859341, 0.208388538287136, 0.1986892857717636, 0.15700730869275137, 0.2007770719581271, 0.21321678629298735, 0.15248917472799928, 0.277108874266943, 0.2968585226246858, 0.29278347502249236, 0.24909432189491154, 0.3037329074455646, 0.2908915279418939, 0.24183975016911008, 0.2976651630246555, 0.23801265760882195, 0.23022448273238127, 0.22744593550029013, 0.21992111668329495, 0.22483395902325887, 0.2360275831353672, 0.22339757131185356, 0.1772236011748327, 0.22075749274212475, 0.14808133531620693, 0.24077941750531362, 0.26209007279701213, 0.23285423219878276, 0.24440383956471046, 0.2394526610955181, 0.22054376819648014, 0.23744586526593647, 0.22401841703984715, 0.2216151211091919, 0.20679264441490308, 0.1786081695595041, 0.28129823869126025, 0.23864891570265612, 0.17766322336840057, 0.16535447039185858, 0.18901559244884725, 0.20181317061675486, 0.17229314884893177, 0.12892518712055212, 0.18684839367158035, 0.18562012115599402, 0.7052674776469923, 0.19979952791350075, 0.1982825185409467, 0.1415622460316618, 0.14986815819640975, 0.7627375207395242, 0.44921571803900184, 0.21093661870008296, 0.44498276526405767, 0.5169573826247791, 0.35648661591452246, 0.1668485782147231, 0.16919496269896683, 0.3236390249816986, 0.36440011324066335, 0.18901394090352763, 0.19536634258302166, 0.19565428423561548, 0.19423990330566265, 0.18147126593482232, 0.1796115914940145, 0.19741505415605165, 0.17803428319273462, 0.1880016556719568, 0.09391703858206057, 0.09137521997858744, 0.07834824370353066, 0.07884280448103653, 0.09311719356183457, 0.07963667981890088, 0.07369098182404032, 0.07941716512965125, 0.09109333976049094]}, "mutation_prompt": null}
{"id": "c62ba59a-28ef-41d9-9325-d76114da94b7", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.quantum_tunneling_rate = 0.05\n        self.quantum_tunneling_step_size = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.normal(loc=0, scale=self.quantum_tunneling_step_size, size=self.dim)\n        return position + tunneling_vector\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Quantum tunneling for escaping local optima\n                if np.random.rand() < self.quantum_tunneling_rate:\n                    self.particles[i] = self.quantum_tunneling(self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a new \"Quantum Tunneling\" strategy to escape local optima.", "configspace": "", "generation": 71, "fitness": 0.20961241114179943, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.4714928292794297, 0.48535798769816074, 0.4666966420999177, 0.44596039784482333, 0.4341369426409436, 0.4522087364180808, 0.4474826909921642, 0.4452766583684128, 0.44672728489543734, 0.024366692092250952, 0.02976133118385693, 0.006254887512568308, 0.0018242822159388883, 0.0003758867565316626, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11859364888926915, 0.12429666556289154, 0.09757143755309605, 0.08825019503451581, 0.09870105975797627, 0.12169985927221283, 0.09513942412908816, 0.13388359615312584, 0.11994709270344106, 0.08132003825571321, 0.10885246633680834, 0.09845746677642042, 0.12635486295165788, 0.0579851496140984, 0.07625879396669133, 0.0863575396184948, 0.08493051358454429, 0.10781212033021925, 0.9017621420546498, 0.9421902875202469, 0.9064524888039914, 0.8444887746956565, 0.9138598228644766, 0.9152566654223537, 0.9061239699954352, 0.9300828110201305, 0.9280206405295838, 0.23434990950012002, 0.2582360200349061, 0.2500172328909236, 0.2503611234744244, 0.2557558203649031, 0.2395704583847612, 0.30363009962834364, 0.23016860848593546, 0.24431080374444414, 0.31703869377252714, 0.3139227149169125, 0.3129275677484561, 0.308052962996366, 0.22039149230094124, 0.20708734868516498, 0.23221426152381153, 0.23321910918625843, 0.27047162190949814, 0.13058099976630655, 0.13399018512672245, 9.999999999998899e-05, 0.10376744064353793, 0.141889279758309, 0.1296641438479964, 0.13931398372534787, 0.20107248215961104, 0.1349300655880563, 0.13184263429868448, 0.15955486926638696, 0.14562345053443548, 0.1334410165344141, 0.1563522005770106, 0.12999646044426905, 0.14607670890162916, 0.1323735868383279, 0.15560930658334582, 9.999999999998899e-05, 9.999999999998899e-05, 0.018350918425152685, 0.003221808916510027, 9.999999999998899e-05, 9.999999999998899e-05, 0.007459402534009341, 9.999999999998899e-05, 0.016573021487357287, 0.09087618611524029, 0.0959499444439218, 0.15266605825390667, 0.07432563668704939, 0.07665976423249543, 0.03608332911743384, 0.09466148375562367, 0.0787245356771431, 0.08977845166848897, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00220134724813692, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11589799590181937, 0.14330701003921564, 0.06483288046247904, 0.11808908119916828, 0.06100775266005787, 0.11082794759453973, 0.07480529429213822, 0.10751157566629976, 0.10955338335457021, 0.4246514350874452, 0.4249417661361815, 0.4100080472874994, 0.43524376059815273, 0.40600830934803367, 0.4057810621966601, 0.43080143661725134, 0.4339367309111334, 0.42613254049776417, 0.10658343940456783, 0.09329477786300722, 0.09958224486046474, 0.13407213042976562, 0.09232076593142535, 0.11329854107936321, 0.12015634071119308, 0.13167801945854152, 0.11358363710374686, 0.15941706355622587, 0.2106414424331644, 0.12911304134962243, 0.21916972677415647, 0.18987289376032157, 0.23105339848802953, 0.13070208124973015, 0.15948086679912266, 0.1761611431799085, 0.2984135846946796, 0.3117959582283535, 0.3095896968131864, 0.21470345383684564, 0.294106500717332, 0.2975207969377861, 0.3049137098188125, 0.27576910308168756, 0.2689752785310212, 0.2184064322110154, 0.24548881057063132, 0.2472591268878147, 0.22612746215821022, 0.2001465833421897, 0.2254222529240032, 0.23990157966391223, 0.2008390318067923, 0.18497884672190246, 0.24748163713632576, 0.21643709977059344, 0.22624946561070636, 0.23580055380087162, 0.2388071860134855, 0.21639300075688506, 0.243667733555053, 0.25145957666800345, 0.23059478031263592, 0.18846695884711584, 0.1779779368715364, 0.17174073326106187, 0.22693643055534984, 0.20395808190644737, 0.18679899072331996, 0.19625004330510787, 0.18646281900509865, 0.18848561388474172, 0.17940982065412392, 0.1845450453818852, 0.18505158744207129, 0.15657382526425212, 0.19851087415131685, 0.16267879839154264, 0.14060653753543606, 0.6587629959629198, 0.561138649004048, 0.5104486209206591, 0.20883788724614138, 0.4165546494521374, 0.45739159020520037, 0.1667836838933595, 0.1674383578854669, 0.16542698569590608, 0.1640787520602467, 0.30776433466040576, 0.18141915562325606, 0.17436407680833166, 0.18206206398533809, 0.19169795006793278, 0.21919784373209927, 0.18934163155728334, 0.18005396779079985, 0.1811949868805136, 0.1843686946421612, 0.081260792069622, 0.09577047602156274, 0.09375206306916262, 0.07779187876565541, 0.0899532095434934, 0.08119540591640595, 0.09201361034910893, 0.08461061053833108, 0.09267364214634799]}, "mutation_prompt": null}
{"id": "9e607ab1-3d45-42ce-9779-136faa328905", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) ** 2:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) ** 2:\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) ** 2:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy and \"Archive\" strategy, with refined strategy based on probability 3, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation.", "configspace": "", "generation": 72, "fitness": 0.21040989761289175, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.43193577528880467, 0.5108018417951706, 0.43991746554503464, 0.43336211926912216, 0.42286331411021405, 0.49777654713727437, 0.42112109509105533, 0.44102605638545334, 0.4540290709216068, 0.0018456794340054872, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005728365783194134, 9.999999999998899e-05, 9.999999999998899e-05, 0.003919370676143452, 9.999999999998899e-05, 0.118103656238992, 0.13862666461873396, 0.09817319855586681, 0.07033076706984942, 0.1192617165698121, 0.10086216719334484, 0.09719634080694317, 0.12872479204336162, 0.09408493265033835, 0.08653186825647607, 0.10883799774349368, 0.09495820746593198, 0.08112135817016863, 0.07533574630645579, 0.09119110736171043, 0.10148425036313924, 0.08891058381753614, 0.0713634298253717, 0.9202984617072413, 0.948120163659617, 0.9026150294454423, 0.8595575808797651, 0.9272956884587111, 0.9015676249115322, 0.9294487135524768, 0.9387531192106028, 0.925335372331618, 0.2542585727312373, 0.2314762337744941, 0.22398325976061406, 0.22931220007152886, 0.231900051275983, 0.2118829375278415, 0.22240515747045997, 0.22566788793230408, 0.1981787426330729, 0.2595987290580326, 0.2791993651811083, 0.23978764383120355, 0.2084127832219197, 0.3377045891454451, 0.2596255354186128, 0.2564781336783568, 0.2002440203976329, 0.2785501571374909, 0.12756028745153802, 0.1271361501927034, 0.14270952454299113, 0.13186344673748462, 0.1241553930475946, 0.1492138115605156, 0.11780696088584808, 0.12447860588181847, 0.151914815182302, 0.1706050824082277, 0.12087487367373073, 0.10764296764302583, 0.15832764998573456, 0.13951971077328307, 0.139523889649094, 0.15687752321052506, 0.12527741232942202, 0.14199174093947564, 9.999999999998899e-05, 0.00010538239677593264, 0.014057291805570693, 0.00456043524241434, 9.999999999998899e-05, 0.0011873713301181477, 0.009547538156460922, 9.999999999998899e-05, 9.999999999998899e-05, 0.19431599282461554, 0.05849446462005148, 0.15172130682934637, 0.09263214904838879, 0.08289002224373143, 0.047771316974746125, 0.19713416598261502, 0.11432945826716445, 0.09517185694057351, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014954545268513364, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11374008002704106, 0.1039914640020756, 0.09125587250899281, 0.11092309687997626, 0.10519477415116674, 0.061138431916133995, 0.11838120363314975, 0.09776194988699194, 0.11354804642784311, 0.4286941009256515, 0.3911061902384062, 0.3817200128484839, 0.3873220769060044, 0.3908226037948469, 0.3956188923732853, 0.39393065759781665, 0.3970785655001372, 0.42760902432422077, 0.10197278736975857, 0.09210728075623598, 0.07112436258691557, 0.13033546260467044, 0.08760101450795954, 0.11587411351307586, 0.10508382884532219, 0.10704058269039729, 0.0953446454335215, 0.15354109083897782, 0.1858396662070706, 0.16794690992651085, 0.15738717945499137, 0.1952732287678629, 0.16575461415202786, 0.17134322337968277, 0.19778812800405499, 0.20281858565159216, 0.29317880709583743, 0.2891181899074692, 0.2786410160090399, 0.2702097785422798, 0.29177777269429817, 0.2953460215043593, 0.24281497750677195, 0.2568203549253554, 0.23568439782969086, 0.23409402909287036, 0.23587821383318575, 0.2077596551219142, 0.23151424763647188, 0.23575543957588074, 0.21281138864678784, 0.17848637095198194, 0.2274974761872952, 0.16243959398981878, 0.23317417831037845, 0.2279269960462823, 0.25979092706336815, 0.2508156428032584, 0.22460625205628948, 0.22763036338908071, 0.23668335998837842, 0.2184932863524145, 0.2309883440297822, 0.17589303979963733, 0.1896006134016106, 0.18344292732488343, 0.19320729315327478, 0.18922234242379365, 0.17769494366578986, 0.22985339420281303, 0.2024337741377823, 0.1713875403905042, 0.18452016894954992, 0.18652832316044177, 0.1869867600094618, 0.11772302565205861, 0.19723347344330455, 0.18976872691945423, 0.14194502561013456, 0.6461052579909707, 0.7385295571978916, 0.5373898192153518, 0.4692413911344451, 0.36236685645633515, 0.45023592653069255, 0.3270856615629162, 0.16666326595181724, 0.16684620267556527, 0.3330683731528912, 0.3564749527260893, 0.19272652804873946, 0.186937867365514, 0.18516396050241624, 0.18136029441060486, 0.17598242102599637, 0.17845738270941058, 0.18738434945285098, 0.21215771846679388, 0.18472330066558318, 0.09042685944682871, 0.08648696716120907, 0.0896251100024108, 0.08375705402305922, 0.08918704191411908, 0.08519987714827892, 0.09213801288593981, 0.09281669382779634, 0.11452612304374121]}, "mutation_prompt": null}
{"id": "7a4dd1a9-c4e7-4afc-95f8-360da45dbdea", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.simulated_annealing_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Simulated annealing\n                if np.random.rand() < self.simulated_annealing_rate:\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and a new \"Simulated Annealing\" strategy with adaptive cooling rate.", "configspace": "", "generation": 73, "fitness": 0.213445643988907, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.445052695893577, 0.4548288715797949, 0.4669832215804971, 0.42485706621454655, 0.4115236580590238, 0.4260892998099711, 0.440689130527365, 0.4363144398403628, 0.4681229769137655, 9.999999999998899e-05, 0.06742029491583656, 9.999999999998899e-05, 9.999999999998899e-05, 0.0053502419877761165, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10646439372295247, 0.13201458860436321, 0.08809157501734954, 0.09648695753621828, 0.09345160610982528, 0.07631432454837106, 0.1478321104147985, 0.12084258709833373, 0.0952245609746667, 0.09491060381401673, 0.11257923566467776, 0.10248325456178575, 0.12243918662214148, 0.07800766058191244, 0.07001287529266831, 0.1063935499385592, 0.09488912056782706, 0.07885916741723631, 0.9013715937252565, 0.9450935501608888, 0.9037883611498417, 0.8311869499068649, 0.8908482761545732, 0.8669362350132023, 0.9106217079951178, 0.9127471507016213, 0.9245378888941901, 0.2761054157404861, 0.2537095502609379, 0.24387191005599318, 0.2425614678944228, 0.2766533166357673, 0.23622567402053396, 0.23371633433418815, 0.24672553710591294, 0.2150241464543141, 0.2462669238709776, 0.28889815313542544, 0.23360426203844364, 0.2374140553827474, 0.7716374990442514, 0.20273527660253354, 0.6605539789198336, 0.28904806178672393, 0.3087294552354982, 0.16506087372345213, 0.1299779145675105, 0.15733164775045794, 0.1255941553817982, 0.12246920366077951, 0.12892669404526402, 0.12163717522601214, 0.10795529268719184, 0.1355743512877483, 0.1420610357486185, 0.1384404295878341, 0.16115606337886434, 0.16670148577337152, 0.1378436350904907, 0.12427430342030998, 0.1361490710074158, 0.16512156928429467, 0.13867875892984505, 0.03042849762698774, 9.999999999998899e-05, 0.00012412177917486833, 0.01346152599464645, 9.999999999998899e-05, 0.0009589149293546262, 9.999999999998899e-05, 0.0005385688707422176, 0.0029168933218809423, 0.08898918457349259, 0.07734082313274793, 0.1276567038620131, 0.09879449890915326, 0.058709806988012314, 0.04119104567386089, 0.09840638461191886, 0.09470515246892719, 0.069562382882985, 9.999999999998899e-05, 9.999999999998899e-05, 0.019420327354088274, 9.999999999998899e-05, 9.999999999998899e-05, 0.009069175954813158, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13801673927145475, 0.10331316215414577, 0.10373922227762, 0.09528439687520462, 0.09173844879861659, 0.06496669173441172, 0.1137340067337318, 0.07684140062431799, 0.07611647170524993, 0.4087452893203486, 0.42903253677184583, 0.4125991243402529, 0.4025711440467691, 0.375566117363202, 0.43207918854593097, 0.40474543117649964, 0.4105830014309153, 0.42834445798168286, 0.09748754404282123, 0.11877085676967092, 0.09706805254940643, 0.1235164463953271, 0.11411115565859875, 0.13693212118596587, 0.13859443624212986, 0.10732297780393474, 0.1431231402001404, 0.19867489146107542, 0.13501925021644712, 0.14273695567198463, 0.18275075745055347, 0.17445152592435154, 0.18934184129125087, 0.1547811776780199, 0.16550769974158697, 0.16487639825016798, 0.2827054477173162, 0.26840901892958624, 0.29467908646444907, 0.28105888990791617, 0.24331166539393623, 0.2980911972974887, 0.2409011906955677, 0.27778106555551774, 0.2706845794334559, 0.21513631906298292, 0.24293539668868103, 0.250384250967854, 0.2440808001994199, 0.2464091308026023, 0.21617684310242213, 0.16561490940913792, 0.21066003704635672, 0.17677257796789758, 0.2593024792260925, 0.25063146645752876, 0.21069058353727865, 0.23278408631178404, 0.209826774792909, 0.25371923916544925, 0.2217913390499392, 0.2234984846426139, 0.2269927375586076, 0.18596545289957556, 0.199612040947314, 0.1897674082321299, 0.18595519546581774, 0.17303597549841143, 0.17471574839878923, 0.17335689482236305, 0.18441500383627962, 0.178317935272005, 0.1299722089948223, 0.1859578874051636, 0.18580220545951687, 0.17144673649024045, 0.19651795555548457, 0.5201421077611827, 0.14062737795036373, 0.6760986449615299, 0.5839546868983456, 0.5295926385182457, 0.20756011602465085, 0.20223225331933414, 0.3625239268937218, 0.1643291445236832, 0.16706950401148024, 0.3579991825173806, 0.36034826467049885, 0.3223519654889666, 0.1925496944199453, 0.1957941875289283, 0.1877225621553078, 0.17612638755696175, 0.19753162764562715, 0.1960391855820678, 0.18379808133969489, 0.182720631628576, 0.18736622008983672, 0.1021128358622796, 0.11092503106035567, 0.09497836056299402, 0.09323371430093097, 0.11552502169072254, 0.08098305056679311, 0.09221305876137742, 0.09896899277430493, 0.08381868067266585]}, "mutation_prompt": null}
{"id": "21868e4f-58ba-4466-b490-9f00736a257f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.surrogate_model = None\n        self.surrogate_model_update_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def surrogate_model_update(self):\n        if np.random.rand() < self.surrogate_model_update_rate:\n            self.surrogate_model = np.random.uniform(-1, 1, size=(self.dim, self.dim))\n\n    def surrogate_model_evaluation(self, position):\n        if self.surrogate_model is not None:\n            return np.dot(position, np.dot(self.surrogate_model, position))\n        else:\n            return np.inf\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < 0.5:\n                    fitness = self.surrogate_model_evaluation(self.particles[i])\n                else:\n                    fitness = func(self.particles[i])\n                    evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                self.surrogate_model_update()\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and an additional \"Surrogate-Assisted\" strategy to reduce the number of function evaluations.", "configspace": "", "generation": 74, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('high <= 0').", "error": "ValueError('high <= 0')", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {}, "mutation_prompt": null}
{"id": "54cb066c-facd-4525-a536-89ce56ece9fa", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.98\n        self.adaptive_cooling_rate = 0.6\n        self.levy_flight_alpha = 1.2\n        self.levy_flight_beta = 1.5\n        self.opposition_based_learning_rate = 0.3\n        self.inertia_weight = 0.8\n        self.inertia_weight_damping_ratio = 0.995\n        self.mutation_rate = 0.15\n        self.mutation_step_size = 0.15\n        self.velocity_clustering_rate = 0.15\n        self.particle_filtering_rate = 0.25\n        self.archive_size = 15\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.15, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(4, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(4):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(4, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(4):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.6 * np.random.uniform(-1, 1, size=self.dim) + 0.6 * (self.best_positions[i] - self.particles[i]) + 0.6 * (self.global_best_position - self.particles[i]) + 0.2 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.15:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.1:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 75, "fitness": 0.20710493434786073, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.41030224880251387, 0.44785348954859683, 0.4765549559553589, 0.4840021463016456, 0.43962232793681366, 0.4234327883712211, 0.471661544784299, 0.4390239695167868, 0.42445795060787106, 0.001203725366831887, 0.00851369694331805, 0.053560579365832695, 9.999999999998899e-05, 0.01936779552610346, 0.0045628969107208706, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11804882752109458, 0.11049522130048683, 0.0769980707184077, 0.119754285288595, 0.09888139070880353, 0.0854072924181406, 0.11557082040628797, 0.09520574644898294, 0.1358973375794641, 0.07633128354380792, 0.06355152884352933, 0.0971236797313435, 0.09762861660907851, 0.07874310009652818, 0.10331280023399281, 0.0819220049032261, 0.07239910168865749, 0.07875654521250508, 0.8886250793636781, 0.949422237969009, 0.9193211868180295, 0.8728048092397538, 0.8582715446697857, 0.8644912364215507, 0.9224031527698011, 0.9335429023213375, 0.9049205062114211, 0.2637172636377719, 0.26110677003480476, 0.2190792722286371, 0.23823850080400777, 0.26903412835784934, 0.2387432382836432, 0.2611453508662993, 0.2392603936924591, 0.25007314420013904, 0.3329122820917204, 0.3107220976248587, 0.2618062144926996, 0.20975503064950962, 0.21051340350264847, 0.2559063045669484, 0.23284937617258705, 0.21326868739918148, 0.24703780343082504, 0.11060823510264162, 0.1421958803976342, 0.11329494033631948, 0.14686145173539622, 0.1678426029578035, 0.18216571619617639, 0.12882772119430885, 0.13821939849502518, 0.1217492422097155, 0.14866541728684346, 0.09530913183887002, 0.16599520164989667, 0.14754372055512466, 0.14975829778550265, 0.1386981565841292, 0.13861016640215806, 0.15730075986891168, 0.13358790798712272, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03467946580369918, 9.999999999998899e-05, 9.999999999998899e-05, 0.01102174749314977, 9.999999999998899e-05, 9.999999999998899e-05, 0.1593095869262361, 0.05617174626608068, 0.10948991408910247, 0.07080636602671764, 0.07702920795085444, 0.02892380359488511, 0.128827597592719, 0.07443284241191306, 0.06861033423837448, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10157525319131622, 0.10029055640869888, 0.10284330987702739, 0.1109778462710519, 0.11945541946565486, 0.07078166520659834, 0.09790374814092118, 0.08780471234530973, 0.08012436795890843, 0.4261146934847344, 0.40079806044584454, 0.3983127807371203, 0.3915724871997943, 0.42393113923896086, 0.3945910822783476, 0.42205746284914547, 0.43263421224015497, 0.39934498997594015, 0.07421322929157415, 0.09240833580506291, 0.10230154951909698, 0.110527099412837, 0.10347054508331366, 0.09748800032840332, 0.09098038263052599, 0.11371465239970457, 0.10976865067342101, 0.20309661123539258, 0.16544850333280825, 0.14444194338334004, 0.1737390436769385, 0.16012305135142646, 0.2197063164137426, 0.18031340583049282, 0.1936306876509396, 0.2045121510968715, 0.2737905021533953, 0.26654382544798827, 0.26080505233603324, 0.2136628986245912, 0.2959900776482751, 0.2587953154810809, 0.2680542705002519, 0.2700138857434723, 0.214975876314205, 0.20045239971417161, 0.2275573883749865, 0.21478141052103383, 0.22974799592062922, 0.23457796006522869, 0.2150311730958152, 0.1990760072202864, 0.22965073197107866, 0.17982366113673343, 0.23049488040940103, 0.21857665110812807, 0.24785207382708008, 0.2514524515029165, 0.23231099864930516, 0.21424892321007105, 0.22605564927688804, 0.22988500896007924, 0.2116221644582158, 0.1847621272020945, 0.18961055652328884, 0.17635925133939256, 0.1805963603594415, 0.19574448180265747, 0.1726517556172421, 0.17861165855935046, 0.2009062850410932, 0.17844951634187567, 0.49634164613987497, 0.18635373564661362, 0.18631836479398844, 0.5599487341489883, 0.19706651074739934, 0.19526227035825472, 0.14093415273739407, 0.16470147799256807, 0.6593669924140222, 0.437909446903204, 0.20698867337397409, 0.44298973635173733, 0.3269143101698043, 0.16645047083341158, 0.16635553627265476, 0.16565592110984073, 0.2192254585045611, 0.42256493616229995, 0.18387644129248926, 0.18910165787478161, 0.1904710429744496, 0.1719033517387465, 0.17868223836380726, 0.17349991420336042, 0.18661820789906203, 0.18340938417958264, 0.18729972369608539, 0.09221210059708251, 0.09226784422213363, 0.10785160884495304, 0.08779660606034445, 0.1326959438019576, 0.09647524796944673, 0.08335747292669782, 0.10068570153280454, 0.09293753542122574]}, "mutation_prompt": null}
{"id": "b0e6e168-1f0d-4dc9-8c99-b8b975cfec41", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with probability 2\n                if np.random.rand() < 0.5:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 76, "fitness": 0.215789005982464, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.44269035962052006, 0.45387475775673625, 0.4797681562097488, 0.4649551311676712, 0.4614594425309516, 0.47786957064124325, 0.44010885249503584, 0.45945100905810954, 0.46229058581993665, 0.012417565134346886, 0.034686367183130784, 0.005994186871088436, 0.0018178567109927712, 0.002555932647310688, 9.999999999998899e-05, 9.999999999998899e-05, 0.002976950942813694, 9.999999999998899e-05, 0.12701304118646695, 0.0941394141031816, 0.08200724530832137, 0.09762233555764, 0.09763867404412052, 0.0940425169581518, 0.1004128318038423, 0.126389867796864, 0.11861924343099295, 0.0905694695030026, 0.08586650525085548, 0.08384574564696978, 0.10913701473592496, 0.0661311810628753, 0.10529088423389454, 0.09658506624827656, 0.10012983419034993, 0.08491674204391986, 0.9090700692478644, 0.9392461777669154, 0.9040524385566702, 0.8432690163672205, 0.8841523735689157, 0.8555555606397365, 0.9015882625559626, 0.9176290279604545, 0.9189877483323166, 0.28934995787780593, 0.2420772956665338, 0.2680261709031867, 0.2394722913008297, 0.22601848872335217, 0.24690792099957526, 0.2492683858994188, 0.26338098932517096, 0.2573464308362997, 0.5201392419836062, 0.3193986439041343, 0.3235837066635514, 0.25799245220494027, 0.25372565906842226, 0.30971934223729547, 0.29946443568637304, 0.23234852001725104, 0.28672747223604267, 0.18717542393437148, 0.12542674889870542, 0.13708800652795783, 0.12765422945037885, 0.12757500165291114, 0.1233832302486022, 0.12594892222508802, 0.18379355769367256, 0.15701246643001154, 0.13805296273721268, 0.1351251039410688, 0.1678935877965403, 0.1718153988816029, 0.1410409800365816, 0.13931103378157061, 0.13133700309785412, 0.17710569636875584, 0.15631304721488248, 0.004662115120770638, 9.999999999998899e-05, 9.999999999998899e-05, 0.021622378824698307, 0.036670344997539406, 9.999999999998899e-05, 9.999999999998899e-05, 0.0005016986799264433, 0.0025644717106523274, 0.12085571458162359, 0.07493669708130479, 0.11863022612277241, 0.0757676856196482, 0.07240219375077817, 0.014228999238605322, 0.08210296711193588, 0.06337656964473104, 0.10413015669449155, 9.999999999998899e-05, 0.009288156195904729, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01072006942748871, 9.999999999998899e-05, 0.03960697019181281, 9.999999999998899e-05, 0.14464390073877675, 0.11712816641465162, 0.11207233612055478, 0.09944264336787878, 0.1288340542819285, 0.11737300699008812, 0.11057792853166015, 0.08495052305687933, 0.08593709564765728, 0.4228592054525516, 0.42151605300551986, 0.41446698560495965, 0.3776684547949559, 0.39847045614054155, 0.4247311362756302, 0.42043914229743706, 0.43702405734473904, 0.4543531209494417, 0.08253712449932604, 0.11351555948541026, 0.09312808134077821, 0.08702386235284976, 0.11251736710302063, 0.1227826990316706, 0.1123505569560046, 0.10269442588558597, 0.0768905810363485, 0.17556238205875851, 0.14951719902763838, 0.137644113198506, 0.18887762834508726, 0.18253214327607437, 0.1566459126073263, 0.18549395554677672, 0.13218509008157275, 0.2345900125188849, 0.3028165769281641, 0.2821402561599007, 0.2871588160771166, 0.2780531348872164, 0.3010965937933706, 0.2754293416248068, 0.22364407816834608, 0.2608672907502487, 0.300139180968782, 0.20732578559264925, 0.20443493014124814, 0.2593425476569221, 0.23878388463118527, 0.25743383094065053, 0.23020650628297357, 0.17690958614518748, 0.21165153968121653, 0.21441658349960613, 0.22817648190105455, 0.2667329750916275, 0.21850342496629505, 0.2021676789782617, 0.2174303964480485, 0.25484969232166754, 0.27971034108782644, 0.21610614774921844, 0.2482454371434304, 0.18455472890920332, 0.17291654045872673, 0.18928032897918678, 0.1977707793266431, 0.19059461274781864, 0.18048427570186543, 0.21582127373254711, 0.1837089350141462, 0.18172122244786648, 0.18515402826500338, 0.18504524344032292, 0.14617456919170402, 0.6378154520126434, 0.19879471307555463, 0.14558798626529168, 0.15136171486895822, 0.620184481572422, 0.6755079987732098, 0.4432241813676753, 0.6102363873857416, 0.5762579645353936, 0.20732260331648955, 0.16577738729417923, 0.16587556102163103, 0.16675585186714148, 0.34878540776273914, 0.2970462608244686, 0.17038691578397325, 0.18595739804577793, 0.17746668740503813, 0.18797969113441837, 0.18496038544706217, 0.19497084807666576, 0.21317588855405234, 0.17680787689224942, 0.17868536278956804, 0.09722018862699644, 0.07295804910923676, 0.09050059737341676, 0.08886958015118618, 0.11179198068856044, 0.08647999269602291, 0.09358030667659145, 0.08903710263321629, 0.09489371464754115]}, "mutation_prompt": null}
{"id": "c101ffb8-f243-4875-8b7b-81d791091362", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.memory = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.memory_size = 5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def update_memory(self, position, fitness):\n        if len(self.memory) < self.memory_size:\n            self.memory.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.memory])\n            if fitness < self.memory[worst_index][1]:\n                self.memory[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    self.update_memory(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                        self.update_memory(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                        self.update_memory(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Memory-based position update\n                if np.random.rand() < 0.05:\n                    memory_index = np.random.randint(len(self.memory))\n                    self.particles[i] = self.memory[memory_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                        self.update_memory(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 1, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate, and with the addition of a new \"Memory-Based\" strategy to store and retrieve the best solutions found in previous iterations.", "configspace": "", "generation": 77, "fitness": 0.20864253595716248, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.48612447733371555, 0.46182775071477844, 0.48081057015149753, 0.42977413607512394, 0.444188592378045, 0.46589809250759195, 0.45257153738746825, 0.459084370786235, 0.46011177093182154, 0.008181745010653496, 0.0006507823530668144, 0.004251297280298272, 9.999999999998899e-05, 9.999999999998899e-05, 0.003857173704454153, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13800685750193187, 0.10526155585208397, 0.0919973644722617, 0.07956437357029444, 0.11009413012595493, 0.09063502319501171, 0.1080401459320699, 0.11520637421845659, 0.11288684279326766, 0.1021324229902808, 0.09832742359671098, 0.0960575279523862, 0.0907522719689372, 0.08594838878765398, 0.08500726192640307, 0.09295225996671563, 0.09275749535522448, 0.07230521684794822, 0.9028186132042185, 0.9333184790007536, 0.8865422531947372, 0.8747981735188417, 0.8864513568893069, 0.8377023931276648, 0.9270876075378476, 0.9203935044717116, 0.9268869023557633, 0.251699190062579, 0.26894395491076684, 0.23485300582251212, 0.22252337902304375, 0.24403410828470795, 0.2720537507253642, 0.2471849743225646, 0.2206917071617579, 0.24820933228261732, 0.2736863607171244, 0.353335213951226, 0.31540807280276717, 0.2513408141123685, 0.2640569771481479, 0.20047968890618217, 0.2313453874578698, 0.21211288701956588, 0.2613569739855607, 0.14482575474670356, 0.1273236483186222, 0.17686855958151393, 0.08654118503226615, 0.2373349336054147, 0.21517328102581879, 0.16105115742948017, 0.15464849438772832, 0.1428014249026841, 0.168086871132614, 0.17143774236022213, 0.15562777092041646, 0.1406826213580693, 0.13887789400016592, 0.14388143875226556, 0.1429606744684353, 0.1842944570600885, 0.15825407468421615, 9.999999999998899e-05, 0.0069504397616340086, 9.999999999998899e-05, 9.999999999998899e-05, 0.018402073437023825, 9.999999999998899e-05, 0.017990614405372418, 9.999999999998899e-05, 0.005393668880076752, 0.1221017275286782, 0.06378142789469987, 0.10931320462370409, 0.09371803259500755, 0.08251536884276933, 0.031904693854006516, 0.1565594591937095, 0.12306451108897087, 0.08567819046084879, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0014526336149125463, 0.015483833686511406, 0.013486147291847383, 9.999999999998899e-05, 0.11530927571038696, 0.1177034172178032, 0.08698327558098429, 0.10917414656856617, 0.1256422867586372, 0.07604857554478583, 0.07814318972072831, 0.09909810062347646, 0.12176191953719862, 0.42401255240772573, 0.4184016303856035, 0.4154689210479281, 0.3839871952608416, 0.389949408274462, 0.40282236738418453, 0.42322555555872654, 0.414514276233949, 0.39829180545277176, 0.09373165016994423, 0.12398244455351959, 0.12495239629226929, 0.11101354669887309, 0.09210909910512544, 0.09820282687915294, 0.10521194979608117, 0.09311859242999965, 0.10492759579580346, 0.13886413017963495, 0.16907390204542294, 0.13871847844891383, 0.18429147532479284, 0.1705639610027163, 0.1794362860692872, 0.16289406884207747, 0.2338444550689659, 0.15428437335612288, 0.3033964596980038, 0.2904719583034433, 0.29186272800766566, 0.2587194123592712, 0.255916473795346, 0.2965720895695755, 0.30984413961344504, 0.3169766601352464, 0.2749220156446428, 0.20393554077426057, 0.1976712254762898, 0.22553672588295925, 0.24709432537015286, 0.2161757362739508, 0.205498350713327, 0.21948272912839606, 0.22382721372917702, 0.19380539110110373, 0.2385125155478286, 0.21140809380131176, 0.23269879055696263, 0.23063212783896136, 0.21011697603263957, 0.24392796700821762, 0.27113176980966647, 0.24320006372780678, 0.256803478753994, 0.19792650439340587, 0.1742962648217532, 0.19004941433440803, 0.18448112759316415, 0.19378733953311544, 0.1713828602731441, 0.18740527294494547, 0.17298485472530234, 0.1887984219126312, 0.1845626619660714, 0.1863649786965913, 0.18647435725586725, 0.15025835103161955, 0.19858009187955927, 0.19524366879361443, 0.14129285139677816, 0.15711169244202194, 0.16500815046641326, 0.5883921177993715, 0.4336000607810113, 0.45742440442652554, 0.3629255025963368, 0.28032000278314595, 0.16568452306140902, 0.1669227129729397, 0.4478176674062203, 0.35067475805861115, 0.1758675420783029, 0.18154703602001265, 0.17294491406469603, 0.17802956824981242, 0.18000461606854912, 0.1678940203892626, 0.17656024891996025, 0.18052116261709872, 0.17606689037392353, 0.09759275348740903, 0.10500737466750487, 0.09556312062248995, 0.11606765815081266, 0.0797109665080803, 0.08128910821460011, 0.08273442104172013, 0.09871884550355703, 0.09634850884980806]}, "mutation_prompt": null}
{"id": "a621446c-2d39-41c6-b435-60cb0eef5748", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with probability 2\n                if np.random.rand() < 0.2:\n                    self.velocities[i] = 0.5 * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 78, "fitness": 0.20802796962889702, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.44855662027112, 0.4979161964756563, 0.4712996305537823, 0.44451472634063693, 0.4649418813808116, 0.45018288507916127, 0.44762109766594327, 0.44941203565527854, 0.45241022580981805, 0.0034665111266684034, 0.030685867588758797, 0.022315783666230216, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00026794845258315547, 9.999999999998899e-05, 0.10253796955694872, 0.11113760324781363, 0.10648701367960078, 0.07988413393453431, 0.10386900639346663, 0.10637738364311988, 0.08638062310565531, 0.13592534124050237, 0.10347394298141932, 0.08955296018170922, 0.0838778552127376, 0.11665373165040438, 0.08993928534030382, 0.09450750646934791, 0.09392614829064883, 0.08648433008927836, 0.09657899515346013, 0.08775061419338492, 0.9211756601802514, 0.936702274698799, 0.9014552455218788, 0.8531788921215163, 0.878886727139935, 0.8750221305116709, 0.9264272814443137, 0.9215646042697249, 0.9116271888118437, 0.2637427813887989, 0.26335363262606004, 0.2601341302329615, 0.24349688161396543, 0.24448023593053914, 0.26519445482215953, 0.25393902224168374, 0.21417369315603751, 0.25564631410903416, 0.3490381456592315, 0.33081577746944, 0.3324775252978889, 0.260528191462745, 0.26511400002341357, 0.2296660897218421, 0.281069100962955, 0.3142814382213315, 0.22108210852272792, 0.1375221903339412, 0.1317756976448391, 0.13098222377304047, 0.0898993899025825, 0.17158417206566878, 0.17919578936164848, 0.14991844856135017, 0.1376936458663931, 0.13393866491929962, 0.13412462027890304, 0.17426334279572642, 0.18289384852841706, 0.14919390267856036, 0.1351215085341806, 0.1521828313954222, 0.15436903140541014, 0.14510154415342835, 0.1716873639588744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000101448711016916, 0.06837437843156713, 0.03230450733046486, 0.0011494227005710567, 9.999999999998899e-05, 0.0003919239079350767, 0.07490160299430082, 0.03330065228700296, 0.14435447964691506, 0.07866048133311665, 0.12525741611517294, 0.02245905574338558, 0.12760588005290652, 0.09754123841970885, 0.190280728499866, 9.999999999998899e-05, 0.00014465220510828658, 0.010704860691488793, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002426307982973941, 0.0016334792497521011, 0.10927893720234838, 0.12608151487747254, 0.1155610647078602, 0.10195723830977443, 0.13648632767874058, 0.08862790587357927, 0.11312283038781057, 0.10216981517632973, 0.07281026012516523, 0.3990088107074382, 0.42757068978378143, 0.4407035750116808, 0.40646839338312646, 0.4054017003606363, 0.38216344342164776, 0.39763718430057693, 0.4368552151569023, 0.3983201798377596, 0.11520976054284293, 0.11910270410452306, 0.089531731975659, 0.10641409447617278, 0.09853135305714167, 0.10112640145131213, 0.10963179956577007, 0.09628848508793963, 0.1298040337489489, 0.14131524663076211, 0.18208993367333737, 0.14083025048220532, 0.16514925028324523, 0.17284340656202424, 0.18826294863377535, 0.20043272932835154, 0.15477299679060874, 0.2148745988655577, 0.30522231726401794, 0.2900866295727176, 0.28221241707213307, 0.2736436826627334, 0.30181179934059543, 0.27966628047749753, 0.24541036573676478, 0.27441488697284777, 0.2672512585260858, 0.22440300207931496, 0.20390420563843492, 0.2346178327098265, 0.2150214011419027, 0.23111008997930182, 0.18831944955012847, 0.19415661340699908, 0.2303783445471973, 0.19898324454830962, 0.25907693142735777, 0.22817438284281677, 0.25062441608160435, 0.2422686771181003, 0.20953367775287468, 0.23494075351396304, 0.2259694545624853, 0.21914253414608142, 0.2253191998908569, 0.1846884000883675, 0.17650844750283956, 0.16976591215981085, 0.17809892606870859, 0.19977541623476347, 0.18509429151651513, 0.1947020962018693, 0.1848097849132011, 0.1738869564133616, 0.1289182738141661, 0.18533757484338897, 0.18633211647660186, 0.1493820267887791, 0.19688143481791565, 0.19534976548957628, 0.1413100228653993, 0.1489087766299575, 0.6122681437154396, 0.45442360252470193, 0.2086072263637877, 0.5251914574741116, 0.3408927743951654, 0.164719061038628, 0.16688845845299438, 0.16659547232920902, 0.28671951145458685, 0.16760466766077298, 0.1975618308299919, 0.19016433277823275, 0.1911520469825796, 0.17876915779475078, 0.18731041607825183, 0.20126989042819166, 0.18293879191056983, 0.17123530757568806, 0.18595012774765496, 0.07693258258401037, 0.1155390318371412, 0.0915056443129173, 0.08629167258613801, 0.08819240323843491, 0.0889930476879548, 0.10172900472618329, 0.08430274937229953, 0.1107920279559137]}, "mutation_prompt": null}
{"id": "09559f99-79f1-4f64-bb38-c2b3b9d9c9d5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.98\n        self.adaptive_cooling_rate = 0.6\n        self.levy_flight_alpha = 1.2\n        self.levy_flight_beta = 1.5\n        self.opposition_based_learning_rate = 0.3\n        self.inertia_weight = 0.85\n        self.inertia_weight_damping_ratio = 0.995\n        self.mutation_rate = 0.12\n        self.mutation_step_size = 0.12\n        self.velocity_clustering_rate = 0.12\n        self.particle_filtering_rate = 0.25\n        self.archive_size = 12\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.012 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.12, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.55 * np.random.uniform(-1, 1, size=self.dim) + 0.55 * (self.best_positions[i] - self.particles[i]) + 0.55 * (self.global_best_position - self.particles[i]) + 0.12 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.12:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.06:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering (HSO-ACL-OBL-DIW-SAM-VC) that incorporates a new \"Particle Filtering\" strategy to enhance the convergence speed and diversity of the swarm, with refined strategy based on probability 2, including modified velocity updates, adaptive mutation rates, and enhanced opposition-based learning, using Cauchy mutation and Gaussian perturbation, and a new \"Archive\" strategy to store and retrieve the best solutions found so far, with dynamic inertia weight and adaptive cooling rate.", "configspace": "", "generation": 79, "fitness": 0.21254814450412282, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.505548230927561, 0.45148167916662907, 0.4503327760098331, 0.4470306510795754, 0.4126203813404542, 0.4371073290493843, 0.4768868032929994, 0.414058754850141, 0.43863775489093493, 0.06650490370554885, 0.03652727372882236, 0.007903762096664435, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.020229594989452426, 9.999999999998899e-05, 0.12361926526083467, 0.10358295052166522, 0.07733628896903721, 0.13159208801366562, 0.10714205348814798, 0.11519194514194842, 0.10275789656366996, 0.1221743632283604, 0.11334648043405726, 0.08314367549965485, 0.09850369946490156, 0.10055994831942627, 0.09645258768487908, 0.08037301752334192, 0.09446027490740849, 0.09714751027853197, 0.10686190643986249, 0.10194246531907303, 0.915111273956663, 0.936460151305416, 0.8771557361684609, 0.8670361590881259, 0.8983386483503505, 0.8977958854965525, 0.9324950933848599, 0.8977911048601989, 0.9009523358208896, 0.24784394322135328, 0.2568068091910557, 0.28554173546927863, 0.26475052305785196, 0.2754176139223179, 0.23777631684917255, 0.22586359742943152, 0.254646257315143, 0.22376739830208303, 0.2524166448734325, 0.7094919781497746, 0.25041921985502613, 0.21173997339408357, 0.31692980670161075, 0.21709485442969612, 0.29360475640948036, 0.20352262755731299, 0.2199738087459986, 0.1553207147278386, 0.17813875679191826, 0.108366087638052, 0.10925293616279719, 0.1698768811903627, 0.11961938014516638, 0.17227929839729672, 0.1850879968143524, 0.1380223576812084, 0.13287002736935827, 0.1616040510593526, 0.12179024072813283, 0.14241812850549684, 0.12581380710991708, 0.16767171879940979, 0.14058589816279343, 0.1691832992690685, 0.12345461020661674, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014156916244441708, 0.0037821859514446388, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0033654085209194884, 0.07030430445789881, 0.04830731021145962, 0.1223772747554891, 0.07899695971325349, 0.03282833644037342, 0.029084739412505556, 0.1565294662404405, 0.13220608056747385, 0.07551831096966921, 0.00012947822841302692, 0.005714005988169402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11661253031959151, 0.1071185939364464, 0.09862921301750283, 0.09993427912061392, 0.09102849426178328, 0.06038229524641214, 0.0957598246737782, 0.09688598738551668, 0.0965592491565439, 0.39501667212088076, 0.417348730719567, 0.4038938915226834, 0.433727866549079, 0.40519136369267994, 0.38197149010189846, 0.40562480202387374, 0.4011130175869586, 0.42058996735345355, 0.09265722581411806, 0.143800344505135, 0.08268158207754095, 0.08169653355304873, 0.10507369074172679, 0.08473656596559176, 0.0949453713432249, 0.11386700163137797, 0.12431102315007536, 0.13734003520854454, 0.1440735713583433, 0.12934334999691366, 0.21784942722597256, 0.23770194297901848, 0.1785221355503085, 0.15699534323104103, 0.1466595609264425, 0.14858419228866204, 0.2925082979129213, 0.2990243536176277, 0.3000587772584278, 0.29643603604466695, 0.29753848932283644, 0.2891867788782554, 0.2817661552929419, 0.2546915552622575, 0.24483554908239435, 0.20227214086270828, 0.20931798253492284, 0.21695283500801954, 0.22633655923661355, 0.20786345092786696, 0.23244794865174123, 0.1776230117492803, 0.24038163200595442, 0.17435786099475936, 0.28919628165737743, 0.22777689776155408, 0.222889409393505, 0.23096153590637136, 0.2529720740428878, 0.21302040407170986, 0.2592778281600544, 0.22982990254390046, 0.22215310395001886, 0.17667452068779954, 0.19395977017925703, 0.17687667983374744, 0.2031655013100364, 0.21773269771656045, 0.17403813500964738, 0.1735895380968635, 0.17413805275529926, 0.17683475525656944, 0.5367083416839638, 0.18404405446396954, 0.18639395658063662, 0.6154641589978747, 0.19827442390531647, 0.19549187481044428, 0.17046058600341907, 0.1549460757291945, 0.5979984730050627, 0.5552341000572462, 0.2082579596663925, 0.4029738403158446, 0.3915569983032835, 0.20236601644440977, 0.16641897075211742, 0.16587056136754164, 0.3054442831737876, 0.4467734296225081, 0.18928917257244315, 0.17473559707430164, 0.1871233817365161, 0.1927307450016369, 0.18589582715484287, 0.18095460174404554, 0.19178131599794312, 0.1964459398970414, 0.19689911003026062, 0.09352647604718767, 0.0923320186729708, 0.06452611064438463, 0.10324679483434307, 0.10369289053535591, 0.08898231189771, 0.11079851507974636, 0.08700145889044775, 0.09058563692946175]}, "mutation_prompt": null}
{"id": "d480965b-537b-447f-9eb7-708ad98b7851", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.probability_threshold = 0.45\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def refine_strategy(self, probability):\n        if np.random.rand() < probability:\n            self.inertia_weight = 0.8\n            self.mutation_rate = 0.15\n            self.velocity_clustering_rate = 0.15\n            self.particle_filtering_rate = 0.25\n            self.adaptive_cooling_rate = 0.6\n\n    def __call__(self, func):\n        evaluations = 0\n        self.refine_strategy(self.probability_threshold)\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Archive\" strategy and a modified \"Particle Filtering\" strategy to enhance convergence speed and diversity, using Cauchy mutation and Gaussian perturbation, with refined strategy based on probability 1 and adaptive cooling rate.", "configspace": "", "generation": 80, "fitness": 0.2162389832514928, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.4543980260149836, 0.47284237499781756, 0.46342211553294577, 0.47267516144365096, 0.4601152323386559, 0.4586977272542695, 0.4825483093165648, 0.4807869748543775, 0.44500975861361025, 0.0026421916778089916, 0.009218548363312817, 9.999999999998899e-05, 0.0014585276473604303, 0.0003401599931542876, 9.999999999998899e-05, 9.999999999998899e-05, 0.0026831068425507976, 9.999999999998899e-05, 0.12531322511418042, 0.0805978194627005, 0.10912892203369462, 0.08161634381226845, 0.08134351060684508, 0.10492173090592427, 0.13301244167502901, 0.10578098578805861, 0.10353756375972079, 0.09837595658842857, 0.10059179316168443, 0.06737549044458269, 0.08503314433548748, 0.08223402185519357, 0.08586424299861861, 0.08875235413343585, 0.09197527503402603, 0.08989616067618278, 0.9137280962192874, 0.9315501323527372, 0.9127523176284317, 0.883356699979464, 0.815103083456137, 0.8801713442905237, 0.8993376185832753, 0.8992783968680882, 0.9241438167864621, 0.25918854801535707, 0.28785444438170327, 0.22351020154929668, 0.24524472755202764, 0.27764892413014297, 0.2940762020591253, 0.26938109488563133, 0.239240935023998, 0.24169466675018236, 0.2693468928513517, 0.34688536168324413, 0.21792586307861772, 0.33263029880873063, 0.7666397678054856, 0.25709147845725766, 0.20908770019084844, 0.2201415035782588, 0.26184768854710305, 0.16542855822133984, 0.1344749394240491, 0.13165339974760792, 0.03760800940960285, 0.2045322723224543, 0.12964491679016577, 0.13039415594286163, 0.1814801836499066, 0.13667114640465627, 0.16675170656740756, 0.14443106019548135, 0.15510446722832205, 0.15071881125602526, 0.14177369636590031, 0.15765598303025485, 0.14309818230278393, 0.14431618400742352, 0.14768869175331711, 9.999999999998899e-05, 0.002329690815018659, 9.999999999998899e-05, 0.0009726346473771796, 0.044391440197008136, 9.999999999998899e-05, 0.0005500449031289323, 9.999999999998899e-05, 9.999999999998899e-05, 0.12940136277217806, 0.06670539975643153, 0.16073431348781086, 0.08609366060444412, 0.08130951142863996, 0.02110630951891812, 0.14664125499236236, 0.08334992672725094, 0.061842912932869476, 9.999999999998899e-05, 0.002444728016753439, 9.999999999998899e-05, 0.0009809397425613042, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12543177477442535, 0.14025264374207114, 0.07062310164343366, 0.10956804578041124, 0.1072117001450591, 0.12244420505585663, 0.10257860217721826, 0.06434246998474169, 0.0883587681618877, 0.41531003928372723, 0.4044291563148823, 0.43372861703983423, 0.39581599729507944, 0.4265826936547904, 0.38985864289426364, 0.4359704727841207, 0.39473437459000504, 0.44337751196579134, 0.08942242728713812, 0.18169677474395873, 0.09465592729363803, 0.11621482286279605, 0.11308946632090322, 0.11782923486184449, 0.09722651957769068, 0.13125274507874785, 0.11973563455151348, 0.13000201151246293, 0.24202072079332004, 0.16075126251632066, 0.14713689787030493, 0.1830678922783423, 0.17138985603478019, 0.19059972431522287, 0.15260489979496072, 0.19660767678593094, 0.2645158564348058, 0.30780234000201956, 0.3156447475315285, 0.2799322311386778, 0.3124533514454232, 0.27195434294204457, 0.23182200975324685, 0.298064480910778, 0.23249467921469857, 0.22642301710538482, 0.21551322616828972, 0.2505046529097058, 0.23103778582998158, 0.2169178775844659, 0.2234562480679897, 0.18624853194257562, 0.19919618834114183, 0.20355484899862408, 0.22265424640899378, 0.2554946332523006, 0.2147997307321764, 0.2365892413721491, 0.23250495206681676, 0.28727262906320605, 0.22073672336489158, 0.2722684417411776, 0.24036259384710446, 0.16745560701474604, 0.17352275114928217, 0.1857049707188091, 0.23021904137082605, 0.19046102786236352, 0.17885943783580482, 0.18630445196827294, 0.19579947081959037, 0.17909829036117186, 0.6199608604991178, 0.18546489179133774, 0.1855015316076588, 0.5469101321036249, 0.19884304459391022, 0.6053242214001823, 0.14126380355876522, 0.1640673068006585, 0.6165409055160567, 0.5231439833288983, 0.16814088537888072, 0.4137115550085575, 0.4077826955835625, 0.27435806158900633, 0.16754036332297562, 0.16669399281442987, 0.1670330018054048, 0.3131281063082302, 0.181666054147816, 0.18342805498103565, 0.1777105511867425, 0.1975903663764761, 0.18201390634950876, 0.18669197441970975, 0.18263033368826775, 0.18018989605414681, 0.17087796376119568, 0.10148201992059513, 0.0836285962645481, 0.0958802095518233, 0.09872549241167383, 0.10202021990263255, 0.1105697182344888, 0.08467582297703324, 0.10080302577080724, 0.08313136632193796]}, "mutation_prompt": null}
{"id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm.", "configspace": "", "generation": 81, "fitness": 0.21974542838273242, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV2 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "a9cf93c1-3a20-4b80-b8a2-cb8ee44a6533", "metadata": {"aucs": [0.45762677657851114, 0.4547887405068367, 0.4822846416047778, 0.496356293355791, 0.4823600517618082, 0.4443851442460154, 0.4430198494653105, 0.44306575493238254, 0.44219111042527626, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.023658774535978977, 0.0035903858081661744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1313428242566963, 0.10344561101545591, 0.10765560763854443, 0.11205713048186661, 0.10858735361718064, 0.11219359227339532, 0.12047994820146601, 0.10998009248735963, 0.10743021626828231, 0.07566761749043793, 0.09649957820621202, 0.09876313610669862, 0.08305024974709829, 0.07086371013452064, 0.08643638089146066, 0.10786883553004922, 0.09033388844252255, 0.08048507691240414, 0.9149437159038689, 0.9463388479092292, 0.9108893139050334, 0.8969920244089592, 0.8949771266263598, 0.900342531086881, 0.9275784881873064, 0.928751963941111, 0.9156287233669277, 0.22438236162804848, 0.2431545756978628, 0.22867507241762397, 0.24061744014172481, 0.25388890657227237, 0.25040796096427553, 0.2567741197202932, 0.23209236597055027, 0.23208952965423268, 0.35220025270887856, 0.5431046251169309, 0.2744909806375153, 0.2672810022949853, 0.5666546614445589, 0.20291533327205624, 0.3397529295396382, 0.2217348104734025, 0.7338215498872716, 0.12903855152518795, 0.11878137964478575, 0.12235729328988765, 0.152889014791171, 0.1920064912253483, 0.17452918282630603, 0.21746926828872026, 0.19526976092056414, 0.12875292309158792, 0.14592524986545263, 0.149530127114188, 0.1650302860818358, 0.1499739620819044, 0.12502230311497675, 0.14938892553489969, 0.1358438500250495, 0.14993199512664324, 0.17284308519457248, 9.999999999998899e-05, 9.999999999998899e-05, 0.006227293225910535, 0.034226946134634506, 9.999999999998899e-05, 9.999999999998899e-05, 0.02551479754435837, 0.00200281354491727, 9.999999999998899e-05, 0.15443389011826292, 0.04858057310156105, 0.1363355272042076, 0.06358410685854288, 0.07389972404886325, 0.01057869182613791, 0.13378630418479065, 0.08821591730754585, 0.03516416855390181, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004370259529300147, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1100712447522123, 0.1525085474856427, 0.11324935712828266, 0.0809354490299955, 0.10969495609411406, 0.08641511136833069, 0.11393964309511107, 0.10151917829269008, 0.1210082238700605, 0.46989464364462896, 0.4146576662246403, 0.4076458742401563, 0.39703224146252836, 0.404504519782962, 0.40882028672978665, 0.42604438299249026, 0.4332694131160657, 0.39659275766493884, 0.12251509030711605, 0.10515877286410158, 0.07958556353682777, 0.09126477572209846, 0.09709287034802472, 0.09619889138859106, 0.1028133245833387, 0.13811919037950815, 0.10221640256115283, 0.1370695998757563, 0.28574570608833716, 0.14348572969954754, 0.1830707328058373, 0.1986794916396375, 0.16983526522070136, 0.18866695012837187, 0.17817945671646285, 0.21492733117120733, 0.283665951063355, 0.31113569303469013, 0.2948268076252606, 0.28044548082950893, 0.25361517359297747, 0.2815429374949733, 0.25783975022597405, 0.29601561603815263, 0.29034668717738, 0.19679896850791323, 0.22333769663743552, 0.20129704885014055, 0.23140811558683294, 0.2121356932117353, 0.23477336420798767, 0.19660604270320636, 0.21501015105671073, 0.172348628394154, 0.21279250739221867, 0.23764093542256115, 0.2654568633088795, 0.28598625631646246, 0.22004133437555318, 0.26458997328433775, 0.22885048702678146, 0.22048292053973284, 0.21795029950174039, 0.1780415499656901, 0.1882880688450116, 0.1707912286706993, 0.18761942290840694, 0.18596966733833276, 0.18228104036205206, 0.2386527251369075, 0.2710860151370078, 0.17810970558677197, 0.1844135678210278, 0.1863547891406131, 0.1864273195133076, 0.11747197294697531, 0.197784126160095, 0.14536199697789287, 0.14121755871828645, 0.578535267535867, 0.6358375313019075, 0.6051018136645642, 0.46078406269790373, 0.40681201564506053, 0.44829561351191516, 0.417716808821484, 0.1668197672673266, 0.1663360887696106, 0.3299818887894198, 0.3502627118402478, 0.18501739253238614, 0.19779285818412362, 0.19384221685336622, 0.1768534064138716, 0.18430133728088693, 0.17429328662166554, 0.1825879076296817, 0.21214562941366866, 0.17568035762661238, 0.07358422322180591, 0.11591344664429648, 0.08720330103667384, 0.08800443778906142, 0.0959509106311871, 0.0923906643647433, 0.10005525813056626, 0.08687654688567359, 0.09634074959131345]}, "mutation_prompt": null}
{"id": "8e3fd1e9-f742-41d4-bebd-e7da57a298e3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.convergence_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 - self.convergence_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget)) * (1 - self.convergence_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined strategy to adaptively adjust cooling rate and mutation rate based on the convergence progress.", "configspace": "", "generation": 82, "fitness": 0.21934556969936536, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4587200087745177, 0.46784936728501836, 0.4730392663245042, 0.42677796297580517, 0.45203129067087977, 0.4624612720889313, 0.47368313630543835, 0.4376593471443956, 0.4586422305049249, 0.002044047311858588, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006674561515600197, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14297567647084342, 0.11982108163338157, 0.07369613060906699, 0.08410912279244198, 0.09793825434910175, 0.08540876216401105, 0.14263328087413174, 0.1124601947420435, 0.10270986742118693, 0.08441454338660037, 0.09282037559124168, 0.10610389269737719, 0.08273051300959, 0.07805047150187494, 0.09134012676501913, 0.09909559351439623, 0.08678405523599886, 0.08802528697557754, 0.9224273159740654, 0.9463388479092292, 0.9134706027182163, 0.901257042314677, 0.8861369242513981, 0.8698726047050792, 0.9173669992820395, 0.928754699972948, 0.9238854322089433, 0.26257754546661105, 0.24222923299629506, 0.27874528861959, 0.2491644964524976, 0.26627983538643907, 0.2578844568875952, 0.22327763611669416, 0.25026261632223656, 0.26778707999467566, 0.3009225259308719, 0.37639710576256624, 0.2788061585835233, 0.265762998757189, 0.7212334048396007, 0.23355472950863432, 0.21822159755231085, 0.2966280973899237, 0.2697021688993133, 0.13756349081752484, 0.11958095259711155, 0.12022418161026271, 0.09717346237183233, 0.20268604014086145, 0.18935480211772882, 0.1556555708489732, 0.1841175084694182, 0.12764328140460623, 0.1627577763649708, 0.1455796282018451, 0.1234250384386325, 0.14081114663171468, 0.1285574461511798, 0.13809449923126127, 0.18208166950470162, 0.1315197102195449, 0.14563509117072226, 9.999999999998899e-05, 9.999999999998899e-05, 0.014681623845280045, 0.023119435423395562, 9.999999999998899e-05, 9.999999999998899e-05, 0.0052786705158065494, 9.999999999998899e-05, 0.03481183554536438, 0.12626085653277608, 0.055997166470242665, 0.1085849769015913, 0.06115342549783853, 0.09014329190641568, 0.03654544770901247, 0.1736048964313972, 0.10283248286311697, 0.07221952439516821, 0.0065394037401994565, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0033825796976277855, 9.999999999998899e-05, 0.129946090740249, 0.1049969010904862, 0.11916510241163247, 0.0955658867162017, 0.13083356610221342, 0.07037129231841022, 0.10479028233649534, 0.10784130282634474, 0.09143443439732601, 0.4345405667044, 0.4126874603351478, 0.43233732666818014, 0.3836503958438595, 0.3977862508492773, 0.3827508284454474, 0.40771739744257507, 0.41447387820917325, 0.39120392459526176, 0.10788966412374079, 0.10696873112498329, 0.08906563724470795, 0.08032216205532827, 0.08749048696651385, 0.11449167907042013, 0.09742037467400333, 0.1110654733337535, 0.10747935896676297, 0.250478896609318, 0.2823872551932102, 0.14688826857373682, 0.18996988326277808, 0.16456224593016944, 0.1778393220587806, 0.16301398535754819, 0.11641594725560112, 0.19774206906678526, 0.2953141351390406, 0.31440935501169653, 0.28741438373554073, 0.31510592802847737, 0.2899447185572067, 0.28056839291866864, 0.2413565420554421, 0.29059124717995666, 0.2887894936979898, 0.20386751633657085, 0.22047918636001473, 0.21520599986927114, 0.2782886446887828, 0.21897748831661656, 0.1998702451618143, 0.17955178536173722, 0.2170426769673115, 0.16385669145247572, 0.24633618199027385, 0.25568393378604914, 0.2444452426088548, 0.2501215098940892, 0.23279180218428586, 0.2308762984618734, 0.22794542267377937, 0.24893137118777486, 0.21391807636567128, 0.1806623483516574, 0.18367451726126205, 0.18925728036525968, 0.20449596591059638, 0.19992005948667824, 0.18203909362928972, 0.26249258093200534, 0.25370925944372746, 0.17754502597675015, 0.18532151400921126, 0.18634199971244902, 0.631622032742261, 0.15857683721728866, 0.1982205413827972, 0.1929263434894135, 0.14148277304871826, 0.6470262241720945, 0.5656480543351518, 0.5673479449332126, 0.4300097469208094, 0.36846480418711625, 0.4408365814743038, 0.3355610232683923, 0.1657355411420267, 0.36696073515668226, 0.33517333729959886, 0.40925945777655137, 0.1749468720148556, 0.1717188377523542, 0.1866140251446985, 0.18924236698767738, 0.17750578028714992, 0.16992206073174565, 0.19129285529008644, 0.21214562941366866, 0.17389671384485228, 0.07641213668809665, 0.10334197584644822, 0.07929675614944831, 0.0910586096998659, 0.09469927908802966, 0.08515125297047266, 0.08820800929535821, 0.09241949560357499, 0.09602609653009153]}, "mutation_prompt": null}
{"id": "b7bc2bd0-8996-48fc-b940-83d123fe1100", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.quantum_tunneling_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Quantum tunneling effect\n                if np.random.rand() < self.quantum_tunneling_rate:\n                    self.particles[i] = self.quantum_tunneling(self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, and a novel \"Quantum Tunneling Effect\" to improve exploration.", "configspace": "", "generation": 83, "fitness": 0.21068493718027476, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.44870870493975845, 0.45553874079757317, 0.4517080332714155, 0.4377849502589741, 0.45771342227911804, 0.4346574854837396, 0.4553304470930296, 0.4180754921017442, 0.447448376747025, 9.999999999998899e-05, 0.03281346991654899, 0.04603526998152008, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12297916971322942, 0.08506304375880902, 0.10809289725150506, 0.10151688383369928, 0.11502999020157045, 0.12736404853999062, 0.13081038121160726, 0.10966789430198354, 0.10179781691547596, 0.08359417671615266, 0.0976583773480092, 0.09938086597953644, 0.10118018654903249, 0.06724767446520674, 0.08357167366378837, 0.08948159710538606, 0.10008632593046152, 0.10119672288274029, 0.8951646896190834, 0.9446132984483498, 0.9199091970130329, 0.8663363684334586, 0.9155326236704517, 0.8732714371338465, 0.9223641768269388, 0.8958974520162809, 0.91500388903734, 0.26350422212951374, 0.243874478857675, 0.2339801796447002, 0.26154615573696294, 0.22940385177675637, 0.24055277894664207, 0.23451544549931236, 0.2402404490671065, 0.23861186306487492, 0.2262609223294283, 0.31548493120113386, 0.25355827189676405, 0.20525242813800115, 0.26494603483439993, 0.20336474294091667, 0.25439523494385763, 0.2383108593140002, 0.5813654346070548, 0.2187735077207974, 0.15639955122328664, 0.11865810201282279, 0.13949251176028865, 0.19253052464639964, 0.11736623569219395, 0.1835716064651064, 0.12170605348670083, 0.12326855679518556, 0.1331395219487529, 0.16165882887292626, 0.135312928475953, 0.13567555295641742, 0.1324845260854205, 0.12372532867765351, 0.16509154920596336, 0.13627292989228823, 0.1315338221987129, 9.999999999998899e-05, 0.013957936902144863, 0.02826780448087174, 0.014815731875185922, 9.999999999998899e-05, 9.999999999998899e-05, 0.0064475913336699, 9.999999999998899e-05, 0.00021430241393904925, 0.19057047769858348, 0.05403824632221654, 0.09767888112906709, 0.1260696797853934, 0.042929828087923894, 0.036059543134385974, 0.10927158635972012, 0.06235942293403751, 0.06965487964200634, 0.011238630846740816, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0025384514911820366, 0.11483118663713798, 0.11719193504359593, 0.07308999489943147, 0.10848990797128777, 0.10290209042188359, 0.0955247732158121, 0.08251685246307316, 0.06720067572074273, 0.11014459392837783, 0.4428255040334358, 0.43131836065775453, 0.42506745322924977, 0.4084824191755574, 0.41279890850414325, 0.4162726211413388, 0.41097552011224747, 0.4274010394811697, 0.40225728292451324, 0.10874884583764832, 0.11688586246526012, 0.10104813098181298, 0.13390879758996965, 0.10316072741632965, 0.11321806639718868, 0.09385767917834054, 0.12392240598476978, 0.09243696191967099, 0.1397440292139559, 0.1810396178692335, 0.1907926790103227, 0.19201149788621275, 0.17127151121098128, 0.16068836058712255, 0.14822715673118836, 0.18561072918258836, 0.19558866731733182, 0.25956147918226957, 0.23161551505268652, 0.2863990135189133, 0.2897141922082639, 0.22646112508399263, 0.26265560580615854, 0.324952550101017, 0.28372775043730203, 0.2339408018368485, 0.2587297168725984, 0.19598169506618246, 0.20560538877585022, 0.20628128732369577, 0.19973087415500113, 0.21664805158534417, 0.18683652874820367, 0.23518294649257343, 0.195949677071645, 0.2140843796323093, 0.22634488996780788, 0.2311512381888261, 0.2244427836507762, 0.235946423644657, 0.23692585691305335, 0.25096014905327113, 0.2374590528046454, 0.24077729213196497, 0.1818594211091945, 0.179696458463799, 0.18533718566713664, 0.18197506719654788, 0.20933846357539088, 0.20062808732599302, 0.17302413721093746, 0.18059011434046957, 0.19422703612634207, 0.6454942347076269, 0.18491011942557345, 0.18515410970230972, 0.17123454492859014, 0.19843165144833907, 0.1950352590490303, 0.14056487897294156, 0.4854622601916395, 0.5475423496538694, 0.44075003014631053, 0.21016524627457944, 0.41709555596860726, 0.3638669087059152, 0.16594035430913567, 0.1674826328818303, 0.16525433917695986, 0.3448188015766672, 0.3873826641339727, 0.18980116862550667, 0.19219384120043814, 0.17465209108568291, 0.1804381939780857, 0.18320503692867174, 0.17682125453649677, 0.1794573684804971, 0.18233502531323198, 0.20494772451173005, 0.11814066190430073, 0.08541861912476656, 0.07420266281785026, 0.07852809531815108, 0.1109476870020446, 0.08845618025278978, 0.09841222253237336, 0.10190940667609372, 0.10192799781394024]}, "mutation_prompt": null}
{"id": "6000d32c-aa16-46ed-b804-7e84566c134b", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < 0.18:  # Probabilistic refinement\n                    self.particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with probabilistic refinement of individual lines.", "configspace": "", "generation": 84, "fitness": 0.20003596850652047, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4577592419772837, 0.4113083701812291, 0.4333331962075566, 0.37337689177521527, 0.3840610221065177, 0.35411359454073443, 0.36087706511729634, 0.3586156486948251, 0.3834585194648563, 9.999999999998899e-05, 9.999999999998899e-05, 0.0010855359247375906, 9.999999999998899e-05, 0.0038914922683621622, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11491167939361224, 0.0802769282151985, 0.09709505151671527, 0.10218069124721896, 0.09072070428140255, 0.107875274461257, 0.08108792072379134, 0.11378243307711178, 0.07584578672235298, 0.09122014255866684, 0.08182267952381084, 0.055700532905009315, 0.08155285662162226, 0.08256345685919075, 0.09338090679179045, 0.09315611586177752, 0.09298141015993555, 0.09253394173671237, 0.897955439174579, 0.9336614780314114, 0.8713357209209074, 0.9254937177339317, 0.9242737348570456, 0.856380804135387, 0.9264375043553431, 0.9258819490915701, 0.9154433839225208, 0.23307881966223876, 0.21846984040707418, 0.20472570524953848, 0.2219003846485197, 0.24751463401159834, 0.2482148582981949, 0.20816742525672804, 0.20256642574402806, 0.20921046364271256, 0.22066251341310816, 0.2552658526457182, 0.21801787321214983, 0.26336018317617127, 0.2533139361150947, 0.3144278615782421, 0.25176749517841657, 0.23833340479301446, 0.2597917583129331, 0.1458722713653493, 0.10901769068478229, 0.1213178262821002, 0.17348629726942744, 0.12243095741023824, 0.123691743568904, 0.12451698765217223, 0.129455216254999, 0.17511164302124893, 0.12952774837810355, 0.12579074431117465, 0.1308035539403103, 0.14778617937412486, 0.14786871621571973, 0.13555680197522435, 0.15764049657671253, 0.12988766939762986, 0.11840259317209934, 9.999999999998899e-05, 0.006466754647067363, 9.999999999998899e-05, 0.007561672941404085, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0637616501110464, 0.06922266465894589, 0.12912542033530194, 0.06557561255058031, 0.06442801928801922, 0.027327658309845515, 0.09395219223212603, 0.10027060471121096, 0.11136086929680822, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08934605677863039, 0.09927281045166525, 0.07755465989627575, 0.09364406532016578, 0.093444840896584, 0.07240162961640528, 0.0752096418508037, 0.05867432463006628, 0.08198643474829037, 0.38991414309798333, 0.35209757601232683, 0.3504174113816577, 0.34419365110725497, 0.38529762940546153, 0.33217837797152394, 0.39551457807679535, 0.3762188940116603, 0.39200945421582734, 0.09600517663704, 0.11524082567069327, 0.07840976431989133, 0.09079401384615426, 0.07600703978618151, 0.1113431786276986, 0.09898417807716064, 0.10236116585121802, 0.07920273177976067, 0.21057028956965507, 0.1711319263318175, 0.13016059294464843, 0.1484574907374887, 0.14851421838398415, 0.16997043655978727, 0.13636011589960306, 0.2452018843780307, 0.1503223769371409, 0.2870169548180602, 0.2670323407549108, 0.2603305774063799, 0.2503899484605736, 0.2759602464770302, 0.27065132808237635, 0.25444141394312725, 0.2705463203281594, 0.2736181427918448, 0.196738822231586, 0.20651546720271274, 0.199814383828678, 0.22639990266135723, 0.20043856832973195, 0.23383672426499935, 0.18190798478112824, 0.20883606596664772, 0.17552488674749744, 0.22855292624686185, 0.2281054754434424, 0.22450940319224022, 0.25681868279039255, 0.20845051093289935, 0.21307575796575517, 0.20950858241329584, 0.22430852305953086, 0.2488013861102949, 0.17912833626371794, 0.17798703075491407, 0.1718582297371729, 0.17867434982181463, 0.18632699579162704, 0.1743095737767708, 0.17956438050442503, 0.18534756167687427, 0.18791239890949785, 0.6161567748817829, 0.18601507970456244, 0.18633303357248665, 0.5894234414820202, 0.5853237528125195, 0.1964122946988739, 0.1562394223551522, 0.556429223224195, 0.14823884190190384, 0.4340471472128121, 0.20659179162443286, 0.5387582628269867, 0.20229880935299394, 0.2072838832667514, 0.2405371720026177, 0.16638297363350263, 0.12657333724456543, 0.2817751714977137, 0.1977499030986829, 0.18965962588337293, 0.19454229057141437, 0.18350773440267598, 0.1770186727730454, 0.1832583843793414, 0.18602688305717652, 0.18097556005435866, 0.17511031369336183, 0.11037794421480052, 0.0773864088433045, 0.0820420716564566, 0.09874998619029374, 0.07910884392844797, 0.08794297261077921, 0.09992431880113994, 0.08718813252672153, 0.08498445273487198]}, "mutation_prompt": null}
{"id": "8672f871-8ec9-44c8-b401-9aef29b9adcf", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.refine_strategy_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def refine_strategy(self, position):\n        if np.random.rand() < self.refine_strategy_rate:\n            return position + np.random.uniform(-1, 1, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Refine strategy\n                self.particles[i] = self.refine_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a 5% probability of changing individual lines to refine its strategy.", "configspace": "", "generation": 85, "fitness": 0.20987321484347315, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.47504578802770003, 0.4504723472047827, 0.46845864171288454, 0.44888926690267417, 0.40173587100226704, 0.4458575899303866, 0.4634218939142277, 0.4255297084872677, 0.443140083753332, 9.999999999998899e-05, 0.018632286552067834, 0.0050373117651437704, 9.999999999998899e-05, 0.006162192650262854, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13763401435236933, 0.09216111664007709, 0.11236972776666276, 0.09019240220736613, 0.09754801989304218, 0.07666515482371616, 0.11552767439724632, 0.11777248359331605, 0.10233511341329504, 0.10496574159110983, 0.08789387298528506, 0.0932419326219831, 0.09115268997061465, 0.09834269594678657, 0.09064817638186728, 0.10139216901597159, 0.09880219569264281, 0.08961354350807216, 0.9196190122557217, 0.9363189347916867, 0.9058545478136444, 0.8806760787005959, 0.8569830741707158, 0.90780703624942, 0.8968587918493199, 0.9309868286217662, 0.9063033047064694, 0.24752660556810424, 0.2538575294524339, 0.2554616711570763, 0.2591241984939877, 0.24725751355798753, 0.23131230729176355, 0.22389730529992813, 0.2286081449408317, 0.23009269139315847, 0.34692298842011315, 0.644737919622795, 0.21523252670591342, 0.27120830552942854, 0.2617783485128816, 0.2615792993550642, 0.26728103593158337, 0.2216901643694037, 0.21132540389336907, 0.1618727767264978, 0.13794440199478997, 0.14673012971103128, 0.11490120220261091, 0.1407136727873376, 0.18258555817931466, 0.1516578552484964, 0.12138050658654898, 0.1346266450905248, 0.1776079029504425, 0.12431587380678266, 0.14069520474931452, 0.12731473368887491, 0.15025091933058687, 0.13047521695389264, 0.15843621622291848, 0.13244818100596856, 0.15845298966420562, 0.004726607585075371, 9.999999999998899e-05, 9.999999999998899e-05, 0.0033712412143753756, 9.999999999998899e-05, 9.999999999998899e-05, 0.003011825439623861, 0.012407298686116564, 0.013485341143446572, 0.10132042448107736, 0.06418580510283811, 0.10891401348751406, 0.10435634458152487, 0.053865414206817674, 0.02375531189733171, 0.12166885666352845, 0.053342816675722826, 0.057654609789424494, 9.999999999998899e-05, 0.009833962798487694, 9.999999999998899e-05, 0.0007452838312765886, 9.999999999998899e-05, 9.999999999998899e-05, 0.03037704769148264, 9.999999999998899e-05, 9.999999999998899e-05, 0.09258248321659646, 0.12312580834918374, 0.08470042446344528, 0.10032468059887356, 0.1181754410955882, 0.12207900590629384, 0.10013558543205459, 0.08928144563137308, 0.11391012460984862, 0.40956760330005415, 0.37901319146046175, 0.4002185243526323, 0.45689901805297917, 0.405548863678586, 0.3911166581010411, 0.394347200465055, 0.4099688285039609, 0.3798005358723977, 0.10141988901244114, 0.12554440650936283, 0.09678924220705609, 0.1169061789710708, 0.1063956805520242, 0.134055229574371, 0.09558090640241057, 0.1123591476506497, 0.08989631058427261, 0.184152133743399, 0.24709982671555886, 0.13135274224801574, 0.2153738482452362, 0.17832983620422493, 0.16462750377178303, 0.18419070086418665, 0.19330708071906522, 0.17215359663566399, 0.30771259229507897, 0.3023740773026454, 0.2814220080276757, 0.245572407761378, 0.26485336356813005, 0.27679488669133434, 0.25561923888039895, 0.27776545031587185, 0.24003456515668198, 0.1836126172823177, 0.19169142734964018, 0.22220395844366747, 0.22513661104047822, 0.18229802303302411, 0.2144373235318301, 0.1764959575736691, 0.20586374652311934, 0.1835666087499831, 0.27626522003754506, 0.24880903076768435, 0.24855822882807155, 0.20511436169742192, 0.23105493621178874, 0.22735831403562368, 0.2720014612258732, 0.2825648514217187, 0.2240943247598598, 0.17966995136657293, 0.1795504785864832, 0.17035482463925855, 0.1975883839750895, 0.19095160343284356, 0.17544745859732336, 0.17674711822479494, 0.18048705583816682, 0.17047664493595271, 0.18521890171069977, 0.1756242039833079, 0.18649137777717828, 0.1713200549935071, 0.19788222790207488, 0.2043974603689419, 0.1415588272949344, 0.6538774708703232, 0.6566356010416903, 0.480435497453816, 0.20922986299676105, 0.34555086043955596, 0.2059952352785862, 0.2029593807974056, 0.35481389592788815, 0.16713205962882616, 0.3723972193076368, 0.3933694899086747, 0.17525990219508425, 0.18332554918730792, 0.181824485350372, 0.1841788895070785, 0.1900513720508118, 0.1835308487485977, 0.18699939481173078, 0.18089448202134395, 0.17913800990158923, 0.09476221808937191, 0.10742447233528496, 0.10453372949865958, 0.0873335420879342, 0.0952788915446845, 0.08593015305627083, 0.07825184944016406, 0.08588126424380171, 0.11627146109270037]}, "mutation_prompt": null}
{"id": "16c54e92-71ac-4269-969f-f9aa81892f23", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.probability_change = 0.8  # Probability to change individual lines\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with probability change\n                if np.random.rand() < self.probability_change:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Novel Metaheuristic Algorithm using Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight.", "configspace": "", "generation": 86, "fitness": 0.20827509114562573, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.43481314980351415, 0.4399781328905241, 0.42228353382295547, 0.43862730485059975, 0.44929224278531577, 0.41557182216532595, 0.4180178836629761, 0.4230317943255558, 0.44370106209135185, 0.010842169653682121, 0.058685002440651224, 0.00990613072133728, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08433019011269716, 9.999999999998899e-05, 0.11736103051776459, 0.09822234742738767, 0.09851312534799506, 0.09304096648925841, 0.06145090830403532, 0.09928883139051325, 0.10219814815427175, 0.12396727044685862, 0.12376871810962453, 0.08741682585218391, 0.09743808341692306, 0.087470586853312, 0.10011616250886268, 0.10043816220341373, 0.09032941030962505, 0.09591469029970556, 0.07066226734139869, 0.07695215690243062, 0.8907224169884348, 0.9485402529485305, 0.873888093196985, 0.8305581555196853, 0.8799215811746454, 0.8530474954009112, 0.934131624524784, 0.9365882944375392, 0.926871093935932, 0.2645082338855841, 0.24391589574248984, 0.2850529259234559, 0.25118298323774557, 0.23580316332155538, 0.23435995043058133, 0.2463821642333538, 0.2288005372408276, 0.22054801330191864, 0.3183768019867145, 0.32046092957171834, 0.26514277461480884, 0.26634426131632005, 0.2831050582854293, 0.2528043064689246, 0.32309265466004844, 0.25932026137046615, 0.26187109966948896, 0.12273888690706758, 0.14986697896900514, 0.22388288107643717, 0.1408633897240117, 0.11174207407081738, 0.11534220436570686, 0.1378900740406318, 0.12368914897589678, 0.16011099375410198, 0.13345808262760506, 0.1464559480636901, 0.13255276207880817, 0.14040378652540075, 0.1274857690290817, 0.14167864383473316, 0.12298163189358069, 0.1271924625479025, 0.14874250329539573, 9.999999999998899e-05, 0.0044348627077397396, 0.003615681079166322, 0.008011029214588627, 0.022333754700410324, 9.999999999998899e-05, 0.0027170116262521526, 9.999999999998899e-05, 0.008074354926451033, 0.1453381141203408, 0.07435380556573512, 0.21103824792743786, 0.0636833469278335, 0.04853029205491333, 0.03895113851179499, 0.11198246277781854, 0.06818439365884954, 0.0962862266079455, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02347741909656542, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10001958466353611, 0.11773661197242635, 0.0990373169983686, 0.07587474570354502, 0.0917720035085633, 0.08641680528684115, 0.11942242942695269, 0.09424279856102913, 0.09151577881660433, 0.37827718961342716, 0.3872053120542037, 0.3962541043323533, 0.42586938344507375, 0.36806124640211446, 0.37585675783102623, 0.38716668391771614, 0.4004732177073299, 0.4420712274851001, 0.10318693147671398, 0.08042029332799261, 0.09097508800396714, 0.11083668621354936, 0.08754956732334163, 0.10197665925986843, 0.10085512954795273, 0.1276350521182532, 0.11950550613639954, 0.14902634000941983, 0.18083629877848184, 0.13834719929480377, 0.20071569312458382, 0.17811388123559224, 0.19431985104322802, 0.15797893545229957, 0.1613630568302351, 0.2442675460156064, 0.2834917853615745, 0.29041974911731283, 0.2962673648767433, 0.2993902349736358, 0.2900274891330109, 0.25952008157851947, 0.28128799672694693, 0.29276651490494476, 0.26195977996804265, 0.2066590492651963, 0.21659653836743886, 0.24134775293229482, 0.22738126224600663, 0.20001734890959877, 0.24618685402316653, 0.17042358340749575, 0.1816105752141851, 0.19269456165087806, 0.2207375356832063, 0.22915166241227813, 0.21662189099186513, 0.2544343026717548, 0.23496577918448314, 0.2096250422689695, 0.22186227138047732, 0.21429117425991973, 0.2413651353011984, 0.1927247850364241, 0.18164111153514717, 0.1997200809108154, 0.21267845447385858, 0.19828576178091428, 0.18382574962320863, 0.19322933408084775, 0.19182732837444605, 0.18344631408465062, 0.17799375553943697, 0.1860844954942118, 0.18478285337771394, 0.1698673027840426, 0.19795054586336625, 0.5409771924516755, 0.6376286420092181, 0.5934538224416928, 0.15091268160526983, 0.6561908729336754, 0.16794066820973153, 0.42083302311047954, 0.43063973145723666, 0.1654762698646164, 0.1662255858332654, 0.1662930274109241, 0.16355033610355185, 0.1653083215213894, 0.1774672460629223, 0.18212191985063042, 0.20586968241356451, 0.1817849141575737, 0.18373167498677556, 0.17474121049618785, 0.18306831026211912, 0.18606416397588477, 0.17591064407120538, 0.08532229990970752, 0.09215778685192144, 0.08307044669138974, 0.0917517247836318, 0.080083091952181, 0.07986279977604682, 0.0884945074902771, 0.09087013765524243, 0.07061135055179202]}, "mutation_prompt": null}
{"id": "0bc2eabe-dd76-4e2b-b9d9-02357064e458", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.adaptive_mutation_rate = 0.5\n        self.velocity_reset_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate * (1 - self.adaptive_mutation_rate * np.random.rand())\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                if np.random.rand() < self.velocity_reset_rate:\n                    self.velocities[i] = np.zeros(self.dim)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive mutation rate, velocity reset, and temperature cooling.", "configspace": "", "generation": 87, "fitness": 0.21481176393181528, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4915733351109929, 0.4769971789862282, 0.480030953051365, 0.4826237841694788, 0.4698927831516476, 0.502667701571447, 0.46033851479304844, 0.45042511468316615, 0.4515979451566692, 0.001513495746461202, 0.031074781959890996, 9.999999999998899e-05, 0.006177123168290222, 0.003819034120825071, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12434699748488653, 0.12053666049781131, 0.1287418462026766, 0.11283852186365606, 0.0957049061538584, 0.14198730984738162, 0.0950686673921306, 0.12652505585612728, 0.12743302850699312, 0.10345239568695364, 0.09767036807756724, 0.0986065205138138, 0.08126645116375364, 0.07163416519569177, 0.09053758872426465, 0.09598449645022489, 0.09028958751637728, 0.1111588646809869, 0.8911862099033476, 0.9436863341534255, 0.9138741139096601, 0.8602448055524127, 0.8998638934519831, 0.9151004671476534, 0.9187650423386939, 0.9045295453294797, 0.916397649680619, 0.2624219996704945, 0.26959080378387856, 0.2768549849777493, 0.24331693397083376, 0.25441929850265066, 0.2647704090684122, 0.2507417474983439, 0.2506227896317781, 0.23012327036860925, 0.46247065625070716, 0.23330119260058502, 0.4127354368536761, 0.24691982986243877, 0.2537757855984931, 0.20129789163905687, 0.17866226972725596, 0.228102994557687, 0.27849438491509393, 0.13121381416606637, 0.12674211198414254, 0.14503518059052822, 0.08707483374368985, 0.17467137699061264, 0.16211852155190354, 0.15911281962187096, 0.12166717287933593, 0.14096906418125887, 0.14276220654731675, 0.1373465485200791, 0.16114290488495586, 0.12003162310366766, 0.15472524019559064, 0.14147263978633762, 0.17693772688797504, 0.14816671955060445, 0.14553798745213298, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10360971251712636, 0.07449106366286196, 9.999999999998899e-05, 0.00034834985279708075, 9.999999999998899e-05, 9.999999999998899e-05, 0.11023556218079666, 0.053699821424328054, 0.1080549704359548, 0.08492010885345957, 0.09416565718368164, 0.03674833966109714, 0.13915919608117, 0.1005888805596793, 0.1237064008442672, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010630241251461836, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09915801477827368, 0.12801000940410834, 0.10430556086343001, 0.10306416138101815, 0.12209413245940992, 0.09075186812994629, 0.11646144730818209, 0.08402022702301004, 0.08508534802786982, 0.42526396871204264, 0.4027446620691799, 0.42216242002211046, 0.4158169397033946, 0.4129181788484857, 0.4365964506149874, 0.4573930793448586, 0.44195897605251044, 0.4406714471202442, 0.1082110450557382, 0.09967856621733773, 0.10312937679989487, 0.11051387875600505, 0.11576109952941582, 0.1472644750504163, 0.12519095525316093, 0.14112722943775602, 0.11753670221870693, 0.14521696063461553, 0.1496082869483687, 0.1334190607093747, 0.20480819475627154, 0.17859592520928513, 0.2171613210785467, 0.20056862670775555, 0.1464650710410813, 0.17570915476146187, 0.2660724657570407, 0.2846742750931236, 0.3161332648579124, 0.2605328469013988, 0.29898649467156146, 0.3201758198926624, 0.2512110007210038, 0.3095680834878223, 0.29127655125421437, 0.21569349721159792, 0.2303196075881223, 0.2595882781746044, 0.26048136288006585, 0.20452822548047322, 0.22949689506848203, 0.22532998797719106, 0.26028993114457954, 0.2030982426342769, 0.22967924692629826, 0.2596236392816462, 0.23648686891028248, 0.23261684225831591, 0.2630670028791605, 0.24373086244973907, 0.23708342061807663, 0.21570532884620697, 0.23396932773418788, 0.17762156079521718, 0.1750796431906656, 0.17205201633718048, 0.22273479733904888, 0.21293033219096846, 0.1852074858838707, 0.17897500238588604, 0.18908016680496076, 0.17375654673659247, 0.12766963249480145, 0.18464719613258374, 0.18621423575575513, 0.6757161080899823, 0.198974127136332, 0.19679058812609274, 0.14142480971040627, 0.6908169846110046, 0.5453448422908511, 0.4147649333220378, 0.2072815697819358, 0.4322180051560026, 0.164948185696274, 0.16557066771641038, 0.16619608732765045, 0.16747768350020142, 0.16520704813903342, 0.318290849211464, 0.19310137797911942, 0.20959793967656193, 0.16999963698988518, 0.18687130231201354, 0.17085206798650798, 0.17386644341440427, 0.17849047376195015, 0.1910220557029344, 0.1992143470410661, 0.08074135455997289, 0.07913531062022594, 0.10947515531658314, 0.08761477322267597, 0.09604050010449205, 0.09382103423524024, 0.09870492597376046, 0.09317543895553515, 0.09899085725122425]}, "mutation_prompt": null}
{"id": "c68c0085-b46e-4e5f-a1fe-f2220608bbde", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.probability = 0.27\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def refine_strategy(self, line):\n        if np.random.rand() < self.probability:\n            return np.random.uniform(-1, 1, size=self.dim)\n        return line\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.refine_strategy(self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim))\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined strategies using probability 27.", "configspace": "", "generation": 88, "fitness": 0.20443632826783437, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4125966060304006, 0.46658551675220483, 0.4726574758854871, 0.46239493271785637, 0.4138316382884685, 0.44794324938398566, 0.4644133830675432, 0.4275580084940338, 0.4332370638439891, 0.006604973897311184, 0.041278982433605615, 0.02405229213136939, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1321253834832371, 0.12198023597502072, 0.10527475341107873, 0.0957789751793463, 0.09990373067020719, 0.09334903094238689, 0.10071537347922566, 0.1307952845934135, 0.11025315190047136, 0.09373540526953361, 0.08978082032402812, 0.08007668562370895, 0.09772783740226876, 0.08984762610231978, 0.0816916238520804, 0.13363734986267717, 0.0740471446420442, 0.10057940110821295, 0.8990940655904222, 0.9359505492104292, 0.8868793706804093, 0.8147509883677984, 0.835142171423124, 0.8723864967139713, 0.927943982883038, 0.9248916235857868, 0.8934158916157225, 0.2642295516494678, 0.24011381188564518, 0.2506836565672409, 0.23842997408841038, 0.23725840173391988, 0.22164938668766354, 0.23950482816975927, 0.24825278584797805, 0.2523987295112905, 0.23557943601104048, 0.22277326611773374, 0.2123212941955308, 0.2711669012328042, 0.2921035182085818, 0.24565882813004125, 0.23642666163254789, 0.20711481184387348, 0.22537926451107537, 0.13469093865473136, 0.15270690891870986, 0.07769644549619459, 0.11640449694378951, 0.128755350286765, 0.1273972749330593, 0.1264879408512204, 0.13055110073509602, 0.1200491043769698, 0.12364029501365659, 0.14142316828899326, 0.14209625310440965, 0.14544365197701847, 0.1378623680818789, 0.120609997254012, 0.14573679383058258, 0.1490695552691732, 0.14184243422333842, 0.061238969575575175, 9.999999999998899e-05, 9.999999999998899e-05, 0.005865926404424626, 9.999999999998899e-05, 9.999999999998899e-05, 0.004844324940463052, 9.999999999998899e-05, 0.0020028515165063654, 0.11807208092126475, 0.07513057621961583, 0.10050607468530037, 0.08851607414320006, 0.08332445553144752, 0.05282031436182566, 0.09631141533867171, 0.0945897339105739, 0.09585597283392311, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0008076085070375383, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1064999680194545, 0.12424579534412916, 0.09371145671641501, 0.12748058875576285, 0.11278579803630873, 0.11823915449091926, 0.09763460880644803, 0.11431715592389824, 0.08783672961336575, 0.3953189132105486, 0.39320651845884325, 0.38577596785020485, 0.43643054388758273, 0.4108420886554349, 0.3674730681854458, 0.394914944247692, 0.4220959747634634, 0.38496760045254486, 0.09277256763856478, 0.0964784782913024, 0.10177086984228967, 0.08751638439043219, 0.09676277792086108, 0.10090856404697457, 0.08646250059607596, 0.12412141380408082, 0.07971604023804868, 0.1446232298052581, 0.14580712811478536, 0.1419185505555799, 0.15322653892146065, 0.18016933521880352, 0.15339872574684832, 0.1647400231770989, 0.2460148264934151, 0.16387515704138078, 0.28669083203342627, 0.28249657199290434, 0.2792782055872808, 0.2533681506832942, 0.2489629796827565, 0.28120741216134915, 0.24974640920243152, 0.26381756424464375, 0.23388142541757373, 0.21388124410052778, 0.2150046095524475, 0.2141776548259663, 0.21035945475617546, 0.23623375556767756, 0.21917552094483694, 0.17547469713531705, 0.1982469977320136, 0.18918343023266948, 0.2073353482869842, 0.2109139171222093, 0.2240250666589102, 0.21615504280565345, 0.21876127131713852, 0.23029249936604512, 0.23725546650587714, 0.22797830843704492, 0.2146952145022809, 0.17445279470476982, 0.18593417575076832, 0.20350969720810907, 0.19806621098524257, 0.19135984485777213, 0.17568375986094742, 0.18505195725797963, 0.17436972778471882, 0.17430479413529065, 0.1812246842744114, 0.18577286402879145, 0.18225381280498754, 0.6130003531223289, 0.1983157725391802, 0.1914232301033909, 0.13924879776103938, 0.5305691056589863, 0.5261401379850845, 0.5109634449553593, 0.16787267808351458, 0.357757808623859, 0.4406110252607326, 0.16621387949649657, 0.2022382881611523, 0.16504650870356874, 0.3172100000911301, 0.32854376821930587, 0.19111217953161608, 0.1731651877212702, 0.19496991393481777, 0.17769760808021806, 0.1824881927274209, 0.1798239416266375, 0.18039445611708338, 0.17304016276658563, 0.18088644901058326, 0.09760495954539361, 0.0842308482299835, 0.0854829134625037, 0.07002606498886976, 0.09523954530463596, 0.09215691135389703, 0.09074563043855555, 0.08623880605932277, 0.10294033244450129]}, "mutation_prompt": null}
{"id": "a7bce3a6-e230-4d41-ad88-d5aa07dd109a", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.dynamic_mutation_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Adaptive velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate * (1 - evaluations / self.budget):\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1 * (1 - evaluations / self.budget):\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Dynamic mutation rate\n                self.mutation_rate = self.dynamic_mutation_rate * (1 - evaluations / self.budget)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate:\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive velocity update, dynamic mutation rate, and simulated annealing.", "configspace": "", "generation": 89, "fitness": 0.20707786792627988, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.45354117785553805, 0.42773730226619955, 0.4120848706408655, 0.45486521850412465, 0.40676288158491547, 0.40177786709123564, 0.47340265722950803, 0.44700543653033054, 0.43424945441274887, 0.006806085571672504, 0.04481878221858138, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12077054461125736, 0.10320172372178682, 0.09914842623421205, 0.07770739815876093, 0.11788215017606851, 0.1080044916692754, 0.1037327856248681, 0.09969801881418283, 0.12545329816681128, 0.1141159855621352, 0.08160844574923776, 0.09411811422696881, 0.09498355105918677, 0.09361998704348584, 0.0813749851867076, 0.08897618820887221, 0.09954281902367224, 0.08336657097337974, 0.9146359326483553, 0.9255001083637899, 0.9186294484817931, 0.9209175699776488, 0.8753233321298888, 0.9055848227519704, 0.9156172852098142, 0.9052852707859753, 0.9290890744136198, 0.23889289510401046, 0.21673622761443534, 0.22112069132943912, 0.21555399279173437, 0.21304129558210894, 0.215125495987175, 0.19753827317903816, 0.19075418931284194, 0.2046553912440524, 0.3062078800897369, 0.3470769698532866, 0.2977627694856584, 0.2629992802769735, 0.5720816696048722, 0.24987759333052928, 0.3050659833536892, 0.22434948317706904, 0.22487946190239294, 0.12587782945451276, 0.13955134692692883, 0.11510603142976883, 0.09716380721600548, 0.1379571933455721, 0.1261109347162861, 0.12129991700470943, 0.12838919603432242, 0.1506771519243859, 0.14423821973780526, 0.16475421598727957, 0.15113554809578256, 0.13340236193644395, 0.13471316655458454, 0.1478816164887521, 0.14083875199807427, 0.1350832806907234, 0.12934976105079754, 0.003896198947462848, 0.013532977158830395, 0.02110650302224748, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010596908960365137, 0.0007795476306681204, 0.007435460967404661, 0.08127746191957685, 0.044369922944775264, 0.13796495012592824, 0.09139706537623404, 0.06832100204516789, 0.10985701326289032, 0.17808439599027936, 0.18816019826754649, 0.1270424698092364, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08556488017409758, 0.1418668852288918, 0.09687675349118641, 0.08188506455284095, 0.09066612121009998, 0.08009646808421544, 0.09422141334099166, 0.07782653281069163, 0.07233709106664077, 0.41411637300523396, 0.36829797201722936, 0.38393598455042344, 0.3865057883431696, 0.3986152861429506, 0.4072289938212169, 0.4085975144350773, 0.3911167259767241, 0.393219755204385, 0.07579783696366393, 0.14152778830161206, 0.09732806754160572, 0.09239546774145424, 0.11532929636641165, 0.12302408744634064, 0.10607056862533515, 0.11030310061093718, 0.09353040800783563, 0.16139941258036028, 0.1475625942997545, 0.137464210337228, 0.18384641386581224, 0.1787916710956431, 0.17212620289725122, 0.16064390466436673, 0.1662124853612078, 0.18393792645399143, 0.2855945474858087, 0.24325240427372663, 0.2695500978362201, 0.292523128546217, 0.293598882757394, 0.25850596639395673, 0.24805782704419388, 0.2809141788571692, 0.28568142834677035, 0.20920363121456154, 0.09549256188387423, 0.21535612442628194, 0.21708345396846784, 0.2183518041992335, 0.20061594063281996, 0.19246711646207126, 0.2317005573322649, 0.1776601787719263, 0.23913900263932175, 0.20503688694720923, 0.22325229839808525, 0.2128663624721101, 0.22120142889218708, 0.23914583917827137, 0.20166142186349523, 0.23529211009422835, 0.22075287579542724, 0.17177068424633923, 0.18363489995872606, 0.17722692019510033, 0.17922183788843393, 0.18722066328020726, 0.1740764344144018, 0.1795563593802192, 0.17535656439175928, 0.18474843447660638, 0.18282111470692963, 0.1840736426796613, 0.18500832196475037, 0.5512499488432829, 0.1964543953961425, 0.19186606723991795, 0.13910904375828104, 0.49475414382149585, 0.5312809207775548, 0.4032779643024681, 0.20940091652766546, 0.39263085395759656, 0.4736935277256501, 0.16587246534390832, 0.17028795257196738, 0.16552193114632496, 0.3502340304061716, 0.4510867688601463, 0.17593027928883676, 0.1996426598223322, 0.18535520022625218, 0.19028592914778053, 0.17468682749273157, 0.18274014505283853, 0.17807317880418216, 0.1949644414267524, 0.18818948640526034, 0.09221816514603831, 0.07202309212230606, 0.08456462413888455, 0.07706598020390631, 0.11063170256538035, 0.09170086835001656, 0.0826163590862734, 0.09494857995345374, 0.09360802813151081]}, "mutation_prompt": null}
{"id": "9b863b20-fafb-4713-a304-c30d94feb201", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.evaluations = 0\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        while self.evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                self.evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - self.evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (self.evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    self.evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - self.evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    self.evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if self.evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    self.evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (self.evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive cooling rate and dynamic inertia weight adjusted based on evaluations.", "configspace": "", "generation": 90, "fitness": 0.21974542838273242, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.45762677657851114, 0.4547887405068367, 0.4822846416047778, 0.496356293355791, 0.4823600517618082, 0.4443851442460154, 0.4430198494653105, 0.44306575493238254, 0.44219111042527626, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.023658774535978977, 0.0035903858081661744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1313428242566963, 0.10344561101545591, 0.10765560763854443, 0.11205713048186661, 0.10858735361718064, 0.11219359227339532, 0.12047994820146601, 0.10998009248735963, 0.10743021626828231, 0.07566761749043793, 0.09649957820621202, 0.09876313610669862, 0.08305024974709829, 0.07086371013452064, 0.08643638089146066, 0.10786883553004922, 0.09033388844252255, 0.08048507691240414, 0.9149437159038689, 0.9463388479092292, 0.9108893139050334, 0.8969920244089592, 0.8949771266263598, 0.900342531086881, 0.9275784881873064, 0.928751963941111, 0.9156287233669277, 0.22438236162804848, 0.2431545756978628, 0.22867507241762397, 0.24061744014172481, 0.25388890657227237, 0.25040796096427553, 0.2567741197202932, 0.23209236597055027, 0.23208952965423268, 0.35220025270887856, 0.5431046251169309, 0.2744909806375153, 0.2672810022949853, 0.5666546614445589, 0.20291533327205624, 0.3397529295396382, 0.2217348104734025, 0.7338215498872716, 0.12903855152518795, 0.11878137964478575, 0.12235729328988765, 0.152889014791171, 0.1920064912253483, 0.17452918282630603, 0.21746926828872026, 0.19526976092056414, 0.12875292309158792, 0.14592524986545263, 0.149530127114188, 0.1650302860818358, 0.1499739620819044, 0.12502230311497675, 0.14938892553489969, 0.1358438500250495, 0.14993199512664324, 0.17284308519457248, 9.999999999998899e-05, 9.999999999998899e-05, 0.006227293225910535, 0.034226946134634506, 9.999999999998899e-05, 9.999999999998899e-05, 0.02551479754435837, 0.00200281354491727, 9.999999999998899e-05, 0.15443389011826292, 0.04858057310156105, 0.1363355272042076, 0.06358410685854288, 0.07389972404886325, 0.01057869182613791, 0.13378630418479065, 0.08821591730754585, 0.03516416855390181, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004370259529300147, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1100712447522123, 0.1525085474856427, 0.11324935712828266, 0.0809354490299955, 0.10969495609411406, 0.08641511136833069, 0.11393964309511107, 0.10151917829269008, 0.1210082238700605, 0.46989464364462896, 0.4146576662246403, 0.4076458742401563, 0.39703224146252836, 0.404504519782962, 0.40882028672978665, 0.42604438299249026, 0.4332694131160657, 0.39659275766493884, 0.12251509030711605, 0.10515877286410158, 0.07958556353682777, 0.09126477572209846, 0.09709287034802472, 0.09619889138859106, 0.1028133245833387, 0.13811919037950815, 0.10221640256115283, 0.1370695998757563, 0.28574570608833716, 0.14348572969954754, 0.1830707328058373, 0.1986794916396375, 0.16983526522070136, 0.18866695012837187, 0.17817945671646285, 0.21492733117120733, 0.283665951063355, 0.31113569303469013, 0.2948268076252606, 0.28044548082950893, 0.25361517359297747, 0.2815429374949733, 0.25783975022597405, 0.29601561603815263, 0.29034668717738, 0.19679896850791323, 0.22333769663743552, 0.20129704885014055, 0.23140811558683294, 0.2121356932117353, 0.23477336420798767, 0.19660604270320636, 0.21501015105671073, 0.172348628394154, 0.21279250739221867, 0.23764093542256115, 0.2654568633088795, 0.28598625631646246, 0.22004133437555318, 0.26458997328433775, 0.22885048702678146, 0.22048292053973284, 0.21795029950174039, 0.1780415499656901, 0.1882880688450116, 0.1707912286706993, 0.18761942290840694, 0.18596966733833276, 0.18228104036205206, 0.2386527251369075, 0.2710860151370078, 0.17810970558677197, 0.1844135678210278, 0.1863547891406131, 0.1864273195133076, 0.11747197294697531, 0.197784126160095, 0.14536199697789287, 0.14121755871828645, 0.578535267535867, 0.6358375313019075, 0.6051018136645642, 0.46078406269790373, 0.40681201564506053, 0.44829561351191516, 0.417716808821484, 0.1668197672673266, 0.1663360887696106, 0.3299818887894198, 0.3502627118402478, 0.18501739253238614, 0.19779285818412362, 0.19384221685336622, 0.1768534064138716, 0.18430133728088693, 0.17429328662166554, 0.1825879076296817, 0.21214562941366866, 0.17568035762661238, 0.07358422322180591, 0.11591344664429648, 0.08720330103667384, 0.08800443778906142, 0.0959509106311871, 0.0923906643647433, 0.10005525813056626, 0.08687654688567359, 0.09634074959131345]}, "mutation_prompt": null}
{"id": "1b0d0dc4-949f-4e17-9bce-4e2a8fc81dbf", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.cauchy_gaussian_perturbation_rate = 0.05\n        self.simulated_annealing_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def cauchy_gaussian_perturbation(self, position):\n        cauchy_perturbation = self.cauchy_mutation(position)\n        gaussian_perturbation = self.gaussian_perturbation(cauchy_perturbation)\n        return gaussian_perturbation\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy-Gaussian perturbation\n                if np.random.rand() < self.cauchy_gaussian_perturbation_rate:\n                    cauchy_gaussian_perturbation_position = self.cauchy_gaussian_perturbation(self.particles[i])\n                    cauchy_gaussian_perturbation_fitness = func(cauchy_gaussian_perturbation_position)\n                    evaluations += 1\n                    if cauchy_gaussian_perturbation_fitness < fitness:\n                        self.particles[i] = cauchy_gaussian_perturbation_position\n                        self.best_fitness[i] = cauchy_gaussian_perturbation_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], cauchy_gaussian_perturbation_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Simulated annealing\n                if np.random.rand() < self.simulated_annealing_rate:\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < fitness or np.random.rand() < np.exp((fitness - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a novel \"Cauchy-Gaussian Perturbation\" and \"Simulated Annealing\" techniques.", "configspace": "", "generation": 91, "fitness": 0.2132467428563564, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.449514024108436, 0.44114470717111054, 0.4539098308264291, 0.43815173089135984, 0.4211892808726524, 0.45107957580046487, 0.4332485508097036, 0.43917503699075855, 0.4458153682904784, 9.999999999998899e-05, 0.03765454649800215, 0.03490231942956523, 9.999999999998899e-05, 0.019939868955376694, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1424806552189155, 0.09345747684782979, 0.10610956338606625, 0.11114779918996465, 0.1275505022113108, 0.0950253531178088, 0.10724565452549484, 0.11752411696091625, 0.1088772511257341, 0.07935093063813514, 0.09899786179662862, 0.0974633167297716, 0.10114911245286262, 0.09206760723445695, 0.06301945262142361, 0.1025140590130964, 0.08268210221249683, 0.1023052310779522, 0.8776741032592402, 0.9430468159608727, 0.8848135507684235, 0.8496502405138722, 0.8950638778871348, 0.8569349993616783, 0.9258367113801158, 0.9233907448796312, 0.9143874653926911, 0.2493378276009358, 0.24036786255877596, 0.24898043945006, 0.2617315107750694, 0.23482514153977208, 0.22632422991573764, 0.22426542224814394, 0.24764079026786145, 0.21914773456486591, 0.22766310197622697, 0.7265816221170807, 0.23440410708823112, 0.24937561998040958, 0.32193813312422315, 0.2057512040773244, 0.2521527083132029, 0.22196956479866958, 0.336235004266055, 0.10113766366054622, 0.1927641948749076, 0.1174747671377907, 0.14340148819434162, 0.1344216897864977, 0.1497252496175865, 0.1267235170986587, 0.12090374974713558, 0.14520131644908219, 0.1606566415282048, 0.15664984546304406, 0.15512897431620964, 0.1304233231914288, 0.15612952084084386, 0.13705263488914787, 0.14768004720095518, 0.15125884864671757, 0.11549416412353752, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.017652269462828385, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015123819641493785, 9.999999999998899e-05, 9.999999999998899e-05, 0.06206763547145855, 0.043889619949067704, 0.12862688600940053, 0.07082488371682427, 0.062280555604940835, 0.042871969428770695, 0.2144603220100657, 0.07463411962288047, 0.07060326954029861, 0.0009202297621886402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0071788467467713835, 9.999999999998899e-05, 0.10282533434313046, 0.10539102694164926, 0.09758015855220259, 0.09023641507902047, 0.11170095339893049, 0.11660978924826326, 0.0807067585565222, 0.07548115230011476, 0.07155301754631327, 0.4161339896764531, 0.42140613588618236, 0.4182624694799263, 0.40540975573562665, 0.4107444659247351, 0.4105931296382067, 0.4438767577488587, 0.41644288384223616, 0.3883878071822744, 0.07181204016884946, 0.11616751443826812, 0.09080339644556246, 0.11332377705447039, 0.09579236219321663, 0.1060479972480014, 0.13405863479592606, 0.10715701733036609, 0.09641750164469809, 0.14862732376602128, 0.18564484721408203, 0.17630734683425453, 0.21192044565084012, 0.1817530978710168, 0.19256168676232688, 0.20925582128906717, 0.1670955187247518, 0.18733216733799662, 0.29213237980578954, 0.2843722509714621, 0.30692776702383284, 0.31305951086563033, 0.3036654130013612, 0.3012784817198497, 0.25684810898329546, 0.3201101077015355, 0.2113809025167569, 0.24286122321121806, 0.21142090937934144, 0.20279412513662276, 0.21719395808384712, 0.22404030200758918, 0.20088598886650466, 0.20510665498907943, 0.22542564573551194, 0.19406574871557858, 0.2562439700095258, 0.2509601879843414, 0.22726156043831625, 0.2538048088290541, 0.23224999953659353, 0.22265096817700802, 0.22913758084227198, 0.2451621637638115, 0.2096948915335396, 0.1719079460480607, 0.18195651079924635, 0.18527929575968427, 0.17965171413217262, 0.18047464880795794, 0.18881130708446758, 0.18709546888601591, 0.22293122940421362, 0.18757432124871998, 0.18469227801626542, 0.1858591537990808, 0.1868980868505935, 0.4718123623493986, 0.19802176584627806, 0.19409122181898852, 0.14086103053810728, 0.6792891480027599, 0.6469721108303472, 0.6322531515579533, 0.16792688053606575, 0.3874441805959117, 0.33426973453157094, 0.4506728757108567, 0.16793016221626744, 0.16774314085656772, 0.304106783268402, 0.2949016978670769, 0.19211881006952214, 0.17530038721856023, 0.17396156080761105, 0.1840785248870188, 0.1850311032103228, 0.1791536673042754, 0.18480836263742362, 0.1897974129347284, 0.17303089371369695, 0.09830880117079555, 0.10052785464940539, 0.10316821008719834, 0.09009105354061153, 0.08927337125166324, 0.09196789385473425, 0.10197222781562543, 0.0992963176694811, 0.11589164197985335]}, "mutation_prompt": null}
{"id": "3be5a82d-6c51-460c-9e79-3127ae90cb18", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.12  # refined mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined adaptive cooling rate, dynamic opposition-based learning rate, and mutation rate.", "configspace": "", "generation": 92, "fitness": 0.2101497623843285, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4563585712635919, 0.44014605458422396, 0.4552018282487329, 0.4110488822804633, 0.42502548132395646, 0.44971851994397083, 0.4628731342995689, 0.4306684388590345, 0.45667501169537317, 0.0026920659567060135, 0.04768232597315969, 0.000455303761889847, 9.999999999998899e-05, 0.006748425063217156, 9.999999999998899e-05, 9.999999999998899e-05, 0.006087694342401084, 9.999999999998899e-05, 0.13067524231922312, 0.12121087689797383, 0.10491663852132493, 0.09831376633556588, 0.10083375600133548, 0.10881391438647392, 0.11812435447748826, 0.144499834189172, 0.12046637270490301, 0.08365111466312647, 0.10510746582229491, 0.12361032025739294, 0.10088554103481617, 0.09577684226328331, 0.06780694188283432, 0.11172677307451484, 0.09092014828389805, 0.08086516414211198, 0.9146263990346154, 0.9487803089706798, 0.9129488885107008, 0.8814127495988044, 0.8969876444320183, 0.8989917639328254, 0.9344503676385406, 0.9235380075632963, 0.9246946917345482, 0.2649316344965781, 0.23816734808898132, 0.2583154517578712, 0.24045648257615893, 0.246006799162794, 0.2614161804233287, 0.2611559771104711, 0.2558686066950534, 0.2746651007892925, 0.24363961842069515, 0.5953713828248335, 0.3018144307189117, 0.27004379945499946, 0.3315498727866839, 0.29261307149805094, 0.2775165805060896, 0.23389315865437588, 0.23229074268613015, 0.1798246192440789, 0.14201445888967446, 0.1858390464771701, 0.1360566487780277, 0.12482911544293651, 0.12644561208119953, 0.1454738263829115, 0.1391737182943883, 0.15696478454028207, 0.15974735529124773, 0.121503369763023, 0.12434574616436878, 0.1427722131897311, 0.14320405394318936, 0.14946277992104295, 0.14932367411498293, 0.16162208366491326, 0.12422740278993583, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0035103589094013232, 9.999999999998899e-05, 0.008574763890718318, 0.12001829899289695, 0.04822606105304916, 0.11903264910112243, 0.07697426994164358, 0.06888910975437101, 0.02388798350813326, 0.140500690160002, 0.10532984318852845, 0.06522124846404731, 9.999999999998899e-05, 9.999999999998899e-05, 0.002787019184924744, 9.999999999998899e-05, 9.999999999998899e-05, 0.006327702225824905, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10864246053212723, 0.09153180151454454, 0.13231479553503211, 0.07372781160527098, 0.08946296523131458, 0.05675776195643012, 0.10592344576884882, 0.08032062699747644, 0.12362725133756847, 0.42605637480264, 0.40596905606582323, 0.40632110789379616, 0.44723862647670953, 0.4097477810936654, 0.3697313388274057, 0.4246121424894076, 0.4070035243012591, 0.4145878006070176, 0.10549870027212183, 0.12984873872355507, 0.12568977821242822, 0.11434570356293838, 0.11450194079310749, 0.0966907202466124, 0.1357107417382789, 0.09748641630795518, 0.09535405491567417, 0.18260036813299518, 0.16192252007241936, 0.16696303871825546, 0.1562565119841689, 0.17661842863972999, 0.15928759539293735, 0.18802663217024562, 0.15983755287979862, 0.19083793009081562, 0.23737078373958675, 0.29111892436287257, 0.303968401176804, 0.26453704527992117, 0.305525424886237, 0.3052245472762025, 0.27777725491131855, 0.2835473821347333, 0.25994645755643164, 0.20300197785324914, 0.2048841243178623, 0.20318955074062883, 0.22143716477211184, 0.21032816112416863, 0.23006795228574262, 0.18274474566820342, 0.24050623198337173, 0.20479676366748867, 0.2464884918756507, 0.2432732028282487, 0.20804225438072188, 0.21427624213276808, 0.2421025845174981, 0.23260634571738004, 0.22315469379591057, 0.21258589178935072, 0.2433321442273555, 0.1760348872399503, 0.19530289494810948, 0.18527867822090405, 0.19169153332474953, 0.20034377120573788, 0.17931526718650548, 0.16853423456409888, 0.1895024210352032, 0.17645892936217988, 0.18527785685715625, 0.1856839212485103, 0.18620176692483625, 0.1175360025889639, 0.19827890584277907, 0.1971895839135135, 0.14106577716917168, 0.15500490033072778, 0.5545436598454154, 0.5465163509863065, 0.2098144974357593, 0.337315554232958, 0.44594940819939255, 0.3568387859900176, 0.16673987596005024, 0.16672711492390624, 0.37155450635342324, 0.3249489206749083, 0.2014155669728347, 0.18441356675029452, 0.172222696040767, 0.19232747002081008, 0.1717781754112251, 0.185201159933975, 0.1857303144821315, 0.21896455373111678, 0.1859964683436297, 0.08325228259246287, 0.08540750773787209, 0.09886152991650143, 0.10035751830353123, 0.08751229014250317, 0.11036086117828525, 0.11254203043016309, 0.09360346773958717, 0.10621804556071779]}, "mutation_prompt": null}
{"id": "7800c5df-2b35-4a42-9272-0966de52e9b3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < 0.18:  # 18% chance to refine the individual line\n                    fitness = func(self.particles[i] + np.random.uniform(-1, 1, size=self.dim))  # Add a random perturbation\n                else:\n                    fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with probabilistic refinements.", "configspace": "", "generation": 93, "fitness": 0.20438989943666622, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4877901918247296, 0.44008232714889595, 0.32309494800331884, 0.3361084630076444, 0.44153508389583274, 0.4760796921370962, 0.4509532912551697, 0.4148616541450567, 0.43424787531113673, 9.999999999998899e-05, 0.012582631451593662, 0.005333455384748276, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10260396992563292, 0.13344763346887778, 0.0883738116261098, 0.09462411926198289, 0.1288592957005612, 0.09775081257054641, 0.09399697590465383, 0.10236881237305129, 0.10631590980108063, 0.11021467205211377, 0.0949572699632879, 0.09184631229679363, 0.12092237489333324, 0.07037519730778186, 0.09665198218506066, 0.08585342803640683, 0.08569178868033667, 0.12464369717164991, 0.9040964407425757, 0.942505694214409, 0.9154902512446571, 0.8658701538233814, 0.9048267771224896, 0.895358184924019, 0.9416566204558551, 0.9236353025419057, 0.906133980534224, 0.2290622293612431, 0.23435268855027003, 0.20112325740741366, 0.27272630247928553, 0.20703663285680463, 0.2368787058250954, 0.23507079455021196, 0.18305456902574202, 0.23047375505015621, 0.25638379332980676, 0.3222418676691672, 0.23188602683121606, 0.2578355039711754, 0.2638262989613527, 0.20520742440977469, 0.29345396322776207, 0.2986311538647618, 0.24467002068710508, 0.13688903912612327, 0.1041616617533011, 0.16023207092129665, 0.13650295044693306, 0.11955403612925675, 0.12185010702783095, 0.16539742446962225, 0.1664932205963663, 0.129279744264731, 0.12465080423109798, 0.14242763065373332, 0.13998156690281593, 0.13631117843970209, 0.13209077264636016, 0.17706880565375138, 0.1480021868150294, 0.136104030690674, 0.10715787626189432, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001036551759140969, 0.00017999391031442435, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15728647616098657, 0.04614527455088613, 0.11731508807130286, 0.06214485904115152, 0.04741270881397852, 0.05165018948215094, 0.12078172837413881, 0.09383102024466061, 0.12018983562465602, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0061359662881373955, 9.999999999998899e-05, 9.999999999998899e-05, 0.00023099331385023625, 9.999999999998899e-05, 9.999999999998899e-05, 0.11424730453835819, 0.11097642383513773, 0.0878367734905009, 0.12281910932172846, 0.12320589640345281, 0.11114956274658272, 0.06589743586994012, 0.1193127508534404, 0.10226691373199015, 0.40776601119226197, 0.4199904385903741, 0.4077202053478485, 0.43006199424714364, 0.3810611393380908, 0.39471923048598634, 0.4020776069235288, 0.39108357859939535, 0.4071368260121653, 0.10760345919753567, 0.12484664961790382, 0.10345757321198656, 0.11827702359751424, 0.11368889850427755, 0.10058689460358239, 0.121012855015316, 0.10797605157733448, 0.10350494880194006, 0.18872468372571627, 0.21230378615464662, 0.13983399590382828, 0.18308846592291272, 0.19315460437117038, 0.15219285154206696, 0.16965455217465275, 0.18341508738432533, 0.1705043293579538, 0.29319774689891465, 0.27537045032556307, 0.29498897775645205, 0.26045281572418544, 0.27071237301648265, 0.30484323043727535, 0.2855546955689646, 0.2882761865669823, 0.2710204506741255, 0.20984293482261707, 0.10875776422617078, 0.22178795055123057, 0.22885733949080866, 0.20609001601377708, 0.25494490850258933, 0.21211407804745241, 0.23669899757503032, 0.18508113164058582, 0.22728347714932529, 0.25370354526355743, 0.2344401857027515, 0.23770502569196628, 0.23147862039239964, 0.21485734629882092, 0.25745111979526214, 0.22516918772259464, 0.2175631676874259, 0.17551032040057357, 0.18066210990680975, 0.19825566561840502, 0.1990762875837221, 0.1877928297106105, 0.2002662976798526, 0.17887196765878666, 0.17427439591138316, 0.16957003168828033, 0.4820281808850224, 0.18492568605362203, 0.18696863486128368, 0.15018192331976787, 0.1989214590597096, 0.19282175913643718, 0.2053301574367279, 0.552640135763484, 0.1602542709450938, 0.4591526096663995, 0.208543648963045, 0.4423125435538018, 0.3861446429930421, 0.19860718349117912, 0.16641753701974504, 0.16618221817296142, 0.16397726570389515, 0.2339336561627997, 0.19406996182873482, 0.18186739105542327, 0.18045205933424424, 0.18346256165551345, 0.1870532912100875, 0.19636743600765172, 0.1845481612641996, 0.1771492640516148, 0.18196811614732755, 0.08515797496216748, 0.10483395964706155, 0.10067102048897192, 0.09116122676847427, 0.07891113444361997, 0.08169706039224367, 0.08789991735792646, 0.08672876859539103, 0.09294405491468605]}, "mutation_prompt": null}
{"id": "660e1dde-ad0d-4c4f-a2e0-a86177d5196a", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.995  # Refined dynamic inertia weight\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined adaptive cooling rate and dynamic inertia weight.", "configspace": "", "generation": 94, "fitness": 0.21301400868940162, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4418598648973362, 0.4509998989059256, 0.47887151318225674, 0.4390862413977187, 0.4439188458484027, 0.42590327619100854, 0.41902366717514095, 0.42871297026508026, 0.4218711228089679, 0.00421933074676728, 9.999999999998899e-05, 0.0020537364273662817, 0.0019332572621917343, 0.0023707772714078867, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1286061047680661, 0.1040163441738956, 0.08815903290020832, 0.0857630314747645, 0.08935633381180763, 0.10166627700603026, 0.12346324531556474, 0.11722049391253953, 0.12501362877175126, 0.08853660548914466, 0.09878261438921476, 0.09715617121081033, 0.08184021969701427, 0.08549685540887564, 0.0890077690664135, 0.09251469647436739, 0.09458237073747422, 0.11014940058403866, 0.9164306730085428, 0.94645646864565, 0.9109293055736334, 0.9033726011935909, 0.8960693991370119, 0.9003810751967429, 0.9278355628559172, 0.9294762166290511, 0.9158495476700906, 0.2417905131980318, 0.27011923791609893, 0.25152619001688437, 0.24606318775289326, 0.2532088617533609, 0.22538931361213832, 0.2511331277653962, 0.2220392326466556, 0.2595193755294143, 0.36682014379611394, 0.3404131206759714, 0.28893544942646154, 0.24061248875017027, 0.3377946634150546, 0.23140135567877784, 0.31797107524313495, 0.18821592302778156, 0.270588927538538, 0.1325278844890354, 0.11953539488050624, 0.1271601527908819, 0.1446655497512147, 0.1959702153275532, 0.15025930636200568, 0.21624119032924105, 0.12299701409955033, 0.1558170580976157, 0.1386121489284705, 0.15159428622216053, 0.1323653782178511, 0.1635344947194004, 0.1272031847354851, 0.13526637227843696, 0.15371940948214435, 0.12495625657001697, 0.16136952640184177, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007934178188853225, 9.999999999998899e-05, 9.999999999998899e-05, 0.0027800968702266227, 9.999999999998899e-05, 0.021379500515953387, 0.13031753672554824, 0.06089044100655194, 0.14963462470010946, 0.0683241639371539, 0.08190923990022947, 0.03513728299626562, 0.1252264807993655, 0.08793133795041741, 0.11420701564501545, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01597865267319798, 9.999999999998899e-05, 9.999999999998899e-05, 0.10363428648941175, 0.11099289062459028, 0.09554789860811708, 0.09599703098558998, 0.0976874138041599, 0.09923230721418475, 0.11940240189913842, 0.09665989572643319, 0.10435856222452566, 0.4402436407316782, 0.3871399447975681, 0.42504138751043463, 0.40336975247655493, 0.3847363637303304, 0.393816148301675, 0.4068497843404958, 0.4075755782853675, 0.407859396367682, 0.12362893278538634, 0.11274103025002713, 0.09718146024626673, 0.1084948256028685, 0.11711385418187314, 0.11623675300826619, 0.10394537610649857, 0.11759690897789243, 0.09608337917816245, 0.1386824072661681, 0.3152903223211758, 0.1221601661934748, 0.2219833034458507, 0.16113650187733497, 0.1856968217291407, 0.16551990838145536, 0.16875971700260284, 0.15581115420042957, 0.29017490142896596, 0.29664355846965196, 0.2949299337123551, 0.27089261290586997, 0.29561694810946826, 0.26395934846503577, 0.2566375655113651, 0.28724965996744567, 0.26288057155394307, 0.1918169999124235, 0.20931532758591942, 0.2191087572188416, 0.21560001221714264, 0.23762468126341463, 0.2227861062000095, 0.20427025615040972, 0.21758503783823369, 0.18133314501121178, 0.22600132671965512, 0.22235273550592305, 0.24349770816263594, 0.22226891114356695, 0.2222910534573742, 0.23309475517669975, 0.2366240432025586, 0.22933032514789664, 0.22373410134701333, 0.18602944590124149, 0.18288857128844194, 0.18743773262982355, 0.1890422122591866, 0.19293232381130132, 0.19742882962920838, 0.2487526891407641, 0.21114997278915348, 0.18398918464720793, 0.18427629934715695, 0.18637276611737408, 0.18616796200682062, 0.11744460920183264, 0.19876172451750662, 0.14526413106498237, 0.14073307502619914, 0.5336021256543526, 0.5532747780982689, 0.5269560500257429, 0.44694755204577674, 0.4623628121607991, 0.43764528081292897, 0.457120947477486, 0.16679880675098102, 0.16649773876831098, 0.3770772846914391, 0.36446963355276274, 0.19837716924557414, 0.18040231059710754, 0.17771653273080534, 0.1738138518898128, 0.1816866484558165, 0.19182817277987496, 0.17795838727285807, 0.21214562941366866, 0.18294422110312347, 0.10636865104147197, 0.08806763694496644, 0.12152292849583723, 0.08180925853292087, 0.08518591450394852, 0.08076395476238107, 0.09062186190696031, 0.08592224897642409, 0.10679395776534162]}, "mutation_prompt": null}
{"id": "2e7ae215-87a8-411a-b4a2-de70292d17ad", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.refine_strategy_probability = 0.19\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def refine_strategy(self, position):\n        if np.random.rand() < self.refine_strategy_probability:\n            # 10% chance to apply a random mutation\n            if np.random.rand() < 0.1:\n                return self.cauchy_mutation(position)\n            # 30% chance to apply a random Gaussian perturbation\n            elif np.random.rand() < 0.3:\n                return self.gaussian_perturbation(position)\n            # 30% chance to apply opposition-based learning\n            elif np.random.rand() < 0.3:\n                return self.opposition_based_learning(position)\n            # 30% chance to apply velocity clustering\n            else:\n                return self.velocity_clustering(np.array([position]))[0]\n        return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Refine strategy\n                self.particles[i] = self.refine_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with 19% probability of refining its strategy.", "configspace": "", "generation": 95, "fitness": 0.20143641744793792, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.42824270414296006, 0.4254957924085, 0.4125538559054933, 0.42485769877058965, 0.42163544890223703, 0.4074074030519854, 0.4129561733164885, 0.40539594243205235, 0.41645680561645937, 0.0008122031202174584, 0.0043186000437033245, 9.999999999998899e-05, 0.0005566092415476565, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09283340470515755, 0.09297765037682981, 0.08491383533157915, 0.10670239322707764, 0.09704052002974917, 0.08583357909135081, 0.09293724357665856, 0.09744125467754838, 0.11899694662326488, 0.07702650734966954, 0.07561779571061633, 0.10289525615009476, 0.09930287377674962, 0.0877247365464171, 0.06863012051627504, 0.09914613211811751, 0.10302983080657646, 0.09235484256925319, 0.9038219919938199, 0.9361300539765807, 0.909739055346401, 0.8964251703616838, 0.9045258613911107, 0.8393761314018807, 0.9342639803885642, 0.9340360689693393, 0.919737690119812, 0.24656970644759735, 0.27953012936674715, 0.2283124565576331, 0.23558180258677885, 0.2245091166053239, 0.20090459933439275, 0.22575707202074313, 0.221025961331069, 0.21333950806481483, 0.40036623995978426, 0.22485954516254558, 0.2569046996636579, 0.20897614880683246, 0.2253568826232697, 0.24454682481054746, 0.27843055267864036, 0.17223433099328977, 0.23253349739697238, 0.12240096636201947, 0.1010653246735379, 0.12472948531941819, 0.08554974131680593, 0.1209456892337234, 0.1259502911674466, 0.1265343512784035, 0.12630125772229694, 0.13491816700289783, 0.14256814667065976, 0.13877536911905064, 0.1432328418648533, 0.14649587764364136, 0.14554872294831145, 0.15912052357857542, 0.1480911541309602, 0.15637402740389839, 0.15695838957820418, 9.999999999998899e-05, 9.999999999998899e-05, 0.002551156863777715, 0.007362541628591179, 0.01213619503949992, 9.999999999998899e-05, 9.999999999998899e-05, 0.029160317178788087, 0.024369020689967158, 0.09698415764274981, 0.059569670382905726, 0.07822795935777138, 0.07585632713762902, 0.06596035726813332, 0.06683329855503706, 0.08166837356445011, 0.06343544323615335, 0.11271361389116608, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10528739821036759, 0.11789604574058798, 0.09726782988079197, 0.11721938558047873, 0.11398576903584778, 0.05567088221839056, 0.07894231495807547, 0.10270289666468557, 0.08923416056620592, 0.3915163937892161, 0.3851360232778407, 0.39444838087310974, 0.37489296788305004, 0.3620806705625923, 0.3881257062057101, 0.40389828440215414, 0.40801407546017543, 0.4172698600147011, 0.08215425689036915, 0.11177053866372899, 0.09448082624649667, 0.12268486032097647, 0.08812693125257953, 0.09971735554522543, 0.10043920799184558, 0.10103775455519193, 0.11589077952386251, 0.2426844390489168, 0.16516161275570607, 0.13331680392699308, 0.17611926083682483, 0.17810687170129536, 0.1886791105828931, 0.1880117137927413, 0.16224899469574594, 0.16794385812834933, 0.23172654874449705, 0.25858985539654666, 0.28136405513047413, 0.2665621036237623, 0.2708297461536727, 0.2948167015224996, 0.21544184334418792, 0.2853058418790081, 0.26281345727167116, 0.21808001497204843, 0.1022644312636598, 0.17005399801833787, 0.2113152114886393, 0.20854858782805774, 0.19997933314269245, 0.1595587725482437, 0.21188122290013434, 0.16447298139719713, 0.23303183817879058, 0.23814007381306623, 0.24128191275783428, 0.2244931520786717, 0.23099177287124717, 0.2451051623221071, 0.22599693448045477, 0.24270670789252147, 0.273189839868453, 0.1778934495217076, 0.17825116579484346, 0.19223810879857317, 0.17949375842311543, 0.1876334019261715, 0.1749515537323879, 0.2625689351863091, 0.20116071158364301, 0.18275344728276854, 0.18005028886760954, 0.18576288209065228, 0.18270121761287328, 0.582319697057776, 0.1971707042508405, 0.11347272291333244, 0.1397178988798874, 0.5174200480879292, 0.49849794685828275, 0.42863721763012086, 0.20986445722733893, 0.4476235491443017, 0.4013523319704352, 0.16585871470742475, 0.16616580457280083, 0.16818011834039914, 0.28863518572150004, 0.23032217096213792, 0.1694905249800116, 0.18748987612501455, 0.16959727260088586, 0.17576435896691622, 0.18742507696476385, 0.1845078230562044, 0.18182365431959835, 0.20770773279951305, 0.1947606495723253, 0.09690791100696239, 0.0841766021980751, 0.08628962317828504, 0.08816705007220715, 0.08258038409885649, 0.10048505935088525, 0.09208713266330015, 0.0866661758476468, 0.08475745118940015]}, "mutation_prompt": null}
{"id": "f9b3d160-59a5-4b73-ab59-71f7dcdb623f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.refine_strategy_rate = 0.2\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def refine_strategy(self, line):\n        if np.random.rand() < self.refine_strategy_rate:\n            return np.random.uniform(-1, 1, size=self.dim)\n        else:\n            return line\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.refine_strategy(self.velocities[i])\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a probability of 0.2 to change the individual lines of the selected solution to refine its strategy.", "configspace": "", "generation": 96, "fitness": 0.21096676061113623, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4551164691275954, 0.4672862108322178, 0.5232927396580567, 0.44252391784927436, 0.4355398283885499, 0.45670940360712897, 0.4591803880430697, 0.4345424739043465, 0.42367965931480356, 0.017277948888190786, 0.0168890597371556, 0.01906538454654505, 9.999999999998899e-05, 0.04760832487323319, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10285786457204671, 0.11452584344283878, 0.1002876252527578, 0.09000284058892483, 0.11228155572529597, 0.12222043335993871, 0.09232617655503528, 0.11108350900324426, 0.12078749239650466, 0.09862771184009811, 0.06981925580623716, 0.0808771742837362, 0.10977745205083445, 0.0759743737377212, 0.0883982102316977, 0.08776796795967878, 0.08355782329276118, 0.10373336646211939, 0.9023474566056652, 0.9410142411643303, 0.8968282527968845, 0.8411078064963966, 0.8607742250269576, 0.9051229744791424, 0.925056992396484, 0.9005479914560618, 0.9188991774739764, 0.2563357641667827, 0.2608844833088102, 0.24471593960001825, 0.2429066837622682, 0.22173319402716618, 0.2612872607281186, 0.23098899554119767, 0.2264542393315241, 0.23976851170741997, 0.25305629755204184, 0.26157476776727695, 0.273990463610589, 0.330265982644078, 0.2398267096577923, 0.20816570507371834, 0.670014553639869, 0.33145111684533357, 0.21768757217412116, 0.1672441758838198, 0.14499874053040784, 0.1159152962680059, 0.090208948928167, 0.11955547916935017, 0.13569136535902437, 0.11973845978402131, 0.19668536338431064, 0.14466396884458643, 0.14130260705463749, 0.14935171557943672, 0.1218760449677142, 0.13271668725150176, 0.1600179126813388, 0.14586379393987703, 0.1384331144452834, 0.13536993729285518, 0.12356520252322412, 9.999999999998899e-05, 0.00010546724968441001, 0.0261721332545114, 0.048243768311840185, 0.010190121350223347, 0.0009467407844738762, 9.999999999998899e-05, 9.999999999998899e-05, 0.013263319390576345, 0.13285027977534902, 0.09919859202175174, 0.11221642064336079, 0.09161785452299698, 0.07598703978667132, 0.04983978518829679, 0.23438644644373463, 0.07264599136631911, 0.13359054504673928, 9.999999999998899e-05, 9.999999999998899e-05, 0.00016891526268736357, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00012004037985458016, 9.999999999998899e-05, 9.999999999998899e-05, 0.10651333605424684, 0.08214707317400682, 0.08832525501371025, 0.08178324505591994, 0.12082371875685805, 0.07553072318054765, 0.0799702933405031, 0.08418755906427178, 0.08141860878104012, 0.4348401630566715, 0.4130632354687799, 0.3991192294550362, 0.40159160104892466, 0.4022064121168244, 0.4048640247395149, 0.420293540412642, 0.4222918576575445, 0.3783544662777224, 0.10651610578087312, 0.1172562397639122, 0.10133071872431343, 0.07731489397120006, 0.09289896288403088, 0.13192555390893979, 0.12441853216071963, 0.13048445290701327, 0.0925032654897392, 0.1486334333167637, 0.12493073467099824, 0.16081909750134293, 0.14603351913782503, 0.15435420098212072, 0.18623624712437536, 0.13355730597891202, 0.15662458256740286, 0.18467259808765246, 0.2674475679512869, 0.2854402135991385, 0.29624482278219144, 0.291834662675327, 0.24407148353751196, 0.29009676182420474, 0.3046554416920322, 0.296521297271229, 0.26911326927041224, 0.1869426352320217, 0.1473402845608962, 0.23132048580324194, 0.20852919047989937, 0.2330044778932473, 0.2231562832883759, 0.1880541924637168, 0.22351139998366065, 0.20368362938331686, 0.2611871037547887, 0.21690551048088613, 0.22463235427326667, 0.2717209052491414, 0.2275586174636205, 0.21294335835946454, 0.2245470315371163, 0.21958590395332744, 0.23189010658985953, 0.19562144419597305, 0.1782262000930941, 0.16979804809705312, 0.20007426327236189, 0.17211535566266534, 0.18132362874701813, 0.211417228432624, 0.1734180900177389, 0.17879114810157448, 0.5833475740393275, 0.18541885796211866, 0.18584139626893992, 0.6605454560861284, 0.19717116357555076, 0.19726918207362332, 0.1407495350367901, 0.6974398808880684, 0.6277091556999126, 0.32891634737884956, 0.20657033090088706, 0.07322176904097799, 0.20403501636834642, 0.39003984588205554, 0.16506724417359164, 0.16506601982745228, 0.15991588974088933, 0.32764607864781115, 0.1844059766137207, 0.19266179672986483, 0.1869516981825614, 0.1847079662427593, 0.17132850113054066, 0.20035930787769007, 0.17520910922243405, 0.1771028598381239, 0.18257984134876915, 0.10218971387034381, 0.08293288541882216, 0.06706423712309484, 0.11299898636708572, 0.09355155342874355, 0.08444129371834075, 0.07567299707701036, 0.10209293498972205, 0.09337058461600156]}, "mutation_prompt": null}
{"id": "49053dae-eb62-492f-a22d-43d914af14b5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.probability_refine = 0.39\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.probability_refine:\n                    self.particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with probabilistic refinement of individual lines to adapt to different optimization tasks.", "configspace": "", "generation": 97, "fitness": 0.18521899274478623, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.37788938015156626, 0.3676439214535673, 0.3520388641401475, 0.3268461756047928, 0.3311572455711025, 0.3246102926305314, 0.3233388244893147, 0.3144726841298001, 0.3543019379035022, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08478803621521258, 0.09407182391381608, 0.09039748251864788, 0.08335750807436415, 0.08077736169080729, 0.0973999929563657, 0.1082771483146433, 0.11394359733817816, 0.08659180615640705, 0.0843225041344805, 0.10938448682512114, 0.08677411863211315, 0.09831595777018864, 0.09101494907052843, 0.09473787765001307, 0.08731790210687318, 0.08781614220903289, 0.08055904582012186, 0.8756813073802034, 0.9398791277076747, 0.8921891904131379, 0.8469443629712524, 0.8560239339165514, 0.8797474796884172, 0.911959453503779, 0.9334266523656076, 0.8686784812100219, 0.19743837221870286, 0.19405581321832022, 0.19448884345339545, 0.20757419730573545, 0.21082636066917537, 0.19488807147200515, 0.18662720823571477, 0.19102716956024823, 0.20191928114534408, 0.22726232987710604, 0.22162148069857524, 0.2217590441112386, 0.20718090122222343, 0.19940548983637663, 0.20594044536532896, 0.21580347831614666, 0.2199976549020637, 0.16100245527539647, 0.11951509372761715, 0.126590652301372, 0.118802065052097, 0.12448511655869132, 0.11828769615597579, 0.12424404868993022, 0.10422993766032929, 0.1098009382960996, 0.10682438873989064, 0.12823001434715386, 0.12549506071898975, 0.13004228677476692, 0.1185636132418274, 0.11676242709511664, 0.1174214142188823, 0.13976863131532902, 0.12210359159914042, 0.12071330855439188, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01431490231949395, 0.02602818503452653, 0.16070783046671455, 0.07498295763148632, 0.09535721877822612, 0.1003576499972294, 0.046488842776344574, 0.08430876018915712, 0.12115149188613727, 0.11093053040353373, 0.08306869442394615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05625362829659464, 0.057394919553226065, 0.06435283463215202, 0.06380603528658235, 0.06772344109449968, 0.026008627418514174, 0.05568947490796983, 0.06096336856207707, 0.04773442120869553, 0.33114398639918574, 0.33750369007595404, 0.3184563379202542, 0.33197083719331655, 0.3238455163148668, 0.3186123097469181, 0.37826157839764074, 0.3429083722016789, 0.33858598912840043, 0.08194299654839177, 0.09446329481502302, 0.06985979443438883, 0.0947285873726249, 0.06697505729942643, 0.09855466230270538, 0.12425413758919435, 0.11683481854875422, 0.09286460462085566, 0.1934677529213199, 0.1527036239984011, 0.13093815247446605, 0.1386629689791753, 0.1514462690545888, 0.15208725624892883, 0.12680447156740915, 0.15035161564275745, 0.13878967956749888, 0.26641733009591384, 0.2321773906003045, 0.23846942730309728, 0.2369340206796996, 0.24301222121813337, 0.26144099369737583, 0.22850831432885932, 0.2603794747804361, 0.2549419327124899, 0.19557955376931901, 0.17871493269452443, 0.18918907307683452, 0.19517155928154306, 0.19493804712530116, 0.20307181466059487, 0.18262598540887953, 0.19667713731842318, 0.1442559952501602, 0.2044129055128059, 0.20389635125605576, 0.2076549680701819, 0.2349382277680424, 0.22310585100980473, 0.2389136749237185, 0.22791793888832346, 0.22662759237949037, 0.232994521934772, 0.1961119064999245, 0.1699988195115082, 0.17497350510976417, 0.182062050298042, 0.20516342154480394, 0.1779002584492695, 0.20319903248320526, 0.17582916197970322, 0.17321728059175878, 0.18174855181148464, 0.18300219704298482, 0.18361979470941847, 0.17008115336942353, 0.3014407145547472, 0.5236093524388842, 0.14386232534124177, 0.2883983032843437, 0.4813003657515976, 0.433920529984126, 0.17156664555533696, 0.2040803523776733, 0.28835668350505916, 0.1665265251980136, 0.29610210660680614, 0.18702526964327304, 0.3035434497562063, 0.2865591583945083, 0.1831239046403702, 0.18562930186837145, 0.1763296086932019, 0.1837158689067787, 0.19219817512011173, 0.176798096868364, 0.19763290016706203, 0.2020694437859787, 0.19748146643834374, 0.09169985961369931, 0.08387646741183852, 0.09388507743621433, 0.07072228237712663, 0.09065238923103547, 0.08225639401968932, 0.07471373431338657, 0.08498601210721013, 0.09884718354704003]}, "mutation_prompt": null}
{"id": "0bde7c93-204f-4bad-b0ab-c1cae6906991", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.cauchy_mutation_rate = 0.05\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.adaptive_step_size = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.adaptive_step_size * self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            # Adaptive step-size update\n            self.adaptive_step_size *= 0.99\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive step-size and Cauchy mutation rate.", "configspace": "", "generation": 98, "fitness": 0.20255849975934664, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.17.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.463281030262674, 0.47850309002379376, 0.5133951493895983, 0.4964761164598719, 0.44298920374474415, 0.4686773691685081, 0.4353732213650432, 0.42256677289971056, 0.4643369418447425, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0017460405154230418, 9.999999999998899e-05, 0.10608134532125535, 0.09082478549566131, 0.11598578898836853, 0.09941395698288558, 0.1112919825160783, 0.11432548652863317, 0.10719959983568084, 0.12731281508635273, 0.1003814372492976, 0.1082237812605028, 0.09195687570851208, 0.0986702709167463, 0.0871981245691994, 0.0709766567801664, 0.07951855231832416, 0.084842249943611, 0.09567292334648048, 0.09450677802716267, 0.8222128863449115, 0.8922145161774978, 0.67916882546241, 0.16219478581931235, 0.7837523326229289, 0.4166287595315509, 0.8418520122889845, 0.8767661721992616, 0.8236063729836389, 0.29587695700891414, 0.26915473758216535, 0.2628797971125625, 0.269456349218968, 0.2645346790694453, 0.2641650534376636, 0.26330667671058194, 0.2558424109435655, 0.2586758145094764, 0.41453423409475376, 0.3146443485792526, 0.16877290952037072, 0.3329880843205235, 0.3943525583320868, 0.24885106322958395, 0.22295033063635505, 0.20822832607457553, 0.339835390240245, 0.12780603866767537, 0.11812055002659616, 0.11449893261584909, 0.14747514431143627, 0.2527998360881364, 0.1656625956050748, 0.24494115968109031, 0.13416976030697747, 0.1312957957165739, 0.16539268047020128, 0.15303678714346114, 0.19360010279565498, 0.15920180012218643, 0.12213814698192837, 0.13427623359298269, 0.15563146493531654, 0.1740059327530551, 0.14136712323056766, 0.0002745374115061816, 0.0021327512717577157, 0.021144464021953024, 0.06884595702145002, 0.02543042780996474, 9.999999999998899e-05, 0.007344194004856419, 9.999999999998899e-05, 0.0009239643929760399, 0.09587304546626751, 0.16455486182156764, 0.11082372199957935, 0.05854627598798001, 0.05769116090431414, 0.04333067919935307, 0.11106411495755586, 0.08105422382081362, 0.07398746356366315, 0.0030900230997192857, 0.04501579467019179, 0.019853509901576083, 0.013343603431724693, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.017595628588773837, 9.999999999998899e-05, 0.13159201746087912, 0.07956583056077526, 0.0809141005208932, 0.0733337573082905, 0.1384500082711746, 0.08446878146890413, 0.09759929019931024, 0.13799573012101862, 0.13015975967604032, 0.4306982965485078, 0.4541238111031901, 0.41026217101844187, 0.3910126904540917, 0.401260477515173, 0.4122892512738827, 0.41232873565777495, 0.4488548165014251, 0.4226716743679323, 0.11007948192557637, 0.07001559473579821, 0.06480944616955275, 0.12012531033129858, 0.06358099100882342, 0.1043253021727989, 0.12780678167076642, 0.07293315784319931, 0.10933832717635128, 0.2018725748851341, 0.16003857618809947, 0.15626721067660743, 0.16774862736288998, 0.1760060325907199, 0.19947941753942577, 0.20535408771465813, 0.23835723517869778, 0.12506617738257486, 0.2832009354948054, 0.24404139457646812, 0.28928384951252417, 0.29245693714053433, 0.3179967116971708, 0.32001323496050993, 0.23068894862433764, 0.3016622958052261, 0.2280751025039176, 0.23798758177982338, 0.09000990913598073, 0.254658667241238, 0.23400175192378103, 0.21093749224912606, 0.21735026531186374, 0.20091962476904923, 0.2223118374306572, 0.17688976477649598, 0.24524218707714374, 0.2492063399062, 0.23389592998233832, 0.22216648382809256, 0.24217032244061465, 0.2374462418747304, 0.22156363475036522, 0.25191671112259173, 0.24849826912052497, 0.17800274716733744, 0.1885082543911969, 0.17535522999750897, 0.193098727668507, 0.23009806443828762, 0.17458763596485882, 0.1999925832457149, 0.17005170041625461, 0.18742427259149685, 0.1861741102886424, 0.18597454966129612, 0.1857510117119756, 0.14387657825843803, 0.199056548652364, 0.1474136373417254, 0.12176125548785566, 0.14358651971892045, 0.5747584946215152, 0.5491610173141748, 0.48455906782986136, 0.6160572022386024, 0.16718696545819, 0.20273519101538606, 0.16525845516207793, 0.16661488414748604, 0.3371067477045332, 0.1624356585099782, 0.2022087924286553, 0.19677882728611817, 0.1790463777305773, 0.1770422323382933, 0.18231961362036486, 0.18066800687412943, 0.19381966636276704, 0.17756274994983867, 0.18438276152431177, 0.06703253971832268, 0.09670202075462364, 0.08921794664127447, 0.08540682500705299, 0.08144805122177845, 0.07952045431235588, 0.07197028447224274, 0.0941809933957738, 0.08344751676648976]}, "mutation_prompt": null}
{"id": "87a699d8-87c1-4289-b915-024a5c90ddfc", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = int(0.1 * budget)\n        self.dynamic_velocity_update_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def dynamic_velocity_update(self, velocities, best_positions, global_best_position):\n        velocity_centroids = self.velocity_clustering(velocities)\n        for i in range(self.swarm_size):\n            if np.random.rand() < self.dynamic_velocity_update_rate:\n                velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(velocities[i] - velocity_centroids, axis=1))]\n            velocities[i] = 0.5 * velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (best_positions[i] - velocities[i]) + 0.5 * (global_best_position - velocities[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n        return velocities\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Dynamic velocity update\n                self.velocities = self.dynamic_velocity_update(self.velocities, self.best_positions, self.global_best_position)\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Novel hybrid swarm optimizer with adaptive cooling, levy flight, opposition-based learning, dynamic inertia weight, self-adaptive mutation, velocity clustering, particle filtering, and archive-based position updates, incorporating a new \"Dynamic Velocity Update\" strategy and \"Adaptive Archive Size\" to further enhance convergence speed and diversity of the swarm.", "configspace": "", "generation": 99, "fitness": 0.12325951559058393, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.12 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.20848684573525067, 0.19126664186933529, 0.15589085087829657, 0.2268673927764645, 0.20755821632816318, 0.21569024737158293, 0.17194794082857856, 0.15656260575316883, 0.20255164489324728, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06728492142226183, 0.03639004572854987, 0.03150932728522271, 0.04752368283383279, 0.03074188693938462, 0.050471652047795024, 0.04684808453240419, 0.03781936359927074, 0.03675523807007253, 0.02109251351585939, 0.02052491467459272, 0.03520702461128078, 0.021627183292734276, 0.030506083668424666, 0.010588666728176377, 0.0461637925515439, 0.02256229622258432, 0.036547758074451986, 0.9648620617142483, 0.9783425260104293, 0.9535479181758939, 0.9563812799383103, 0.9325402065599189, 0.9730873369526328, 0.9692022420111277, 0.9521829441803586, 0.9457099131775374, 0.06267247986442037, 0.07395984280846257, 0.06765867730410247, 0.10992468858613069, 0.07333374466876208, 0.02853093082435676, 0.05577042487907424, 0.05016022783369112, 0.09686099586634389, 0.11638881753028563, 0.14303611158793716, 0.10649993047402329, 0.10968454541568029, 0.154274770311158, 0.08419544327787931, 0.1331930911693573, 0.0899830565458567, 0.11063620490290138, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008960034397826888, 9.999999999998899e-05, 0.015639548340945608, 9.999999999998899e-05, 0.014777303803276687, 0.04592633779757793, 0.002560025650683695, 0.0009546303849637949, 9.999999999998899e-05, 0.0021547634914562686, 9.999999999998899e-05, 0.00958933264965689, 0.005853174418439133, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04571097100496213, 0.0002678401342809389, 0.034528882657043125, 0.048605261703705605, 0.03331098653742082, 9.999999999998899e-05, 0.03191807692298221, 0.005390011622084079, 0.0361688694798169, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.19376010288017664, 0.19175173401289158, 0.23378624076957166, 0.1534392303313139, 0.14563994336649067, 0.22418671242005828, 0.18768335937935032, 0.16472124763023333, 0.16980157156825948, 0.10312863852472276, 0.03329771849580898, 0.05361563585656348, 0.047644739096340705, 0.03161192694362802, 0.06345945704621136, 0.04900287905838452, 0.03152247216999182, 0.06083282840048565, 0.14213712598495454, 0.12519313074176475, 0.13177675727429794, 0.15278902444235865, 0.13791826381003558, 0.16531837627780677, 0.15112116295458722, 0.14570293639605547, 0.18736292529275855, 0.14524078431137, 0.1444901812690832, 0.16622841140566125, 0.16512645516845748, 0.1725962485875121, 0.16167952017572773, 0.1640718158758283, 0.17906183552183264, 0.14788656716000037, 0.08821314422549964, 0.06989168002726942, 0.11724818560084316, 0.12265762377884382, 0.11763349275721335, 0.10981631304853978, 0.09288046682509177, 0.1616802027769325, 0.08804709577440517, 0.1553427059356396, 0.16413759581459542, 0.17153755002851379, 0.13383423238714898, 0.14247961119361008, 0.12589809326514845, 0.1316932610860615, 0.17110184192973488, 0.16268301032877774, 0.14231755663624557, 0.15229868263720558, 0.13699315026174919, 0.13163738473082554, 0.13436521607228735, 0.14237914393572249, 0.1353061666640195, 0.12799974929449676, 0.18910043150709133, 0.11780293561932031, 0.16245642657926163, 0.1420129810135874, 0.2251455187087047, 0.1414412934384911, 0.2044647189257628, 0.13615237039138517, 0.16446891961730215, 0.22061986781711973, 0.19062173159853568, 0.13135404004025508, 0.15284607825458518, 0.11785146302712657, 0.10987786508580999, 0.13463601056251195, 0.16250013271957575, 0.18387482618227802, 0.20806194436606207, 0.17895522594383895, 0.19883399010473635, 0.20109879593459146, 0.18598537546057492, 0.1758771646435645, 0.17587581998149815, 0.18101021600999367, 0.2139379322988254, 0.18835940906256254, 0.03648244861678651, 0.07002704963643303, 0.05147748687695508, 0.05056636279311766, 0.05257353499924833, 0.04592033781450422, 0.0587924873803749, 0.04972024583615897, 0.05208752530006555]}, "mutation_prompt": null}
{"id": "8ddc5606-c9b3-4ac7-94c8-7c7a52bd23ce", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with dynamic inertia weight\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                self.inertia_weight *= self.inertia_weight_damping_ratio\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update and dynamic inertia weight.", "configspace": "", "generation": 100, "fitness": 0.2051216711349328, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.16.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.46329942972396954, 0.49798691665948835, 0.4926102599532325, 0.4596656829502467, 0.437855804464519, 0.45180961894490557, 0.4681539445993138, 0.5002776339140841, 0.4357495444429468, 0.019397033690322307, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0043159713761294904, 9.999999999998899e-05, 9.999999999998899e-05, 0.008655377274766951, 9.999999999998899e-05, 0.14462642483967536, 0.1139884630792889, 0.08153042915323716, 0.09349482049751312, 0.11760408600229244, 0.10805770886334554, 0.10037342253722348, 0.10921412296740096, 0.09114056335314324, 0.11130614116515625, 0.09559449896250483, 0.10139045341022734, 0.09528337495468553, 0.07882381953798179, 0.07922590396303508, 0.07630560448180457, 0.07276619686381669, 0.09455481181333503, 0.7617433374853653, 0.8102009971344732, 0.6030050508628697, 0.6452249530044292, 0.6912654715620128, 0.3910161140088285, 0.6244112415319004, 0.6105280137590581, 0.6266456000842644, 0.2715953697355181, 0.30211631086637913, 0.2548719140620753, 0.2644584856617773, 0.23644155123082633, 0.26493531499931544, 0.2768599765182751, 0.20689513340953058, 0.25334622914940397, 0.291862938965723, 0.32178145905073086, 0.2545460427370019, 0.27059326027310404, 0.4398247699771899, 0.20851432939170367, 0.27041544581133814, 0.15745006992507793, 0.28629316493203827, 0.19196562807738127, 0.15531286611789996, 0.1384538655338542, 0.13737149483198063, 0.208097387223817, 0.23778707093087936, 0.2009561542708621, 0.1477334212026652, 0.13242643707823476, 0.1435309090040291, 0.17458793545193663, 0.15204620902296195, 0.15985192536858828, 0.1297463255023078, 0.15699165721172226, 0.1805573948124507, 0.14806958067436093, 0.1586007426111018, 9.999999999998899e-05, 0.015373831004270144, 9.999999999998899e-05, 0.013425900377802114, 9.999999999998899e-05, 9.999999999998899e-05, 0.03329223959882588, 9.999999999998899e-05, 9.999999999998899e-05, 0.1254172831643987, 0.07020604960895505, 0.1491349262012731, 0.0776948098913528, 0.04764010509295624, 0.010349811591110702, 0.1081799630897442, 0.06902312828557589, 0.04683994952215287, 0.020434522087920626, 9.999999999998899e-05, 9.999999999998899e-05, 0.0027561520969507924, 9.999999999998899e-05, 0.011211882629313052, 0.004437142490249735, 0.009404649506116414, 0.0006903679233452031, 0.1475289070450344, 0.12190089782250157, 0.09208040602009604, 0.12560774825676657, 0.12358729980136451, 0.09920494244819822, 0.1271681502505908, 0.11803368608013898, 0.10370080299823914, 0.39680704604371453, 0.4133202960280743, 0.4137921998900006, 0.4359674183278627, 0.3791208466677515, 0.3800393332801322, 0.47122740991293544, 0.44291777230303864, 0.40720479789050334, 0.1019458253065002, 0.06869665488298593, 0.0882956991341749, 0.10729659367864752, 0.10123349059097231, 0.13922206301653894, 0.12142228025511936, 0.10331379920127515, 0.13256145910785833, 0.19003818776234083, 0.20493644362930563, 0.17141667361471358, 0.1691223344573609, 0.18985287125295713, 0.22947223912158587, 0.18158520564676806, 0.1294311978171312, 0.16864540847921128, 0.2675998584517679, 0.29281748890965587, 0.287578011962609, 0.2874932441614012, 0.27834113277048433, 0.26582394116039176, 0.24101208079346903, 0.2674055941785165, 0.24814032628885452, 0.24885822502903943, 0.20933277529907512, 0.2054344982048104, 0.2169607443150703, 0.2551771174282268, 0.22073985930328177, 0.21653767587957085, 0.20638635989327359, 0.19297566337571004, 0.24700746024117193, 0.22737524088562033, 0.2461034814523939, 0.26492381492186734, 0.22553773457034787, 0.260165773595017, 0.236747827224133, 0.25289757489683473, 0.23167366842161174, 0.16542619849268103, 0.17423472308378718, 0.17153618386093672, 0.1686913848689634, 0.17652416412997862, 0.1726412459284713, 0.1943691219771969, 0.18375327178983136, 0.17660446322923384, 0.18482333217137592, 0.18667892845250544, 0.1869293908648234, 0.11776415196727141, 0.19825653092944118, 0.11395493854386807, 0.1405745059363287, 0.14712035124934641, 0.6640167026489578, 0.5195452274241787, 0.67162139577087, 0.4703701053094922, 0.5183639075106682, 0.3187108014745722, 0.43028140266660575, 0.16626575927306442, 0.42328320488537274, 0.3983904275233535, 0.17875085339153662, 0.19327218379379274, 0.17366992769395695, 0.1723483875048305, 0.19042478818475683, 0.17880708484468688, 0.20047732699184606, 0.21214562941366866, 0.17753516088201793, 0.10628067897748605, 0.07835468673102164, 0.10266381004584146, 0.09906370604604275, 0.10341937908156829, 0.07489261224767974, 0.09638665997902696, 0.07182032299720553, 0.08349005307958945]}, "mutation_prompt": null}
{"id": "82cd7554-eefd-4d35-8278-ac8fc762f238", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.quantum_tunneling_effect_rate = 0.05\n        self.dynamic_velocity_reset_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def quantum_tunneling_effect(self, position):\n        tunneling_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + tunneling_vector\n\n    def dynamic_velocity_reset(self, velocity):\n        reset_mask = np.random.rand(self.dim) < self.dynamic_velocity_reset_rate\n        return velocity * (1 - reset_mask) + np.random.uniform(-1, 1, size=self.dim) * reset_mask\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.velocities[i] = self.dynamic_velocity_reset(self.velocities[i])\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Quantum tunneling effect\n                if np.random.rand() < self.quantum_tunneling_effect_rate:\n                    self.particles[i] = self.quantum_tunneling_effect(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Novel metaheuristic algorithm, HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3, incorporating a new \"Quantum Tunneling Effect\" strategy and \"Dynamic Velocity Reset\" to further enhance convergence speed and diversity of the swarm.", "configspace": "", "generation": 101, "fitness": 0.20701370129856164, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4496889189081983, 0.4355172619049401, 0.4404024550621165, 0.4448536971750535, 0.40265036815376465, 0.44166206230562455, 0.43610805100881556, 0.45580205764172166, 0.45679564295337627, 0.0204112781894491, 0.0012193674228067053, 0.004042810344043191, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1184988583122989, 0.14730958311438025, 0.10313533165923872, 0.09947125316065664, 0.10175870140159027, 0.09242279149914034, 0.10708089870312709, 0.10804158361324867, 0.11910786381447014, 0.09270152661395625, 0.09295105714874374, 0.08434942233512044, 0.08686355004838808, 0.10182818300276664, 0.08301305411277715, 0.08654239930072705, 0.08642757599438555, 0.08922478850488824, 0.8971295845807937, 0.9426050482088405, 0.8841417191053825, 0.8571665782120139, 0.8682549162317935, 0.8817444261379518, 0.91392578762962, 0.9287892262006122, 0.9300666231468986, 0.2560021108726571, 0.2945179483237922, 0.2544244979291319, 0.2484836418361036, 0.24815131576295002, 0.23014526587054573, 0.22742761720869853, 0.24078168800985322, 0.24075932160980362, 0.2761113524347969, 0.2983842353321332, 0.2195106188502235, 0.2634867197045896, 0.3328671570457078, 0.311260006197816, 0.2273626229948914, 0.22005689416234397, 0.2338494743350913, 0.16192042931388517, 0.12240695832330961, 0.12586924132761235, 0.10248871886979383, 0.13047459303726705, 0.13060323115072914, 0.1535724413360382, 0.14550894965302197, 0.1375408263838146, 0.13396218497695755, 0.13325290551464675, 0.14777628589640956, 0.12499568349224488, 0.13609929750886762, 0.15708033698554913, 0.1369811520120715, 0.16104998368257661, 0.12173663754382069, 0.013971443804313477, 0.03458785424826438, 0.0007927500088741324, 0.04323723920743472, 0.008652637170741717, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0010516721615213553, 0.12230924212069494, 0.09819957079540942, 0.11731483392609787, 0.08672786642614971, 0.0471229582001893, 0.02305034992589594, 0.12344978613850055, 0.08985662054569676, 0.09732069361613138, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.001930403462474306, 0.0016680712750319904, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11854255276795533, 0.10699511527724226, 0.11791871159253897, 0.09242130733494558, 0.10526780660006352, 0.0832280835163357, 0.11419623053119554, 0.10104223638135523, 0.07881317895595297, 0.41077189632562927, 0.43144087725080293, 0.42048153488391615, 0.42440710497804024, 0.37547234731383594, 0.40315472859064416, 0.45611471814221927, 0.41794899225361926, 0.37433529264326637, 0.11013970453983402, 0.12450139406065841, 0.10377646173613342, 0.10163816455325014, 0.12148488834350335, 0.10767091252340066, 0.08922113316653724, 0.11131871499528079, 0.08325430351808771, 0.24895322910461926, 0.14567713980834507, 0.13463090744202766, 0.1894987945107528, 0.1833829433672376, 0.1840370749971012, 0.1610378229316073, 0.18246937468307756, 0.1651474457512142, 0.28168532200054486, 0.29224195953616217, 0.3042919743365502, 0.30001471981737815, 0.28238943407471884, 0.2933385568395952, 0.2873567249648299, 0.3152636629440929, 0.27486556437184284, 0.22670785923218773, 0.18966670881293968, 0.24923786948865922, 0.22794661389966853, 0.1928318186767345, 0.24812440846116823, 0.1886948760773708, 0.2198687698865348, 0.2014441679734812, 0.23057069086360515, 0.23673492898320114, 0.20898017677646352, 0.2763674652197614, 0.2217884679440576, 0.23576993306486804, 0.2564844019281878, 0.22696675811275258, 0.20094635442746567, 0.18025511316619847, 0.18741288379800924, 0.18505982732799864, 0.18320048994701288, 0.1860607344842845, 0.18240909487883694, 0.18032037911331134, 0.17361276516438373, 0.18480937727705748, 0.18593070431769188, 0.18586897504835298, 0.18571676678465032, 0.17085456690680711, 0.19671742764690603, 0.1948109165602443, 0.1217384199781536, 0.15698537183188677, 0.6213206302085543, 0.5450819602882006, 0.20652120082555103, 0.41418164282176617, 0.33322404697220454, 0.16333132120016836, 0.16643478461190975, 0.16621515130052755, 0.29002516247177346, 0.4269191624848594, 0.17599007632894026, 0.20855550033994796, 0.19625281617969692, 0.2239866354377238, 0.1899646435258313, 0.1795053447107503, 0.17569495252754008, 0.19534633506562482, 0.1730925230574738, 0.10466984407675994, 0.0843924987023944, 0.08747960652729858, 0.1092034440395162, 0.08692174095535721, 0.11427985576939359, 0.098434535088323, 0.095864198097794, 0.09588009716770374]}, "mutation_prompt": null}
{"id": "e136f89e-3d32-4c58-978d-acd7b4ec278b", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.differential_evolution_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        while r1 == r2:\n            r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        return position + 0.5 * (self.particles[r1] - self.particles[r2])\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Differential evolution for enhanced local search\n                if np.random.rand() < self.differential_evolution_rate:\n                    differential_position = self.differential_evolution(self.particles[i])\n                    differential_fitness = func(differential_position)\n                    evaluations += 1\n                    if differential_fitness < fitness:\n                        self.particles[i] = differential_position\n                        self.best_fitness[i] = differential_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], differential_fitness)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, and a new \"Differential Evolution\" strategy for enhanced local search.", "configspace": "", "generation": 102, "fitness": 0.20888521172397403, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4382156243507599, 0.4374897260574353, 0.4104421116179692, 0.46819857156558853, 0.4416952609314533, 0.4558290499696642, 0.4410264268870724, 0.426333972838826, 0.4269187337082925, 0.02806168108395035, 0.0014898172759533201, 0.028996799449581556, 0.00296270834562129, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12216611630316287, 0.08697407849794359, 0.11298346653207458, 0.09285492614053659, 0.11623182773336427, 0.11033980034778124, 0.08338079504878892, 0.12658931729998602, 0.09423508497459931, 0.09271675836297544, 0.09800782144000564, 0.08982920445853648, 0.09475833766877495, 0.08936483801418249, 0.08811677737459866, 0.08853995021963379, 0.08639608822812517, 0.08901646841944477, 0.8868181477813576, 0.9448153762708987, 0.9070377383508742, 0.9190103978166493, 0.9111756188591253, 0.8589920793529051, 0.9121612355671366, 0.9317064605772042, 0.9104308223614944, 0.26609817805946134, 0.25599694773132375, 0.2097223575888757, 0.23110333160472074, 0.24494044142174998, 0.25213193759341923, 0.22869455101612202, 0.23946566395533653, 0.23136882071046916, 0.22007092895489244, 0.23816815288825122, 0.32601365747681954, 0.24624767281066962, 0.30591756274011084, 0.22057155294159714, 0.2483494647043667, 0.33439817453537624, 0.24378099636796036, 0.1420567701570744, 0.14063143110042697, 0.12172494258962052, 0.1354074849912582, 0.1699740930113416, 0.17132851886870903, 0.1300531252829984, 0.11753687544321878, 0.12065221802172366, 0.13862911296344282, 0.14205076802414096, 0.1357129917520442, 0.1355270907256727, 0.15664847429638795, 0.13617449647455737, 0.1627629406940918, 0.13619460485639556, 0.17728345446949156, 0.0059574347234830904, 0.03494485397201519, 9.999999999998899e-05, 0.02323108066409385, 0.02777276774782056, 9.999999999998899e-05, 9.999999999998899e-05, 0.0032834367110025076, 0.00614835290278426, 0.15891683365942955, 0.054295028449742655, 0.09801893202477563, 0.08498013695220874, 0.05016623106188656, 0.026838857096495805, 0.10976031256432817, 0.09086571409226485, 0.052525273560857566, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0003100312711178388, 9.999999999998899e-05, 0.017555390165161944, 9.999999999998899e-05, 0.11143135409525817, 0.10985836908713698, 0.09900403969293425, 0.09646526740954631, 0.11321070717408743, 0.10358386541016085, 0.11623286554926904, 0.10712345158328995, 0.07709806258154206, 0.38085309422538405, 0.4079328923565054, 0.3957393273714206, 0.40313247090207205, 0.3927406099931874, 0.42297225620289736, 0.40740651688657203, 0.4222483966773334, 0.4016494280923122, 0.08383316615960212, 0.10687873605139997, 0.07439782749938417, 0.07037046580406459, 0.13179080685214684, 0.09792501453298896, 0.11061470362600434, 0.09658731602070658, 0.09027083158693783, 0.15351242755001204, 0.18242747908268975, 0.14113110258462913, 0.19052584694363472, 0.18450418814803293, 0.20031621302423364, 0.20338486584980608, 0.1888493761717217, 0.1857481653319928, 0.3184562395526047, 0.29677699205208263, 0.29037380652849265, 0.2965281935840095, 0.2782849321706049, 0.264982633958032, 0.30521137427288414, 0.24496935189926838, 0.2980875778555294, 0.25087395641323806, 0.23915646834746684, 0.22295650563354996, 0.2271187200048388, 0.20006098800425354, 0.21077971729606182, 0.17472396656654599, 0.22362284218881257, 0.1812931139263364, 0.22880601417440594, 0.22830355400720936, 0.23809783640866222, 0.22700347062056248, 0.23622869352966613, 0.2253921729787398, 0.22690709853218682, 0.20913884942895866, 0.24624696393752654, 0.1842575782173772, 0.17502484892246173, 0.1757472366323376, 0.196752862377496, 0.19346162282308155, 0.18133903148013197, 0.1840534779961479, 0.21904143976493928, 0.1822200051170585, 0.6387736717005361, 0.18407964313725078, 0.1853350886818278, 0.18834452138518987, 0.1969837829373543, 0.19269949540357956, 0.14007945243822084, 0.49109549239673167, 0.6091975074702376, 0.42254538130738706, 0.15322088572603298, 0.38917229944894793, 0.16672413889187665, 0.3863235338554435, 0.16716482723034565, 0.1651075434343776, 0.3707688044466315, 0.3552692081478894, 0.18601299075808475, 0.17872887464294673, 0.1951258694623107, 0.1802854628321109, 0.18559055996409057, 0.18439607962893423, 0.18674320271725797, 0.1754212703559066, 0.19123870639785856, 0.10185906707171566, 0.08818128840029438, 0.09157650058448175, 0.09946624052592723, 0.08336017741887825, 0.07534622960174564, 0.08611149652602856, 0.08484847430697551, 0.08522584530060773]}, "mutation_prompt": null}
{"id": "7fb27605-4e19-46c6-bf07-e9cf409ed43c", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.25\n        self.dynamic_opposition_based_learning_rate = 0.15\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined adaptive cooling and opposition-based learning rates.", "configspace": "", "generation": 103, "fitness": 0.21261450698295611, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4288739015154649, 0.44512432333517904, 0.4417526965385935, 0.4513923665736608, 0.41687343492843043, 0.456964804523469, 0.43155809903568476, 0.42580872701498074, 0.43485807869153315, 9.999999999998899e-05, 0.025970661074543044, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13388014861052966, 0.11732355224920643, 0.10572511354772318, 0.09608871726430568, 0.11179223114729753, 0.11023390658148169, 0.1017618783794394, 0.12106887226580165, 0.09940582023599931, 0.07686383905628447, 0.11894854316863024, 0.07711002421212709, 0.09307558880371403, 0.08259630998555134, 0.08715099380380831, 0.09787098838542352, 0.09284969135752996, 0.08479863456876247, 0.9124439604611155, 0.9437188706883772, 0.899336662857447, 0.8987388565797598, 0.8837806161080997, 0.8957145827435525, 0.924849015912688, 0.9255977938748586, 0.9120428217570066, 0.26887380193516597, 0.26507238581235515, 0.23842213102746912, 0.2270643800957438, 0.24422921844853507, 0.2711082710134447, 0.2507588661109358, 0.23286956575925988, 0.23603943844134012, 0.29710773290325365, 0.33643204854884534, 0.22248062425876092, 0.25622499065008675, 0.34391388983065463, 0.24574062614820846, 0.5128821526960494, 0.2643502005263664, 0.30404116974742523, 0.13678363203097033, 0.11684606184722346, 0.1284228305313847, 0.14163523024405678, 0.15459517850306637, 0.18194849198026686, 0.13426714081951374, 0.13974378490773431, 0.14026216430846705, 0.16355379646432955, 0.15473292741894895, 0.1375240511992466, 0.17005379562257172, 0.12345895286788577, 0.14400256164865877, 0.1614024562426002, 0.15124000726006637, 0.14410025605260723, 9.999999999998899e-05, 0.0003221369262260687, 9.999999999998899e-05, 0.00011822539100836416, 0.0006886187304140368, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12456997346521237, 0.0534477922003298, 0.09313295105398756, 0.09402846837960588, 0.06330570248342626, 0.02319192957903138, 0.11206205437386829, 0.07852047095419568, 0.0758395546494236, 9.999999999998899e-05, 9.999999999998899e-05, 0.010871680916703319, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0035677073548795457, 0.004988298699286298, 9.999999999998899e-05, 0.097140224525058, 0.10119068825591171, 0.10935129874689797, 0.05904545853023868, 0.11144867069455, 0.11754513666717425, 0.1401833714220564, 0.10503242786608558, 0.10190014100048594, 0.44360930444651814, 0.42570491474182093, 0.4618853457622608, 0.41933631865945087, 0.40602377906802123, 0.40349516093586213, 0.4438262409337499, 0.4173497743802467, 0.399794123242708, 0.10471277341538521, 0.0930665545951821, 0.09779949474989769, 0.09674770648241848, 0.08173468661613825, 0.09533064180849815, 0.10353959601548468, 0.0935505262049996, 0.1057990531147116, 0.15210820966033023, 0.2897756913230606, 0.12214604796516015, 0.17854730839555177, 0.18363509060201622, 0.1456754474568217, 0.18331469712383686, 0.1748990610005987, 0.1438209329618263, 0.32653486167073154, 0.26517957253970403, 0.2892924949791381, 0.27253479903386013, 0.2714977501983187, 0.28138265791989225, 0.252566998060923, 0.2923518755069313, 0.23169797713572415, 0.18309799088297884, 0.23974583912103187, 0.21193677347958317, 0.22361878844631122, 0.19274223736118024, 0.21131720702637724, 0.21011885675138298, 0.21800884119662678, 0.16085923911564026, 0.22579786681317382, 0.244372285731145, 0.25793154987680045, 0.22025587321167828, 0.24222908019792666, 0.23086599638103245, 0.20421638909422202, 0.21973993650503243, 0.24336864159240668, 0.18401961611030304, 0.18039683371661208, 0.1782989987356135, 0.1863030066488649, 0.22200686314079343, 0.20795221358526528, 0.2129865238770322, 0.18533715195151768, 0.18302351038890152, 0.18444821452887328, 0.1868805220588836, 0.18616973678310722, 0.11838712049566658, 0.19841005388619593, 0.192753766959599, 0.14086292730371608, 0.6511519370156515, 0.6191667396704434, 0.45358778443393477, 0.4659637931503753, 0.5542709189066786, 0.35797457907542807, 0.35509271821527333, 0.16657674712088788, 0.16628779221442713, 0.32871309792494885, 0.37904081109767473, 0.1894717592952374, 0.17431150284147456, 0.18249842620476497, 0.18145898462724952, 0.17676725127890835, 0.18054330220763937, 0.17889267565687772, 0.21204802014723856, 0.18670395039978727, 0.11265171684225517, 0.08842345584772904, 0.09261227710977893, 0.07786621936399174, 0.10029410686185325, 0.09393945899425926, 0.09112557079294747, 0.07886234016833371, 0.10008472458159956]}, "mutation_prompt": null}
{"id": "ef181437-dcd9-4ed0-abf8-531390688e69", "solution": "import numpy as np\n\nclass NovelSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with dynamic inertia weight\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = NovelSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "NovelSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Novel Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update and simulated annealing.", "configspace": "", "generation": 104, "fitness": 0.21974542838273242, "feedback": "The algorithm NovelSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.45762677657851114, 0.4547887405068367, 0.4822846416047778, 0.496356293355791, 0.4823600517618082, 0.4443851442460154, 0.4430198494653105, 0.44306575493238254, 0.44219111042527626, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.023658774535978977, 0.0035903858081661744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1313428242566963, 0.10344561101545591, 0.10765560763854443, 0.11205713048186661, 0.10858735361718064, 0.11219359227339532, 0.12047994820146601, 0.10998009248735963, 0.10743021626828231, 0.07566761749043793, 0.09649957820621202, 0.09876313610669862, 0.08305024974709829, 0.07086371013452064, 0.08643638089146066, 0.10786883553004922, 0.09033388844252255, 0.08048507691240414, 0.9149437159038689, 0.9463388479092292, 0.9108893139050334, 0.8969920244089592, 0.8949771266263598, 0.900342531086881, 0.9275784881873064, 0.928751963941111, 0.9156287233669277, 0.22438236162804848, 0.2431545756978628, 0.22867507241762397, 0.24061744014172481, 0.25388890657227237, 0.25040796096427553, 0.2567741197202932, 0.23209236597055027, 0.23208952965423268, 0.35220025270887856, 0.5431046251169309, 0.2744909806375153, 0.2672810022949853, 0.5666546614445589, 0.20291533327205624, 0.3397529295396382, 0.2217348104734025, 0.7338215498872716, 0.12903855152518795, 0.11878137964478575, 0.12235729328988765, 0.152889014791171, 0.1920064912253483, 0.17452918282630603, 0.21746926828872026, 0.19526976092056414, 0.12875292309158792, 0.14592524986545263, 0.149530127114188, 0.1650302860818358, 0.1499739620819044, 0.12502230311497675, 0.14938892553489969, 0.1358438500250495, 0.14993199512664324, 0.17284308519457248, 9.999999999998899e-05, 9.999999999998899e-05, 0.006227293225910535, 0.034226946134634506, 9.999999999998899e-05, 9.999999999998899e-05, 0.02551479754435837, 0.00200281354491727, 9.999999999998899e-05, 0.15443389011826292, 0.04858057310156105, 0.1363355272042076, 0.06358410685854288, 0.07389972404886325, 0.01057869182613791, 0.13378630418479065, 0.08821591730754585, 0.03516416855390181, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004370259529300147, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1100712447522123, 0.1525085474856427, 0.11324935712828266, 0.0809354490299955, 0.10969495609411406, 0.08641511136833069, 0.11393964309511107, 0.10151917829269008, 0.1210082238700605, 0.46989464364462896, 0.4146576662246403, 0.4076458742401563, 0.39703224146252836, 0.404504519782962, 0.40882028672978665, 0.42604438299249026, 0.4332694131160657, 0.39659275766493884, 0.12251509030711605, 0.10515877286410158, 0.07958556353682777, 0.09126477572209846, 0.09709287034802472, 0.09619889138859106, 0.1028133245833387, 0.13811919037950815, 0.10221640256115283, 0.1370695998757563, 0.28574570608833716, 0.14348572969954754, 0.1830707328058373, 0.1986794916396375, 0.16983526522070136, 0.18866695012837187, 0.17817945671646285, 0.21492733117120733, 0.283665951063355, 0.31113569303469013, 0.2948268076252606, 0.28044548082950893, 0.25361517359297747, 0.2815429374949733, 0.25783975022597405, 0.29601561603815263, 0.29034668717738, 0.19679896850791323, 0.22333769663743552, 0.20129704885014055, 0.23140811558683294, 0.2121356932117353, 0.23477336420798767, 0.19660604270320636, 0.21501015105671073, 0.172348628394154, 0.21279250739221867, 0.23764093542256115, 0.2654568633088795, 0.28598625631646246, 0.22004133437555318, 0.26458997328433775, 0.22885048702678146, 0.22048292053973284, 0.21795029950174039, 0.1780415499656901, 0.1882880688450116, 0.1707912286706993, 0.18761942290840694, 0.18596966733833276, 0.18228104036205206, 0.2386527251369075, 0.2710860151370078, 0.17810970558677197, 0.1844135678210278, 0.1863547891406131, 0.1864273195133076, 0.11747197294697531, 0.197784126160095, 0.14536199697789287, 0.14121755871828645, 0.578535267535867, 0.6358375313019075, 0.6051018136645642, 0.46078406269790373, 0.40681201564506053, 0.44829561351191516, 0.417716808821484, 0.1668197672673266, 0.1663360887696106, 0.3299818887894198, 0.3502627118402478, 0.18501739253238614, 0.19779285818412362, 0.19384221685336622, 0.1768534064138716, 0.18430133728088693, 0.17429328662166554, 0.1825879076296817, 0.21214562941366866, 0.17568035762661238, 0.07358422322180591, 0.11591344664429648, 0.08720330103667384, 0.08800443778906142, 0.0959509106311871, 0.0923906643647433, 0.10005525813056626, 0.08687654688567359, 0.09634074959131345]}, "mutation_prompt": null}
{"id": "c1b348a5-d59d-484c-b7b7-89c854ee8903", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                if np.random.rand() < 0.19:\n                    self.velocities[i] = 0.8 * self.velocities[i] + 0.2 * np.random.uniform(-1, 1, size=self.dim) + 0.1 * (self.best_positions[i] - self.particles[i]) + 0.1 * (self.global_best_position - self.particles[i])\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            if np.random.rand() < 0.19:\n                self.inertia_weight *= 0.95\n            else:\n                self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined strategy through probability-based modification of individual lines.", "configspace": "", "generation": 105, "fitness": 0.21168966332581743, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.442000857723053, 0.46553622541990813, 0.46787018105555755, 0.44987818631524124, 0.4587220121361718, 0.4217491257452187, 0.45751583966661513, 0.435807266742248, 0.44397297312356676, 0.011341155132223002, 0.002816763794687316, 0.015525493617120856, 9.999999999998899e-05, 0.006253703740225491, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13668187795096076, 0.12190572807140065, 0.10038721802526851, 0.08309002320109315, 0.09833423707628886, 0.09764228472571557, 0.10699191023648091, 0.10078124031177216, 0.1016837930132033, 0.0863286451320815, 0.09107665636682782, 0.07487943022921739, 0.08900568357039884, 0.08973387081543238, 0.08311240822934018, 0.09144526727261604, 0.08147010794123888, 0.09072795492381824, 0.8947900237761452, 0.9483787189739139, 0.9013497031093246, 0.8679162602782637, 0.9204667698917275, 0.8604318422183055, 0.872832891849455, 0.9331326824201385, 0.919185882816907, 0.3151100930278571, 0.26149731246853325, 0.2460192367337085, 0.24049831323217763, 0.26120861116273164, 0.2644121219397694, 0.23480233489142732, 0.24472695923088195, 0.24275309787741295, 0.2475075622171521, 0.37787053786974856, 0.22424863963325148, 0.2691633046891858, 0.32749562908723573, 0.20627576967175498, 0.21983298453132094, 0.2279602939084583, 0.22428624562834465, 0.18453152801756156, 0.11030613778530496, 0.12767351920015968, 0.12235125038911376, 0.12512977924783864, 0.12645881352415023, 0.1254581673562596, 0.14815094299204778, 0.1278223096694151, 0.15594847128119615, 0.1417960681292203, 0.11670419919751329, 0.14938997797792886, 0.1574663122373846, 0.12562835445414, 0.18187360264837604, 0.14757651758922186, 0.1263522351732721, 0.01196624601684848, 9.999999999998899e-05, 0.0017919141081221834, 0.00305437736783698, 0.0030404483918434755, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007050372713296227, 0.07204263670058242, 0.034984031187253684, 0.06823902268556414, 0.055254553209101, 0.06431714815756118, 0.0378383693108606, 0.10699195355457047, 0.06354049492492453, 0.1257906914513669, 9.999999999998899e-05, 0.002234716816249205, 0.056972609682017894, 0.008750720219452002, 9.999999999998899e-05, 0.00343258109738942, 0.0079911131149496, 9.999999999998899e-05, 0.00126118588701285, 0.11465591565588906, 0.1178359873382595, 0.1261690905263415, 0.12557011328614098, 0.10853516751976078, 0.10164844686864383, 0.12496833878823876, 0.07383221797627215, 0.09677576761540585, 0.40353117667009086, 0.400217048416587, 0.41460288431569026, 0.39491943133525376, 0.4072206133007342, 0.420493358814503, 0.4382594203991764, 0.4079961356892864, 0.4048599701157277, 0.09927709976383481, 0.12015154886292767, 0.07818489517267913, 0.09954837612571388, 0.12842256603540902, 0.12497538047372203, 0.13257692798502207, 0.08027596033073947, 0.08738822214506092, 0.2035546585052258, 0.14539761127379747, 0.1336002397114413, 0.19290147158774318, 0.1730910834406426, 0.19842991851970238, 0.1661656810916744, 0.17701671952820675, 0.17982941025406907, 0.2626970718255027, 0.2910305262363657, 0.3069086658470902, 0.3002868083912831, 0.2803851533374463, 0.2788688534087952, 0.2647137466550309, 0.27384480194285366, 0.22735095226169655, 0.18387009626480133, 0.22333787867988653, 0.24323418188776103, 0.24109866278018777, 0.1974222596302886, 0.23305936805101268, 0.20756918278467906, 0.22727400318521762, 0.1875880024780664, 0.23599158021302424, 0.23343906774399448, 0.22207689052624324, 0.23222658735718915, 0.22061154252068216, 0.19906810099528982, 0.2479874942447967, 0.2745682116443805, 0.21710100690255107, 0.21217578366439782, 0.1874239286249395, 0.2105532648893661, 0.24348341607553636, 0.19297645824120924, 0.18936947954864336, 0.1935903064897564, 0.1791654697594347, 0.19258082380068253, 0.1845913285292745, 0.18582062610093064, 0.5835838117724161, 0.6387676060302154, 0.1977914103150491, 0.1957849095592964, 0.12184149751785478, 0.15121836129437471, 0.6376156641264299, 0.4958987553871411, 0.16802397553632764, 0.3874610117316589, 0.4453424661373837, 0.291528333560081, 0.34182042288719305, 0.16916152840668897, 0.3144941368358133, 0.38268374005174044, 0.18801400121892076, 0.20951533946402, 0.18795464825351316, 0.1977270590399759, 0.1882292362340401, 0.1790360172386647, 0.18244073776255587, 0.19335542142124662, 0.19085541007607798, 0.08742052062564709, 0.08202214807899821, 0.08154406353586052, 0.0873395099753812, 0.07594845049271592, 0.0925969200162231, 0.10140261033556475, 0.09702519010726696, 0.09451660648329907]}, "mutation_prompt": null}
{"id": "d96132d8-9dc9-4e9d-8b10-5f30e30ffba7", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.adaptive_mutation_rate = 0.5\n        self.adaptive_perturbation_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate * (1 - self.adaptive_mutation_rate * np.random.rand())\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1 * (1 - self.adaptive_perturbation_rate * np.random.rand()), size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive mutation and perturbation rates, and a modified simulated annealing schedule.", "configspace": "", "generation": 106, "fitness": 0.2130456481280165, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4483079231180752, 0.45636628844862803, 0.4818294193667463, 0.44404746218464286, 0.4341099190643052, 0.4044570953257708, 0.4822042324613147, 0.42861762743145326, 0.43821510743821346, 0.0004266111419497509, 0.03273006851121718, 0.011868922623704425, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09719656859097126, 0.10185359480974654, 0.11267399598573469, 0.09222948977557122, 0.08861899521021732, 0.07676307800660453, 0.08377870591105507, 0.190390386392842, 0.10499694866513021, 0.08691091648569949, 0.12289939705927588, 0.09350028029281898, 0.0917567592617301, 0.09575610120209543, 0.08276081772682953, 0.09179163094970533, 0.09797121152862132, 0.09447244148811018, 0.9146141391894999, 0.953135589708724, 0.8907198324174177, 0.8700439424608601, 0.8973807011563721, 0.8664253720121471, 0.9370358910700188, 0.9173887124373821, 0.9210891593442389, 0.24903518390453128, 0.2626463263277806, 0.24593780984369673, 0.2705685380208357, 0.26819113409582473, 0.24198594762983816, 0.2339788876921518, 0.22777148886775933, 0.2623800811014626, 0.3572667781893081, 0.24235870410206317, 0.2859891001868997, 0.251828162864729, 0.26879423614597187, 0.23173011912773167, 0.23591074714670113, 0.21426585516892604, 0.2847825589938817, 0.14634424062433538, 0.12300426416329935, 0.12234378873959051, 0.15034443652918306, 0.23518943698150152, 0.15773947176884262, 0.19258533436297642, 0.12998899847901613, 0.1252786746847172, 0.1783292654522617, 0.13301926329742042, 0.1341279059712711, 0.1522347704958813, 0.17184809983403904, 0.1397492756166121, 0.15750830322126907, 0.15424734251311256, 0.16177517778754702, 9.999999999998899e-05, 0.02938919187360367, 9.999999999998899e-05, 0.0037765870572987748, 9.999999999998899e-05, 9.999999999998899e-05, 0.000268531651219428, 9.999999999998899e-05, 0.0236772599067413, 0.12249337861547116, 0.053303967196881796, 0.10716043306424983, 0.158034648168783, 0.07272387148635429, 0.02030552149095166, 0.15290201682651583, 0.11701036461000636, 0.039087181049359376, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11986926570859269, 0.09861460355784624, 0.10960881855933435, 0.11317758231591635, 0.0996665809353422, 0.08449622422576286, 0.08375099978590006, 0.07913488247491585, 0.08042435971031059, 0.4489762242739014, 0.4290266379405231, 0.41602001680574985, 0.4354731123974491, 0.4167189777633713, 0.40305390289521303, 0.42668328935278077, 0.43047307398663515, 0.41966585185279515, 0.10934035329155845, 0.10173451341797923, 0.11250369987674169, 0.09836294299590886, 0.1440569947545557, 0.13304416250615891, 0.0897039124640372, 0.11417538482803424, 0.10122491107593834, 0.17093983859202688, 0.11645733127658076, 0.12558500413636597, 0.20900568340499925, 0.16786281298392913, 0.20120899951431803, 0.16748946218629557, 0.18806355519173812, 0.20851297487466314, 0.28264992486355844, 0.28625527104734916, 0.28726152626738577, 0.28317368357626693, 0.27981830355957316, 0.30573888887458256, 0.22996135370310988, 0.2752565400070709, 0.2938551631468893, 0.20354762974583207, 0.1985339818432046, 0.2406441380663099, 0.2146556825519238, 0.2200457751641225, 0.2194907948442285, 0.18644706155338475, 0.22597926862767714, 0.2233250460672842, 0.23578438216091413, 0.2682665878433603, 0.22424584549416882, 0.22345840661315086, 0.2233317580580808, 0.23048396861805354, 0.2228957651983412, 0.217555755880666, 0.24315682280008055, 0.1777871897262865, 0.17475357011855408, 0.17998958067554793, 0.1986017466484704, 0.26266079041472, 0.17552123346070825, 0.1928513234659962, 0.18334278020005446, 0.17033984974676353, 0.18468761973268266, 0.186179159177984, 0.18520373512429855, 0.5448660163166107, 0.19883732708208635, 0.14997248623473147, 0.14072405812264766, 0.5925919192833018, 0.5615492107875333, 0.5883350326439507, 0.20768693968160912, 0.48393505309751506, 0.3761656796882492, 0.29484218710285326, 0.1658492548203454, 0.16601735093069692, 0.33666766462158026, 0.29453769212245273, 0.18731121793307037, 0.17195279739495128, 0.19252362403158052, 0.17326145832937234, 0.17917653318931803, 0.18274057567196367, 0.18408197939478177, 0.18028112501946747, 0.1949174035066299, 0.09808308574484692, 0.09021623498816211, 0.08663719064538522, 0.09801942599893387, 0.08276742805129211, 0.10978186053489913, 0.10299094226711969, 0.10004787276932636, 0.08809852187564904]}, "mutation_prompt": null}
{"id": "8ded6669-f645-4572-8257-b47d4168d8b9", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.dynamic_mutation_rate = 0.1\n        self.dynamic_archive_size_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Adaptive mutation rate\n                self.mutation_rate = 0.1 * (1 - evaluations / self.budget) + 0.01\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Dynamic archive size\n                self.archive_size = int(10 * (1 - evaluations / self.budget) + 5)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive mutation rate and dynamic archive size.", "configspace": "", "generation": 107, "fitness": 0.21434404972204166, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.46477245131930267, 0.4605723415188907, 0.46805654630281956, 0.4537085578615754, 0.45431257651845225, 0.4579214209528416, 0.43985560597828866, 0.44688082395469453, 0.45896570081472665, 0.0031764078668308215, 9.999999999998899e-05, 0.0007043973511452473, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09609824296524117, 0.11597360956112734, 0.13545650895429406, 0.10758143366374895, 0.09282085380526262, 0.1108139964896534, 0.09016198134495135, 0.12307239137004167, 0.11149616613196667, 0.1220732454523672, 0.09877878569438292, 0.09467933740669543, 0.09059467579184166, 0.09106062596237374, 0.08730899005802006, 0.08833106814165492, 0.0740220720273348, 0.08178385054858495, 0.9189808528834074, 0.93786593745175, 0.8922280406136976, 0.8761398461117839, 0.8948504756740941, 0.9188760641889543, 0.943632050508607, 0.9256677174593403, 0.9245192910695134, 0.26892720773744483, 0.2516359456472339, 0.2891943444845666, 0.27880322073145825, 0.2540226813640608, 0.24635683477621717, 0.2726097855537365, 0.22510935341225613, 0.25555569064737216, 0.299580932440213, 0.2788200106411711, 0.23483123733434141, 0.26302188009822325, 0.305502774298933, 0.20241244836831618, 0.3105056847866695, 0.28162217378835597, 0.3108814241793917, 0.12774769141599607, 0.15378196778791298, 0.20705457062818888, 0.15656841715181768, 0.18991482887791078, 0.13594309692938078, 0.15742399067096902, 0.20701419531216758, 0.1336351388227709, 0.17847128273905577, 0.18775457204364576, 0.11932427572237936, 0.19533929553218254, 0.12470369222921729, 0.12443090266495926, 0.15656959793484926, 0.18631797890670365, 0.13741118975105493, 0.001352795950254615, 0.010914894304042022, 9.999999999998899e-05, 0.02961437874349193, 0.0008873924409800171, 0.004645907514319925, 0.005787638542314788, 9.999999999998899e-05, 0.013506467743691242, 0.11958306422092135, 0.06089553384030677, 0.1166005789557919, 0.06605627580960516, 0.04937005976963005, 0.025975140048055456, 0.2110029681317399, 0.09383186136602839, 0.07690588955507849, 9.999999999998899e-05, 9.999999999998899e-05, 0.0019258425161302606, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00022101863564460977, 9.999999999998899e-05, 0.09441698745343796, 0.09755715106994745, 0.058299993708035625, 0.09008610349752855, 0.08371716581891686, 0.0966423991189207, 0.11729172510215036, 0.10698379786719125, 0.10458391447728932, 0.39490510661008527, 0.40809127388053756, 0.42627407242083304, 0.42614720972717324, 0.4162872758669328, 0.39674273080333056, 0.40544447115514703, 0.425146739292116, 0.4205280949520641, 0.11090616921969321, 0.094359217186886, 0.12502967292459166, 0.10227590241138618, 0.10605060076122608, 0.14097852833039126, 0.09738396737641264, 0.11691905949296744, 0.10213492965598148, 0.18958669599194067, 0.1442134964202305, 0.1417424753131179, 0.17326527767062216, 0.1692178290602211, 0.19560742362067596, 0.18630917666457159, 0.19012897904209236, 0.18739001165202995, 0.2799234964877185, 0.2823514605837767, 0.2592081395564968, 0.2951238888954384, 0.3165277629798662, 0.2583951916903612, 0.2835099791622676, 0.28094422448604517, 0.24324245903029018, 0.20649543210579324, 0.16568214974101336, 0.21537096103874886, 0.2399679373245246, 0.196452487869617, 0.22234254512947238, 0.18610546449995702, 0.23486603788906724, 0.20827320144651662, 0.21645484557369044, 0.23206857343954757, 0.248392239436786, 0.2347299658867077, 0.22874924943107344, 0.27226963531249804, 0.23081641887873783, 0.2417987211399737, 0.22058796190358543, 0.18191066247989252, 0.19037340131539926, 0.191840825627413, 0.17795835202813048, 0.2177466964998549, 0.2005788916944331, 0.19295318818346963, 0.19498612473323929, 0.18828973438092467, 0.18522695991045268, 0.18672764432988442, 0.18637561510830414, 0.1552178004261392, 0.19811439325589786, 0.1671578924880016, 0.1427262377402323, 0.5547717439683355, 0.6642885131390102, 0.5517395627531113, 0.4807365699343652, 0.6220342001053785, 0.3955158750907789, 0.16997929385604726, 0.16639254116197977, 0.16620568734268049, 0.39290634134807034, 0.27368250551736717, 0.1773447069466274, 0.1988761236622032, 0.1948317962360676, 0.19632603222190048, 0.18434930801545202, 0.18750734759737053, 0.18642207254034215, 0.182612432347125, 0.17403833725005846, 0.08514668409190074, 0.08298748769006492, 0.08330437061892948, 0.08973331574138488, 0.09374698550242355, 0.09962525079694784, 0.10463736560357151, 0.09539096900228383, 0.0884278778719021]}, "mutation_prompt": null}
{"id": "7d8ce23f-abaa-408a-b91e-f9e9d590eee5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.probability_to_change = 0.67\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.probability_to_change:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a 67% probability to change individual lines of the selected solution to refine its strategy.", "configspace": "", "generation": 108, "fitness": 0.20163230629371828, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.35813170987535936, 0.3649103798310198, 0.35890843668294714, 0.36954588197245153, 0.36210000043621526, 0.3808830421624618, 0.35508926843927724, 0.3724148504072803, 0.3394424907415755, 9.999999999998899e-05, 9.999999999998899e-05, 0.0033889998575982183, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009624405116121282, 0.08920151590321512, 0.10482999777185054, 0.08929268486492126, 0.0956954261835179, 0.13114480344657609, 0.09355251954332566, 0.11412628096347543, 0.10707984100846057, 0.09565230484692844, 0.1083863573083036, 0.0887258016153597, 0.07374639705393182, 0.09717582169016481, 0.09432151754216211, 0.08786100448330747, 0.09116216907963148, 0.09535800311884013, 0.0787248412583249, 0.9517017473108511, 0.9500202956187085, 0.9385060101213493, 0.920842194603529, 0.9550608178763196, 0.9467700789852055, 0.9531082269033828, 0.9564844643409522, 0.9543195767319571, 0.2277619695940052, 0.2306685682530336, 0.23255195774370974, 0.25074156766942224, 0.2494676160164303, 0.2536193648615568, 0.22685450064344503, 0.22203839547815774, 0.22644367140909016, 0.27425898929208214, 0.3069148821114923, 0.2693411235722044, 0.23728197720802613, 0.2960482231928201, 0.2513611659038133, 0.3071200751553953, 0.2874662304068838, 0.2286575570936702, 0.12795673124526452, 0.13154880614370013, 0.1388871073518252, 0.11477706064477933, 0.1459429044269286, 0.13388157360517783, 0.13636247665391654, 0.1149376528371997, 0.12967188664422102, 0.13464655485943966, 0.14046022167479622, 0.13368980179006618, 0.14397882910365256, 0.12541974932590472, 0.13713817798392813, 0.13041930353588127, 0.1380018590693437, 0.14553961121429349, 0.04063069900916794, 0.012696896967397509, 0.038767103058633845, 0.010578698659716057, 0.013630181388672113, 0.0045928118551906705, 0.010984618703595905, 9.999999999998899e-05, 0.030232059096758523, 0.10818648455372981, 0.11817402247502085, 0.11410728077262589, 0.08981595826103439, 0.07727668305849111, 0.09842926586558809, 0.1269656497316931, 0.08279733882042617, 0.08106643987397999, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08378530703459963, 0.07369063345078508, 0.07000506069655499, 0.05820345098936375, 0.05888302308146198, 0.06757705158455829, 0.06769544124199856, 0.05460556570069752, 0.05963701845332037, 0.38378259260408953, 0.3554339457608712, 0.3461992361976046, 0.33671333020651417, 0.3601266606697976, 0.35528231455247306, 0.35419167183696176, 0.35110632821242893, 0.34576804034906694, 0.09287058803508008, 0.10700315026625973, 0.09886808282548065, 0.10764147772904653, 0.0934167550045859, 0.10563375499999983, 0.0953180031019194, 0.10888286868112595, 0.06424753637873515, 0.18378305690909025, 0.2022614770399166, 0.2075468830240227, 0.2004078175600741, 0.1994477782518349, 0.16637266111603843, 0.18922226435322942, 0.17957680649942098, 0.18878930372683111, 0.237124086356158, 0.26663177553200845, 0.25290796941818394, 0.26073866961309144, 0.2570954924104316, 0.2638376752226371, 0.2527663630529947, 0.24829081368382966, 0.2486024440315816, 0.1961117511710162, 0.20707164227580088, 0.20252844316463636, 0.1955449714781995, 0.1880843865767986, 0.20090450910826674, 0.18120435184135153, 0.18610148294670148, 0.16103864178134575, 0.22690497430446654, 0.21612890317443378, 0.2148810108461514, 0.24628448929918745, 0.2403025838160574, 0.22718693294093195, 0.23427365334519834, 0.21480936513522975, 0.2316453158335261, 0.1984642970577033, 0.21854206595291592, 0.19172172955951006, 0.1983781426207999, 0.17926887389859603, 0.21045977954902484, 0.19363294491452143, 0.184254084837982, 0.18428904702549398, 0.15686098617467892, 0.1869131234027651, 0.18586565533002508, 0.5220323308763668, 0.169337938263031, 0.11488424589348756, 0.5213024378051647, 0.1597127106129803, 0.48442713960513717, 0.4392973110661972, 0.41903827381900804, 0.4222746316197926, 0.20889311439067415, 0.20714649047321465, 0.20526778166088866, 0.32982560626144863, 0.1683737538788821, 0.37009412536199693, 0.1815409413108594, 0.19144071396247686, 0.18301923437766532, 0.19271534065310258, 0.1791990601404555, 0.19033461582730127, 0.1697688978965851, 0.18651786010868587, 0.19048397642377923, 0.0928699214103963, 0.10543348174643286, 0.07348496951925354, 0.10300565147138518, 0.08802424646648255, 0.10298920941539069, 0.09773323882430451, 0.08938196553380673, 0.09131607439230716]}, "mutation_prompt": null}
{"id": "c9ca673b-f954-426a-8db8-07900ad892e5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.refined_strategy_probability = 0.8\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.refined_strategy_probability:\n                    fitness = func(self.particles[i])\n                    evaluations += 1\n                    if fitness < self.best_fitness[i]:\n                        self.best_fitness[i] = fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], fitness)\n                        if fitness < self.global_best_fitness:\n                            self.global_best_fitness = fitness\n                            self.global_best_position = np.copy(self.particles[i])\n                    # Modified velocity update\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                    velocity_centroids = self.velocity_clustering(self.velocities)\n                    if np.random.rand() < self.velocity_clustering_rate:\n                        self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                    self.particles[i] += self.velocities[i]\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                    self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                    # Levy flight for enhanced global search\n                    if np.random.rand() < 0.1:\n                        self.particles[i] += self.levy_flight(self.dim)\n                        self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                    # Dynamic opposition-based learning with adaptive rate\n                    if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                        opposition_position = self.opposition_based_learning(self.particles[i])\n                        opposition_fitness = func(opposition_position)\n                        evaluations += 1\n                        if opposition_fitness < fitness:\n                            self.particles[i] = opposition_position\n                            self.best_fitness[i] = opposition_fitness\n                            self.best_positions[i] = np.copy(self.particles[i])\n                            self.update_archive(self.particles[i], opposition_fitness)\n                    # Cauchy mutation and Gaussian perturbation\n                    if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                        mutated_position = self.cauchy_mutation(self.particles[i])\n                        mutated_position = self.gaussian_perturbation(mutated_position)\n                        mutated_fitness = func(mutated_position)\n                        evaluations += 1\n                        if mutated_fitness < fitness:\n                            self.particles[i] = mutated_position\n                            self.best_fitness[i] = mutated_fitness\n                            self.best_positions[i] = np.copy(self.particles[i])\n                            self.update_archive(self.particles[i], mutated_fitness)\n                    # Particle filtering for enhanced exploration\n                    if np.random.rand() < self.particle_filtering_rate:\n                        particle_centroids = self.particle_filtering(self.particles)\n                        self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                    # Archive-based position update\n                    if np.random.rand() < 0.05:\n                        archive_index = np.random.randint(len(self.archive))\n                        self.particles[i] = self.archive[archive_index][0]\n                else:\n                    self.particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined strategy.", "configspace": "", "generation": 109, "fitness": 0.1981291186568591, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.41765107575372884, 0.38070506091874445, 0.4055475477797008, 0.3808741738535337, 0.3566694386719208, 0.37386387748191896, 0.39063669692698344, 0.4005626545664346, 0.393480475093567, 0.020429625319809186, 0.00029738577813609446, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09846078048990237, 0.10224529302251506, 0.09075960751006351, 0.08605528232036175, 0.096845259432781, 0.12918489546347756, 0.09548523539017317, 0.10438450908240515, 0.10863875304802872, 0.09155273688448418, 0.09010584630528196, 0.09813538689061174, 0.09622339017545423, 0.09506519697364069, 0.0844464676513258, 0.08651641246461628, 0.08710833788906602, 0.08250997520462866, 0.9099501619897808, 0.9430943618564848, 0.8852613605159987, 0.8970417826084603, 0.9010418875183958, 0.8468658140338337, 0.9369159273790184, 0.9440449249484161, 0.9380912429285718, 0.21901751016920568, 0.2363861412766043, 0.2228952413671037, 0.22243670048068576, 0.22010586427553658, 0.20598157108748527, 0.21627655950910707, 0.21573990224345496, 0.21239335919596258, 0.28220341849332886, 0.23364162173643954, 0.22283704901280454, 0.2639245497052519, 0.26357742289471775, 0.2424467989122958, 0.30744000202215893, 0.17414099634768676, 0.23380408472023584, 0.13904634597428345, 0.1678880207054284, 0.12359449478567497, 0.14349915641574185, 0.13747729430273103, 0.19749567256853506, 0.1372761527387849, 0.15778805102997195, 0.15371818619357525, 0.1187395204163606, 0.11662238043125894, 0.12226466333105968, 0.1771722840814829, 0.121263586510713, 0.12742051185140768, 0.131671660219853, 0.10972641277331274, 0.128901662257482, 9.999999999998899e-05, 0.001397451867182431, 9.999999999998899e-05, 9.999999999998899e-05, 0.028454934498099327, 9.999999999998899e-05, 0.027578822969856254, 9.999999999998899e-05, 0.005574731184421533, 0.17464026590450243, 0.06835578449105217, 0.1168294479156119, 0.13478031271670565, 0.06838353065447778, 0.0393223556462452, 0.09046611545859817, 0.11759816588165317, 0.09380859946456732, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08402749163851908, 0.057352733658420196, 0.05154469298233577, 0.08942494636432297, 0.07784648710946496, 0.07509635434150008, 0.08114152862795421, 0.0711764069544848, 0.05849244760858041, 0.3825474088807669, 0.35043297230656456, 0.3755570885921454, 0.3598168544542689, 0.3641013744227689, 0.34689670268800044, 0.3669546843267866, 0.38333020720718836, 0.3628259756111686, 0.10668034197018428, 0.0966486106474731, 0.07841521450189737, 0.09656157710611912, 0.08401062538821846, 0.10774260985095097, 0.08551801234769663, 0.10577080984168552, 0.11646606750067534, 0.13741062682447425, 0.11838792462625203, 0.19405518137468025, 0.15363035218932086, 0.16682265042423838, 0.14561946469269382, 0.21142124262818263, 0.16180804476527033, 0.15440771330058523, 0.2652960457360458, 0.2832402950932552, 0.2722894510842915, 0.2685016545699863, 0.25893140151637584, 0.2563879280649862, 0.2227657910937504, 0.2582936532531662, 0.2420913823366757, 0.22467989549595613, 0.20038580594499056, 0.22744303260189458, 0.21822357560148786, 0.20006178464043012, 0.21938422690691928, 0.1962804356876945, 0.2000914715820733, 0.1738835061603461, 0.21830273482988727, 0.24024854217336467, 0.23217117248634378, 0.23766878621076215, 0.22408018657805673, 0.22729059427619214, 0.21252075723439523, 0.21133698695815906, 0.22192328549342188, 0.18019838199895244, 0.1886772998805485, 0.17801495137636192, 0.18244350679922838, 0.19620711797794488, 0.18882996095410431, 0.17496642614146474, 0.18857269283767997, 0.18349431000931116, 0.18532563499204702, 0.19906607606759108, 0.18621709183618973, 0.45637533585166645, 0.19288326796190436, 0.14623102684118405, 0.2039661485905172, 0.5679522105334069, 0.15931924838658884, 0.47029633030008433, 0.20695890440858833, 0.44333470935687047, 0.31680557487586725, 0.16555753661028594, 0.16604298520018934, 0.2935291480093908, 0.39086486310817836, 0.3966573191765719, 0.17521461195001198, 0.18252155182184127, 0.19086634252330725, 0.19161586835402633, 0.18393214027256, 0.1870957496171537, 0.17787052196831377, 0.17080512941989467, 0.18487994707948996, 0.07722736803500652, 0.07792036915127576, 0.08940867675685371, 0.07944514708696349, 0.08820216554803195, 0.08835889755849602, 0.07964095698698348, 0.088180891041032, 0.07734321244790132]}, "mutation_prompt": null}
{"id": "aabcd863-03a3-46b6-8610-429256aaedb0", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with random perturbation\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim) + 0.1 * np.random.normal(loc=0, scale=0.1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, dynamic opposition-based learning with adaptive rate, and modified simulated annealing with adaptive cooling.", "configspace": "", "generation": 110, "fitness": 0.21342041425223743, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.46665138140303974, 0.4965953846094594, 0.46986955665469554, 0.4492125888972397, 0.444788314615311, 0.4484372273696463, 0.4409617748741427, 0.5227204348809968, 0.45338086911116837, 0.02512228253165072, 0.017408707473156593, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.011208419893540711, 9.999999999998899e-05, 0.11182640108837494, 0.09726660671747156, 0.11855808715000093, 0.1117644434148688, 0.08345428156529111, 0.12839431080028973, 0.12549577460446903, 0.12040999547503761, 0.17203424328055117, 0.10432435903551518, 0.09006176842492897, 0.08524448257826911, 0.08732922286051559, 0.07881171706840706, 0.08565903942655473, 0.11292420842257811, 0.09714548467678574, 0.10193925010488403, 0.9032165519799172, 0.9447524675288065, 0.897418320669196, 0.8818223191658259, 0.8991734407811244, 0.8973725156748353, 0.9194262137261833, 0.9417655582131895, 0.9166858468499406, 0.2787110929659018, 0.26290709426084535, 0.25341780966093297, 0.2391443341145092, 0.2295425514330217, 0.24496139283843954, 0.2701904992779768, 0.2269787839564288, 0.269721735921301, 0.5480572038136465, 0.23591874333657736, 0.30372662795925576, 0.2702180686240854, 0.24793605046506673, 0.20045496514392858, 0.2709125861205681, 0.23114182947515516, 0.23661721262710667, 0.16783735467944239, 0.12844355549798203, 0.11776780771233208, 0.0899123476930136, 0.12321465035333234, 0.13696459867424693, 0.13506809510565088, 0.10891402838211472, 0.13005728903552172, 0.17748541108136828, 0.12888164545506076, 0.14076835422856182, 0.1700540348539471, 0.14147890282631437, 0.14000037150004951, 0.16082002460436706, 0.13865052931048283, 0.13664642116045567, 9.999999999998899e-05, 0.025740845082843244, 9.999999999998899e-05, 0.05845726623656777, 0.0025524281035288476, 9.999999999998899e-05, 0.002415328110351389, 9.999999999998899e-05, 0.009366217274677235, 0.18172192567330625, 0.08909557315534034, 0.11840478454577319, 0.06543736614981521, 0.06537953598724211, 0.022744238647077197, 0.10052336001493567, 0.08236634655947983, 0.06929467173616399, 9.999999999998899e-05, 0.00015238519342308798, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0007141989350062383, 9.999999999998899e-05, 0.004445945335882051, 0.11568690825694938, 0.09585686023852336, 0.0864456156870057, 0.10366008009053296, 0.12762750441015247, 0.08135923768849918, 0.11293444646344653, 0.12403097795742901, 0.09931225233014174, 0.4262753385804199, 0.4245980015332731, 0.41321374037167613, 0.4188336635800375, 0.3942866635706458, 0.42914543403329397, 0.40760822429398214, 0.44718367138067827, 0.41660031663739805, 0.07629050146737648, 0.08074955284311147, 0.08405236606340549, 0.10868944317254914, 0.09468119992599444, 0.1134006828617905, 0.11347489004111355, 0.14874474170813423, 0.08443286846857045, 0.1689734722543984, 0.16348907326795292, 0.1727168787350163, 0.17168554587157536, 0.1739407826745788, 0.1721875748839823, 0.12392876584601586, 0.18986929747352788, 0.1377968728453689, 0.2853142559384778, 0.27428514774287693, 0.29447438667391834, 0.31045153703874795, 0.3215171267908802, 0.25700140588759546, 0.2464789170794257, 0.3085548489682084, 0.2522290054709, 0.2297590437284951, 0.212469196066838, 0.23191699182881687, 0.22752126960627816, 0.21768522898653808, 0.2251047092132249, 0.16173045889054538, 0.24024484283858072, 0.19700089046426805, 0.22966957839732371, 0.25818612660205076, 0.22163608930334866, 0.21790479359551984, 0.21903158074938267, 0.2146125879816767, 0.22943264824906473, 0.2212106675690899, 0.22566799435294504, 0.18653507464225982, 0.1759883658631225, 0.18117881218575926, 0.2011715748579992, 0.1838073920322999, 0.1881260092304461, 0.17540014318913055, 0.20376730297761692, 0.1770679890623007, 0.1292058385717899, 0.18588989074337536, 0.18768074597611517, 0.5611705148896653, 0.19953044587857804, 0.19698749146096572, 0.14036712804202833, 0.5962244854876764, 0.6138233098516577, 0.4746620657641186, 0.20928101965235013, 0.3911987461068719, 0.2048932365961229, 0.16536134357098364, 0.45628604611751067, 0.16674339694657503, 0.3927659227948206, 0.4267587849091812, 0.2042840726750974, 0.18977209002582618, 0.19340444110693777, 0.1788449593323037, 0.1785181874738333, 0.2020295358367108, 0.18144940198390702, 0.1777498720307742, 0.18132474894050588, 0.08473397069227995, 0.10780424052507309, 0.07052276139416158, 0.10707594146699906, 0.09000534779503555, 0.10333253639321993, 0.1035363188668893, 0.09392763068307863, 0.08919529184749697]}, "mutation_prompt": null}
{"id": "fb50a1de-6064-47c4-b9df-79bc357a1099", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with probability-based modifications\n                if np.random.rand() < 0.3:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined strategy using probability-based modifications.", "configspace": "", "generation": 111, "fitness": 0.19882953095568184, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.18.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4304371939907392, 0.41705503408024935, 0.43049548013426975, 0.4288106980564994, 0.4284813384383418, 0.4153186146696969, 0.43006145680304964, 0.4076986887976687, 0.41736075120420124, 0.009756643217442296, 0.0020258137488139427, 0.0013993040638088372, 9.999999999998899e-05, 0.0002680158754081452, 9.999999999998899e-05, 9.999999999998899e-05, 0.0025015564508088506, 9.999999999998899e-05, 0.09234412125215186, 0.0707992506851951, 0.10548978819722998, 0.08640706746092708, 0.10594321782137339, 0.12609344818385126, 0.10072327705768458, 0.09599036773981684, 0.09780395148984522, 0.08610772150754087, 0.09441388490183, 0.07978834467444307, 0.08922493479963745, 0.08200998718318842, 0.08501331955984892, 0.08221424601840643, 0.0952702074548133, 0.0799355856401357, 0.8740925178241287, 0.9270382651932662, 0.8650625776254536, 0.7946412691188951, 0.8631400869233432, 0.8747080821079146, 0.9148510714840813, 0.9107182613336022, 0.8157287997753134, 0.2185252029423027, 0.19496380048610462, 0.22184075607639442, 0.22354006934038517, 0.2057818188435816, 0.18982539419138955, 0.21422825784004285, 0.2043348188197781, 0.2183826797579148, 0.25170588840772046, 0.2838289339088651, 0.23734123535532914, 0.2447866718725269, 0.31525333095413355, 0.2004025383140985, 0.2072783759403446, 0.21329487258089652, 0.3012333405064104, 0.1593274697054825, 0.13832792861936305, 0.11644028140233276, 0.10859384642932601, 0.17493596509568365, 0.13796726439838713, 0.1252687366948243, 0.08610434353316176, 0.12750098138694144, 0.1226534545566017, 0.13210468285180543, 0.1315615450335641, 0.14207721290772102, 0.12799471997672174, 0.13042150213590298, 0.15487903139080317, 0.13947909672724146, 0.11773283169883875, 0.0015874645346317662, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13105135802570644, 0.08523141482214391, 0.10184142233559634, 0.07139508853011978, 0.0779152871107266, 0.05847086752934305, 0.11285414210193745, 0.15395104909269197, 0.09826845472648582, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11442530543858953, 0.043176903172822856, 0.07834870485362933, 0.09212022406672116, 0.10466674093901651, 0.07897397663183381, 0.07821438210263809, 0.09213512427155546, 0.06403194116849753, 0.39389140838268455, 0.40924701451394774, 0.3974884499558733, 0.37697590029619354, 0.3666399447121128, 0.3870049161152902, 0.3810222853448981, 0.39032167393080963, 0.4078339406046554, 0.08342164350878889, 0.11055923661691491, 0.08561503696000405, 0.11354722214615653, 0.09346892041521315, 0.10304727422462223, 0.12321617756102932, 0.08843921630192852, 0.08762323692044227, 0.203670852446045, 0.13282346699687964, 0.13194172350411004, 0.14505167515180106, 0.21076882908840733, 0.14073607136587674, 0.16003426982624025, 0.1838044142343931, 0.17641869455256054, 0.2600394226429701, 0.25882607713428984, 0.28440463051311704, 0.2576919091280888, 0.28343442896231563, 0.28557033000267296, 0.2564457290745126, 0.25828014621890294, 0.2532072290468733, 0.21301957429731688, 0.22909078309955677, 0.22397938762169, 0.22139954209202595, 0.22708317803277744, 0.21665077157012602, 0.17640324051426415, 0.1886470518542065, 0.16312330546994092, 0.2395739547054262, 0.2300518603931121, 0.20925411619159917, 0.22624973676375237, 0.23372173641704752, 0.25028361188262616, 0.24946906758342757, 0.22177628553034756, 0.21520498047787295, 0.1821683182071674, 0.16830823221752056, 0.18348489431986514, 0.18647610859943742, 0.1902508339893425, 0.1766453099729186, 0.17861712146995157, 0.17810207341693562, 0.17411358753289785, 0.1810090801102755, 0.1840035958674595, 0.18694504948597557, 0.4604255496625774, 0.19338628425757676, 0.19117691458766584, 0.4899151501271707, 0.46501641355077294, 0.4638682012169719, 0.37718383575298653, 0.2083890689821687, 0.4126573698878089, 0.41658297833594304, 0.16201522646756417, 0.1653040512440448, 0.1641082978291042, 0.15988240947376597, 0.2103724263615533, 0.21238950816753754, 0.1934591625536065, 0.190280656658537, 0.17581639217836653, 0.1831603584003315, 0.1909418636966871, 0.1867191136364137, 0.17529256116247582, 0.20563216715625376, 0.09614534021941012, 0.08723156061619353, 0.08796224730027713, 0.11886019149387661, 0.09122200777021794, 0.08714303387905198, 0.08533497967818438, 0.08451975368355868, 0.08926084766762055]}, "mutation_prompt": null}
{"id": "d2576a3b-e848-421c-ab23-92ba73892e91", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.98\n        self.adaptive_cooling_rate = 0.6\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.25\n        self.dynamic_opposition_based_learning_rate = 0.15\n        self.inertia_weight = 0.85\n        self.inertia_weight_damping_ratio = 0.995\n        self.mutation_rate = 0.12\n        self.mutation_step_size = 0.12\n        self.velocity_clustering_rate = 0.12\n        self.particle_filtering_rate = 0.22\n        self.archive_size = 12\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.12, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined adaptive cooling and opposition-based learning rates.", "configspace": "", "generation": 112, "fitness": 0.21173158258737804, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4764591533994773, 0.3888784325658776, 0.4719888550607606, 0.45950891166070074, 0.42060381070712594, 0.430360601827812, 0.4407639577426865, 0.43260421992979603, 0.4660338946415976, 9.999999999998899e-05, 0.008278357868961028, 9.999999999998899e-05, 0.0010174998151265546, 0.04228745094167585, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09620474465180118, 0.08410535514898387, 0.09294933167954877, 0.09628914491923857, 0.09749664466981123, 0.07756809065061243, 0.09324114897392433, 0.10957930868991572, 0.10616896445897672, 0.08372901041554015, 0.09183647603486589, 0.10709144957160477, 0.08436001525988324, 0.08145292906381851, 0.08872064842596517, 0.10903732743711592, 0.08670809936410062, 0.09533680691743973, 0.8786465559670885, 0.9379250721533132, 0.8951877806792451, 0.8736000060475452, 0.8825929328377093, 0.8798202542096533, 0.924489811715553, 0.916435503325154, 0.9120874468857851, 0.28387253495926157, 0.26733282532033953, 0.22576645261789208, 0.2470236072693458, 0.24295032356648916, 0.2563383221811599, 0.24334184903245315, 0.2158953494675997, 0.2466001935419403, 0.24462561666591565, 0.6237423977125197, 0.30852777075107873, 0.26865996352292243, 0.3662253880019992, 0.20716188245760947, 0.2816160074449723, 0.3000970123726998, 0.2130973110582649, 0.13257793152657027, 0.11993486875059334, 0.12841909330900558, 0.10556815371128836, 0.1811808352352885, 0.1282402023498055, 0.13741171366406757, 0.14639817639857844, 0.12360956142114987, 0.14600318842101478, 0.17067851715317905, 0.1412628239030408, 0.21627653343056696, 0.15497960886820727, 0.1770035058065027, 0.14851934842786163, 0.1481294415558948, 0.1411902950281787, 9.999999999998899e-05, 9.999999999998899e-05, 0.019729718172094013, 0.021132066776337943, 0.0016327922323103872, 0.00999231972805481, 9.999999999998899e-05, 9.999999999998899e-05, 0.011527721275489733, 0.09307684263028515, 0.04618799928326667, 0.10730184311925128, 0.09943933060028398, 0.0577903790691342, 0.03550609513994418, 0.16109896325950945, 0.07922410290837612, 0.05966013172642037, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10810811649510366, 0.08919858879214149, 0.1092092454969752, 0.10843263093976185, 0.08423970675245906, 0.08133273250335205, 0.09077493146709692, 0.09463163601182856, 0.10062290523470052, 0.41639636900980326, 0.383160454116262, 0.4152230940702266, 0.38073466046207893, 0.36963799471017833, 0.37916579796775973, 0.40897680217997, 0.39819853027499896, 0.41053034609789174, 0.09254035311415032, 0.09257221286098716, 0.079036306429081, 0.0855233853560109, 0.10517861588137989, 0.10964306697187642, 0.10452724090727517, 0.12449236783320705, 0.10519077858326198, 0.16609088389568627, 0.20173853488529625, 0.12739330462543053, 0.17999246735365182, 0.1889943939732618, 0.15704059807919235, 0.1573735316591952, 0.18269658676920542, 0.18358440957313193, 0.27400908849800776, 0.2862295108478441, 0.2857087825810992, 0.2878110248529303, 0.2832200664835538, 0.3055118031900471, 0.26850643869654156, 0.26046891081869716, 0.24604347043843033, 0.22493694937107322, 0.2430318284374796, 0.24416731060380092, 0.20971888883203837, 0.21326687490445217, 0.2251828777811702, 0.16834212571663576, 0.22670913349587118, 0.19882184639571632, 0.22108578170061466, 0.21559938514323107, 0.25196273823392534, 0.2455396897493516, 0.24436963488907537, 0.2458977943790659, 0.26155062158426456, 0.21196156493113127, 0.2201299053687027, 0.17769133380912538, 0.18447101989601455, 0.18635402529192502, 0.223303260520469, 0.181027176455261, 0.173136319727913, 0.17880771514965632, 0.18510670586689648, 0.17645609698402076, 0.12672011311003628, 0.18463685909137229, 0.6415584513169776, 0.575312907512167, 0.19851626189787164, 0.6201478450099547, 0.14091994075289882, 0.1455797168176599, 0.6374268213408398, 0.47056921023285225, 0.5041300502586308, 0.40958898828668955, 0.20499410014744268, 0.33481098052547165, 0.1649227792715423, 0.16537148761402365, 0.11100144632135611, 0.16509084833706134, 0.18232162682179365, 0.18192851570065327, 0.1904931794610376, 0.18439299307314572, 0.18064036999157373, 0.18453466813208574, 0.1761262243397732, 0.18443154040829413, 0.1851248582317494, 0.10797654853487637, 0.09923598839390146, 0.09523890804930502, 0.09252467983620116, 0.0977390816863919, 0.08268878828648396, 0.08990493641642117, 0.10095327861815973, 0.09124064294524903]}, "mutation_prompt": null}
{"id": "ce5a32a8-f393-44d1-a7a3-48d08e2f471f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.refine_strategy_probability = 0.02\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def refine_strategy(self):\n        if np.random.rand() < self.refine_strategy_probability:\n            # Randomly select a line to change\n            line_number = np.random.randint(1, 100)\n            if line_number < 20:\n                # Change the inertia weight\n                self.inertia_weight = np.random.uniform(0.5, 1.5)\n            elif line_number < 40:\n                # Change the mutation rate\n                self.mutation_rate = np.random.uniform(0.05, 0.2)\n            elif line_number < 60:\n                # Change the velocity clustering rate\n                self.velocity_clustering_rate = np.random.uniform(0.05, 0.2)\n            elif line_number < 80:\n                # Change the particle filtering rate\n                self.particle_filtering_rate = np.random.uniform(0.05, 0.2)\n            else:\n                # Change the opposition-based learning rate\n                self.opposition_based_learning_rate = np.random.uniform(0.05, 0.2)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                self.refine_strategy()\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a 2% probability of changing individual lines to refine its strategy.", "configspace": "", "generation": 113, "fitness": 0.20342021242356162, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.42405717968765444, 0.4433621347462172, 0.4200931346182568, 0.387764951057876, 0.44084069115658164, 0.4155443686566733, 0.4452274726740322, 0.4516551363222453, 0.3928924647040577, 9.999999999998899e-05, 0.006236435817709718, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.010602143836351385, 9.999999999998899e-05, 0.10908151778357711, 0.10578924025208558, 0.10597782537901335, 0.09641773557398481, 0.08103953456262603, 0.08321685003980872, 0.10111991688617561, 0.11155539346811749, 0.08797802591619097, 0.09300508378566064, 0.0784314199834375, 0.08014463488276047, 0.08142826199168007, 0.08062526956493699, 0.1082006407772258, 0.08599190329048123, 0.09577930073014962, 0.07726912762977667, 0.9216592829002452, 0.9443373565082129, 0.8976614083992484, 0.887350634051862, 0.913912387754937, 0.8673821141243674, 0.9455779578755178, 0.9249225221786249, 0.9235850701766622, 0.22275984813413785, 0.26620332495246635, 0.21948948061670503, 0.21718933272174223, 0.24171116853694063, 0.2198425493532261, 0.20703298148044114, 0.20642100604166957, 0.21934387762263474, 0.3297761912703294, 0.33281078051255997, 0.2228558775856574, 0.27192840486610015, 0.2660192737189445, 0.20638477592427917, 0.23052911366791318, 0.21707543568426435, 0.2780789413274186, 0.13364182460574103, 0.1441826790863655, 0.11515391074076176, 0.11128007786914074, 0.13549231768197112, 0.11974376414372456, 0.13730101333237776, 0.12278719933129245, 0.13594187991274553, 0.13681885683983186, 0.13872652635942995, 0.13885748629228345, 0.1364619465043153, 0.1292962025757668, 0.12664323450066073, 0.14185139812079828, 0.14968501942077073, 0.12006414565762624, 0.021622458395260225, 0.009458051097508413, 0.01538525695362003, 0.0013643858182520452, 9.999999999998899e-05, 0.00110295498119517, 0.029198573102708125, 9.999999999998899e-05, 0.011127410729791176, 0.1399573900200709, 0.041052558775107384, 0.10353245025800328, 0.05499717724187125, 0.08841245002572617, 0.051889991987989714, 0.10497613861182487, 0.06973938646302935, 0.06431526069192639, 0.0003822778919267966, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00018321488591466206, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09433690516194004, 0.1171121392466965, 0.0881485384295172, 0.09146577037430648, 0.09401412581858115, 0.05679566752418996, 0.08756876541171421, 0.09203943039797213, 0.06939138117336019, 0.3957906564099599, 0.42852330704538233, 0.38159878760212873, 0.37471569136457616, 0.375462198232141, 0.3922880172246872, 0.38698811621675167, 0.39644082520574553, 0.3684860292198534, 0.0979174106398919, 0.10217731975233435, 0.11846127160921949, 0.09760653864881264, 0.1281607702622366, 0.09803779490864362, 0.09392641797235501, 0.13602414639427884, 0.08947392486785244, 0.15503216744533288, 0.19185859046785525, 0.15864739216746349, 0.1691520039991148, 0.17114887740107698, 0.1983265584445112, 0.2025855359088029, 0.15697775249735224, 0.14982588537597474, 0.2904181740649294, 0.2807945296270058, 0.2779236747766116, 0.22959688422050462, 0.2554877073617474, 0.2829588663831357, 0.2793033824815815, 0.30443009583236513, 0.26186672443163994, 0.15454786660816733, 0.2476418703230403, 0.19223599482676368, 0.2321748682849536, 0.20434859451628573, 0.2077476135794607, 0.20601036874063905, 0.23427946026288882, 0.18082205683093067, 0.23324706900830827, 0.2174270362981401, 0.23600948046604409, 0.1877967505922956, 0.24553332177277287, 0.21568472321683974, 0.2418873957377342, 0.21310423647922927, 0.21975402826370305, 0.18052214621877083, 0.1938018875636467, 0.17852935451863083, 0.19334559107104654, 0.18296050060585545, 0.18010151414858333, 0.17876918893644556, 0.22811342754009856, 0.17954888687709736, 0.12920048814365415, 0.1850961493397938, 0.18523907331166733, 0.5765794645409446, 0.19634492823471084, 0.145119884528651, 0.1399805924533799, 0.1533808885242126, 0.5552958063708217, 0.4253358250163768, 0.20976266547464362, 0.41442778049443163, 0.5624265002393343, 0.4137206872589986, 0.4045047571843301, 0.16649232607358355, 0.10323821168496139, 0.3808714252827712, 0.18954046928303414, 0.18522469047475432, 0.18199500073636177, 0.19259132254964073, 0.1801774557582414, 0.17762985012806765, 0.1701218978339304, 0.1778204943306606, 0.1809461852823957, 0.08791863149521051, 0.07832084833286423, 0.11567665298816232, 0.08500451139192955, 0.12493457875032077, 0.09025551889471606, 0.08650979275853099, 0.0795120194469513, 0.08494076093597835]}, "mutation_prompt": null}
{"id": "59c426aa-9a01-421a-a6d3-a12b1b399d75", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.gaussian_perturbation_std = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=self.gaussian_perturbation_std, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and adaptive Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_position = np.clip(mutated_position, self.lower_bound, self.upper_bound)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            # Adaptive Gaussian perturbation\n            self.gaussian_perturbation_std *= 0.99\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive Gaussian perturbation and modified velocity update.", "configspace": "", "generation": 114, "fitness": 0.21830046368780115, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.46592958539272933, 0.44900729995353916, 0.4813034528116429, 0.44306169582492416, 0.43981056953013553, 0.4483535099600702, 0.43903328556125154, 0.43627639652548456, 0.4287924527590028, 0.010072786684241497, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014683326120041196, 9.999999999998899e-05, 9.999999999998899e-05, 0.00911190428990627, 9.999999999998899e-05, 0.13249372227169953, 0.10354157140560061, 0.08178087533085376, 0.11669828595510368, 0.10608160666914979, 0.08893309795703841, 0.1202792053891899, 0.10805673007824845, 0.08527908494327441, 0.07848233305135677, 0.11821281895716762, 0.09072484254755742, 0.08882486416945723, 0.0774915409244219, 0.10230362013126726, 0.09922020846437174, 0.07694761976650155, 0.08794089715402897, 0.9149738182086363, 0.9463439409640868, 0.9136262017751003, 0.8828003135849329, 0.8915414631276131, 0.9001302968614564, 0.9271058817241348, 0.9287399139361476, 0.9157101878267053, 0.24082189438629098, 0.2624113297367294, 0.24726768938720434, 0.2342763042364867, 0.2654698112135204, 0.27943552777713776, 0.25170616574753657, 0.2096394115146003, 0.23798393463146028, 0.35361726523893466, 0.35371931223882147, 0.2725396328951416, 0.27038264069218454, 0.7488952965059066, 0.26529451076283717, 0.46880538276851447, 0.221830965679075, 0.28109768799888857, 0.12247276143375074, 0.11939717995875343, 0.1251497874805938, 0.1556620194276982, 0.19335451948878257, 0.17288817512965327, 0.2261970047859262, 0.20674023008034992, 0.14431114866217232, 0.1576920561728733, 0.1226496165548131, 0.2565144526091071, 0.1523412845041261, 0.1298375708808036, 0.15583016586837928, 0.14944433685848724, 0.1649094043158862, 0.1718847624068065, 9.999999999998899e-05, 9.999999999998899e-05, 0.008115234921026615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0010715347224713456, 9.999999999998899e-05, 0.007864103694507185, 0.1480239381605306, 0.04453238207453303, 0.09502740776088214, 0.07613260359620289, 0.07524487668119961, 0.012064365437950753, 0.11627882559305402, 0.0714227105647588, 0.03992265261308836, 9.999999999998899e-05, 9.999999999998899e-05, 0.00010345450527970979, 0.009888618591988085, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.000601224849108406, 9.999999999998899e-05, 0.10421779987756086, 0.09084621421607464, 0.10049746115145974, 0.09342400537835915, 0.12781805225935383, 0.1231241421356819, 0.10795076176852869, 0.11220709893027359, 0.11190283199323714, 0.4287928687331971, 0.41200965713353543, 0.43282775502922133, 0.3986416213484927, 0.4118554328633244, 0.41952924984681705, 0.4431186128155471, 0.4469630624456379, 0.4013681656879272, 0.1240202941777081, 0.09939217265180889, 0.08465080676020931, 0.1070608090723506, 0.10751338529171595, 0.09578127642249967, 0.11789321667918962, 0.12078863496682224, 0.10130173742319626, 0.16291689492458117, 0.24410292019630464, 0.13853908610777, 0.19330546826362116, 0.18863533150666512, 0.17050871509016174, 0.17947252293398175, 0.1894123923318891, 0.14925989572798504, 0.3172925814965174, 0.30479052209313684, 0.28372168522575414, 0.2984103141932237, 0.26369256720731293, 0.2774629643611306, 0.28226376755923, 0.29491585060078085, 0.27711020520687146, 0.20176825069923687, 0.1925802187483564, 0.20199235021973538, 0.21146912075673985, 0.22539509437811855, 0.22243103508816453, 0.19826783703592588, 0.23208734569270295, 0.1629783453146343, 0.20877472916745698, 0.24745969184144878, 0.2229171249921882, 0.23123585297900906, 0.2595127261401612, 0.2320892402050947, 0.22835428369974875, 0.24157604652516007, 0.2142453938949831, 0.18351431594921486, 0.18457291341245274, 0.16988078231247605, 0.2210399404392509, 0.1836921107568672, 0.19294115380550958, 0.18624345032919354, 0.27287515961232334, 0.1870435331391631, 0.1843953541653366, 0.18633298799928866, 0.18635746010524, 0.11739618274323527, 0.19793590370938696, 0.14523372393000378, 0.1410823636112385, 0.6512934828955133, 0.5890379900175724, 0.5803488693614616, 0.43666919603824206, 0.544431487612725, 0.4565796533833031, 0.4056703243869981, 0.16682802226810256, 0.16640238475354852, 0.3201560090297664, 0.32670596504058635, 0.18523018917558187, 0.18400999283764763, 0.19769977444194975, 0.18472025146697235, 0.1806710696430971, 0.17533296745820937, 0.17782711719730582, 0.2136308952488395, 0.18626745725773497, 0.09537627880393373, 0.09733384457929384, 0.10552345685027908, 0.10129827493550403, 0.09249280914890512, 0.07021507447478925, 0.08574356290307783, 0.11108709009934592, 0.0970674473841795]}, "mutation_prompt": null}
{"id": "89b31c77-93a2-40d4-bf0d-7d50a38ffa28", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.refine_strategy_rate = 0.19\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def refine_strategy(self, line):\n        if np.random.rand() < self.refine_strategy_rate:\n            return np.random.uniform(-1, 1, size=self.dim)\n        else:\n            return line\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Refine strategy\n                self.particles[i] = self.refine_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a 19% chance of changing individual lines of the selected solution to refine its strategy.", "configspace": "", "generation": 115, "fitness": 0.19457298241967436, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.18.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.381550549380543, 0.38234780679455493, 0.36070943351041773, 0.36466874676317096, 0.4339880791364833, 0.377557624127534, 0.37105965920597106, 0.3957133495182642, 0.3621376683691325, 9.999999999998899e-05, 0.006445921898217577, 0.0010141513799222235, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10574674838033848, 0.11168071689071257, 0.09664746555236703, 0.10799581940888425, 0.07809061490515667, 0.0658735756235379, 0.08876265005015849, 0.13847589910727653, 0.09700207203391042, 0.1008655604312425, 0.10378745422770352, 0.08482936456374701, 0.11007598603457158, 0.10647508029996355, 0.07258872094155266, 0.07127138741194028, 0.09181813400804006, 0.06463174942238259, 0.908167706041877, 0.9441457104455638, 0.894459784568978, 0.8579642501548397, 0.9133198976507534, 0.8730101860316801, 0.9343817733106256, 0.9205323657365828, 0.9185634921897167, 0.21383504913293683, 0.2125174288765258, 0.2084026390904674, 0.25585685891265175, 0.22495552409499708, 0.23029158084109524, 0.18712797797178593, 0.18427763884740866, 0.20875917899859553, 0.22297812968538133, 0.28491878349106337, 0.2644201240950733, 0.25452681507815156, 0.28384503581383236, 0.20299342735193004, 0.26968171357442117, 0.21240269466227368, 0.2519247574452198, 0.1327806238422773, 0.13296319525216171, 0.10241237791738478, 0.11555675838208279, 0.13929169896560145, 0.13281348670637583, 0.12275985937744704, 0.10246085728576149, 0.1452264057173117, 0.1406742204742264, 0.17921164351189112, 0.16361501945573487, 0.13769430564843277, 0.13648090928719336, 0.1298207543838582, 0.13117970418662028, 0.12448336419684203, 0.1393497109936992, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015676961658247501, 9.999999999998899e-05, 9.999999999998899e-05, 0.019608419090221485, 9.999999999998899e-05, 0.003924621803622408, 0.10315828699326635, 0.04971387173418573, 0.12665255317383695, 0.09383505647141333, 0.06250114455564948, 0.025802691618889373, 0.0712750218104895, 0.11181349971486998, 0.10595765871468865, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07284759898362647, 0.09454361796122934, 0.09031622020780683, 0.0783777771894405, 0.0860619764740197, 0.05278196035437488, 0.05915324180177972, 0.07548715328151101, 0.05544330369255279, 0.3582989811649979, 0.3926390790449086, 0.35203061826701154, 0.36038227263005407, 0.3631418022663946, 0.36891065699098813, 0.3736754406468942, 0.3547757306121071, 0.3619990462753837, 0.09405357792196212, 0.09491970778578995, 0.07842263718838038, 0.08912325467653404, 0.10423770815112943, 0.10333237719143051, 0.08414941940836673, 0.11860157444739472, 0.07689205525469656, 0.15736722131415648, 0.16235507920811543, 0.14758203198216746, 0.17048640849397467, 0.15382871747453597, 0.18437062606858012, 0.17669685586529105, 0.19831643159253276, 0.18351505014847957, 0.24916104627580737, 0.23263467676159333, 0.25437979529805077, 0.2669478729309517, 0.266366983200657, 0.25006206917053664, 0.2224755532911018, 0.24687947831905888, 0.2799640429965732, 0.2112985743597744, 0.20648641141138258, 0.1885590331928675, 0.22782655286362152, 0.19917607694656403, 0.19600317472959128, 0.17474961252333798, 0.1757487855612926, 0.18015377689995982, 0.2388346116875043, 0.27441749645906754, 0.22665964750392564, 0.24066390571325058, 0.2571349625567345, 0.23313994085897471, 0.23469399630234078, 0.2384189382715861, 0.22707636445417312, 0.1751216303271731, 0.1839975388683881, 0.16468647059735542, 0.18117243746693934, 0.1945391409317555, 0.17989787862481954, 0.1853745584888099, 0.18723329358189866, 0.17279964497836486, 0.12569548265754016, 0.18423640896289628, 0.18756623331862043, 0.4686048900786194, 0.19569692286168372, 0.14453978233342202, 0.1389078736976571, 0.4441452316762734, 0.4979273040114841, 0.43109590978192414, 0.16741797765842836, 0.30997081508895985, 0.3420100400342553, 0.16574292155585102, 0.16835095950052403, 0.1652165826806704, 0.1672012569218465, 0.3871108480941797, 0.183479587060014, 0.1883501375054445, 0.1896410833907909, 0.1881078331038305, 0.18216251312237908, 0.19171751950378169, 0.17595172448973062, 0.1922210360503981, 0.1892982549144252, 0.09334082824120649, 0.09281413292562446, 0.08682876515945115, 0.1208630802147147, 0.09936129216934841, 0.10177265264006441, 0.06926781522928982, 0.08217638297242924, 0.09626100571353746]}, "mutation_prompt": null}
{"id": "7966ce9a-5c1e-4e1c-a5c3-cfbe189cf3f7", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.simulated_annealing_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Simulated annealing\n                if np.random.rand() < self.simulated_annealing_rate:\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < fitness or np.random.rand() < np.exp((fitness - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight.", "configspace": "", "generation": 116, "fitness": 0.20799416889931752, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4651218150545806, 0.45589824866720097, 0.4262353565768424, 0.4530063199026909, 0.44230122435879926, 0.4347853131525571, 0.4477532120817902, 0.4545933914711482, 0.4494412832538426, 9.999999999998899e-05, 0.0024662652581289857, 9.999999999998899e-05, 9.999999999998899e-05, 0.0028813678589021396, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11056495236880359, 0.11225764785230008, 0.10599363294729647, 0.07769546932955751, 0.08193277032216717, 0.09011043466098889, 0.14980668232918692, 0.1291255162537256, 0.08504825989951259, 0.08845979220842926, 0.09531483689671005, 0.09244202896011533, 0.10999247391050049, 0.09543423060301026, 0.06774705850701612, 0.09888475066005376, 0.11490610708716853, 0.07879996316095117, 0.8993109000833981, 0.9367696869329974, 0.9086344795864194, 0.8484172771154761, 0.8758365205902463, 0.866850277777776, 0.911329636365458, 0.9125752619269889, 0.9245378888941901, 0.2543470907988512, 0.24091205373336189, 0.2143164423229127, 0.2614884443239289, 0.22051784217171722, 0.24669070296627915, 0.21216693359376326, 0.24725638043811715, 0.23828417334970176, 0.2731060674464776, 0.5814229069163597, 0.3384423763602483, 0.260017951813429, 0.25628989466921015, 0.2024348438688166, 0.27936352558895206, 0.22634512698188514, 0.22725524435010525, 0.17371136430034806, 0.1517874699939088, 0.11431610261176117, 0.08550035118408283, 0.12314852176919866, 0.12935313607387855, 0.11871180061857867, 0.12536365778553848, 0.12890516519288742, 0.17334124858268696, 0.20506320417024992, 0.12856875834071013, 0.16405952284353775, 0.1398294452447626, 0.12372483819990399, 0.1266160653029721, 0.16227760290593973, 0.1412398227446876, 0.00011765235913696603, 9.999999999998899e-05, 0.004310164684113493, 0.0019927469384319885, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014975052586148174, 0.0727336764205585, 0.12447463106010037, 0.17430336542675795, 0.09283105654504764, 0.08611412555003894, 0.06779358270901481, 0.11031808320715664, 0.0848313797638075, 0.09799941083299912, 0.035553358821843406, 0.02399691019673733, 9.999999999998899e-05, 9.999999999998899e-05, 0.0004488819689937307, 0.0038303994893874593, 9.999999999998899e-05, 0.0005537093610888943, 9.999999999998899e-05, 0.10100789049554537, 0.10840032041756764, 0.12429319174495834, 0.0954441924907855, 0.11503446270170847, 0.10114822758312125, 0.09910088556240915, 0.07048287226132866, 0.07270036478900943, 0.41365166764967454, 0.41429247282858606, 0.41126154181324126, 0.4229955299657764, 0.4079093715132506, 0.4335972011385377, 0.39510605509135377, 0.4187860736930372, 0.40332409214485965, 0.11217047781068812, 0.10491858453244962, 0.09066912628981083, 0.0917474891293023, 0.1219880602155079, 0.0969648338029927, 0.10557018308733901, 0.1334504818966601, 0.10529795648299733, 0.13580590503515888, 0.1761335802306747, 0.17247182108636394, 0.18715628708301468, 0.17411076743707543, 0.21337298078778755, 0.17634883106008237, 0.17625211356963066, 0.19012172202655442, 0.2650744875288935, 0.3047665139202076, 0.29433686715598206, 0.30105184247801786, 0.2728106903614904, 0.31239630327252543, 0.24813516242157785, 0.289263156842515, 0.2970594577160759, 0.18794471128364676, 0.17126326360530275, 0.23774407768997086, 0.23423332002274033, 0.24061467567083183, 0.2254554150742507, 0.16445362125780372, 0.21961149321681994, 0.16857148399999644, 0.23367207344768515, 0.20950315405567677, 0.24278622640506187, 0.27617344792007426, 0.23171411316193713, 0.22179506592537435, 0.2415219753118999, 0.2873312992970335, 0.24399677959420496, 0.18350258593382418, 0.1833032878758155, 0.19353418427683378, 0.19217892734240005, 0.18525418868068955, 0.18248015366466563, 0.1838886441283224, 0.18402779135578162, 0.1787751602425235, 0.1294114112141781, 0.18575658776039994, 0.18561820103678106, 0.17130128659784882, 0.19620803539106402, 0.11381975998663951, 0.13962082346893334, 0.6627281663212333, 0.5410754785316885, 0.5378261998637927, 0.2092051946106993, 0.09290733009358043, 0.20538918138442797, 0.1653823688522199, 0.16642512897614248, 0.35216328608539593, 0.4504968271691301, 0.29802442936900264, 0.1806121650064355, 0.1917079079989764, 0.17506462226039676, 0.18317655347254203, 0.18189074979537967, 0.191813985917763, 0.182916459170141, 0.19595193245185283, 0.18011548754485684, 0.09683071517035291, 0.08518546190979703, 0.07082792237971958, 0.11303044554976183, 0.0935211328968728, 0.07885125002612181, 0.07859804455822872, 0.0920962905762408, 0.08965983891864548]}, "mutation_prompt": null}
{"id": "4572d314-df04-42d3-8d15-8f33301ff48e", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.velocity_clustering_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - self.velocity_clustering_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                self.velocity_clustering_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return self.velocity_clustering_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update and simulated annealing.", "configspace": "", "generation": 117, "fitness": 0.2114561555765137, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.47417969584717834, 0.4623084378811966, 0.46558187587830047, 0.42997039597289355, 0.4476221226073278, 0.46440545394764776, 0.43299371682711196, 0.4550390223564674, 0.47923659893588155, 0.022496570369913038, 0.025610920413827953, 0.003909558475424402, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00042027479067274776, 9.999999999998899e-05, 0.10884990232258329, 0.11304330600809576, 0.08678141826141927, 0.11058442712857253, 0.08799684560675358, 0.07017660493351341, 0.09314652235666376, 0.14059314338765905, 0.08161757796440394, 0.06387608837680003, 0.10548175698650064, 0.10200203829811527, 0.10062050697699942, 0.10776061411704507, 0.09708162283202271, 0.09675443705604081, 0.10507564751850329, 0.09394460161392382, 0.9105279635080485, 0.9524916158981538, 0.8711620694555461, 0.8552421539901526, 0.8950173027321497, 0.9222054095877426, 0.9346393676698639, 0.9319284483321971, 0.928403047418377, 0.23962948524607475, 0.24695810472873014, 0.2508613843529597, 0.2558723836292389, 0.23075937844319827, 0.24532811563382995, 0.24577961173427731, 0.23711152822365578, 0.23244962754562526, 0.27338222285605795, 0.321303914485748, 0.3559417304141712, 0.2510256136077267, 0.27012704563141543, 0.24411231173960934, 0.34008657128627295, 0.1845122647670594, 0.2788268836692359, 0.17168319711036706, 0.10575998838779765, 0.11708162712676717, 0.09045239928191673, 0.24538585507055743, 0.12719127074017778, 0.12753341104301985, 0.12477202133830834, 0.13033480774498862, 0.13733866538293404, 0.1519361723203989, 0.13845635493589603, 0.13614161787874313, 0.1431067260858837, 0.12670192349175635, 0.1601851218217344, 0.17926008002324256, 0.1328203326162024, 9.999999999998899e-05, 0.012660582617989746, 9.999999999998899e-05, 0.00020221262874364765, 9.999999999998899e-05, 0.0009248065069042966, 0.0015134029675994976, 9.999999999998899e-05, 9.999999999998899e-05, 0.08743217659183267, 0.06634659940070797, 0.13307257056521538, 0.06145254367897146, 0.06299141605974434, 0.03579612141300981, 0.15990692092986758, 0.06723921597777649, 0.05748807381641341, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002004401263835831, 9.999999999998899e-05, 9.999999999998899e-05, 0.002618512201432943, 0.0039299300143966764, 9.999999999998899e-05, 0.11628879437639117, 0.10360047397871353, 0.09266353524843729, 0.09745462448754438, 0.1128317565307616, 0.1013447259871777, 0.11502240427577015, 0.10529980199899236, 0.09810471947553412, 0.4545810885988941, 0.3957361074743537, 0.4088247424976147, 0.39343391094287905, 0.4016937184195416, 0.437906497878804, 0.3828559520433429, 0.4273392277687371, 0.4029898631060128, 0.09657757673938971, 0.09880587419412135, 0.09189944071973455, 0.11362632503326675, 0.10110213213301555, 0.11212935538986712, 0.10175442087939557, 0.11430539519906868, 0.10211375371123343, 0.18293124136309047, 0.20012300723996612, 0.14006255190037953, 0.16170383528082055, 0.19116842504837506, 0.19552270480842704, 0.1786466872300827, 0.15629281351723712, 0.23127516548796545, 0.30216482392524446, 0.25343126567253227, 0.29666698380807033, 0.2786351287478779, 0.28500995500893, 0.28965816901435215, 0.2623780580987328, 0.30218597105041556, 0.24253032375819117, 0.21483379900294208, 0.2488231917534327, 0.20641270891304253, 0.23877171850462542, 0.21081775659859092, 0.23014532449643477, 0.2093820595564697, 0.23803392560190595, 0.17597581177996713, 0.2259995834779881, 0.23210860919383658, 0.2234656078684979, 0.28205623821515147, 0.23321423140037156, 0.26551819203966043, 0.2084833204389812, 0.23171466312188382, 0.22403061965437743, 0.18783700077930465, 0.17775955961481282, 0.1744884998533318, 0.19220037827188452, 0.18374532190757953, 0.18536365111024733, 0.2170739968682115, 0.1918750424703216, 0.17810856543701337, 0.18532073876073407, 0.18493671765678588, 0.18717104382014071, 0.5671195325914495, 0.19990488415201435, 0.16709464361868054, 0.17188316968370998, 0.5622651236630176, 0.6073292374568899, 0.4693605316071662, 0.20666639067232484, 0.33441432647030955, 0.3963981487186279, 0.165269608201427, 0.16863201601662425, 0.1666997550810655, 0.37758975769844005, 0.3601174796174321, 0.18825476440885913, 0.1859026474547748, 0.19802402951958675, 0.18173015831889594, 0.17903709909232457, 0.17937494230847062, 0.18723070318231072, 0.19395857207850675, 0.18579284298717103, 0.0986778899809504, 0.08709576467677471, 0.10065568288452109, 0.12393282061194677, 0.08853735057700018, 0.09079299765309601, 0.09271808688424621, 0.0880298677913599, 0.08952924897745851]}, "mutation_prompt": null}
{"id": "3819baf2-6914-4288-a084-a4759192a723", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.velocity_update_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                if np.random.rand() < self.velocity_update_rate:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update and dynamic inertia weight.", "configspace": "", "generation": 118, "fitness": 0.20747388296349029, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.18.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.48013895128184836, 0.48152297590886295, 0.48716259151880537, 0.5063213496326902, 0.48192210647720335, 0.47819080319658813, 0.46573141618675684, 0.49483952166330014, 0.4376173461660503, 9.999999999998899e-05, 0.028592929820037916, 0.03508605211740923, 9.999999999998899e-05, 0.00017584121390368246, 9.999999999998899e-05, 9.999999999998899e-05, 0.008449415801892846, 9.999999999998899e-05, 0.1267964971839015, 0.13042356699285773, 0.09637564366691609, 0.12051136414821617, 0.07934925334901544, 0.10279295625069118, 0.0852392750752693, 0.11250666094590778, 0.09592829126171998, 0.08404177090617937, 0.10717163580739086, 0.09060659496615608, 0.09247984200892612, 0.07074416793881078, 0.08348527332345623, 0.13184278377858372, 0.09976168361853521, 0.0791807204156244, 0.8753557832892196, 0.9350959018626661, 0.8572520076079362, 0.7601309638829936, 0.8591331931273477, 0.850594445587068, 0.8848721115945003, 0.8890953180769806, 0.8486091463768795, 0.27478195799479677, 0.2578640433021434, 0.24382962111803663, 0.25439931774624824, 0.25254642163655217, 0.24582063183331682, 0.26957270985778825, 0.24857516207324037, 0.2618036690063017, 0.31710019293283975, 0.23448560434084476, 0.24791404440443088, 0.32396880176699727, 0.26249851333894725, 0.20172883734058777, 0.21572257219178592, 0.22159989199189245, 0.29271245434304183, 0.1248720601043759, 0.10346279104591594, 0.1517205935218333, 0.13410124768806275, 0.16295104573739883, 0.17804081588190623, 0.1411265296989559, 0.13895346603336767, 0.18128615980935303, 0.15124454719584168, 0.15705918279695996, 0.17393830841411728, 0.14403635565078698, 0.16902017769297584, 0.15836591811718115, 0.163971972461465, 0.14146067689356934, 0.17886995685994478, 9.999999999998899e-05, 9.999999999998899e-05, 0.015263766864356487, 9.999999999998899e-05, 0.008830161575582696, 0.01087788715780369, 0.01714148281434935, 9.999999999998899e-05, 9.999999999998899e-05, 0.13594348496131914, 0.03613449560592685, 0.11641217929976277, 0.08585776653757549, 0.048196298788869885, 0.044168968055604774, 0.09909107399518036, 0.05602634144121399, 0.09865303931470482, 9.999999999998899e-05, 9.999999999998899e-05, 0.006020980485135663, 0.00018061978750649743, 0.015950487526081858, 0.005593581847395779, 9.999999999998899e-05, 9.999999999998899e-05, 0.000882594100803491, 0.11471965403576434, 0.08498767619346781, 0.09948617387556224, 0.10013461953846203, 0.13186972867251257, 0.09026141053136527, 0.11246972369665453, 0.09504678104186282, 0.09759565496675371, 0.43402759078600917, 0.42917599930553096, 0.41115312871204734, 0.4611905738823574, 0.4112903410806181, 0.42313222747122314, 0.4107280590558936, 0.4433355037685144, 0.4202191335391351, 0.10647610739199553, 0.08676153956646815, 0.10406405636579608, 0.08793396178740609, 0.10061559686271904, 0.1435774975488715, 0.11623485370676478, 0.10505474936172776, 0.11691044859629396, 0.12757849188086234, 0.21291791668088955, 0.15161838427883845, 0.17959105531940855, 0.19704738095425967, 0.1933221439737869, 0.17400859748961206, 0.18411523405217434, 0.19205105307899817, 0.273709279637001, 0.28652497337007354, 0.2877291139914231, 0.252941544783429, 0.3083255656950511, 0.30974880293328166, 0.23085878860019626, 0.3156659820193597, 0.23965690254731042, 0.20475575971220839, 0.18401690267671933, 0.2547398478581082, 0.2152543352993751, 0.22637781047392713, 0.21737570124432504, 0.18196543597842152, 0.22219218700294252, 0.20208620065158, 0.2620710409699123, 0.23372969848705927, 0.23131363507290903, 0.24711454514657327, 0.24530422483237835, 0.2269019570594809, 0.2491611844133116, 0.2623261840453641, 0.24677646581000645, 0.195771103713399, 0.17557694265888346, 0.18413854370653715, 0.21376835095508018, 0.18742822450679208, 0.17288308824213217, 0.21509182240250913, 0.17776719503445815, 0.17817483995131733, 0.12827628265489743, 0.17345227022785914, 0.1875358057296843, 0.15164528292381785, 0.19849309026340112, 0.1952553813687663, 0.1406814868903148, 0.15013563036100297, 0.16489203245080408, 0.4695914298392304, 0.20874963994197704, 0.5512058271908984, 0.5722755922360329, 0.4285064481253076, 0.16645444439219392, 0.16680421910778553, 0.29438917642739704, 0.1661462071788644, 0.20554959239453374, 0.18220528971503347, 0.18604779018105033, 0.18342285756118426, 0.18127893399122796, 0.19437916362842889, 0.17913336303053307, 0.18503422706013894, 0.19884070029546386, 0.08980941427145117, 0.07329454445161032, 0.09260893124771685, 0.10264503758090848, 0.08831701641571621, 0.09606601173473228, 0.09548485259543993, 0.08805395435882435, 0.08860994474415307]}, "mutation_prompt": null}
{"id": "af1d60c4-4ad6-4f2e-9ee1-5e65db110e91", "solution": "import numpy as np\n\nclass NovelAdaptiveSwarmOptimizer:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.hierarchical_opposition_based_learning_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def hierarchical_opposition_based_learning(self, position):\n        return self.lower_bound + 0.5 * (self.upper_bound - position)\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Hierarchical opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                if np.random.rand() < self.hierarchical_opposition_based_learning_rate:\n                    hierarchical_opposition_position = self.hierarchical_opposition_based_learning(self.particles[i])\n                    hierarchical_opposition_fitness = func(hierarchical_opposition_position)\n                    evaluations += 1\n                    if hierarchical_opposition_fitness < fitness:\n                        self.particles[i] = hierarchical_opposition_position\n                        self.best_fitness[i] = hierarchical_opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], hierarchical_opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = NovelAdaptiveSwarmOptimizer(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "NovelAdaptiveSwarmOptimizer", "description": "Novel Adaptive Swarm Optimizer with Hierarchical Opposition-Based Learning, Levy Flight, and Dynamic Inertia Weight, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm.", "configspace": "", "generation": 119, "fitness": 0.21415936683639877, "feedback": "The algorithm NovelAdaptiveSwarmOptimizer got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4499288408952129, 0.45300542700690627, 0.4827686078215391, 0.4517756106152099, 0.4441859544572354, 0.4226483915834277, 0.4472127078241678, 0.45880107376555557, 0.4737059188213265, 0.012669898845325545, 0.03824349020732043, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12291864370324235, 0.0648126359876382, 0.10444536173286378, 0.08381237515318041, 0.09353117158092539, 0.11183283101274866, 0.1407736735472077, 0.1441175874903794, 0.10446949822315854, 0.08691998319740357, 0.09917525092622548, 0.10474431484383862, 0.0869165177888368, 0.09588602470034657, 0.0757178154569298, 0.10004960649450845, 0.06795917811945273, 0.07673237626907614, 0.9105282733437153, 0.9288555732898414, 0.8905062253331721, 0.9093881476432829, 0.86823652471642, 0.8873742745280643, 0.9207177230327783, 0.9117061913977408, 0.9251936042358514, 0.24393579897665518, 0.26441900963998755, 0.24362456049437342, 0.20676861978091243, 0.23096580016831014, 0.20407884971495027, 0.2269831955183753, 0.2288755985639881, 0.2633819358554458, 0.31969494521828046, 0.7520172749170492, 0.21431070625934856, 0.2601633618750522, 0.3574027157951446, 0.23901672557646347, 0.23865207050518578, 0.26987225474485455, 0.22715000083904224, 0.13238265080044131, 0.1309469988821209, 0.13181237524093126, 0.1101799511404612, 0.14193256981340252, 0.11795653942508944, 0.13274940985079287, 0.11543827866100509, 0.14424046591808715, 0.15843520622402252, 0.15915188630631205, 0.13011075907603298, 0.13082590789955206, 0.12468174506249419, 0.1379669316145592, 0.15696054876583565, 0.14568218947642164, 0.15970572079443723, 9.999999999998899e-05, 0.04395940370989215, 0.008411749055709294, 0.0041798218457003156, 9.999999999998899e-05, 9.999999999998899e-05, 0.0016443556936684978, 9.999999999998899e-05, 0.0005069301349208688, 0.11697589946378395, 0.07874895058572673, 0.11012076236755419, 0.09682264758125603, 0.08239804608728685, 0.05041193234592012, 0.1433434908163368, 0.14563208559439333, 0.07523299236050862, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12758188510349777, 0.10635335996188644, 0.09500039753113365, 0.07294775348244342, 0.1175533724851825, 0.12325100254013599, 0.09128391436808814, 0.11472483290987434, 0.11351692545612369, 0.4260622436287119, 0.4261756726993329, 0.4125523750649195, 0.39369435998251834, 0.40155359782749966, 0.40750516644407964, 0.41789637295470516, 0.396147820331753, 0.39980252204705036, 0.07934132883623246, 0.08220225322477148, 0.07258462614880368, 0.09728258087745867, 0.07175693466968336, 0.09729127688909411, 0.10943523671722999, 0.12508228689349687, 0.10170406735723625, 0.17574141354868755, 0.1689336788121817, 0.17900858223778449, 0.19103653697219247, 0.18858417903273872, 0.19472126471487783, 0.17634483776149756, 0.1819789164780352, 0.17092208757865923, 0.2764419069777966, 0.3034517511781303, 0.29116540501016475, 0.2801212259323608, 0.30264154224829987, 0.3256682155543842, 0.24714850387336806, 0.296691791367396, 0.2170210312699583, 0.18971057176808037, 0.22677822054817798, 0.25626427127092766, 0.2656477187992101, 0.22089275646677886, 0.22048843723746236, 0.20194129237681135, 0.2504474947611478, 0.20584050170921386, 0.22634614545517306, 0.2352025846902882, 0.23838451874395528, 0.22788110109606408, 0.21633655589522371, 0.2574087239345648, 0.23885389208648944, 0.23057774937276176, 0.2139310214657928, 0.19875756132104383, 0.19121391697891799, 0.19489993516452875, 0.19386039829736157, 0.20806408672535626, 0.18394334349297503, 0.19422416148664767, 0.18783475052123455, 0.17893681197669353, 0.12680252409395, 0.18628546894971865, 0.18609992234679607, 0.5931893904032433, 0.19913960885898363, 0.19177675349502943, 0.1412513407131406, 0.6655329404412014, 0.6888427320609141, 0.4458581487796396, 0.20443010964697872, 0.45159277757894845, 0.41790194863871877, 0.20186832163655188, 0.16686669437198565, 0.16382582472900253, 0.40875103822351966, 0.3743378938671936, 0.1896626800727247, 0.18956318659957994, 0.18229301242344254, 0.1751295330261644, 0.18234582682996026, 0.18898888568173666, 0.18507627731579235, 0.188625018553352, 0.1754116155764145, 0.0788364802801017, 0.0855713239619732, 0.09119317079657963, 0.10582160384832628, 0.078751633115276, 0.07775163030075494, 0.08770462991433636, 0.12706503279619807, 0.08657276347943321]}, "mutation_prompt": null}
{"id": "436da71b-cb86-4aed-b12b-b46631069ec8", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.adaptive_opposition_based_learning_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)) * (1 + self.adaptive_opposition_based_learning_rate * np.exp(-evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive opposition-based learning rate and dynamic inertia weight.", "configspace": "", "generation": 120, "fitness": 0.2179674378999134, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.44498344049191185, 0.44337449813484786, 0.45877063773048476, 0.44125432475131565, 0.44715785278063613, 0.45085034001475066, 0.44348056601622354, 0.5066910934137643, 0.423257832571471, 9.999999999998899e-05, 0.025635257846377657, 9.999999999998899e-05, 0.00010303969499581012, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13050881592288732, 0.09092307724003434, 0.10209885097155491, 0.11438399698760371, 0.1322607758851273, 0.09086664202340256, 0.11967799449000849, 0.13026352367091276, 0.08332082714550448, 0.09588364460262311, 0.11238252158294493, 0.10319685749744245, 0.092129623886825, 0.09227860225631701, 0.08539840981308566, 0.11294907852302272, 0.09867447780943117, 0.09017759142412773, 0.9139022534599567, 0.9451916840068095, 0.9092688504139625, 0.8956850319978324, 0.8863296249455396, 0.8984829104281988, 0.9267484664547952, 0.9274132306869658, 0.9142066612972743, 0.26992226186498425, 0.2529690930795373, 0.26927162930784987, 0.24641209688597943, 0.2537930147140892, 0.24333565296716064, 0.26757926726208503, 0.2306642338381124, 0.25083313328151646, 0.3139652051953459, 0.5234944360705428, 0.28083213857627165, 0.2573778089413623, 0.5878493732671142, 0.1997188916733713, 0.2981917873013207, 0.17431409185202318, 0.31799541982632196, 0.10623016601879409, 0.11744721609850062, 0.12992550686109394, 0.1490127750139265, 0.12000427444672224, 0.2029833349554947, 0.20546238345526502, 0.12869586257495247, 0.14723202225788978, 0.1674286399937266, 0.16997411081617142, 0.1542145640738536, 0.1814410010555828, 0.12367781212005136, 0.16484008391760818, 0.15068801365225026, 0.12467281384532469, 0.14137292986694538, 9.999999999998899e-05, 0.0003204187106371492, 0.0015836087860013892, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0015847345383841471, 0.00027724482079849455, 0.000363965959476964, 0.1382307470131805, 0.039791112838586384, 0.08336808072272595, 0.07748500197784813, 0.10744144365065, 0.022050667131811807, 0.09957542522144502, 0.07484951272230878, 0.07198335596316807, 0.013714910393669566, 9.999999999998899e-05, 9.999999999998899e-05, 0.018779384777059982, 0.00504497775144408, 9.999999999998899e-05, 9.999999999998899e-05, 0.0004995627901025479, 0.0017145497024172451, 0.10001630531790362, 0.11303480273029765, 0.121587239519791, 0.06359994231823474, 0.11906051979381194, 0.12151182087940982, 0.12108586302242386, 0.10057189569709246, 0.10179388923422317, 0.4415113271854141, 0.4254886409888129, 0.40547635783789726, 0.41830609077354974, 0.41515648892791246, 0.41244881635882435, 0.42799913785823096, 0.4246738330754347, 0.43529526783941985, 0.10374270033421851, 0.13799191130886246, 0.07417095313626743, 0.11484154631079802, 0.10017470679404816, 0.09796680325124674, 0.10471568287054944, 0.09980918970985209, 0.09448490675853372, 0.18291255107269166, 0.22410306264126745, 0.12419546146687299, 0.1839175880657259, 0.18863731785642734, 0.20465829659523127, 0.18196902072400212, 0.18707870696971263, 0.17018990367186193, 0.2905666581840959, 0.2826675105031935, 0.3078333095983843, 0.27318219947137024, 0.2734000058391389, 0.27226225585968455, 0.23996010288391234, 0.2793172060580258, 0.2909840624437102, 0.2004470702258221, 0.23154556427826856, 0.1983626932783542, 0.21495077369358306, 0.20102613826618432, 0.2268711709870258, 0.19354632903376334, 0.2315042100281447, 0.16410326669069586, 0.2323896196992764, 0.2208434812142399, 0.23994778202609013, 0.21993525928228486, 0.22807781749452838, 0.23556355142167162, 0.22527398341355942, 0.20636138212619848, 0.23100575030409043, 0.18149845266400655, 0.18307752877758143, 0.18935314725060126, 0.18551744206622667, 0.19504750377408653, 0.18478789345011215, 0.1917189281339542, 0.18263800405519026, 0.17495493693759467, 0.18437492020056412, 0.1869525527807555, 0.5462162057604769, 0.1184998514946698, 0.1982248991751977, 0.11383877924163388, 0.14102407735888867, 0.6026725587506607, 0.6878962018232078, 0.6110109808797743, 0.5152906352708936, 0.44728095875476226, 0.3717748953724108, 0.36831982848849176, 0.16689898887997556, 0.16634047128476703, 0.3927306029765082, 0.48092166827946625, 0.17827233452309577, 0.1834707117180121, 0.18887577896390362, 0.18846015636910096, 0.17216928385275276, 0.20194051091660714, 0.18707167873853536, 0.21209008342043223, 0.18061812561655732, 0.09019133022318837, 0.08432015615304678, 0.08346028996716726, 0.08721663087883302, 0.08780473429986346, 0.09474580792218934, 0.08348480005273773, 0.08740736416363215, 0.10025153024520095]}, "mutation_prompt": null}
{"id": "922ba6a6-3565-44a1-817a-4e4f237063b1", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask * (1 + 0.1 * np.random.rand())\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Refined mutation strategy\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget)) * (1 + 0.1 * np.random.rand())\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a refined mutation strategy and adaptive cooling rate.", "configspace": "", "generation": 121, "fitness": 0.21072315247517479, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4423561224658741, 0.4398247858357347, 0.47639031131085763, 0.4732594881840291, 0.4612412311692736, 0.43037700434519444, 0.4755653172215144, 0.46281937414953567, 0.43901169173121357, 0.001912688232718951, 0.03020168616098784, 9.999999999998899e-05, 9.999999999998899e-05, 0.004414854256017731, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09506869352776415, 0.09900738469482662, 0.10768299568388195, 0.1069441227403719, 0.11061994379013818, 0.1043149017083208, 0.0837548611229133, 0.15379355064898514, 0.10186853960818187, 0.09663601369245589, 0.1022272136268021, 0.09354057346919142, 0.08706036616280144, 0.08455195534892812, 0.10130472980909255, 0.09709555553677907, 0.09204484489524634, 0.09354525695445937, 0.9150220684478018, 0.9484744598222052, 0.9063236523007288, 0.8520309463961622, 0.8648894481351431, 0.8827477654515157, 0.9218721785098127, 0.9347937446114165, 0.9220739804187458, 0.25698799431163877, 0.24380529840936616, 0.26352020483370386, 0.25942532974499966, 0.2580242989127036, 0.2328584615678575, 0.24218542470186089, 0.2411200180283506, 0.24021199963540008, 0.20998345395871332, 0.32831096401423643, 0.30081101354243345, 0.2642836062947318, 0.3552689600069959, 0.20682531376286273, 0.24222383484746102, 0.23000131100916021, 0.3392496949376893, 0.13340286148843772, 0.13421102921325623, 0.1165909994589085, 0.13770022773679813, 0.12759182408752334, 0.13161872508531247, 0.14439270039798047, 0.22804058529234683, 0.12455268774878936, 0.1430539798408017, 0.13160259898523596, 0.13955283102260796, 0.14342727935506305, 0.14085711517050914, 0.13667170264514938, 0.14004641283668373, 0.12554632296687107, 0.12324157682031689, 9.999999999998899e-05, 0.018524096982598715, 9.999999999998899e-05, 0.010047753968984163, 9.999999999998899e-05, 9.999999999998899e-05, 0.0036486485219949794, 9.999999999998899e-05, 9.999999999998899e-05, 0.08610466253043692, 0.045931868417433686, 0.10898815972177178, 0.0676589207608227, 0.10931258878188488, 0.03120282116871964, 0.11343299877961543, 0.16393698248825894, 0.05836874314372453, 0.014762802537093944, 0.023242632170111355, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0023392390197118917, 9.999999999998899e-05, 0.00012664960724251273, 0.1078821070396212, 0.07529300338997569, 0.10565701768073665, 0.09354995293336177, 0.10037016532448673, 0.09199081707796142, 0.11879076776524311, 0.10358461767367921, 0.1026369421503579, 0.3984681745722223, 0.4461494964571171, 0.4244307697486952, 0.3839805922085985, 0.42394890370741956, 0.402384959318707, 0.38847959852433034, 0.41182336154526855, 0.4223250585632671, 0.09699487330426149, 0.09002300406122321, 0.0818820846520657, 0.12413893458102288, 0.10369087920882825, 0.11267613786921371, 0.13131420291713147, 0.1468114813908682, 0.08706945597028148, 0.17859650563137397, 0.15980622658415355, 0.1841837119289288, 0.1903324336225103, 0.19864898806591158, 0.22568226652700218, 0.162644159275401, 0.20159733333571117, 0.1545362286345371, 0.2964497085887786, 0.29710031667293646, 0.2931018504943862, 0.28538572820914465, 0.30600038946727337, 0.3149005401777212, 0.2511777392038763, 0.300268234719579, 0.2811869466275242, 0.18632232426769668, 0.15713760183828074, 0.21705251026908767, 0.2215631665621196, 0.21680806967341615, 0.21214486946544908, 0.16493462446562313, 0.24561204796322267, 0.2295925578707314, 0.2327355032658438, 0.23150161936513303, 0.24737513960401025, 0.259681439169531, 0.2188346599098573, 0.24975018003765248, 0.29616331474791047, 0.24262650988357815, 0.22665799963878908, 0.17819164106252627, 0.17922453237762725, 0.17297147311296845, 0.18238649301847432, 0.19601994508097442, 0.19005845911210328, 0.1918549966346219, 0.17868835259221327, 0.17844726639461483, 0.12882090027442883, 0.1738667874303641, 0.18653776837333025, 0.6816179598636551, 0.19828883036192368, 0.19282944590661055, 0.14084450550226757, 0.16621207825858997, 0.5343053385946619, 0.5075317159444145, 0.2084250636032977, 0.3672353657049483, 0.3594091498161486, 0.362224735982855, 0.16714969823476644, 0.16740978790971572, 0.3645092268485872, 0.34960251221497396, 0.20034368486774512, 0.18902543194971022, 0.207720886805296, 0.19299014096640654, 0.1790178740163274, 0.18177067103067945, 0.1771078437989727, 0.1785116654810377, 0.17665818367472452, 0.09504709217450602, 0.0759601855604175, 0.09954156801787162, 0.08760386572874301, 0.08625588022435027, 0.1113352478595312, 0.11420084470339242, 0.08354453493880154, 0.08726798377615685]}, "mutation_prompt": null}
{"id": "5d91bcda-765e-4798-bc7c-f514e71dab73", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.refine_strategy_rate = 0.19\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def refine_strategy(self, position):\n        if np.random.rand() < self.refine_strategy_rate:\n            # Randomly change individual lines to refine the strategy\n            if np.random.rand() < 0.5:\n                position += np.random.uniform(-1, 1, size=self.dim)\n            else:\n                position = self.opposition_based_learning(position)\n        return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Refine strategy\n                self.particles[i] = self.refine_strategy(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a 19% probability of changing individual lines to refine its strategy.", "configspace": "", "generation": 122, "fitness": 0.19764683865460667, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.39500962723969346, 0.40523424719271783, 0.37723175380707274, 0.358387144383274, 0.4459313561497401, 0.38939503779141105, 0.41913793063281524, 0.41767455775279505, 0.408732132814711, 9.999999999998899e-05, 0.024070678530329292, 9.999999999998899e-05, 0.0041666403038700395, 0.014114991034483548, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08936302079207781, 0.10831857770630993, 0.09172384879926354, 0.09624460556157699, 0.096389073397944, 0.0768693917097848, 0.0886868186678812, 0.11743011127335612, 0.09195000903453843, 0.0749636977843322, 0.08075874438225528, 0.0849816432778091, 0.09057987215771102, 0.08821790032181054, 0.0935831729450658, 0.09063186012211322, 0.06629627004752714, 0.07404113227803721, 0.9101232267283694, 0.945183989126921, 0.9102335187330926, 0.8583506495950326, 0.8907746240472373, 0.8253673597182798, 0.9135587589738898, 0.9347981722129011, 0.9078989890600639, 0.24776057151407072, 0.20761766749324517, 0.21515342203482646, 0.21945246783101824, 0.2129172932664697, 0.21745326399659393, 0.21623447888405822, 0.22352945898354848, 0.22460389520311919, 0.295998903217254, 0.2840032035598299, 0.24402331571255242, 0.2129419952625271, 0.32887347812165724, 0.25300564586939345, 0.22794318758800491, 0.22031040308087002, 0.29422223059995367, 0.12073601512077914, 0.11959442058570802, 0.13160020349502433, 0.09998302998939002, 0.1303010957744033, 0.1757671053389679, 0.11914647202744766, 0.1066357835720968, 0.1519922687415336, 0.15653243960493401, 0.11697879555161583, 0.1563912464721272, 0.14771353783256347, 0.14349183537578702, 0.13586332358212017, 0.15340977418657908, 0.1588076921735746, 0.133838653614619, 9.999999999998899e-05, 0.0011100635414134086, 9.999999999998899e-05, 0.0066904391659081686, 0.012245713501693567, 0.0054433043851839225, 9.999999999998899e-05, 9.999999999998899e-05, 0.011314471489130673, 0.09873623912678409, 0.04960062310632907, 0.12294863809983292, 0.05103859733014815, 0.05330219335019959, 0.037541424079635566, 0.13860315193542283, 0.09717636358434889, 0.04448808891604672, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07500891300464319, 0.08878460870646887, 0.08720566968409915, 0.04890551481635719, 0.1020421581419132, 0.06598060192200761, 0.07542992575304541, 0.09663965798417662, 0.09512973784121082, 0.36784602790040866, 0.3547609161182135, 0.3456786920861007, 0.370452885075776, 0.34795646667512714, 0.34104639115200286, 0.34271932773297953, 0.3910759688891926, 0.37703704803746385, 0.086147693852761, 0.09632681035007207, 0.08651566115337483, 0.10061462328801174, 0.08593443939652134, 0.11060863856382441, 0.08974095286219508, 0.11538663912626801, 0.10535394358625094, 0.1606447713650836, 0.19127801867491612, 0.1457244780421072, 0.13958144108537107, 0.21933378877241927, 0.18282602992274288, 0.23397613065331335, 0.15071365229739242, 0.16242792311866672, 0.27697978828765835, 0.24778111693860805, 0.2705910684567042, 0.2568680648356564, 0.28098606918930125, 0.2716651144509402, 0.24745085552419765, 0.28040683484038953, 0.2491089187439972, 0.18240055525355114, 0.21553624057236698, 0.2024318221993643, 0.19526103418494067, 0.19620759279526956, 0.21177678414791212, 0.19466189164641734, 0.20506318481881203, 0.1944870538153458, 0.23931098280967666, 0.2188457958436021, 0.21538891580064412, 0.21989268379323157, 0.24405829926605827, 0.24298614902538362, 0.2522474257257237, 0.22197781142574635, 0.26395404481728046, 0.18853817920752047, 0.17205360417713977, 0.1733324918386786, 0.1797154128909786, 0.1872327021141429, 0.1789637284888137, 0.18873774874788307, 0.1867301577296373, 0.17188247336159235, 0.1263024811472263, 0.18338908916267194, 0.18371489475649327, 0.16996625281837163, 0.1982639276785101, 0.1676495237923884, 0.1393601345361627, 0.5146998342132749, 0.58711161493586, 0.45426575555162163, 0.20613265409680925, 0.5773588161851546, 0.35117904774718334, 0.19979113885942368, 0.16720629013383992, 0.16665207100602586, 0.16472113309524083, 0.3910796558114845, 0.18258643293170085, 0.1782435458104734, 0.18072732062810715, 0.17883759441895675, 0.18299634322917535, 0.1969792294543652, 0.2087690896812312, 0.19341045814501867, 0.17764353682266032, 0.0864187969674769, 0.07479410158044408, 0.08566826293455321, 0.09277643588971951, 0.07437853808384676, 0.10482261804262272, 0.09030091805380269, 0.08881066967741513, 0.10898717315964424]}, "mutation_prompt": null}
{"id": "cfd864f8-02bb-4c24-9e8a-546f9b270361", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.gaussian_perturbation_rate = 0.1\n        self.cauchy_mutation_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.cauchy_mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Gaussian perturbation\n                if np.random.rand() < self.gaussian_perturbation_rate:\n                    perturbed_position = self.gaussian_perturbation(self.particles[i])\n                    perturbed_fitness = func(perturbed_position)\n                    evaluations += 1\n                    if perturbed_fitness < fitness:\n                        self.particles[i] = perturbed_position\n                        self.best_fitness[i] = perturbed_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], perturbed_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a novel \"Gaussian Perturbation\" and \"Cauchy Mutation\" strategy to improve exploration and exploitation capabilities.", "configspace": "", "generation": 123, "fitness": 0.2122671686316947, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.46887778694589977, 0.44444269492675603, 0.45876081967997595, 0.4457864578085172, 0.4476039958129563, 0.42691288700984176, 0.44875108730864555, 0.40072112019550976, 0.42237961031100135, 0.010965031489702626, 9.999999999998899e-05, 0.0055571220012001765, 9.999999999998899e-05, 0.005132082589532905, 9.999999999998899e-05, 9.999999999998899e-05, 0.0003212545781833276, 9.999999999998899e-05, 0.11483429800658729, 0.1134219371628511, 0.09040300291100667, 0.1000989701498769, 0.11563366061163904, 0.11370508726716455, 0.08983741506911158, 0.12422714306656912, 0.10075862409678737, 0.11886686201298058, 0.09993252502973404, 0.10655118301772293, 0.10218465629508355, 0.07759087442944146, 0.1046122950642171, 0.09695099006691921, 0.07018521749412099, 0.08529516676393778, 0.8850194328956243, 0.9180412493406646, 0.885921525281715, 0.8684211379084344, 0.8438155864015346, 0.903829828266783, 0.9296661111679937, 0.8552917096055895, 0.916952815612249, 0.26031766292822456, 0.22894459314852955, 0.2701677279033722, 0.23521132242813791, 0.26293526179188487, 0.23620078235919884, 0.24177304703316327, 0.24122575166642612, 0.2544626161158632, 0.3019306019645913, 0.6739265490955391, 0.22517892727972344, 0.20952883430654978, 0.2669242236667806, 0.20574268163324327, 0.22264734167636713, 0.22843591310894384, 0.3713269871891579, 0.12677298793219327, 0.14007562711845167, 0.15197816894999672, 0.04973120642368778, 0.12056773649578323, 0.2421192146886746, 0.1451855876756063, 0.12046510463037341, 0.12842176750631518, 0.1383274190860433, 0.16591987386481377, 0.1534018188677866, 0.150750298193971, 0.14708497241573826, 0.1313988652983067, 0.17064686534925622, 0.13110385148304426, 0.16225446876480598, 0.004355250977425729, 0.06068429908843753, 9.999999999998899e-05, 0.01633313597885211, 0.05343442622886774, 0.005094434158010475, 0.004107184437989964, 9.999999999998899e-05, 9.999999999998899e-05, 0.1254119250438296, 0.10447655339991324, 0.13255811226867553, 0.08617908905104521, 0.07501990560656979, 0.060870945865554305, 0.08183854941783353, 0.050552028622932954, 0.10443514769274675, 0.020215630279300734, 9.999999999998899e-05, 9.999999999998899e-05, 0.00019882501106172068, 9.999999999998899e-05, 0.0014854081187477552, 9.999999999998899e-05, 0.005600203232780543, 0.01637823285636497, 0.10906778973831133, 0.10419412167625763, 0.05838992526758835, 0.12277194360018095, 0.12224479086286533, 0.06198037112949095, 0.07287130680024079, 0.1313011784203436, 0.08469403331045744, 0.3987489457057378, 0.4256426084779512, 0.40404457364858304, 0.4101788889151856, 0.3814503892373826, 0.42484368050944354, 0.4018464588086945, 0.38386417856653243, 0.4130572401604985, 0.10742393203071665, 0.08504773102494889, 0.0956003773571954, 0.14122495218680065, 0.11125131426183665, 0.10366897340307601, 0.09965294800646918, 0.13341222522146168, 0.09644545812362626, 0.14339686637727467, 0.14335835939757346, 0.13906331956495355, 0.21681712129958897, 0.17749569237911034, 0.17169202596162814, 0.17562660578901246, 0.19181020277873062, 0.18718012397421513, 0.29411563258897533, 0.2997631517266144, 0.2609033786454158, 0.29915108570175275, 0.2687731965020902, 0.24485028161441658, 0.23900552966294986, 0.30736227732815724, 0.2761111241856924, 0.2139419554950266, 0.20570240182537836, 0.23441092652903217, 0.22026160834297892, 0.2522474646286441, 0.21267172387811628, 0.22405643773944994, 0.22446281130394596, 0.1981873207770073, 0.23293931127804413, 0.22244280345215695, 0.21857563520233114, 0.21158567309649612, 0.23071094738978137, 0.2225267663859246, 0.2578743265058834, 0.239160237087076, 0.27345714164843926, 0.17036937521907625, 0.18983047904626005, 0.18040089815976412, 0.21749947708028317, 0.1775671834608773, 0.20706663560484329, 0.18918408452836366, 0.1971031950079969, 0.17890299489836148, 0.17884910174687807, 0.18637693205012307, 0.5553302344925826, 0.6149518893106811, 0.19940622361748295, 0.11450872282061231, 0.1408381212912464, 0.14464373896053817, 0.6535483537725167, 0.4260063648041962, 0.20927291899529188, 0.504935741937875, 0.46960561905764464, 0.16316453887692883, 0.166949016574937, 0.16622590996075615, 0.16164510645249175, 0.6013016203160899, 0.17811718096832063, 0.19307892700525786, 0.18998873643208192, 0.17418843872573486, 0.18595457355003397, 0.19365515610826267, 0.20926080354005105, 0.1751936265578935, 0.18798701589312028, 0.0985185199035219, 0.10911403978733214, 0.09399985819440848, 0.0960750845781122, 0.0917422952227378, 0.0864093584117338, 0.07835070277219203, 0.08592113851581729, 0.09827948270745379]}, "mutation_prompt": null}
{"id": "35ae613a-994f-4372-a7d7-7fb5932680d0", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.adaptive_mutation_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate * (1 - self.adaptive_mutation_rate * np.random.rand())\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            # Adaptive mutation rate\n            self.mutation_rate *= (1 - self.adaptive_mutation_rate * (evaluations / self.budget))\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive mutation rate, improved velocity update, and dynamic cooling rate.", "configspace": "", "generation": 124, "fitness": 0.20834016843997163, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4950398424419641, 0.45828233183321376, 0.4799665502302871, 0.4634224123229582, 0.4267149208382739, 0.4371209851810559, 0.4403054139590974, 0.44913944685541973, 0.43835355555767563, 0.026140396664453336, 0.02073387193102516, 0.004168083076170337, 9.999999999998899e-05, 0.03090148124325276, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11164384622865253, 0.09518635464282921, 0.11046626572679974, 0.07042277811929032, 0.08932070787028046, 0.08305011315292543, 0.14173031624571653, 0.12614295617028182, 0.12358929345169378, 0.10355585941982826, 0.09309669822949784, 0.08395944294120505, 0.08246825113583856, 0.07732675340025585, 0.09627252597946301, 0.09507151558320415, 0.08381089243036188, 0.09532737924937862, 0.9152047177853615, 0.9536521880356741, 0.8869562069310387, 0.9063050972158723, 0.8424357596742575, 0.8204328342481276, 0.9229255844149586, 0.9111123291390851, 0.9257371851459084, 0.24719570456125828, 0.21409276712509717, 0.2539100565525919, 0.2670947644463183, 0.24489589947323354, 0.2700495222894419, 0.2729416169942295, 0.24797090792201093, 0.24508250585533786, 0.3231888280257522, 0.26845328077315656, 0.30743563738813895, 0.21105036418830603, 0.35575487410940776, 0.23238385248774351, 0.28607049592685285, 0.2273124112414786, 0.2982245819069568, 0.19132867708665824, 0.1252199947319932, 0.12330617733444083, 0.0776278528762312, 0.13636422811154025, 0.12497742145646484, 0.15359580642713444, 0.1922554082117276, 0.12015732933779022, 0.14683864443164985, 0.13164494571271568, 0.20599718938000056, 0.12253350555119014, 0.13730283367228002, 0.14820609100354976, 0.14794391781908012, 0.11911787183967859, 0.13219638165148062, 9.999999999998899e-05, 9.999999999998899e-05, 0.022453826243649555, 0.0003732232701307847, 0.007979792488767457, 0.0063277138554490575, 9.999999999998899e-05, 9.999999999998899e-05, 0.001518008083336131, 0.11485271891992666, 0.07447707018118999, 0.11409381910133143, 0.1204752372534369, 0.08657703096858227, 0.08655141656440335, 0.13042986919652577, 0.11678825742019838, 0.098032745959033, 9.999999999998899e-05, 0.0006292794696614035, 0.0008380840192083738, 9.999999999998899e-05, 0.000646028273842636, 9.999999999998899e-05, 9.999999999998899e-05, 0.00012965900551153986, 0.004530073457724715, 0.09506339890187487, 0.09999463394602259, 0.07725355114028731, 0.12979579454478896, 0.09370756446481987, 0.06957597606896526, 0.12127294073125339, 0.05661721718557111, 0.11419401042258215, 0.3835450306894106, 0.48643734193019594, 0.4187821108224461, 0.4066636998797897, 0.39422953331247623, 0.4119662614401888, 0.42337731139582413, 0.45511038604319354, 0.39966740117386546, 0.10390048918955386, 0.09337084684573416, 0.1062834069377202, 0.1296201544063883, 0.09600963645085814, 0.12020330241702304, 0.10839964219164888, 0.08710439493564004, 0.09057383990560686, 0.14725755535288354, 0.17784561031448243, 0.17247004130267485, 0.15046655372857243, 0.1635154001828485, 0.26654301460731455, 0.16010393923252486, 0.22808113027739996, 0.22340379642221664, 0.25694941787750747, 0.30143511027414827, 0.3144779445425453, 0.2809289060174166, 0.29652440821736104, 0.3096264166049618, 0.2507947872935794, 0.30297061063385844, 0.2556888506275544, 0.22284589518507059, 0.08783237999709059, 0.21681303426555187, 0.21652858798209862, 0.21191074787894615, 0.23636739409642127, 0.21999539232159437, 0.20300207429009243, 0.20200942401063438, 0.2580601179975731, 0.2411113010446405, 0.23738155312761433, 0.21590052167161689, 0.25128871267206154, 0.21833354775521885, 0.23136484146949277, 0.23608138146940405, 0.24431960070124514, 0.20984616380794907, 0.1881192533542989, 0.17132746735529492, 0.25909249231384646, 0.18309345232829755, 0.1837633155122841, 0.1887391267124522, 0.20643926891450348, 0.17555854454027853, 0.12966365178744166, 0.18429622511454047, 0.18542530356052067, 0.32439825796724797, 0.19796935569994045, 0.639318319152177, 0.14170223037177787, 0.15849916450909318, 0.16266835248899092, 0.5850390597715482, 0.16856041120954635, 0.3713530992278824, 0.3691050503932206, 0.2047021779311673, 0.1662768255378605, 0.1668225257822099, 0.3600750513704438, 0.16650238409037388, 0.17491600491870107, 0.17355579309201818, 0.17899078548434322, 0.16755300027685538, 0.18595788323197204, 0.18884344098011885, 0.18636243531459784, 0.17920792058539758, 0.18763433274989183, 0.0867235287297008, 0.07959512838946325, 0.08515266340056094, 0.09228657773069282, 0.08674723833795928, 0.1090223390044528, 0.10356860830296533, 0.09214532749675985, 0.09568761904482637]}, "mutation_prompt": null}
{"id": "9238bc5a-4b39-4ec4-99fb-08f30a854a82", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Refined velocity update with adaptive weights\n                w1 = 0.5 * np.random.uniform(0, 1, size=self.dim)\n                w2 = 0.5 * np.random.uniform(0, 1, size=self.dim)\n                self.velocities[i] = w1 * self.velocities[i] + w2 * (self.best_positions[i] - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim) + 0.1 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined strategies for velocity update, opposition-based learning, and mutation.", "configspace": "", "generation": 125, "fitness": 0.16154257730721808, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.16 with standard deviation 0.12.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4030553479075456, 0.46306439334974503, 0.4468521277510257, 0.41272464725840396, 0.32090437832201457, 0.32911091138871174, 0.3472497922671881, 0.34012759708663043, 0.3540519144638823, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006006516264349671, 9.999999999998899e-05, 9.999999999998899e-05, 0.001115986293680593, 9.999999999998899e-05, 0.08411939533920709, 0.06808224539935237, 0.10265492512117869, 0.07522715783610368, 0.07017587431153371, 0.08834598398301785, 0.10876974155588393, 0.1201642594592589, 0.09329036951513081, 0.06128822467508599, 0.050983281862654106, 0.06872708005613548, 0.07000927855200789, 0.07329448398089444, 0.059812235413602144, 0.07990189922500213, 0.07393756709862631, 0.06773000848101907, 0.14285878568169197, 0.3888034090250151, 0.2991694256046451, 0.11982878590555623, 0.362731203540546, 0.1156766134470748, 0.3264386321817998, 0.667646592702175, 0.23470290319048814, 0.20600645281698549, 0.13487995663483832, 0.10686199660698714, 0.19432347947629125, 0.1643608084605812, 0.12501681793634123, 0.12197493606084131, 0.11823708109152353, 0.10384747463053678, 0.2031046212762022, 0.16842226681735517, 0.1688452693340451, 0.19556916523931878, 0.5436810035906402, 0.17407146564492582, 0.19422646502277996, 0.15628258921593297, 0.1588460268538049, 0.19346191042694405, 0.10340499463675057, 0.11165074540450626, 0.12921501488083287, 0.20580667889220872, 0.1675071030609543, 0.14188116095387449, 0.16599914146499428, 0.06031371151979492, 0.19228685201035944, 0.18463676416067887, 0.19112650233387607, 0.11912563920921371, 0.17543975728354466, 0.20339937515327844, 0.19190784976011976, 0.16133232795224794, 0.11979557174883615, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00045907615544804603, 9.999999999998899e-05, 0.015209925560505488, 9.999999999998899e-05, 0.019739612662520223, 0.16339609501156227, 0.08589213039790189, 0.13232924111164923, 0.07390185025996343, 0.05775845651553313, 0.05521588344678863, 0.06800640186166673, 0.08999704223813021, 0.07632733892910604, 0.006011556327656931, 0.011285462425999815, 0.002170483569015391, 0.02802869017783738, 0.028212473580031094, 0.017390107410209743, 9.999999999998899e-05, 0.0012364325554495847, 9.999999999998899e-05, 0.0948027449695581, 0.06653907274382742, 0.05302580982037142, 0.041740514411016005, 0.07671773414786331, 0.06996959001304404, 0.05601489933264969, 0.056938704002845064, 0.06982432538484751, 0.3692275499848541, 0.35238489688021446, 0.35991077276083705, 0.3203597218774913, 0.34261361079743136, 0.3095749989959756, 0.39779783058700946, 0.36840669185167285, 0.3816734694718027, 0.07122332956703026, 0.06418695405044506, 0.06277502115534572, 0.11689130334074238, 0.059259043412863144, 0.09863259018478643, 0.08490072961918527, 0.0766154907441573, 0.08013096588169522, 0.16103121339026727, 0.10660839294725688, 0.1223322654081368, 0.13759190717953373, 0.14928102318489878, 0.17050792988048302, 0.1349521612175375, 0.21041426883510594, 0.17781172448478955, 0.23847668455527793, 0.15865400407239705, 0.21346304319853726, 0.28428638272646467, 0.2585361276184752, 0.24333572645248325, 0.19141253448212348, 0.21965032378251914, 0.21593920597251826, 0.1653294057399426, 0.13029938076328706, 0.1909636346645499, 0.1709287792516876, 0.1827708393958445, 0.23280703497554456, 0.15170372559715417, 0.1864276736247843, 0.17973679138338283, 0.23654335812592253, 0.23410489860125527, 0.21877422475693487, 0.232758585574396, 0.22374714965878462, 0.2787343569404547, 0.252233748249174, 0.22981128291179986, 0.24850380123425397, 0.16173160788163077, 0.19407531974675174, 0.16597882745753179, 0.18110482313366505, 0.1665831583404428, 0.17647002580415105, 0.1730125574865511, 0.18983302608346142, 0.18209291745594203, 0.12181937658705377, 0.17998692764636692, 0.18072135104777787, 0.1665265594609726, 0.302963974422098, 0.5563308385567193, 0.15411300714139708, 0.12423203221335011, 0.4961128932518659, 0.4189449687962997, 0.6069484987132862, 0.3325699265398363, 0.3738640423395114, 0.13315530997827696, 0.15856792663442887, 0.1522676160390556, 0.16327192226791654, 0.1555637268461414, 0.1822492525834698, 0.17941937335708513, 0.1762768597097618, 0.18677238424399567, 0.1980803143066452, 0.1779142107401387, 0.1753175147959879, 0.20350640955218147, 0.1775194434939753, 0.07633006132313203, 0.09356945188462362, 0.08966037813062266, 0.08064656052235297, 0.09177905471418835, 0.08211258962068746, 0.08223463359845251, 0.08388624485298735, 0.06033149360894097]}, "mutation_prompt": null}
{"id": "2a86521b-ba48-4d2a-a56e-437cf4ac551a", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.simulated_annealing_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Simulated annealing\n                if np.random.rand() < self.simulated_annealing_rate:\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified simulated annealing and dynamic inertia weight.", "configspace": "", "generation": 126, "fitness": 0.21289777473720584, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4448941552702399, 0.4546566333895061, 0.46813650413542796, 0.43034719665864485, 0.41298032588000466, 0.4239895662930101, 0.4403931284263338, 0.4360019046784942, 0.46799448553575873, 9.999999999998899e-05, 0.06566706320315552, 9.999999999998899e-05, 9.999999999998899e-05, 0.0026938187127950597, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10645230757288704, 0.13728062459378543, 0.0880817854373428, 0.07107435234265191, 0.09372253894809235, 0.07626236969750078, 0.14778888771660237, 0.12083200512398529, 0.09066740644426352, 0.09489585098090725, 0.11017933162359317, 0.10478670995133565, 0.12241644768806803, 0.0780173312749961, 0.06986052912903218, 0.10635008542740199, 0.0950033724691377, 0.07660917794417033, 0.9011086899564318, 0.9450109752367123, 0.9037116609335054, 0.830747415684039, 0.8907584206984313, 0.866850277777776, 0.9106217079951178, 0.9125752619269889, 0.9245378888941901, 0.27585277769981353, 0.24171111113407462, 0.24372719655721553, 0.24243690660909534, 0.24031023196515078, 0.24407748411783936, 0.22972461044183956, 0.2234191806155219, 0.22738368595396397, 0.25229724002680887, 0.29418270057832985, 0.2616411288596874, 0.24130188008540732, 0.7712385953829374, 0.20268301915969, 0.6595916392308869, 0.2898729289258185, 0.31128025408352455, 0.1650025670098646, 0.12995710069789224, 0.15730329796704923, 0.12551132733138093, 0.12245612011885387, 0.12891753365287917, 0.12161996461252622, 0.10861734495351139, 0.1359345673244623, 0.12932332131141433, 0.1337693780624819, 0.14713597645173682, 0.17397014098951402, 0.14558768860418636, 0.12429588288663818, 0.1378720498233602, 0.2037506312640971, 0.13882211568109593, 0.030405607961329406, 9.999999999998899e-05, 9.999999999998899e-05, 0.014501552909841675, 9.999999999998899e-05, 0.0013229634229992016, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0889501921397774, 0.08605515419876397, 0.12454333075937052, 0.0987242575111964, 0.06418487958329788, 0.04115879541106837, 0.09839354899630781, 0.09149687289727804, 0.07087683407633338, 9.999999999998899e-05, 9.999999999998899e-05, 0.020188393550833683, 9.999999999998899e-05, 9.999999999998899e-05, 0.008096707379821821, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1341312636569585, 0.10024914709502997, 0.1037176686705994, 0.09526038186975516, 0.09393343684475042, 0.06190704479955289, 0.11360960974432532, 0.07825600602158156, 0.07610251011142732, 0.40862101462256595, 0.428816922252789, 0.41250858313301053, 0.4005950167892144, 0.37485367005106063, 0.43201880958526084, 0.39697868767909084, 0.4104776628086564, 0.4282768902200018, 0.09347189858747884, 0.11875357722810764, 0.09698619171128142, 0.1234728325712009, 0.11360837791082845, 0.13455169765418906, 0.13653317075760207, 0.1071988196235949, 0.14310505131706797, 0.17640564921233903, 0.14954758776923227, 0.13619393289251747, 0.15128756714052982, 0.1772065148854821, 0.19315941664540048, 0.16198488618625273, 0.14645291367593416, 0.1674871535664293, 0.28310224800010353, 0.26957660755293866, 0.29722041332478544, 0.2795045514856558, 0.24327275571284335, 0.2980522174013762, 0.24117578638158554, 0.2793408234536592, 0.2690227383813881, 0.21503992510049408, 0.22132660252611036, 0.25034660888415006, 0.24399481883637486, 0.24669302930593862, 0.216999263926566, 0.16549683107684665, 0.20185296423266164, 0.17675601833809618, 0.27006048718745634, 0.21693337264552548, 0.2216370041372696, 0.24340339279922296, 0.22906831971537145, 0.24148937983218965, 0.22556506039166035, 0.2312110207644702, 0.21558692364201848, 0.18594275078778177, 0.19957598985414693, 0.18654551309628964, 0.18592432241110346, 0.1730264865990474, 0.1747032998418666, 0.17333172680979692, 0.1871579899658795, 0.1783054292257128, 0.12997165121643595, 0.1859555384706738, 0.18580145532192904, 0.17146542375603835, 0.19651599497569772, 0.5803068764871069, 0.14062950506843375, 0.6759890903304565, 0.5878834803916331, 0.529603364581426, 0.207778418604601, 0.20222069433946122, 0.37442911715345295, 0.16516163232141046, 0.16706042982225522, 0.3452436318656894, 0.37491572088441794, 0.30445893736194274, 0.19020195295399922, 0.18328570445245118, 0.190634795590075, 0.16966152427286219, 0.19858822178400637, 0.19603539987914664, 0.18101020842141546, 0.1827171305069415, 0.18093294903069024, 0.09477408810700894, 0.0891596278245208, 0.0903345133603154, 0.09508215343072457, 0.09478056007847302, 0.08271774740695204, 0.10509873770752198, 0.08659749219037982, 0.0855144677453431]}, "mutation_prompt": null}
{"id": "65d27ecd-8997-4ee0-ae2e-0e96ad163ef8", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.gaussian_perturbation_rate = 0.1\n        self.cauchy_mutation_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.cauchy_mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a novel \"Gaussian Perturbation\" and \"Cauchy Mutation\" for exploration, and a \"Modified Simulated Annealing\" for exploitation.", "configspace": "", "generation": 127, "fitness": 0.21974542838273242, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.45762677657851114, 0.4547887405068367, 0.4822846416047778, 0.496356293355791, 0.4823600517618082, 0.4443851442460154, 0.4430198494653105, 0.44306575493238254, 0.44219111042527626, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.023658774535978977, 0.0035903858081661744, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1313428242566963, 0.10344561101545591, 0.10765560763854443, 0.11205713048186661, 0.10858735361718064, 0.11219359227339532, 0.12047994820146601, 0.10998009248735963, 0.10743021626828231, 0.07566761749043793, 0.09649957820621202, 0.09876313610669862, 0.08305024974709829, 0.07086371013452064, 0.08643638089146066, 0.10786883553004922, 0.09033388844252255, 0.08048507691240414, 0.9149437159038689, 0.9463388479092292, 0.9108893139050334, 0.8969920244089592, 0.8949771266263598, 0.900342531086881, 0.9275784881873064, 0.928751963941111, 0.9156287233669277, 0.22438236162804848, 0.2431545756978628, 0.22867507241762397, 0.24061744014172481, 0.25388890657227237, 0.25040796096427553, 0.2567741197202932, 0.23209236597055027, 0.23208952965423268, 0.35220025270887856, 0.5431046251169309, 0.2744909806375153, 0.2672810022949853, 0.5666546614445589, 0.20291533327205624, 0.3397529295396382, 0.2217348104734025, 0.7338215498872716, 0.12903855152518795, 0.11878137964478575, 0.12235729328988765, 0.152889014791171, 0.1920064912253483, 0.17452918282630603, 0.21746926828872026, 0.19526976092056414, 0.12875292309158792, 0.14592524986545263, 0.149530127114188, 0.1650302860818358, 0.1499739620819044, 0.12502230311497675, 0.14938892553489969, 0.1358438500250495, 0.14993199512664324, 0.17284308519457248, 9.999999999998899e-05, 9.999999999998899e-05, 0.006227293225910535, 0.034226946134634506, 9.999999999998899e-05, 9.999999999998899e-05, 0.02551479754435837, 0.00200281354491727, 9.999999999998899e-05, 0.15443389011826292, 0.04858057310156105, 0.1363355272042076, 0.06358410685854288, 0.07389972404886325, 0.01057869182613791, 0.13378630418479065, 0.08821591730754585, 0.03516416855390181, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004370259529300147, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1100712447522123, 0.1525085474856427, 0.11324935712828266, 0.0809354490299955, 0.10969495609411406, 0.08641511136833069, 0.11393964309511107, 0.10151917829269008, 0.1210082238700605, 0.46989464364462896, 0.4146576662246403, 0.4076458742401563, 0.39703224146252836, 0.404504519782962, 0.40882028672978665, 0.42604438299249026, 0.4332694131160657, 0.39659275766493884, 0.12251509030711605, 0.10515877286410158, 0.07958556353682777, 0.09126477572209846, 0.09709287034802472, 0.09619889138859106, 0.1028133245833387, 0.13811919037950815, 0.10221640256115283, 0.1370695998757563, 0.28574570608833716, 0.14348572969954754, 0.1830707328058373, 0.1986794916396375, 0.16983526522070136, 0.18866695012837187, 0.17817945671646285, 0.21492733117120733, 0.283665951063355, 0.31113569303469013, 0.2948268076252606, 0.28044548082950893, 0.25361517359297747, 0.2815429374949733, 0.25783975022597405, 0.29601561603815263, 0.29034668717738, 0.19679896850791323, 0.22333769663743552, 0.20129704885014055, 0.23140811558683294, 0.2121356932117353, 0.23477336420798767, 0.19660604270320636, 0.21501015105671073, 0.172348628394154, 0.21279250739221867, 0.23764093542256115, 0.2654568633088795, 0.28598625631646246, 0.22004133437555318, 0.26458997328433775, 0.22885048702678146, 0.22048292053973284, 0.21795029950174039, 0.1780415499656901, 0.1882880688450116, 0.1707912286706993, 0.18761942290840694, 0.18596966733833276, 0.18228104036205206, 0.2386527251369075, 0.2710860151370078, 0.17810970558677197, 0.1844135678210278, 0.1863547891406131, 0.1864273195133076, 0.11747197294697531, 0.197784126160095, 0.14536199697789287, 0.14121755871828645, 0.578535267535867, 0.6358375313019075, 0.6051018136645642, 0.46078406269790373, 0.40681201564506053, 0.44829561351191516, 0.417716808821484, 0.1668197672673266, 0.1663360887696106, 0.3299818887894198, 0.3502627118402478, 0.18501739253238614, 0.19779285818412362, 0.19384221685336622, 0.1768534064138716, 0.18430133728088693, 0.17429328662166554, 0.1825879076296817, 0.21214562941366866, 0.17568035762661238, 0.07358422322180591, 0.11591344664429648, 0.08720330103667384, 0.08800443778906142, 0.0959509106311871, 0.0923906643647433, 0.10005525813056626, 0.08687654688567359, 0.09634074959131345]}, "mutation_prompt": null}
{"id": "f5e8c984-90bd-4d82-b220-ef212dba1b96", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.15\n        self.dynamic_opposition_based_learning_rate = 0.05\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.05\n        self.mutation_step_size = 0.05\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask * self.mutation_step_size\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.05, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined mutation and opposition-based learning rates.", "configspace": "", "generation": 128, "fitness": 0.21552079657226794, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.45050526894241993, 0.4442668653327867, 0.45796860197762757, 0.4850521370989922, 0.46549467234824893, 0.43680906541402575, 0.4655624870206343, 0.4363880666975415, 0.4748155728302008, 9.999999999998899e-05, 0.0033438343951702754, 0.020837537294433384, 0.0005562539355216112, 0.005885709019050056, 9.999999999998899e-05, 9.999999999998899e-05, 0.043143581524296315, 9.999999999998899e-05, 0.13868477991426242, 0.1088147715515726, 0.10297768217006575, 0.09480364061523017, 0.11384695956815227, 0.0942167597990885, 0.12060197815278095, 0.1272075209581519, 0.11154889606403917, 0.0953749949228413, 0.06924910347856894, 0.08365965500753769, 0.09348290361723122, 0.09668087983223417, 0.06825468286105318, 0.10177843228821204, 0.09853724876523207, 0.09818860039376764, 0.9276325647152215, 0.9502143673853262, 0.9153539939237005, 0.8920345905513438, 0.8751962221384102, 0.8736860158169917, 0.9225442049287101, 0.9331985016854554, 0.9206011641375236, 0.27072728300751026, 0.2513408889555776, 0.2426676855298131, 0.26772666069301143, 0.2512638523376268, 0.252409424672546, 0.23706140054249492, 0.23391265144236817, 0.23288077987602396, 0.36495349772398356, 0.32297217633418873, 0.21999302447678004, 0.27122787818886174, 0.25069326571652295, 0.2163235231886267, 0.22840219906202242, 0.2365303292780203, 0.2739093483779864, 0.2088976637850446, 0.15974331932415775, 0.12334477195476845, 0.12833246936853504, 0.12411626062659653, 0.12329843262643825, 0.14195989340992887, 0.14456581556527526, 0.1679187428617439, 0.13392368390201825, 0.13350479038373797, 0.14935167367560154, 0.12755215948645726, 0.15559790072851387, 0.15397163516502044, 0.14924029007118533, 0.11096441247434263, 0.17178940447417468, 0.00736512196589878, 9.999999999998899e-05, 0.0023075340592687565, 0.012789285609237422, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003659500553145123, 0.0024588168967458746, 0.1622051834344631, 0.07413075968831495, 0.1307250538757535, 0.07913286867618119, 0.0736656654949196, 0.019308929709827893, 0.13246873874413612, 0.0830735028168339, 0.08035238699199398, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.014155795796358173, 0.0008279162232214254, 0.0026618881807994876, 9.999999999998899e-05, 0.0003747123778331529, 9.999999999998899e-05, 0.09054606032455026, 0.11197738407807478, 0.10660515403043369, 0.11312449113804612, 0.1056256201976048, 0.11731159977774952, 0.11501965477494691, 0.116464935455876, 0.08053157483008022, 0.42926163278891405, 0.4486595767507524, 0.4141377527950082, 0.4363981096653853, 0.4176980666193546, 0.43548843676923443, 0.4135237275895568, 0.4058851424266534, 0.4120653166468021, 0.13449104395690792, 0.11986155272879828, 0.08689930742901142, 0.10230235076191818, 0.08580128248333785, 0.10879014335467707, 0.07904214610015492, 0.13524468504812048, 0.12254435918958939, 0.1414875285694812, 0.16983515545651318, 0.19772482729379248, 0.18686234546620695, 0.18310205156343273, 0.2002604044252716, 0.1818480104352307, 0.19537220808632505, 0.15187590603479728, 0.3105339203402747, 0.3149719432764232, 0.3171543454699135, 0.27647519092346284, 0.2947519637653748, 0.3087365601474801, 0.2188620115513601, 0.2605031020534476, 0.268478019044049, 0.19755595149853533, 0.17177562452119632, 0.23033653430453727, 0.20357760113806556, 0.215184060729129, 0.21633975610225875, 0.2117423034582092, 0.24243449963614727, 0.18824862053180302, 0.2397284970082224, 0.22913626534886344, 0.21114440262210965, 0.22022108746228575, 0.23224574551035537, 0.21643211377610472, 0.24942335200082666, 0.2537100917610319, 0.22903760996230027, 0.1862218907613542, 0.17744070352543362, 0.18941962112375443, 0.23731389857755125, 0.1970718092765995, 0.20735803362475969, 0.21605994752815016, 0.2180554785204728, 0.17689477601751114, 0.1854297362254932, 0.18652832127453034, 0.18678682286641402, 0.11848431101950041, 0.1993428515713045, 0.19671308541609478, 0.14099824231600488, 0.5574429721823612, 0.6788795737863307, 0.5589491674614985, 0.4941465429262113, 0.39346894955780576, 0.5842304607062208, 0.40116137589646184, 0.1667878527732295, 0.36210632340615456, 0.3314688858946231, 0.3088192950537182, 0.19039774909381146, 0.17833324032707443, 0.17614120793547516, 0.18803929556189236, 0.17356509740361703, 0.19862122430041418, 0.17567186311644112, 0.1845878636203664, 0.1933884629595859, 0.08865046608687788, 0.08609881902285432, 0.08730023696523803, 0.08554637532498377, 0.08914794328327202, 0.08584904587033138, 0.09954365900291251, 0.10606413343488108, 0.09052010856784853]}, "mutation_prompt": null}
{"id": "7daab59c-75fc-4ffa-9abe-59705a6b537f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.gaussian_perturbation_stddev = 0.1\n        self.cauchy_mutation_scale = 1.0\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask * self.cauchy_mutation_scale\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=self.gaussian_perturbation_stddev, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Gaussian perturbation with Cauchy mutation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update with simulated annealing\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    new_position = np.copy(self.archive[archive_index][0])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a novel \"Gaussian perturbation with Cauchy mutation\" and \"archive-based position update with simulated annealing\".", "configspace": "", "generation": 129, "fitness": 0.214217233052197, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4643438084363345, 0.4477594882332562, 0.45863544005393453, 0.4652331818109309, 0.45067892927515996, 0.4499043917274783, 0.46174798728698996, 0.4261098067972199, 0.49338401706059065, 0.007881135114374604, 0.03880645044581288, 9.999999999998899e-05, 9.999999999998899e-05, 0.011143944546863405, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10379617450451029, 0.11292543344037242, 0.11145705784654969, 0.08974733599858697, 0.14336754559649456, 0.0860510310533209, 0.09478210855172964, 0.13177542424287947, 0.11723683888549274, 0.09312020180023306, 0.06205849005457653, 0.10361843154790729, 0.09155180113614936, 0.08151332647506548, 0.10368906926914534, 0.1059351039437233, 0.08865123287004639, 0.09581567566508675, 0.9031510644681123, 0.9403749556726666, 0.8928853362048739, 0.8686712238561038, 0.8927492557908238, 0.919470668538548, 0.9322971874358038, 0.9071156077335703, 0.9145044186842143, 0.2477050504776338, 0.23852180355152552, 0.2215967156386327, 0.22287337557726628, 0.26858217100448, 0.25548913240767923, 0.24329479608186477, 0.2167468896709015, 0.2467397357056077, 0.36498828214275614, 0.29839816875116354, 0.29160939039753453, 0.26741554574591586, 0.3462127270299865, 0.2057822468777466, 0.2918272638745023, 0.21990897628119221, 0.3270015821473178, 0.1870037510687258, 0.09687853744452568, 0.11942603676259966, 0.09006459173444092, 0.1448493397809163, 0.19100218305268257, 0.14486883890482982, 0.21876114519700285, 0.13100521175329305, 0.13311804908503677, 0.12157773891788637, 0.14213404488733172, 0.1360296765351532, 0.16540967536051288, 0.14447110175377997, 0.17220069734963395, 0.143483851887241, 0.14889867494138376, 9.999999999998899e-05, 0.009106857497724552, 9.999999999998899e-05, 0.019087479883198255, 9.999999999998899e-05, 9.999999999998899e-05, 0.02204536342220742, 9.999999999998899e-05, 0.0031720141852696893, 0.14869489957116966, 0.057956322059596777, 0.1037839174676396, 0.08513572313541973, 0.08096744379404264, 0.06981828090445108, 0.16461795322237704, 0.11843811915152469, 0.06926724616538449, 9.999999999998899e-05, 0.0012177317482826577, 9.999999999998899e-05, 9.999999999998899e-05, 0.006143001288692496, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0936457723808084, 0.11682314954558937, 0.08148734651418199, 0.10911116162801804, 0.08854296357097324, 0.09408195842760447, 0.12383554192213886, 0.1150834440999704, 0.1088703234722832, 0.37906623491084457, 0.4239659998309574, 0.44295401032068416, 0.4215855175343851, 0.4248717275758005, 0.3888867176958689, 0.42346918226067554, 0.41847761505083614, 0.41390175791677164, 0.10316994385590228, 0.10438257405372331, 0.08988670317347591, 0.10297240414162712, 0.11056478586360952, 0.08457044224310573, 0.11036962068362133, 0.12283503074348068, 0.08446860303472514, 0.15495342355625363, 0.1662738402619761, 0.1581894015385895, 0.17137750246436512, 0.2501722813516579, 0.17815564787618643, 0.1685377695563529, 0.17606323242657218, 0.1493016147151096, 0.24585129263685612, 0.2963865274238551, 0.27663814208306536, 0.26481431461325833, 0.3215246621689837, 0.24218510483714273, 0.23706175829441145, 0.29079918790271597, 0.25330099400107653, 0.20081424069569143, 0.21594972918306854, 0.2212994646984705, 0.2282858216079119, 0.21398119990218145, 0.2327350395481006, 0.18331057681222473, 0.22282763202804046, 0.19929239708294189, 0.21360650248660495, 0.23096017804764302, 0.2650893476039824, 0.22716333070827954, 0.225682072652153, 0.2139761818071667, 0.2189320599803949, 0.23327479304178278, 0.2697446520886835, 0.17278469233131732, 0.1848092110834505, 0.17809605438541054, 0.18346257734034588, 0.20223240235782847, 0.17816325452223314, 0.17096016235895872, 0.18057339380660398, 0.1809779586056467, 0.1859957983265883, 0.18566459847677352, 0.1853033735885451, 0.11833246659600793, 0.19803767723332144, 0.19653611103617374, 0.14081583487690696, 0.701468517072048, 0.5370066631659238, 0.6289890104487301, 0.43999438511450994, 0.43690353713384433, 0.3449673901669106, 0.16157945118019523, 0.47595996785923567, 0.31597630196151016, 0.46001989724400083, 0.3129481182434962, 0.17989699247263657, 0.17014961641610682, 0.1753903939727688, 0.19028675349825575, 0.17480270422392807, 0.20552698055299856, 0.1851600556348575, 0.19581393875546527, 0.19362604691499985, 0.07599463186457778, 0.07572557712042394, 0.0884103480659254, 0.10198836851882553, 0.0930834731450555, 0.08808429934201834, 0.09335682061071471, 0.0847655817379509, 0.10883856444192297]}, "mutation_prompt": null}
{"id": "75fdf81a-67a6-4bd7-b9e1-0bab6b43db8d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.cauchy_mutation_rate = 0.05\n        self.gaussian_perturbation_rate = 0.05\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Adaptive Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.cauchy_mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with adaptive Cauchy mutation and Gaussian perturbation.", "configspace": "", "generation": 130, "fitness": 0.2145368806760022, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4650431969995318, 0.41956603840145457, 0.46771916308575223, 0.4622343119443274, 0.46296464647260127, 0.4117085665432271, 0.46908642795925026, 0.42042723845222685, 0.4566689448590815, 9.999999999998899e-05, 0.014415449996920016, 0.007102800607974524, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03082709464041089, 9.999999999998899e-05, 0.11421324103032116, 0.11235034709561986, 0.09598659064015769, 0.10355417307681436, 0.11483881294578058, 0.0922189917756423, 0.1350756889632092, 0.10118787545848063, 0.08831537836934478, 0.0861377546972859, 0.09463803155330985, 0.09559417107673818, 0.09415732730045823, 0.08176532799436698, 0.08256272512872254, 0.08930511309092293, 0.08686121056993157, 0.08297047389928014, 0.9246226850098671, 0.9479623128523983, 0.903990772428338, 0.887460197883252, 0.873025844441166, 0.8668122509543541, 0.91879402311246, 0.9302217965383424, 0.9446892358745161, 0.2688909757076997, 0.24954547191895882, 0.2448259367525455, 0.23870486989689854, 0.2705620682641968, 0.2594171167233821, 0.24589327017820806, 0.21600876246282497, 0.2780359325987072, 0.2851557685919519, 0.29348854941296854, 0.3012201912460386, 0.2580487214661409, 0.32656469953902634, 0.19980309744869296, 0.2810185338508714, 0.1767792717958271, 0.241804788101463, 0.216243282957298, 0.14671028730482572, 0.12070197623792023, 0.12673384120782216, 0.1252171785470646, 0.1319375634311717, 0.1286796374391732, 0.14148458132977537, 0.1361277837350684, 0.15291076379146196, 0.13594159209269596, 0.1403490441150077, 0.14909360176027475, 0.17846072077327046, 0.15120773499455897, 0.16719617289431576, 0.14411005906571484, 0.14531954287001503, 0.014229797934890986, 9.999999999998899e-05, 9.999999999998899e-05, 0.0035330967746954878, 9.999999999998899e-05, 9.999999999998899e-05, 0.004112599965412689, 9.999999999998899e-05, 0.01191532823114616, 0.135473022274904, 0.04324539121997728, 0.10458814046229814, 0.07637598400479562, 0.07239524582338819, 0.03529972052468733, 0.16056770890159355, 0.06558544444403491, 0.07330408036460667, 0.0018053320482236401, 9.999999999998899e-05, 9.999999999998899e-05, 0.00047509611658425044, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09884324960471746, 0.07465848945255804, 0.1071228286264364, 0.13553921606938324, 0.10946493793602097, 0.12630513750179584, 0.11269249414602711, 0.11230206133535248, 0.093333208084451, 0.42735244838761277, 0.45420107660570086, 0.43157755114602336, 0.4267101761405525, 0.4434781582507821, 0.4252849772942201, 0.3917974499247986, 0.40464454948358863, 0.4395928140105817, 0.09861984697091908, 0.10853909570644282, 0.09925885064868745, 0.1478462340042943, 0.09884043706793122, 0.10329023360077372, 0.09332442258279716, 0.13042870510184768, 0.10309780670351998, 0.15917268533813, 0.1563406750418349, 0.16971618003477085, 0.18421299697152393, 0.17902716273108654, 0.20613988343839373, 0.17923913004304104, 0.15666357197370195, 0.1425488402950139, 0.3062968532239132, 0.274878678114974, 0.2780360388871449, 0.30551505195798534, 0.2971769157406525, 0.312846688420771, 0.25854572882532434, 0.28129155845050846, 0.3199628370319024, 0.20935955283926855, 0.1794846876858026, 0.23215640622339406, 0.24654995278894376, 0.18934095114175586, 0.228897121823892, 0.19078263400124718, 0.24962607843758, 0.19847528854888064, 0.25073591441989507, 0.28183670199996236, 0.2056796952383786, 0.22096975120269624, 0.22109289392235543, 0.22841878314383857, 0.2537176879179659, 0.219600632926217, 0.221249732468086, 0.18061734978123567, 0.1812048109531219, 0.17807808193979857, 0.1805011203748258, 0.2013731139488305, 0.19008701845829268, 0.2261739901458205, 0.19791070204169936, 0.1786186570379541, 0.18521294754202522, 0.1861696498194838, 0.18674015792955234, 0.11823505585622429, 0.1989563167845121, 0.1944490707739891, 0.14090691128649324, 0.60886948858045, 0.6200950601989925, 0.6129389281332294, 0.517860434007509, 0.49563396971532336, 0.393254804125004, 0.2986441037124131, 0.16660687228804127, 0.38021022459705467, 0.3156611444223474, 0.36928295555548507, 0.1821915029257054, 0.1742436725974601, 0.18758051358308003, 0.18746842089618065, 0.18955019081483648, 0.17534537237761272, 0.17774831603313812, 0.19341570768349836, 0.21314789282156366, 0.08157955031287822, 0.10050770706189482, 0.11229387187588158, 0.08851354225358465, 0.09646540332854325, 0.08252578023632029, 0.09104606976311513, 0.11539460933079881, 0.07694714915312073]}, "mutation_prompt": null}
{"id": "cb2ef92c-c6ca-4fac-aa96-eabcb5d754b8", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Changed from 0.5 to 0.4\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.995  # Changed from 0.99 to 0.995\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with improved adaptive cooling rate and dynamic inertia weight damping ratio.", "configspace": "", "generation": 131, "fitness": 0.21301400868940162, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4418598648973362, 0.4509998989059256, 0.47887151318225674, 0.4390862413977187, 0.4439188458484027, 0.42590327619100854, 0.41902366717514095, 0.42871297026508026, 0.4218711228089679, 0.00421933074676728, 9.999999999998899e-05, 0.0020537364273662817, 0.0019332572621917343, 0.0023707772714078867, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1286061047680661, 0.1040163441738956, 0.08815903290020832, 0.0857630314747645, 0.08935633381180763, 0.10166627700603026, 0.12346324531556474, 0.11722049391253953, 0.12501362877175126, 0.08853660548914466, 0.09878261438921476, 0.09715617121081033, 0.08184021969701427, 0.08549685540887564, 0.0890077690664135, 0.09251469647436739, 0.09458237073747422, 0.11014940058403866, 0.9164306730085428, 0.94645646864565, 0.9109293055736334, 0.9033726011935909, 0.8960693991370119, 0.9003810751967429, 0.9278355628559172, 0.9294762166290511, 0.9158495476700906, 0.2417905131980318, 0.27011923791609893, 0.25152619001688437, 0.24606318775289326, 0.2532088617533609, 0.22538931361213832, 0.2511331277653962, 0.2220392326466556, 0.2595193755294143, 0.36682014379611394, 0.3404131206759714, 0.28893544942646154, 0.24061248875017027, 0.3377946634150546, 0.23140135567877784, 0.31797107524313495, 0.18821592302778156, 0.270588927538538, 0.1325278844890354, 0.11953539488050624, 0.1271601527908819, 0.1446655497512147, 0.1959702153275532, 0.15025930636200568, 0.21624119032924105, 0.12299701409955033, 0.1558170580976157, 0.1386121489284705, 0.15159428622216053, 0.1323653782178511, 0.1635344947194004, 0.1272031847354851, 0.13526637227843696, 0.15371940948214435, 0.12495625657001697, 0.16136952640184177, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007934178188853225, 9.999999999998899e-05, 9.999999999998899e-05, 0.0027800968702266227, 9.999999999998899e-05, 0.021379500515953387, 0.13031753672554824, 0.06089044100655194, 0.14963462470010946, 0.0683241639371539, 0.08190923990022947, 0.03513728299626562, 0.1252264807993655, 0.08793133795041741, 0.11420701564501545, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01597865267319798, 9.999999999998899e-05, 9.999999999998899e-05, 0.10363428648941175, 0.11099289062459028, 0.09554789860811708, 0.09599703098558998, 0.0976874138041599, 0.09923230721418475, 0.11940240189913842, 0.09665989572643319, 0.10435856222452566, 0.4402436407316782, 0.3871399447975681, 0.42504138751043463, 0.40336975247655493, 0.3847363637303304, 0.393816148301675, 0.4068497843404958, 0.4075755782853675, 0.407859396367682, 0.12362893278538634, 0.11274103025002713, 0.09718146024626673, 0.1084948256028685, 0.11711385418187314, 0.11623675300826619, 0.10394537610649857, 0.11759690897789243, 0.09608337917816245, 0.1386824072661681, 0.3152903223211758, 0.1221601661934748, 0.2219833034458507, 0.16113650187733497, 0.1856968217291407, 0.16551990838145536, 0.16875971700260284, 0.15581115420042957, 0.29017490142896596, 0.29664355846965196, 0.2949299337123551, 0.27089261290586997, 0.29561694810946826, 0.26395934846503577, 0.2566375655113651, 0.28724965996744567, 0.26288057155394307, 0.1918169999124235, 0.20931532758591942, 0.2191087572188416, 0.21560001221714264, 0.23762468126341463, 0.2227861062000095, 0.20427025615040972, 0.21758503783823369, 0.18133314501121178, 0.22600132671965512, 0.22235273550592305, 0.24349770816263594, 0.22226891114356695, 0.2222910534573742, 0.23309475517669975, 0.2366240432025586, 0.22933032514789664, 0.22373410134701333, 0.18602944590124149, 0.18288857128844194, 0.18743773262982355, 0.1890422122591866, 0.19293232381130132, 0.19742882962920838, 0.2487526891407641, 0.21114997278915348, 0.18398918464720793, 0.18427629934715695, 0.18637276611737408, 0.18616796200682062, 0.11744460920183264, 0.19876172451750662, 0.14526413106498237, 0.14073307502619914, 0.5336021256543526, 0.5532747780982689, 0.5269560500257429, 0.44694755204577674, 0.4623628121607991, 0.43764528081292897, 0.457120947477486, 0.16679880675098102, 0.16649773876831098, 0.3770772846914391, 0.36446963355276274, 0.19837716924557414, 0.18040231059710754, 0.17771653273080534, 0.1738138518898128, 0.1816866484558165, 0.19182817277987496, 0.17795838727285807, 0.21214562941366866, 0.18294422110312347, 0.10636865104147197, 0.08806763694496644, 0.12152292849583723, 0.08180925853292087, 0.08518591450394852, 0.08076395476238107, 0.09062186190696031, 0.08592224897642409, 0.10679395776534162]}, "mutation_prompt": null}
{"id": "732a0e9f-1408-4c02-9a51-e6b4e5d5f2e5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with 19% probability to change individual lines\n                if np.random.rand() < 0.19:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined strategy using 19% probability to change individual lines.", "configspace": "", "generation": 132, "fitness": 0.21161551799846604, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.467982670439409, 0.47256494686758266, 0.4600472473951248, 0.42734273139301726, 0.4547153310105646, 0.4712094917428744, 0.42256488837656203, 0.4468891582709904, 0.4396703444046349, 0.0002741923145087588, 9.999999999998899e-05, 0.005391038901697343, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1447472321710338, 0.12070586459747557, 0.10731578829468613, 0.10201884088010371, 0.10007534042874555, 0.08780378776718412, 0.10829336124327271, 0.11073632170577508, 0.1182523645814626, 0.10042020307935706, 0.06366893814738106, 0.09198097606672495, 0.08930761318139735, 0.094402734857987, 0.08319376779112331, 0.11333889007014153, 0.06058653719065732, 0.10622486703618672, 0.9030850413513445, 0.952967559147887, 0.8778992249424695, 0.8816796662414981, 0.8846088068235963, 0.8632467148340843, 0.8910790472309836, 0.9268027479124432, 0.899401531518929, 0.2862732094145196, 0.26266232724348393, 0.23288405494285802, 0.2698697381569575, 0.2448748699208827, 0.24331327452236062, 0.2190352644676382, 0.26781978536627116, 0.23460838013547047, 0.3066349625971162, 0.30091679531939897, 0.22366767149360334, 0.2644331703256566, 0.2685053559928484, 0.23568547182104138, 0.2751204744910535, 0.24771172499324445, 0.24567529129057375, 0.14173370586358292, 0.15705808399929522, 0.13401895211653936, 0.14048734008818975, 0.1632486324359559, 0.1241364623881891, 0.17156308036886914, 0.16840187688964037, 0.13881387894663988, 0.19382425451147833, 0.15653319975072155, 0.14297614247821588, 0.1535727599452129, 0.13476892206368063, 0.13738947510648414, 0.15727557045664875, 0.1772801130631002, 0.1361432361492909, 0.015422053794235002, 9.999999999998899e-05, 9.999999999998899e-05, 0.028012534707679837, 9.999999999998899e-05, 9.999999999998899e-05, 0.0335450086462461, 9.999999999998899e-05, 9.999999999998899e-05, 0.1705857606149015, 0.13849774219108735, 0.14444433014573865, 0.10707123246127082, 0.08010654849801302, 0.0304952461436242, 0.1658523644276957, 0.11497362876975459, 0.06539780901103165, 0.006847737302624224, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03164829110401701, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13609032642105068, 0.13640509516117505, 0.10385340390214193, 0.08067941765454745, 0.10423850816550362, 0.05289056808362347, 0.08810487203578721, 0.08495502200259653, 0.07910613519558907, 0.4281213071500315, 0.4100145494398294, 0.45034015725102694, 0.3798307923051091, 0.47371236037669073, 0.4159464024690701, 0.41127528343469233, 0.41193885016625165, 0.4139670082076766, 0.10371214537162654, 0.10214031818326552, 0.09652361538257848, 0.10268249285080655, 0.10563815963616796, 0.0956415603372418, 0.1266486321495689, 0.12540668767327534, 0.10449730136332458, 0.17600417883012853, 0.16399960690396986, 0.13278645389212684, 0.17523222019625284, 0.17824481515000168, 0.1855635307136403, 0.18730867977886223, 0.12919928577189344, 0.18019507440988036, 0.22943811570708061, 0.2918851767218774, 0.2795047658507944, 0.2799811890448678, 0.3017496670348043, 0.31963767026864476, 0.24171123929617433, 0.29422195296967346, 0.2609940038722497, 0.20126109899588096, 0.23221929902082405, 0.24500003404274995, 0.2427890270667138, 0.24100500449897377, 0.24064209423774652, 0.18891453780368928, 0.24034794496698164, 0.17277962550839732, 0.24816857010212912, 0.22783129326316953, 0.22746271169651755, 0.21515229601283958, 0.22689799030851032, 0.25347348202524134, 0.21696034876375425, 0.23853939960007986, 0.2174423933116908, 0.18536620984518404, 0.17686793685679858, 0.17790138989133686, 0.19975316437004398, 0.20547203413283055, 0.18234125840831683, 0.18141742817686812, 0.16809126409345532, 0.1814411621260491, 0.18572423076268008, 0.17092723624216155, 0.4777248858682366, 0.6077753805587703, 0.47041551159122263, 0.19423899800521172, 0.15889409819247136, 0.16996184556860916, 0.6620919950152426, 0.406444245520323, 0.20941291321976319, 0.07338280172821432, 0.5052958125560039, 0.16674540667914772, 0.16636343940340337, 0.16739428003674306, 0.2982600389195693, 0.2918890863209491, 0.17620202970904242, 0.18276739081113136, 0.18363010402639324, 0.19338742001126108, 0.1896151581691421, 0.16871862530884463, 0.18912501204530952, 0.1983263198131333, 0.18577892180275235, 0.08670069853759743, 0.11180022366540343, 0.11375898999503575, 0.09036771993662718, 0.09896868828996319, 0.08543945664311936, 0.07950093480146747, 0.08354206601376046, 0.09450871684448214]}, "mutation_prompt": null}
{"id": "f9c198b5-cd6e-4f18-bb4b-f43c415953f5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Changed from 0.5 to 0.4\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.98  # Changed from 0.99 to 0.98\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined adaptive cooling rate and dynamic inertia weight.", "configspace": "", "generation": 133, "fitness": 0.21583922845647177, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4481244164463689, 0.4685779595540376, 0.46773228501597963, 0.5114040357736209, 0.47264504166392396, 0.4372518231770136, 0.46720495647362636, 0.43501897142354806, 0.4567279259855854, 0.004991276261257727, 9.999999999998899e-05, 9.999999999998899e-05, 0.004732632806520032, 0.007935348944868692, 9.999999999998899e-05, 9.999999999998899e-05, 0.03094317197063079, 9.999999999998899e-05, 0.11850657936910525, 0.08963883254019256, 0.0784164069524701, 0.1091260171686157, 0.09861938162182216, 0.10836438747242516, 0.1233933180602218, 0.10488417128689176, 0.10528419197854055, 0.11071845784293477, 0.09022814125571954, 0.09233133598781873, 0.08675514801590944, 0.06507821208359998, 0.10435950012692952, 0.08788156571560302, 0.09068216310958654, 0.0927809002046237, 0.9156940071464299, 0.9461656415254367, 0.8992645050619752, 0.8855231071342965, 0.8845650421629994, 0.8922484608214919, 0.9269541519864443, 0.9287165578500403, 0.9149520437065584, 0.277932037387424, 0.2533956177249368, 0.26136251776775365, 0.26323822693192367, 0.2840819430710192, 0.25322667482055083, 0.2612418513723299, 0.23695904542643953, 0.2404788228879503, 0.3577086411372923, 0.3148994404695271, 0.26885412324380564, 0.26598538331817434, 0.3555905605201023, 0.23332901986357102, 0.2679803993689762, 0.2198847233356186, 0.28765962575003623, 0.12341369261194668, 0.14321717694909875, 0.11968388765713645, 0.13748148449290043, 0.12981305510686125, 0.17204648628907637, 0.12842792472740838, 0.20284584144441875, 0.12275735821258948, 0.14140825106456667, 0.12310502123090572, 0.1539004890204787, 0.14445495389345397, 0.12626768777460706, 0.1511374401044734, 0.1510843367970336, 0.16713019994680056, 0.16396562680745996, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0218857595187526, 9.999999999998899e-05, 0.009312626324442297, 0.0026398743865650998, 0.002204176557981552, 0.13555061121922973, 0.05295345527031459, 0.12873575754870092, 0.06879510412870582, 0.04777139520137863, 0.03284085938002701, 0.15218315083581024, 0.06502295447246453, 0.07306550153467029, 0.002204765080144, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005769839280616362, 9.999999999998899e-05, 0.0053491136403114314, 0.013854734570910132, 9.999999999998899e-05, 0.11716837949108883, 0.11767528874440925, 0.11777208484671375, 0.08753645040844771, 0.12780007351071165, 0.12084060774374972, 0.11427833064124482, 0.09527263587649215, 0.11214328343250968, 0.42757184177797714, 0.4038165546852007, 0.45136590886763417, 0.4229126101913383, 0.40870604694710433, 0.40313675754685263, 0.4320897910443875, 0.4075512497532582, 0.4100412807880667, 0.08829889410906, 0.11102787029945738, 0.08640044842690275, 0.1346337644162029, 0.10660115507397094, 0.11308218758317945, 0.08254637055346026, 0.14944120241448, 0.08952259982032573, 0.1960239113520731, 0.2645297308422505, 0.14080024847217065, 0.1954061301535447, 0.20051093557577182, 0.18149084551054362, 0.19269587291671775, 0.13457746227607714, 0.1891246568208338, 0.2963990041253053, 0.3090213082694103, 0.2835344931031166, 0.26919948291233897, 0.29993491236742675, 0.26880864136524873, 0.24713549352948527, 0.3052567012659001, 0.28656634990279584, 0.19239038908305484, 0.2074085910841621, 0.2061426595431698, 0.23576694957161903, 0.26221458579836665, 0.22560643176974726, 0.21601774779376748, 0.21708270034440402, 0.16490733050741424, 0.26025317023522054, 0.227152652145998, 0.25421647605232733, 0.23156658746569947, 0.23972420844709608, 0.2522778042101188, 0.2263250620813192, 0.2171666800098414, 0.22824309766294926, 0.18413374450223385, 0.18229123530972802, 0.18117856808165345, 0.17969414289109287, 0.18997657433741044, 0.17564133322229758, 0.19964359999194603, 0.2603786496622895, 0.17994134885358015, 0.18461006851896922, 0.1863182538760081, 0.186436388672653, 0.11746443465743217, 0.1979063366522158, 0.14535524141085676, 0.14106991890159293, 0.5072551343076173, 0.634214713487881, 0.5531392084402476, 0.43791789569730655, 0.6009003334036174, 0.52557377380672, 0.346443507569585, 0.16649618833619573, 0.166405768396776, 0.38267785268029353, 0.37092879175298243, 0.18856495264600381, 0.18834989970094562, 0.1756322114824438, 0.18811830173198418, 0.1790794209110349, 0.1751059721492828, 0.18432080490517289, 0.21214562941366866, 0.17863748943541613, 0.08725241017902119, 0.08150143916394081, 0.10374346876548646, 0.08562858705243037, 0.08253583708405599, 0.07870386625658032, 0.11548914176137681, 0.09575203868929116, 0.07999457312173452]}, "mutation_prompt": null}
{"id": "74c0e49d-6a44-4d89-9e6d-6c82a94715aa", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.probability_of_change = 0.19\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.probability_of_change:\n                    self.particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with a 19% probability of changing individual lines to refine its strategy.", "configspace": "", "generation": 134, "fitness": 0.19848025054075719, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.20 with standard deviation 0.19.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.4107941079644616, 0.44253604005192515, 0.42189337895288337, 0.3896306735791162, 0.41378414460115587, 0.39739908839059224, 0.3402679912458513, 0.36226810300210077, 0.38590955607754696, 0.004338473068166038, 9.999999999998899e-05, 0.0034905240944342886, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13488190353017648, 0.07525490946361169, 0.08972126623704024, 0.10604760661925006, 0.09500174037543185, 0.09961955839268544, 0.10292977118699143, 0.09416932895505892, 0.0900566904499085, 0.08078870190399134, 0.09583729736205115, 0.07093486347586553, 0.08552696736821885, 0.08065782290288048, 0.11258495868799712, 0.08958710676891934, 0.06780175936441735, 0.09700807543130863, 0.9079192141253336, 0.9374343488947978, 0.8943920932069961, 0.902068190965998, 0.8953783772589126, 0.8877405112290795, 0.9107278643520785, 0.9313871083445356, 0.9259691999372862, 0.2211424716879694, 0.19756107245613252, 0.23437556334249887, 0.21159872849674444, 0.20972978744381832, 0.23717896225456192, 0.24664318705307464, 0.20563265000084252, 0.2114055472734957, 0.3757823659668751, 0.24636641944584592, 0.20960112568220834, 0.20721929383454674, 0.3484127214939048, 0.20327615150603429, 0.2183865092475782, 0.1757820049056441, 0.22252224139798293, 0.1189104850843673, 0.13029334767448886, 0.1628419635098095, 0.1318345508003369, 0.12304513073947743, 0.1543869708708815, 0.12245413475292899, 0.12443718165322082, 0.1254880851536011, 0.1354158183892168, 0.16422307867208696, 0.1394452686603066, 0.13115962979892304, 0.1359074863487726, 0.15054904310630446, 0.15611564219905705, 0.18405023520413, 0.13391510764089565, 9.999999999998899e-05, 0.016118405299827332, 9.999999999998899e-05, 0.02081768613795032, 9.999999999998899e-05, 0.05471248374407911, 0.009287919244910348, 9.999999999998899e-05, 9.999999999998899e-05, 0.07866601600940415, 0.06132747656957094, 0.053539771084086696, 0.0730182261309199, 0.049176635434257876, 0.022840774622725935, 0.10838210726263497, 0.1369054985412098, 0.16216153244069187, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08807309520156414, 0.10222213885586262, 0.08959406595479813, 0.0569816843420069, 0.07437687619901057, 0.06280848400039285, 0.07081061259088528, 0.06395247962593165, 0.07362165637785167, 0.3665583002824716, 0.3716626396649062, 0.3421291182830821, 0.33537005748575, 0.35433310728668543, 0.33140375824349577, 0.3632747252182684, 0.38539407915404467, 0.39053103289112956, 0.09561025963445757, 0.09307685219509099, 0.05996676944527879, 0.08548339860782905, 0.08846392337521902, 0.07652018571185304, 0.09111317516017314, 0.1069435353589746, 0.10134753639666105, 0.15077679186919557, 0.16625527692953745, 0.14038253041473714, 0.17108140317850629, 0.15550284904339529, 0.1512583075399171, 0.18360483514687498, 0.1828165249760163, 0.14724403221987248, 0.2947669424829382, 0.24594654563483231, 0.27710738147201197, 0.242386482098087, 0.27343106601531764, 0.2519065242967471, 0.26668005980191445, 0.27453709507635005, 0.2727267289229143, 0.19998920567231193, 0.20758829874771623, 0.2068592583323292, 0.20942941790303837, 0.18911395481047388, 0.2034178621931182, 0.2197315798474868, 0.18429629141274173, 0.19434265369714576, 0.21455908191189788, 0.22834157410317946, 0.23072536736852223, 0.18961366695158566, 0.2236953248839163, 0.22380961657162568, 0.22230615013227273, 0.23295121484566073, 0.23910834447937068, 0.16608012646328862, 0.1840925633813396, 0.20131661008145496, 0.17760354213195573, 0.20386492248770527, 0.20320797942193647, 0.18112045845305058, 0.17493334491885193, 0.17614016816585243, 0.5711464674203488, 0.18384414144499295, 0.3885068368273914, 0.5511902850870677, 0.19583145720161943, 0.1942496823761488, 0.14804261218524584, 0.16319585753498778, 0.16893479486445773, 0.5120623603729817, 0.20540525216288197, 0.3220830472364352, 0.33948431135220913, 0.32170468034518085, 0.1663107665199317, 0.1651258527010877, 0.36743254550978954, 0.3299848245016931, 0.17646806112724467, 0.19806254799526146, 0.18109299594147577, 0.18847429682719286, 0.19653041698850038, 0.19293675596284687, 0.17586916234163896, 0.1810657946315538, 0.18381844326894292, 0.10194858511776306, 0.08637938077931684, 0.07356724322937047, 0.1068633485757664, 0.12379738126087136, 0.08262580066593161, 0.09395266801248214, 0.09461065344661457, 0.09097748686376839]}, "mutation_prompt": null}
{"id": "fc412e6f-6813-4065-af6c-650190b3a4c8", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.refined_velocity_update_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Refined velocity update\n                if np.random.rand() < self.refined_velocity_update_rate:\n                    self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                else:\n                    self.velocities[i] = 0.5 * np.random.uniform(-1, 1, size=self.dim) + 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i]) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with refined velocity updates and adaptive simulated annealing.", "configspace": "", "generation": 135, "fitness": 0.20747388296349029, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.18.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.48013895128184836, 0.48152297590886295, 0.48716259151880537, 0.5063213496326902, 0.48192210647720335, 0.47819080319658813, 0.46573141618675684, 0.49483952166330014, 0.4376173461660503, 9.999999999998899e-05, 0.028592929820037916, 0.03508605211740923, 9.999999999998899e-05, 0.00017584121390368246, 9.999999999998899e-05, 9.999999999998899e-05, 0.008449415801892846, 9.999999999998899e-05, 0.1267964971839015, 0.13042356699285773, 0.09637564366691609, 0.12051136414821617, 0.07934925334901544, 0.10279295625069118, 0.0852392750752693, 0.11250666094590778, 0.09592829126171998, 0.08404177090617937, 0.10717163580739086, 0.09060659496615608, 0.09247984200892612, 0.07074416793881078, 0.08348527332345623, 0.13184278377858372, 0.09976168361853521, 0.0791807204156244, 0.8753557832892196, 0.9350959018626661, 0.8572520076079362, 0.7601309638829936, 0.8591331931273477, 0.850594445587068, 0.8848721115945003, 0.8890953180769806, 0.8486091463768795, 0.27478195799479677, 0.2578640433021434, 0.24382962111803663, 0.25439931774624824, 0.25254642163655217, 0.24582063183331682, 0.26957270985778825, 0.24857516207324037, 0.2618036690063017, 0.31710019293283975, 0.23448560434084476, 0.24791404440443088, 0.32396880176699727, 0.26249851333894725, 0.20172883734058777, 0.21572257219178592, 0.22159989199189245, 0.29271245434304183, 0.1248720601043759, 0.10346279104591594, 0.1517205935218333, 0.13410124768806275, 0.16295104573739883, 0.17804081588190623, 0.1411265296989559, 0.13895346603336767, 0.18128615980935303, 0.15124454719584168, 0.15705918279695996, 0.17393830841411728, 0.14403635565078698, 0.16902017769297584, 0.15836591811718115, 0.163971972461465, 0.14146067689356934, 0.17886995685994478, 9.999999999998899e-05, 9.999999999998899e-05, 0.015263766864356487, 9.999999999998899e-05, 0.008830161575582696, 0.01087788715780369, 0.01714148281434935, 9.999999999998899e-05, 9.999999999998899e-05, 0.13594348496131914, 0.03613449560592685, 0.11641217929976277, 0.08585776653757549, 0.048196298788869885, 0.044168968055604774, 0.09909107399518036, 0.05602634144121399, 0.09865303931470482, 9.999999999998899e-05, 9.999999999998899e-05, 0.006020980485135663, 0.00018061978750649743, 0.015950487526081858, 0.005593581847395779, 9.999999999998899e-05, 9.999999999998899e-05, 0.000882594100803491, 0.11471965403576434, 0.08498767619346781, 0.09948617387556224, 0.10013461953846203, 0.13186972867251257, 0.09026141053136527, 0.11246972369665453, 0.09504678104186282, 0.09759565496675371, 0.43402759078600917, 0.42917599930553096, 0.41115312871204734, 0.4611905738823574, 0.4112903410806181, 0.42313222747122314, 0.4107280590558936, 0.4433355037685144, 0.4202191335391351, 0.10647610739199553, 0.08676153956646815, 0.10406405636579608, 0.08793396178740609, 0.10061559686271904, 0.1435774975488715, 0.11623485370676478, 0.10505474936172776, 0.11691044859629396, 0.12757849188086234, 0.21291791668088955, 0.15161838427883845, 0.17959105531940855, 0.19704738095425967, 0.1933221439737869, 0.17400859748961206, 0.18411523405217434, 0.19205105307899817, 0.273709279637001, 0.28652497337007354, 0.2877291139914231, 0.252941544783429, 0.3083255656950511, 0.30974880293328166, 0.23085878860019626, 0.3156659820193597, 0.23965690254731042, 0.20475575971220839, 0.18401690267671933, 0.2547398478581082, 0.2152543352993751, 0.22637781047392713, 0.21737570124432504, 0.18196543597842152, 0.22219218700294252, 0.20208620065158, 0.2620710409699123, 0.23372969848705927, 0.23131363507290903, 0.24711454514657327, 0.24530422483237835, 0.2269019570594809, 0.2491611844133116, 0.2623261840453641, 0.24677646581000645, 0.195771103713399, 0.17557694265888346, 0.18413854370653715, 0.21376835095508018, 0.18742822450679208, 0.17288308824213217, 0.21509182240250913, 0.17776719503445815, 0.17817483995131733, 0.12827628265489743, 0.17345227022785914, 0.1875358057296843, 0.15164528292381785, 0.19849309026340112, 0.1952553813687663, 0.1406814868903148, 0.15013563036100297, 0.16489203245080408, 0.4695914298392304, 0.20874963994197704, 0.5512058271908984, 0.5722755922360329, 0.4285064481253076, 0.16645444439219392, 0.16680421910778553, 0.29438917642739704, 0.1661462071788644, 0.20554959239453374, 0.18220528971503347, 0.18604779018105033, 0.18342285756118426, 0.18127893399122796, 0.19437916362842889, 0.17913336303053307, 0.18503422706013894, 0.19884070029546386, 0.08980941427145117, 0.07329454445161032, 0.09260893124771685, 0.10264503758090848, 0.08831701641571621, 0.09606601173473228, 0.09548485259543993, 0.08805395435882435, 0.08860994474415307]}, "mutation_prompt": null}
{"id": "af523b88-b6fd-43b5-86e9-d9b7e5698a26", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight.", "configspace": "", "generation": 136, "fitness": 0.22018600375249126, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV3 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "4e74979b-a0c6-4e0a-bfe6-5c1604805ce3", "metadata": {"aucs": [0.456700318822181, 0.4833788397842409, 0.5061491512554788, 0.5039337025509767, 0.461447676623558, 0.4793965737745358, 0.47661452201908794, 0.47636627860474423, 0.4998815336285555, 0.05139920111877705, 9.999999999998899e-05, 9.999999999998899e-05, 0.026478731305344838, 0.0032666734907246253, 9.999999999998899e-05, 9.999999999998899e-05, 0.009326730458738886, 9.999999999998899e-05, 0.13770839453258, 0.10568945894190307, 0.09726742908204689, 0.10697912772010498, 0.09874847731037084, 0.0865205160925383, 0.09118340773165545, 0.11264117433628185, 0.09764177143265673, 0.09232031086682058, 0.10249484716644364, 0.08246385802762912, 0.08998974597482778, 0.08023641006384863, 0.10153763543002536, 0.1138196969506049, 0.08954121687369876, 0.08920937610943713, 0.9155006125687125, 0.9492471409411627, 0.9016500569531458, 0.8712961956246548, 0.892607256363704, 0.9012123160852215, 0.9272320335334312, 0.9285989868411928, 0.9191702012628302, 0.2831834357810472, 0.2664379213996766, 0.2664368579558217, 0.27497517356401, 0.25728348932662415, 0.26722286736005385, 0.2796564867301017, 0.23739084016591272, 0.24795131570218543, 0.29263983628592183, 0.32357096762303494, 0.3082122508853382, 0.26939425577893483, 0.3467330580908563, 0.19701541329605265, 0.2269557055988043, 0.219125136240796, 0.29057432622442525, 0.1501056466189521, 0.13933070134136227, 0.11495936806312257, 0.1521723572165603, 0.12525550469989288, 0.15559497728975635, 0.13980202316590185, 0.21045914144722733, 0.14528760871769641, 0.1456973805300158, 0.1399160979986538, 0.16851500876272074, 0.20356680258877602, 0.12550029355787462, 0.16248674948006758, 0.16224897457669996, 0.15060050921493662, 0.16137177226256083, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003920604485076584, 9.999999999998899e-05, 9.999999999998899e-05, 0.0009225401099127728, 0.013041243715345652, 0.03330776757475451, 0.1045047286291918, 0.07186019271812583, 0.17475637626936913, 0.07735246392046191, 0.07352874601869464, 0.023541833792408373, 0.153481953141424, 0.10906196530402035, 0.08116237046669084, 0.01810285189190053, 0.022099831862473884, 0.00601939070821611, 0.02419892327249218, 0.011457880394436848, 0.02471447676053995, 0.015213371173297352, 0.024823878738394756, 0.01596588696886614, 0.12539973573075713, 0.1046588109517359, 0.14563695524347076, 0.08705535195239389, 0.10063148062128113, 0.1210939789453962, 0.1296378352276022, 0.11595010204069944, 0.13139886257560796, 0.46564647273217996, 0.47533459910598086, 0.4405390464541009, 0.4206481872313984, 0.4002578164703302, 0.42026168104013706, 0.4702277678819585, 0.4287634508774437, 0.4734347414183774, 0.09701830021267865, 0.08906590342321108, 0.08061672960692756, 0.10329946475573526, 0.09231217848717732, 0.12440585251090874, 0.10004324469755976, 0.12033020676915862, 0.11364980394514768, 0.18950749157365254, 0.24287317534227448, 0.1413795900596675, 0.18957479995029947, 0.22454874252999124, 0.1923246596923679, 0.18811707818217027, 0.1466828244879378, 0.19335971441430888, 0.31628812122720185, 0.31385733984180075, 0.2999451865928193, 0.26633106407057705, 0.2753743216374356, 0.27333786496052437, 0.2463994656835342, 0.2882829011035123, 0.2814328742480906, 0.22955466720715778, 0.18410194947187852, 0.20987767612023123, 0.24569091265276133, 0.23612697541201533, 0.23965172587062, 0.22544354190674265, 0.2396785375533721, 0.19016363517107915, 0.2102378162816826, 0.22422497743538905, 0.21619434170080254, 0.23307063924156346, 0.2444199646621491, 0.23080790196052325, 0.24763858779144876, 0.23722558652427483, 0.22652822848240617, 0.18826190523195674, 0.18220337974391432, 0.17840784820539357, 0.1948167778790979, 0.20197471712201942, 0.1990910768187285, 0.18586447253934713, 0.187081565702928, 0.1869583978795577, 0.1845750207729725, 0.1864193152243886, 0.18623882196432429, 0.11837097029492838, 0.19771004803916814, 0.14541692219947344, 0.14124891887240776, 0.602081090284006, 0.56213539599605, 0.6389809502415043, 0.4770547690665873, 0.5323160885425835, 0.4586873514214974, 0.45929437544838847, 0.16660883147609307, 0.16653825002922162, 0.33259491669025, 0.39111327935977636, 0.17803261974274942, 0.1814197468317308, 0.19082766701836573, 0.1860411694794084, 0.17825720731289052, 0.1862767741039334, 0.17552720317813852, 0.17203906365905042, 0.19384423364101844, 0.08105428816191507, 0.08790242504953716, 0.10260489873990974, 0.10818886516350579, 0.10570042682242387, 0.08868600090967049, 0.09558949868408739, 0.08243546703377702, 0.08761323429287371]}, "mutation_prompt": null}
{"id": "c1e0e3a9-769a-4d28-83a3-7801769c3f51", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.refine_strategy_probability = 0.19\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def refine_strategy(self):\n        if np.random.rand() < self.refine_strategy_probability:\n            # Randomly change the inertia weight\n            self.inertia_weight = np.random.uniform(0.5, 1.0)\n            # Randomly change the mutation rate\n            self.mutation_rate = np.random.uniform(0.05, 0.2)\n            # Randomly change the velocity clustering rate\n            self.velocity_clustering_rate = np.random.uniform(0.05, 0.2)\n            # Randomly change the particle filtering rate\n            self.particle_filtering_rate = np.random.uniform(0.05, 0.2)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                self.refine_strategy()\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a 19% probability to change the individual lines of the algorithm to refine its strategy.", "configspace": "", "generation": 137, "fitness": 0.21498813701411856, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.21 with standard deviation 0.19.", "error": "", "parent_id": "af523b88-b6fd-43b5-86e9-d9b7e5698a26", "metadata": {"aucs": [0.43888200279901035, 0.4696360165296981, 0.4861483205372896, 0.45392840805412793, 0.4440141064771569, 0.47741522793169344, 0.47779490277156655, 0.4646052220121374, 0.45145765979710595, 0.010663086517544995, 0.0400757250993955, 0.0074413410063706165, 0.0005021165522979265, 0.006751642358179377, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10819264239993032, 0.10625462444735878, 0.09486859837862971, 0.08687682898003035, 0.09856698762725735, 0.09670921423902767, 0.1271496428982235, 0.11485714302989858, 0.11436469416635409, 0.09327066724250421, 0.10806114004731593, 0.07178162439099856, 0.08219235431744587, 0.0954243425514878, 0.0780747281513744, 0.09785579714986581, 0.07290817296575747, 0.08242453055642818, 0.9122733643048976, 0.9404415498759476, 0.8956837780164975, 0.8677790332044217, 0.881711516679905, 0.8985707931490836, 0.9230359963586111, 0.902978232395117, 0.9183834344304771, 0.24675815760411535, 0.25058925546987854, 0.2549081076913944, 0.2569144278706178, 0.25244791554882273, 0.24294331277317993, 0.2399599293263438, 0.2440831391385152, 0.24506029530590578, 0.3606905902331963, 0.32896148961910143, 0.2967043402281784, 0.25468156738843795, 0.27452862639585895, 0.23012035263102615, 0.22611863556159495, 0.24822673664158013, 0.2854561917232694, 0.10047769379573857, 0.1314237590338404, 0.11813677061034666, 0.10399717922421459, 0.12961782305899228, 0.18510748116225006, 0.12216084020577311, 0.14508365598237682, 0.15151656589037388, 0.17377581497383676, 0.16388667758631092, 0.16837452291197952, 0.12036900328017419, 0.17394387453511695, 0.16259642553357878, 0.1912790267298189, 0.15604549279679236, 0.16324281909026717, 9.999999999998899e-05, 9.999999999998899e-05, 0.009362255228542393, 0.027761574029239622, 9.999999999998899e-05, 9.999999999998899e-05, 0.0019053468322135503, 9.999999999998899e-05, 9.999999999998899e-05, 0.11478788234208803, 0.08652160478131266, 0.10818640529070012, 0.08782955927005809, 0.09696106787972203, 0.030668671631607136, 0.10749564685155621, 0.0986570668538772, 0.06400134654726064, 0.012342277572182647, 9.999999999998899e-05, 0.002870627842123441, 0.0007479854704462996, 0.0006406088037971269, 0.0067915580695835365, 0.0009121110834290347, 9.999999999998899e-05, 0.0008012445935304813, 0.12377765985492528, 0.13805654933075062, 0.1056196155444804, 0.08930811366909508, 0.11308608193224301, 0.12324105127925034, 0.10856118047634788, 0.09023555340423695, 0.12693354933198897, 0.41912598045299776, 0.4145461908407103, 0.4396469592928979, 0.41774905926458406, 0.4131492744388, 0.42311020013608847, 0.41658843779471044, 0.4151357834072784, 0.43931676307211187, 0.08989111852719511, 0.12242354046748405, 0.0956881317983842, 0.08818855495785483, 0.11248985951826396, 0.09145598227144625, 0.1108606122028496, 0.12377620858814276, 0.08948305717699545, 0.21875276393019782, 0.17850202499146306, 0.20951141888436864, 0.1990796308232997, 0.2113328404282363, 0.1872196256594134, 0.20037386333521268, 0.20614772170168527, 0.19563280683417017, 0.27883503407741805, 0.2925198219211027, 0.29669043386907956, 0.3022217863106814, 0.30314721171187786, 0.2934849011775422, 0.23457721468737758, 0.3009439807418387, 0.24045603742569677, 0.2407649945673942, 0.22008829701873056, 0.2413042498236092, 0.23856109605854603, 0.22121685581386985, 0.23689196574328863, 0.195263973383224, 0.2254742144069518, 0.17796112027836064, 0.24759706214586186, 0.24012470491406168, 0.23169156255155288, 0.22546253381334258, 0.2506256563513982, 0.23158654848001836, 0.24088461845312792, 0.2315435704339196, 0.21385972349924887, 0.17941848115652992, 0.19535769134486325, 0.1864184743039755, 0.22547044270428318, 0.2091078294058556, 0.17667946903479892, 0.18401960458623434, 0.18174724183344693, 0.17653491049710957, 0.18407998946415638, 0.18654446489012866, 0.18592505954308136, 0.5949541487250818, 0.1986942470540386, 0.19620290158016063, 0.14127071792330514, 0.5575389825318323, 0.6163997903886331, 0.43921698420438837, 0.20826879625848727, 0.5596413121030916, 0.16586102360873978, 0.3676056564746668, 0.16762885576239972, 0.16450853310889724, 0.33303320655711877, 0.34275132549609166, 0.187537195156531, 0.1778902165327576, 0.18595515033106536, 0.18069521376091235, 0.17402446011881734, 0.19727077710875285, 0.1813296669278448, 0.17676954561178704, 0.19421014082577714, 0.09392644974714226, 0.10830185120130531, 0.09000176463060283, 0.09017951326439011, 0.11753774067328648, 0.08205554931535897, 0.09874618166886029, 0.10749261556485812, 0.10621593786438843]}, "mutation_prompt": null}
{"id": "660d2341-3055-468a-96c1-f7c9e5bafc6f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.gaussian_perturbation_step_size = 0.1\n        self.cauchy_mutation_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=self.gaussian_perturbation_step_size, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.cauchy_mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Adaptive Gaussian perturbation step size\n                self.gaussian_perturbation_step_size *= 0.99\n                # Adaptive Cauchy mutation rate\n                self.cauchy_mutation_rate *= 0.99\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a novel \"Gaussian perturbation with adaptive step size\" and \"Cauchy mutation with adaptive rate\".", "configspace": "", "generation": 138, "fitness": 0.22008945676216196, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "af523b88-b6fd-43b5-86e9-d9b7e5698a26", "metadata": {"aucs": [0.5032181296960887, 0.48401229147676406, 0.5165066901121209, 0.4879943582837286, 0.509661603770093, 0.4718922414543707, 0.48773101582675993, 0.48984344479806574, 0.48910094679700133, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0009062555749025369, 9.999999999998899e-05, 9.999999999998899e-05, 0.0007737115133308325, 9.999999999998899e-05, 0.1308427498330893, 0.09987893851196006, 0.09782711080644713, 0.09899798055383069, 0.09195360302289757, 0.10727333945923578, 0.12168248733865128, 0.11354710159909609, 0.10347407443274348, 0.09445027168073972, 0.09696028938944257, 0.0934229088239823, 0.08376699008761967, 0.09508946964232068, 0.09030870790314294, 0.10429837705581246, 0.09123867806078156, 0.09901058592618572, 0.9261194825727329, 0.9454385997968396, 0.8930014479863658, 0.8756247090602208, 0.9000808015715726, 0.9047312944047436, 0.9304564825606559, 0.9091950091518128, 0.9240383503080775, 0.27582579210038416, 0.27175764049856543, 0.2744053495829719, 0.2563108107592168, 0.2881852723102536, 0.2517226692623007, 0.26364207756111624, 0.24437084391432673, 0.26197307284984095, 0.29829159868970223, 0.30952989144216503, 0.317501468153359, 0.25975835278688697, 0.295409254181912, 0.20543937362632547, 0.2924302990804778, 0.2186654343041674, 0.3020207449910669, 0.197530386013141, 0.15263171852958912, 0.23952494679828418, 0.13572410013206138, 0.12671074785813397, 0.1453717105863781, 0.12482784289113025, 0.229348724589858, 0.1473448945709379, 0.12733959129626782, 0.1590296895744746, 0.15231252374332782, 0.19246042195754154, 0.14978272992156016, 0.14861444741027174, 0.16722235102615435, 0.16822429477735745, 0.14697752369101547, 9.999999999998899e-05, 0.003515334016777172, 9.999999999998899e-05, 0.011089262562423596, 9.999999999998899e-05, 9.999999999998899e-05, 0.0033795673126167936, 0.0005149252475308286, 0.009548505530534768, 0.14665665947785167, 0.05043801910450785, 0.11657625712357589, 0.08614878120142899, 0.08764232677319328, 0.02946603208931542, 0.19983851717905465, 0.0818026860865706, 0.08699642988556866, 0.004789837924165652, 0.010049371263639473, 0.028863820403853047, 0.038342628023976255, 0.004388266876340974, 0.017615029420062434, 0.03242529264332383, 0.016993594284523517, 0.0027089342973602992, 0.13648314092883007, 0.10630079264420489, 0.092234809166864, 0.14720622439655617, 0.12272299945406451, 0.14094691777100576, 0.11228479171739525, 0.09954739275819102, 0.11316343622887293, 0.4202913480415854, 0.45181756016093755, 0.424762755535565, 0.4073146496449437, 0.4176637042104375, 0.39567604535585155, 0.3983513910400044, 0.425150348444439, 0.44738841573542987, 0.08517977039584657, 0.10903174883500033, 0.09262061090021378, 0.09220589258035361, 0.13207136693881383, 0.10537506637178418, 0.092812462587892, 0.11564862651920027, 0.1069668161736137, 0.15936516078492258, 0.1772007198803116, 0.16090767016526264, 0.1890955567864968, 0.19384597246382285, 0.19528093461095652, 0.19696710499366532, 0.18476168513568714, 0.1733345319942733, 0.29185071424803866, 0.26446122433962893, 0.31133988541444835, 0.29820255562642883, 0.2847649709922284, 0.3074828835221066, 0.24071257945761104, 0.2645605914083822, 0.2712900710847369, 0.22847684301275262, 0.19205692374537653, 0.22145327812957483, 0.2727768200688525, 0.28869391442434966, 0.21768394794598456, 0.21281039594693874, 0.23577277957351972, 0.18145246306113627, 0.25158204652502913, 0.2244732623788489, 0.2501255185189969, 0.2611888346416428, 0.2213120675580761, 0.21857834330504944, 0.2596288685734297, 0.23165468750084905, 0.23295048866374768, 0.17073824508782542, 0.17923054520073234, 0.17792486188667078, 0.20495761347120844, 0.23472560267567877, 0.18546598021402316, 0.2051024165721208, 0.18847832856268854, 0.1821562368790577, 0.18430201710308092, 0.185779555535172, 0.1860317071362031, 0.15994471773025576, 0.1986933551310477, 0.16679020885171325, 0.14132053092490027, 0.5849211729661806, 0.5779799218931061, 0.5673916720115111, 0.5594386214901843, 0.4148631049590825, 0.37322918169856345, 0.32896041291475253, 0.16613092665011187, 0.35905929463150754, 0.29151413703242246, 0.3977688688201574, 0.18193429209147105, 0.18670480198115857, 0.18353714393777854, 0.1725340717678191, 0.1778471397776682, 0.17666520578452183, 0.17195026805016445, 0.18152290615448996, 0.20538176226172966, 0.11133976817276414, 0.10547664246598487, 0.08493223039833842, 0.08633971485548131, 0.074289976171522, 0.0943933002172318, 0.08520399208614382, 0.09841097773343321, 0.09518464663331794]}, "mutation_prompt": null}
{"id": "a5cefb54-3bf5-4621-b331-1ac2d3fa56ae", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.5\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.1\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism.", "configspace": "", "generation": 139, "fitness": 0.2260220522192344, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV4 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "af523b88-b6fd-43b5-86e9-d9b7e5698a26", "metadata": {"aucs": [0.5712443632712993, 0.5953689594020377, 0.6002969498926918, 0.5916125059761662, 0.603941010533041, 0.573409766356125, 0.5292673256905316, 0.5480935816762075, 0.6185513475384607, 9.999999999998899e-05, 0.019997347344637983, 0.01202894391100795, 9.999999999998899e-05, 9.999999999998899e-05, 0.04486625676118705, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11289803326178682, 0.11673381735053867, 0.10310270135087773, 0.11681227574754416, 0.10238843974395895, 0.1525546103790706, 0.10684533850509648, 0.1272867299661884, 0.11970804566800797, 0.08867713579107162, 0.11690550233832564, 0.08630159461313036, 0.09946381689499906, 0.07097166659080845, 0.10089637681629482, 0.08661902026152146, 0.08437964560090327, 0.10331718453231442, 0.8198181149102339, 0.9249087898175509, 0.8789932075858126, 0.8164777675978816, 0.8247857757334414, 0.846644757780253, 0.9357594833921372, 0.9123877121908494, 0.8948406589071854, 0.22447468340029408, 0.22884823829635392, 0.20945956609836247, 0.2385073874953102, 0.26018979636936823, 0.2558637965879047, 0.18659496005876752, 0.2578227233979321, 0.20979621183138264, 0.2902197140888688, 0.2783831696559639, 0.3126348159537562, 0.2672867630058644, 0.3227803706056006, 0.201864321616669, 0.2411580268252288, 0.23056550172844092, 0.34739523696417385, 0.14286274328960613, 0.12323088056255216, 0.12039644530651972, 0.1063538506239824, 0.14827451205637066, 0.18039563215940524, 0.14026752785387253, 0.2316441749244944, 0.1317097686097788, 0.1447023649915613, 0.17866202459002656, 0.1284918392833635, 0.12584922722272762, 0.14185320842097027, 0.18720363103403326, 0.17414290013954414, 0.13439077573589364, 0.17368418219791804, 0.006273180016532542, 9.999999999998899e-05, 0.005245636772926221, 0.05525994063272632, 0.014340078292228498, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002758326729912719, 0.09268335537925254, 0.032665618854291645, 0.07569759536705967, 0.04632156144962318, 0.027192753199390962, 0.025952167385817848, 0.11717193932801617, 0.05744892558488224, 0.06810188105248594, 0.17691289220354278, 0.0962872948410548, 0.055162826123397624, 0.09098363057668812, 0.1881183569886633, 0.0912687679723182, 0.07471398332324264, 0.10591656194759891, 0.1046187597226299, 0.1429143308182933, 0.14808037659003226, 0.1651046485273271, 0.1355273457351801, 0.17499099157189046, 0.07226642960318352, 0.08912649231463532, 0.16234370470519555, 0.10894994078961295, 0.4033610556189887, 0.4271340966348781, 0.395869057119676, 0.40371085826228126, 0.3874619762783206, 0.4289405986439543, 0.5030728695674979, 0.40844790146210785, 0.42179325500167264, 0.1166712614975941, 0.1276075187649427, 0.09764649515717228, 0.09456517853909086, 0.11869448901490454, 0.10783885453003728, 0.07625782290611571, 0.12929375487914874, 0.1135317055954218, 0.18799880465280572, 0.23625453950041697, 0.18176102035865493, 0.15380241670532646, 0.343946828661732, 0.21322891707310987, 0.20418489228627523, 0.16941750921294874, 0.23790381905125968, 0.28414851151786413, 0.2713849734780761, 0.2968641417993414, 0.2974700175366831, 0.40346580863297077, 0.2629588754798755, 0.26973075489430465, 0.28080012596068404, 0.23637311563417518, 0.31848332925773426, 0.18379668454931986, 0.226059900152896, 0.2926038714598379, 0.24641771566398551, 0.2698380211177478, 0.19204641333058958, 0.18404038548421608, 0.1948737733797956, 0.2273084903068926, 0.22743699798023886, 0.23273039600638457, 0.2286442534406179, 0.234333377051118, 0.23826926417487093, 0.2123836120878818, 0.22767337539942767, 0.20443507021569163, 0.18371316096629886, 0.17681648915590975, 0.18980525732909725, 0.18955368334184453, 0.19445358698068171, 0.17508557748705111, 0.19128553456979547, 0.18203770774934158, 0.17299772042307193, 0.12863272758101862, 0.1866115318986814, 0.185835756294487, 0.6751777266878476, 0.19785057762679115, 0.7714819662507574, 0.2740280970765063, 0.5141219059641735, 0.6399063023114833, 0.43953486786287865, 0.21007393441105027, 0.3739807456530666, 0.2028515371326759, 0.32432088788048163, 0.1667478511716145, 0.1684296673742941, 0.1632015781023909, 0.3814538487819924, 0.21490170494142846, 0.19066829871575408, 0.1838906129233152, 0.1975467494618739, 0.17997015802437777, 0.18863002273207663, 0.18737198796298593, 0.19597342208554225, 0.20639495019179477, 0.08487157517564103, 0.08140144518655523, 0.10039996428200615, 0.10054514286751148, 0.09871445865897566, 0.09621828807569688, 0.08902118570685036, 0.0949715781827627, 0.0857949240809679]}, "mutation_prompt": null}
{"id": "82e8eb1c-ca5e-4dcc-9777-ee34861e61c2", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV5:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate:\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV5(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV5", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate and dynamic opposition-based learning rate.", "configspace": "", "generation": 140, "fitness": 0.22674328831701052, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV5 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "a5cefb54-3bf5-4621-b331-1ac2d3fa56ae", "metadata": {"aucs": [0.5750337288145827, 0.5989373611569022, 0.6470645740982197, 0.5936883807730764, 0.6040192499973318, 0.536125449156918, 0.5601969351723854, 0.5769252016773934, 0.5865031382862238, 9.999999999998899e-05, 0.01704670369273975, 0.011819802107428168, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11222051855767512, 0.11652874273267899, 0.10319005907496304, 0.11673292668163582, 0.09866063289526106, 0.11409620832189227, 0.10697795875895133, 0.14237329434865875, 0.1251171372521036, 0.0884590809303949, 0.11478579053046067, 0.08631939848151537, 0.09968499240505457, 0.08113910000402502, 0.09617122151293156, 0.08645085420098553, 0.08546547430331086, 0.10250565257729416, 0.8197402157197144, 0.9249087898175509, 0.8788151485019191, 0.8163946397606399, 0.8247310506978676, 0.8463813964468115, 0.9357594833921372, 0.9123877121908494, 0.8946684287588619, 0.2460828556863648, 0.23261527267838622, 0.20901567025806955, 0.22483273520218705, 0.30507063930696354, 0.2355749771958049, 0.19519157127826525, 0.24806436736890392, 0.2137638866198227, 0.26706379035498273, 0.24408724070941845, 0.2844939098317141, 0.26709608015002695, 0.350970169980928, 0.1946904736380417, 0.24288627454408884, 0.2309134664992244, 0.33486899418839244, 0.14266990473935626, 0.12319817518777965, 0.12020947559722195, 0.10578251449678899, 0.14753838833319455, 0.18744538845308423, 0.14017850747822214, 0.2309753206463231, 0.13139195128547798, 0.1474843643772289, 0.17846511423586997, 0.15678765425464192, 0.12586892346002676, 0.17543716014524158, 0.18677267102809514, 0.17495276940898496, 0.14130709257821095, 0.18729980475213714, 0.00739649019477584, 9.999999999998899e-05, 0.00011422643123171206, 0.05504302352100421, 0.014315273161698894, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.09002223567583045, 0.0313638161574028, 0.07831990115031295, 0.057662387899662604, 0.027440978201851984, 0.02235092693516194, 0.11978705584037364, 0.0573273329898315, 0.07414437687239206, 0.1779072305235173, 0.09583911297188463, 0.062487625347768305, 0.09099653448727107, 0.17874331653029074, 0.09157410142527611, 0.07721542896042743, 0.10568083407266637, 0.10820262794651625, 0.14293470432881694, 0.19221171705461704, 0.18850698599726023, 0.1356919369881967, 0.18899955701337623, 0.07307834231214416, 0.08815758345811442, 0.14761927630347327, 0.10739529179448215, 0.40145750747237385, 0.4334095034492562, 0.4058687159701686, 0.41861278506401556, 0.3917136834316285, 0.4041214671921368, 0.49688983745953463, 0.4169376358786824, 0.41772786226550374, 0.11427145611522593, 0.12774855703466836, 0.086774713195091, 0.09455245335899631, 0.1224763105505674, 0.10812835891534067, 0.08456034933458412, 0.1315970692887336, 0.1126594892787609, 0.18633340162424228, 0.23751249195232138, 0.19524306444668305, 0.15372790338873132, 0.24774932194711263, 0.21022199089811489, 0.20823250461373244, 0.1516773699294276, 0.23457341152142686, 0.281681856156919, 0.26967521920090254, 0.3186740331627288, 0.3016722826746926, 0.4011166119779922, 0.2632638263369159, 0.27290872024376067, 0.2807361302368545, 0.23652577716196332, 0.30584778244849364, 0.1848899456760832, 0.22377717370118844, 0.2940714838096493, 0.25883015205756055, 0.2713166266938919, 0.19206635330484056, 0.2043191805986525, 0.1943387173614547, 0.2273084903068926, 0.2013828815350196, 0.22447491709359002, 0.24543915491601132, 0.20291505505518725, 0.21645781926101837, 0.21315740829961982, 0.23449483468976307, 0.23988004254144601, 0.1836414337087191, 0.17689882334003526, 0.19092340251745665, 0.18958075351179537, 0.1844199830392581, 0.1710608343019372, 0.1909307434733365, 0.18183812525843102, 0.17296242349246405, 0.1304695171485415, 0.18661110329126795, 0.1857934798420856, 0.6650222605346279, 0.19788445021622503, 0.7542107934415324, 0.2934188770009639, 0.6511858116223785, 0.6752292332261849, 0.44595275140904, 0.2100751598968108, 0.35297642826063513, 0.20279222906389582, 0.3361359407224882, 0.16672017378132564, 0.16848754568073587, 0.16319215937326392, 0.38931342880891284, 0.19360943593007818, 0.19094885403419526, 0.20072158776921756, 0.19112934690504912, 0.17951088951921756, 0.1871519133575824, 0.1829043420962848, 0.1941315143713005, 0.18437310886608482, 0.08487119743341098, 0.09048611000484397, 0.10293212532988205, 0.09809520330199739, 0.08153342146240139, 0.09621363284907314, 0.08868463101307766, 0.10861460176002147, 0.0881045801396021]}, "mutation_prompt": null}
{"id": "64b373f4-aa31-40ac-b7cc-c90dd4548e4e", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV6:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV6(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV6", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate.", "configspace": "", "generation": 141, "fitness": 0.22888583725798278, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV6 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "82e8eb1c-ca5e-4dcc-9777-ee34861e61c2", "metadata": {"aucs": [0.7371036974975537, 0.6240183098767279, 0.6766668729071157, 0.6103338627352053, 0.5940645845614463, 0.5520439694075802, 0.5309763857131206, 0.5854501334017783, 0.6920884922303054, 0.0010721294245215063, 0.03915977663295034, 0.16119653393136435, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11094932250328526, 0.08934926322893666, 0.09123915151721107, 0.11703005136946143, 0.10486798037286793, 0.11374952646406944, 0.10789865243627828, 0.1358600424585953, 0.11030126971723786, 0.06905390360792574, 0.1039348186546385, 0.08917821326624797, 0.09335884242747383, 0.05936043243675648, 0.11372251412761214, 0.10034393942975661, 0.07833246594695809, 0.10476501399082083, 0.8630253714418565, 0.9217692414361234, 0.8504116046272716, 0.8051151816991785, 0.8383705298600138, 0.7481003430060411, 0.9357594833921372, 0.8978995564796667, 0.8944132163342531, 0.23938069631490733, 0.2623926228406913, 0.2686557614450892, 0.21408377362794562, 0.258181939422224, 0.18845264670693118, 0.20939012744586438, 0.23474820154412268, 0.23772724139749268, 0.2251138956396923, 0.25655391637418945, 0.22293523831066464, 0.26623073361866834, 0.273445433210751, 0.22058423809282646, 0.22601418662234063, 0.24378799014070407, 0.4139347326123928, 0.14240346495051437, 0.12254433236938289, 0.1830152682446896, 0.11325470695639472, 0.15789411086437855, 0.17617918020595247, 0.14048599853191357, 0.22807904207446317, 0.12738557182810017, 0.14499421885149932, 0.19061477867393817, 0.13035423161220483, 0.1255339037636164, 0.17499943378517824, 0.13026046191612517, 0.19127485419312396, 0.20002704311437702, 0.18122340731838238, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.026265068726066043, 0.019843098405507242, 0.019212495178215216, 9.999999999998899e-05, 9.999999999998899e-05, 0.0501581713230993, 0.09324934032770338, 0.04067367567046909, 0.07678423524325595, 0.046331045771585755, 0.06399760258540721, 0.010147614326962873, 0.11538466434352868, 0.06498915232788427, 0.07201668493039215, 0.17790975034783696, 0.0959119575246341, 0.08827560673475376, 0.05259192767601506, 0.20116106902772413, 0.08435520517479023, 0.06695728580665128, 0.11643648386079641, 0.06979385501552793, 0.1362641101474381, 0.20138916738959756, 0.12953179668730685, 0.13190692757528177, 0.1646786111991121, 0.06920725369764913, 0.09171114803824787, 0.14644310080668854, 0.12063265148555402, 0.4138089654930561, 0.44383199147060437, 0.44016469014886184, 0.4172746163542004, 0.41632971075908587, 0.3950632840988477, 0.4579893351844304, 0.4184148056899275, 0.4195827046538555, 0.09574378362798941, 0.11790394047778696, 0.10509287470104045, 0.09373366873543221, 0.09674977651218963, 0.13734617898773827, 0.10351944596496965, 0.1430372630096728, 0.11482496312237034, 0.19162592085599672, 0.14912196588878046, 0.14729121700364722, 0.20392291477458435, 0.38419498999812773, 0.19900212826691044, 0.18208039806927467, 0.1729102649436618, 0.27109147261674926, 0.23823457121175828, 0.3059359467384861, 0.2522201436501308, 0.2994863786815316, 0.2512784732796557, 0.2600668409029704, 0.25026875503627044, 0.2804436917681513, 0.23107204391789005, 0.3050383705950691, 0.17133492836302433, 0.22760308962604925, 0.33056161807671647, 0.22827907417844284, 0.27173526606716414, 0.19159772411562603, 0.2224106637993093, 0.1990162334638358, 0.22263571198691523, 0.2657190443335059, 0.2325012387370542, 0.22865043990780254, 0.2113264287287605, 0.23905130479591474, 0.25196782050876276, 0.2234502740097778, 0.2408354950818088, 0.18615707783200452, 0.17934694636044823, 0.17886905897313699, 0.189425659691844, 0.18820981851209062, 0.17512102961367293, 0.17691942821242468, 0.19118378699075012, 0.17957715016230102, 0.16112934775292664, 0.18638505024918273, 0.18627530883104737, 0.7600947123737998, 0.19863072406460847, 0.6527726895639847, 0.1409264013594531, 0.6271210692782714, 0.6688320177259999, 0.43018648816653304, 0.5259000806420872, 0.4878841761678052, 0.20157471453267695, 0.32444906291819275, 0.16674799206234914, 0.16831762403431438, 0.16412254750635025, 0.3382598846123235, 0.18277097998222558, 0.20888329156440488, 0.19119693290163764, 0.20162025589218924, 0.17654966479836554, 0.19177899388281716, 0.1829043420962848, 0.17549942009757957, 0.18430045184956323, 0.09968274885749018, 0.08427270884883242, 0.09718041759646434, 0.08927137778823457, 0.10133042959031335, 0.09620432239582588, 0.08687040625052267, 0.08262199501163503, 0.08782459462737957]}, "mutation_prompt": null}
{"id": "43c4c45d-776a-45d0-ac87-817d4e792d5f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.multi_objective_rate = 0.1  # New multi-objective rate\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_objective_search(self, particles):\n        multi_objective_particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        for i in range(self.swarm_size):\n            multi_objective_fitness = np.sum(multi_objective_particles[i]**2)\n            if multi_objective_fitness < np.sum(particles[i]**2):\n                particles[i] = multi_objective_particles[i]\n        return particles\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Multi-objective search\n                if np.random.rand() < self.multi_objective_rate:\n                    self.particles[i] = self.multi_objective_search(self.particles[i])\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV7(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV7", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a new \"Multi-Objective\" strategy to handle multiple local optima.", "configspace": "", "generation": 142, "fitness": -Infinity, "feedback": "An exception occurred: IndexError('index 10 is out of bounds for axis 0 with size 10').", "error": "IndexError('index 10 is out of bounds for axis 0 with size 10')", "parent_id": "64b373f4-aa31-40ac-b7cc-c90dd4548e4e", "metadata": {}, "mutation_prompt": null}
{"id": "056184fc-8522-46bf-842c-2715d0831be3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV7:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV7(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV7", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism.", "configspace": "", "generation": 143, "fitness": 0.23078521452870643, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV7 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "64b373f4-aa31-40ac-b7cc-c90dd4548e4e", "metadata": {"aucs": [0.7520868654036085, 0.6331682049357465, 0.7073173329336446, 0.6501039428899176, 0.6587613885075687, 0.5750219392134897, 0.7058635695263455, 0.5830607643021253, 0.5899575605293138, 0.009712997018751057, 0.013247646689059533, 0.00915668671593417, 9.999999999998899e-05, 0.057912974943145845, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10063713307139965, 0.07908732478842717, 0.0828580688659446, 0.12346912046216152, 0.14058442136766192, 0.08039015002929606, 0.11589877596175735, 0.10749606395540467, 0.08947123287556147, 0.10176501653933101, 0.11461730722977514, 0.09743474228666016, 0.10787558587826829, 0.08807901812831531, 0.10150079929833022, 0.12667267218312395, 0.08238365590710162, 0.08193839820766502, 0.8630394813951499, 0.9374120248001451, 0.8964378571091949, 0.8533966465538956, 0.8618684472861301, 0.7777951430112878, 0.9043444049980138, 0.8873512380277757, 0.9148637861624744, 0.25506725140318054, 0.23190136063159916, 0.25710809075116337, 0.2354817616060615, 0.22951297798834425, 0.23651428769737282, 0.2713501261790633, 0.3174899086581209, 0.229701516675335, 0.24170396377452363, 0.38937433559229795, 0.219033085524026, 0.35517074980069796, 0.27328503680579075, 0.27303873607652007, 0.3116336167612471, 0.21517332230597397, 0.3293040728827825, 0.20900113672124954, 0.13873194444799486, 0.1790978043220881, 0.1748897589018763, 0.16630704233878446, 0.16556084261863357, 0.12569924517778508, 0.3354244879395689, 0.1274650275702155, 0.1869422896578864, 0.12942485955676364, 0.1817904821022739, 0.1489718287647478, 0.14506204888923535, 0.137653265862964, 0.1275947066114662, 0.16487817739481925, 0.15148576898164068, 0.0021019909344042187, 9.999999999998899e-05, 0.012723429145954701, 0.0028914415178160624, 9.999999999998899e-05, 0.017448320265980533, 9.999999999998899e-05, 9.999999999998899e-05, 0.08004393044390834, 0.10135950573815411, 0.07698974519296875, 0.11798758259806053, 0.12103272461996517, 0.10207600390303762, 0.04717572183853114, 0.0952469388777738, 0.06177190855755521, 0.10008947452293648, 0.06383652806245788, 0.06977860251570656, 0.16195843938163357, 0.10040683175657872, 0.13466393774615504, 0.15082464025727227, 0.10336149223945135, 0.18469555623566536, 0.0629296527445713, 0.23622861363208159, 0.12686787847718461, 0.1385410316374962, 0.16948479672600603, 0.15067152562608666, 0.1361648559635079, 0.12613872294425055, 0.17605477087847943, 0.12031746901119311, 0.48269463553077196, 0.43483476694218637, 0.4201017803350511, 0.41365916153862814, 0.42356114095641395, 0.4946571837287542, 0.4607852990008501, 0.4101311250774764, 0.490289704138108, 0.10140212034781981, 0.1121576173584461, 0.09364244387444609, 0.14156676276126123, 0.09502298816024868, 0.17026972679844476, 0.0901470123142668, 0.1277362873759752, 0.10527070954338813, 0.24030348372745414, 0.1938183922033131, 0.15756127509920226, 0.250483746696756, 0.19231386937735795, 0.22914137835034776, 0.23338877232413058, 0.17041830314263207, 0.1699962003879677, 0.25444717067623535, 0.27184400886635396, 0.31121346554193063, 0.3113214011307487, 0.2974955983236448, 0.2735695180518972, 0.2783770434812819, 0.30918230631570687, 0.2577193038781004, 0.24085151735843224, 0.20185946274535405, 0.22300372963472148, 0.25647562608239216, 0.2088493269414501, 0.247526386811598, 0.20096299197870338, 0.23161345284468227, 0.17690376989666823, 0.22926598256057473, 0.20832434427828428, 0.302572302045909, 0.24036352338879885, 0.25652339937672863, 0.21101062517292646, 0.22473508551764965, 0.2048585658608295, 0.23389198910559916, 0.17151653313296533, 0.1763593763847161, 0.17619971662508527, 0.1764657604929344, 0.18995982006876588, 0.1810779509470568, 0.1923403126438492, 0.17779697991980614, 0.173336885265306, 0.18571821718004033, 0.18582191223879796, 0.1856139516227875, 0.7924854894649215, 0.1987284270327363, 0.14653080102389304, 0.14191452197405174, 0.22350973647980354, 0.6846955927984317, 0.3697123021046942, 0.2119277510592107, 0.3850959456233536, 0.4556234531481519, 0.16641976882326848, 0.16612501941692337, 0.16681607794219055, 0.30083446182094065, 0.2675937596410085, 0.20214033278300714, 0.2066092284218043, 0.1915424284973869, 0.18809864615358352, 0.19866707581001064, 0.19675384312867938, 0.19762796572648933, 0.17958518154509806, 0.20071688288510858, 0.09116307440551519, 0.07335156540189292, 0.06839835504131497, 0.10312816623337095, 0.08527958184695394, 0.10043365584113695, 0.0809323056801915, 0.09294692171136865, 0.08726344429725907]}, "mutation_prompt": null}
{"id": "5c7e79fe-d496-420b-a172-355b73649425", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        restructuring_vector = np.random.uniform(-1, 1, size=self.dim)\n        return particles + restructuring_vector * np.random.uniform(0, 1, size=(self.swarm_size, self.dim))\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    self.particles[i] = self.swarm_restructuring(self.particles)[i]\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8", "description": "Novel Metaheuristic Algorithm: Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism to restructure the swarm to maintain diversity.", "configspace": "", "generation": 144, "fitness": 0.2297374904098629, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "056184fc-8522-46bf-842c-2715d0831be3", "metadata": {"aucs": [0.6104974253653226, 0.6347005974779898, 0.6662729545441987, 0.6175826243993165, 0.6935410257303911, 0.5794442507190146, 0.5797943618231912, 0.7839146574442057, 0.6367914128873188, 0.015676387741464515, 0.02601497444432166, 9.999999999998899e-05, 9.999999999998899e-05, 0.0013825531303014449, 9.999999999998899e-05, 9.999999999998899e-05, 0.021304844567635928, 9.999999999998899e-05, 0.09446316762190565, 0.1032723487054602, 0.14426422238072323, 0.10779093414247332, 0.10311711209179952, 0.08399177551873871, 0.11131458103587633, 0.13129946346534616, 0.08672915691002547, 0.10089304853074632, 0.07661040078500136, 0.07531339690727368, 0.10193076270532098, 0.06374337646753214, 0.07722492758300237, 0.09078125043407126, 0.07321782281213873, 0.12470843473312232, 0.8893345665466272, 0.9201840369128248, 0.8953775144435618, 0.692127341612113, 0.8845904903680074, 0.8770615515518413, 0.9015839468768159, 0.9161468888709345, 0.9238613330990308, 0.24666259454027994, 0.23756049743885221, 0.3017896386637371, 0.2478960457353847, 0.2769931580066909, 0.2594375761944592, 0.23083517203456705, 0.23172271874162675, 0.24896947383039625, 0.34004790094427173, 0.2260414068368416, 0.21738156187492086, 0.21927905155466443, 0.27232141144929434, 0.2105398892234983, 0.3005431981713299, 0.21969370886054507, 0.30139262393358535, 0.12373825004777717, 0.12577108123287217, 0.12198012520031332, 0.11261839046398103, 0.1320294016656569, 0.15012718726856455, 0.14304888305085717, 0.13498413816703048, 0.14372231671771318, 0.1688672018320302, 0.1970690481050834, 0.20996887725994196, 0.1812670741246366, 0.15337907348026325, 0.14618032103024903, 0.19338947074699375, 0.12806408858294438, 0.2053751256636106, 9.999999999998899e-05, 0.004889179224876861, 0.005789866881314665, 0.04795733412163339, 0.0052933276540768626, 0.004624275796762611, 9.999999999998899e-05, 9.999999999998899e-05, 0.019845817603134308, 0.11788665647621599, 0.03306067892008724, 0.17022077529087842, 0.08344985103608737, 0.06493238088535114, 0.04147692737981612, 0.0925756352503202, 0.06396340798039146, 0.056486597909929714, 0.05631603065425206, 0.0930195960728959, 0.09034184485252739, 0.09728957740597999, 0.08081286311343594, 0.059999051614687104, 0.1042272225166001, 0.10482714951443506, 0.06392307893806426, 0.2526562261186389, 0.21350490320849624, 0.1180999680177145, 0.08294778828261551, 0.28359607222838756, 0.09846236699322053, 0.18376491761696845, 0.15710341192834143, 0.11005989077131795, 0.42033432907995405, 0.3921187983840365, 0.42489215417586434, 0.380979590137676, 0.3847997072715158, 0.41301420321978766, 0.4432302862415428, 0.4350697012299142, 0.4430984995169923, 0.11522925869445566, 0.10813530640643254, 0.08250250447093621, 0.11506918051087267, 0.11773415478928395, 0.11571159689806187, 0.12246998421349287, 0.12190996649442098, 0.10445505883583939, 0.18526075574843914, 0.1706602029089732, 0.16401029691040347, 0.17120601140457836, 0.20592562126476943, 0.18868885779464994, 0.33316621443437666, 0.1912171352839468, 0.14195747570366768, 0.27039785244164316, 0.4011693675468291, 0.30512754933308484, 0.3680294406863387, 0.2806403477189543, 0.3873824160580489, 0.2898527616407195, 0.3955411249157088, 0.24265234701454652, 0.2150096377485885, 0.20005234651943116, 0.2366607052455112, 0.2497820050183831, 0.23045742877294395, 0.25331510269506685, 0.19165052542425265, 0.21731971568276354, 0.17339369695658713, 0.2188631251017985, 0.24583996116715334, 0.2604481725602481, 0.22431257888693168, 0.2176250021365428, 0.23048432325403334, 0.22252224906477502, 0.24873511808724857, 0.21298712436085543, 0.1840624918943028, 0.183697110920524, 0.18396860173778218, 0.19032002408195758, 0.17844918551789102, 0.17133035269546293, 0.1979439494303845, 0.1723118300726696, 0.1749061741018635, 0.18524309479404588, 0.18720091381445914, 0.1872846198822692, 0.172049111588376, 0.19956026336498578, 0.19623370229635662, 0.140543321026678, 0.8726601724878872, 0.769395105772533, 0.36823086369236746, 0.2099506063617339, 0.48458821350954406, 0.4948735907099192, 0.3046395402284021, 0.4305536082678669, 0.1670228231141, 0.29346903755473497, 0.3050448178159998, 0.20065844204302374, 0.1871577094854393, 0.21041833314806946, 0.18766190025009777, 0.18160404207623493, 0.18921849794233792, 0.18563599514809326, 0.1839992348635815, 0.19696768338249548, 0.09066625963165786, 0.08564976449158679, 0.09883038207647254, 0.08863983736867054, 0.10965456145429942, 0.08712807921595145, 0.08203529896349704, 0.09011451845586504, 0.13588110541213827]}, "mutation_prompt": null}
{"id": "b3886a97-9dfd-44e2-8b99-dc84a8342d79", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_reinitialization_rate = 0.05  # Novel swarm reinitialization mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def swarm_reinitialization(self):\n        for i in range(self.swarm_size):\n            if np.random.rand() < self.swarm_reinitialization_rate:\n                self.particles[i] = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n                self.velocities[i] = np.zeros(self.dim)\n                self.best_positions[i] = np.copy(self.particles[i])\n                self.best_fitness[i] = np.inf\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            # Swarm reinitialization\n            self.swarm_reinitialization()\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a novel \"Swarm Reinitialization\" mechanism.", "configspace": "", "generation": 145, "fitness": 0.22826991155700557, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "056184fc-8522-46bf-842c-2715d0831be3", "metadata": {"aucs": [0.6189945733628275, 0.6157870909706715, 0.6268455052511052, 0.713680068535264, 0.6004531104737798, 0.5321445845711676, 0.5832536068210452, 0.5658636492905069, 0.5941435109195885, 9.999999999998899e-05, 0.005199362661632789, 9.999999999998899e-05, 0.005233642655862791, 0.050925541864912494, 9.999999999998899e-05, 9.999999999998899e-05, 0.030670802277613096, 9.999999999998899e-05, 0.11688721903830246, 0.07729315301438544, 0.1265365951095173, 0.0988678620953749, 0.1005379358924321, 0.08763046757755111, 0.1007984777884825, 0.12116339587015068, 0.12340920228535435, 0.0891320176366176, 0.12293647754096437, 0.0958593462529268, 0.1386873844391996, 0.08463714911805909, 0.09659210673486684, 0.09739318703659006, 0.10095963128970376, 0.08438418588763541, 0.9040941240683764, 0.9132231296879723, 0.8761727891304549, 0.853312889206483, 0.7667152510792099, 0.8254459181688303, 0.8683801843604626, 0.861600871293625, 0.851451299158203, 0.28050706539747317, 0.21977914568378476, 0.25552970771360217, 0.26427170770295694, 0.24727619987560734, 0.2490127497570217, 0.25120692197681393, 0.21963485695685803, 0.27595969686458033, 0.22330535113791894, 0.3760705353086974, 0.22741556205987468, 0.4021620716234574, 0.36787628437821296, 0.2750077329209335, 0.25650087693243007, 0.2811620694486434, 0.22234733613060487, 0.1212365905409637, 0.11299096770498818, 0.11857348788012911, 0.0524990428833042, 0.1516230695258155, 0.28863073331060296, 0.19119437063942268, 0.24252395610452215, 0.1505567815922133, 0.2687213240157934, 0.12414306181143853, 0.2066385966710177, 0.23935240842676064, 0.16274628179458905, 0.24879386385839586, 0.16111320349281355, 0.13632008105827098, 0.16379199966213231, 9.999999999998899e-05, 0.01073603889171082, 0.027709654927451588, 0.05968159136439988, 0.0053431137325622435, 0.07341461957893003, 9.999999999998899e-05, 9.999999999998899e-05, 0.05655956179210808, 0.13252352549766544, 0.04827926216718692, 0.1329368680341737, 0.061740218481077136, 0.08626079299508327, 0.027972028526294324, 0.11252919478319034, 0.13102860012367168, 0.08688242828693105, 0.10881114308601958, 0.058622157699062205, 0.06949352939059028, 0.10613210026304276, 0.12385982604714885, 0.07328840722972929, 0.1733742766006917, 0.18467191656687332, 0.06867392327209654, 0.21406287428396686, 0.16044530948241575, 0.14488008391394547, 0.10661497641735973, 0.22489419037659775, 0.11532927279216543, 0.15785279967915866, 0.15273182127594753, 0.10052878485790373, 0.43732573955215726, 0.3988496362332872, 0.42597524169863366, 0.42137290556212936, 0.4790004561105329, 0.4452607412651205, 0.4473329603608537, 0.48646473441431637, 0.4139088599743407, 0.08563263982897351, 0.1006888262369392, 0.08468549432841788, 0.09428583701215265, 0.12267714149676434, 0.1651247542502311, 0.09374324788532995, 0.10169281327178337, 0.12849566386693334, 0.24531632072438092, 0.18159468367832687, 0.17397042855719924, 0.24207986833073936, 0.18024726155431037, 0.16218203991811497, 0.21316669298517577, 0.21756879845696997, 0.15469530469595916, 0.3274118604569649, 0.2741206351556781, 0.3202906505586648, 0.3218134963424546, 0.3101223854013897, 0.3175812504299306, 0.26664753384143547, 0.2887040058342093, 0.24459844507678097, 0.21901056582381684, 0.27284717265616787, 0.21793730711110892, 0.2603999828524748, 0.19007420203424785, 0.2585582845494264, 0.17239622708060687, 0.15188052744807934, 0.17338882322176963, 0.22539502448935522, 0.21647734970699306, 0.2725906779072028, 0.206782603718064, 0.23664379949871517, 0.2846492122990997, 0.2213722353018881, 0.26710248376860213, 0.2314445737624029, 0.1774597805433319, 0.17526426819664154, 0.1752102732858266, 0.1959300935139785, 0.19421927384995374, 0.18171407235028147, 0.1725483920797506, 0.1842457151821456, 0.1733240765414834, 0.18521832283308892, 0.18529083211519437, 0.18609282259287785, 0.5080691552383392, 0.19841703204604222, 0.19481010295542478, 0.3222106845543963, 0.15253789322033662, 0.6336723262546375, 0.48718455967044993, 0.21109966279825199, 0.38773736456567154, 0.38318716950808174, 0.166023773697907, 0.166364465045709, 0.16598119384571441, 0.30230577041864104, 0.27378444246912026, 0.18897991954957094, 0.19142339827012023, 0.19734865304941518, 0.18857350318821453, 0.19765929780296132, 0.18445133968998184, 0.1934589324805146, 0.19367787911117462, 0.20321358844219373, 0.10652168439445231, 0.0884934583813134, 0.08497949045974451, 0.09191893408996676, 0.09051299737739704, 0.10244957667754984, 0.0755220871710871, 0.08675104928285748, 0.08444329326630173]}, "mutation_prompt": null}
{"id": "7d518182-da44-47ab-9440-bdd0399af3da", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.cauchy_mutation_rate = 0.05  # Adaptive Cauchy mutation rate\n        self.gaussian_perturbation_rate = 0.05  # Adaptive Gaussian perturbation rate\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Adaptive Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.cauchy_mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8", "description": "Novel Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and adaptive Cauchy mutation and Gaussian perturbation.", "configspace": "", "generation": 146, "fitness": 0.2265500962281917, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "056184fc-8522-46bf-842c-2715d0831be3", "metadata": {"aucs": [0.6711738302502079, 0.5311991098237898, 0.702306480404133, 0.6576085732844921, 0.65207029367088, 0.5539787637529137, 0.6771402579560815, 0.6332870766360368, 0.6809210098116494, 0.04029627469335084, 0.03864262002439445, 0.01308582200413999, 0.002362042982735457, 0.011944060877561835, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08997590665709632, 0.09175619186128392, 0.09441020882097761, 0.09088226302053848, 0.11183441065607336, 0.11005942595834128, 0.10447661516951989, 0.1100748863158737, 0.10627030407098759, 0.07504652325207184, 0.06781947648295372, 0.0858724870195634, 0.08981501026824079, 0.1120251502690065, 0.1032551219626735, 0.1033498461612562, 0.09771512122001658, 0.07453499424253296, 0.8647451706895833, 0.9232011521492652, 0.8720035428762751, 0.8379689734129834, 0.8150593006433356, 0.7815902986100289, 0.8975772300272584, 0.8438964161305811, 0.8845403787657978, 0.26931750198388826, 0.25464203942042785, 0.22716261930359172, 0.22096900628916494, 0.22462862127252903, 0.28267254146857745, 0.23799463779289587, 0.22629035639470307, 0.26265875418979345, 0.2556728786615641, 0.2140671239922627, 0.2329261298967087, 0.36150685696122653, 0.27368244761983207, 0.2798020750923407, 0.2124324570827062, 0.18151825685456513, 0.320156363196201, 0.17447903865186798, 0.18865089575269578, 0.1942061165883875, 0.04999445641878142, 0.1234046764322636, 0.1519959905727477, 0.14548730027624646, 0.23408503439935469, 0.16287168550354159, 0.14381534302996457, 0.14640506770122097, 0.19033401966717367, 0.13275381409924125, 0.14913194913672378, 0.20178843548238556, 0.21431865394237815, 0.16552171045454978, 0.15626327143125673, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01834020635678768, 9.999999999998899e-05, 0.0010700889338557396, 0.01997192026027972, 9.999999999998899e-05, 0.02733498138471191, 0.11916780100916546, 0.0531936667259435, 0.0872535482216743, 0.0946530414866591, 0.08842018748112901, 0.012277369440746422, 0.07699976234064765, 0.06637632462892196, 0.0893310617250882, 0.1687010271704048, 0.14044777209107928, 0.08734865328054953, 0.07114286879393494, 0.1422778187450251, 0.08046349600397584, 0.1519262325502092, 0.11464079778495428, 0.08011802135285029, 0.16650509771737831, 0.15220509390827808, 0.2050979752406591, 0.12423272291739906, 0.19706549139802576, 0.10833696260080483, 0.175177735213209, 0.16167881877936685, 0.1426661113774751, 0.4289845516886518, 0.44069087151869457, 0.4223024409156374, 0.4086107431184659, 0.41051803730623637, 0.4042536984462216, 0.47390858819345283, 0.4151859894103116, 0.42955992994384684, 0.1151475571386329, 0.10040202996005443, 0.1004212529234354, 0.13371754428198723, 0.08181361126653774, 0.08935114434742975, 0.1042606323087859, 0.17587630398593124, 0.07875868472849945, 0.13477709659382286, 0.164522468216442, 0.1926938623454676, 0.2571768141049988, 0.2571138855799271, 0.37157703597961655, 0.21519268310152173, 0.18978643422385744, 0.22048908220824448, 0.2936581537211529, 0.2770976862955775, 0.3058301495536998, 0.3881882505186627, 0.25599446860692066, 0.2903977776988137, 0.2591325510951399, 0.27743111684636035, 0.24469159941375795, 0.21013242588786207, 0.21568802070241322, 0.23523304971285142, 0.23468984941179638, 0.2043334362239423, 0.254762222106207, 0.1723869465612603, 0.2388578478188048, 0.21225444476553568, 0.21152555676225737, 0.230586126514698, 0.2265617014507636, 0.21659831355025905, 0.22805223056144475, 0.23815521968921383, 0.21000786983362174, 0.20619904625577712, 0.2374252610228238, 0.1847792499480303, 0.1902723156304712, 0.17324620258502488, 0.18991254647999312, 0.22176886048492717, 0.17014845738077677, 0.18371404162132643, 0.19681170573492635, 0.17024904405451047, 0.18541757430864736, 0.18624927857430362, 0.18631034775200872, 0.6149801319620389, 0.20009422337826022, 0.14556623278519676, 0.14033304537916824, 0.16257900274074732, 0.6930264639431807, 0.40397564323203017, 0.21125901567386507, 0.35818852148202074, 0.4788702129330046, 0.3961425159577171, 0.1662396565479125, 0.16683536601105897, 0.3350767025361845, 0.3520285013469686, 0.18576216384884936, 0.20289459943495847, 0.201658839500938, 0.18474280652970343, 0.1766446475276261, 0.19480031549190568, 0.19161126776248072, 0.18865971541319737, 0.18510024558622507, 0.07854985998021169, 0.08590048271859252, 0.0862312220640824, 0.08502195805084356, 0.09794876688022902, 0.08219563360830084, 0.09722702570572495, 0.07364227349202734, 0.08448639798943514]}, "mutation_prompt": null}
{"id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism.", "configspace": "", "generation": 147, "fitness": 0.2344443937982632, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "056184fc-8522-46bf-842c-2715d0831be3", "metadata": {"aucs": [0.6681531027263308, 0.6350653632850285, 0.6655502402613767, 0.690366955510556, 0.5867479293058473, 0.6148715598288759, 0.5613397864037635, 0.5768269066589208, 0.658871676817635, 0.007096303458888231, 0.0009894074530854002, 0.0075349876237891245, 0.07749163693426675, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00859297955769156, 0.1106625957398717, 0.09848098582800102, 0.09367082754496714, 0.1121099150498236, 0.11561290644821254, 0.1014941995276144, 0.10606965155184567, 0.11202005495977241, 0.1388534471275631, 0.11524914259785968, 0.10811644806434528, 0.12287667347700548, 0.10769169486479513, 0.07679821693853395, 0.1124736956032717, 0.10355641175994645, 0.07745137663628954, 0.08307462061597248, 0.8981454220049488, 0.8914103160338822, 0.8859602463965012, 0.7982238304169225, 0.8506994383147176, 0.828400506851471, 0.9008293826147071, 0.9000967379749815, 0.9119675982795074, 0.2589899583164633, 0.2166563180358143, 0.264161173473317, 0.2614696011754343, 0.251682126695183, 0.25201479648726066, 0.25791182718757355, 0.2374232362568428, 0.21344167996389118, 0.3740722586318721, 0.3691395710580929, 0.22662726085660245, 0.273339605539184, 0.21615218837854733, 0.2088451218170756, 0.2948046317897911, 0.23996661155662613, 0.24004046175754912, 0.12407626134338023, 0.12396398377633944, 0.12257418420282307, 0.12791122854585124, 0.1984436148815122, 0.3536612727601026, 0.15533026208203082, 0.13418728229123622, 0.12900494011803643, 0.14667808731691878, 0.1583015467334633, 0.1560367816611059, 0.1728958186499463, 0.15964819403063812, 0.18575401695377391, 0.15864021468139167, 0.1700946144322033, 0.15933592753504722, 0.03884039481701074, 0.00035426638843805147, 9.999999999998899e-05, 0.009688508851320887, 0.08194407568828987, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11475115159443106, 0.0486985033733216, 0.0711382300062765, 0.07939702720253294, 0.10778528832605638, 0.037427060712921234, 0.13357100792168863, 0.045925952432900874, 0.09233106907640143, 0.09679953682208675, 0.11240926138447138, 0.07632318889208367, 0.09662306417592026, 0.07559370259500808, 0.09589840350444934, 0.2023006050382713, 0.12167551500704299, 0.05806676667619848, 0.14916602024075531, 0.17026595101707498, 0.09770533234153622, 0.21102564001655344, 0.2130588719783797, 0.1291305334118582, 0.17804894970696006, 0.12925568843007462, 0.13635384638453707, 0.42804750065348207, 0.4466845679781385, 0.4668292390729113, 0.3907491320306635, 0.4225938347505027, 0.4397638056471268, 0.4340710509273321, 0.5253908269483608, 0.3955023048976143, 0.11594038080050995, 0.09910509134896073, 0.07696949221235394, 0.14259875499342, 0.10917106119334474, 0.09992913915890422, 0.13822924577306261, 0.123400057006404, 0.11979761951195322, 0.21038007397940262, 0.17257362250094554, 0.14806609940662852, 0.20589590785297984, 0.26342231440301744, 0.21119816793646828, 0.20755793445911552, 0.17449465604923353, 0.14939932596625427, 0.3290048994323437, 0.283823188930457, 0.33289573324922805, 0.2777608726231975, 0.3464999397160533, 0.2703793856837333, 0.24380969297345523, 0.38106061337344044, 0.2920472411376348, 0.24866898433592155, 0.19202846126170503, 0.3065168749077116, 0.3022021561945538, 0.26183023441936926, 0.26033057808291327, 0.1847721576846566, 0.228735453425168, 0.1891565147524723, 0.20749105907062826, 0.23959526358861105, 0.24431529156948206, 0.19871462764682535, 0.21003113494667736, 0.22898418419011735, 0.22198188928248097, 0.2387074709851904, 0.21487565228733363, 0.20274443308149548, 0.17662922927035163, 0.1900567814396794, 0.1985714686338108, 0.22837440146093368, 0.18912652700702004, 0.18914506934205277, 0.19624333569855512, 0.18682613016525806, 0.17014537284987763, 0.18623076825341212, 0.18558319783422728, 0.7985343298318806, 0.19811839591544878, 0.1980700113578494, 0.6721115059205223, 0.5703076641872986, 0.6047633529394164, 0.4850314347749136, 0.2103012844057578, 0.5085395137010538, 0.3915209534288834, 0.3046395402284021, 0.1674189618094708, 0.1684395999677919, 0.15468578865289762, 0.3496542497358539, 0.17903449329332322, 0.1901678140153027, 0.22071201700196807, 0.19106300044163205, 0.18421452688790596, 0.21561818047671155, 0.18669448438475134, 0.18149792026418476, 0.2110822042881646, 0.10378447922407563, 0.08243121161504119, 0.09448553917052926, 0.09136923105103056, 0.09101726576886982, 0.08892789860743777, 0.09190324982870102, 0.08083308227241726, 0.09213314269108319]}, "mutation_prompt": null}
{"id": "da2a85d8-b248-4155-86ea-3fa82abf1905", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.adaptive_opposition_based_learning_probability = 0.5  # Adaptive opposition-based learning probability\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_probability = 0.5  # Adaptive mutation probability\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate and probability\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)) * self.adaptive_opposition_based_learning_probability:\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation with adaptive probability\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * self.adaptive_mutation_probability:\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, with adaptive opposition-based learning probability and adaptive mutation probability.", "configspace": "", "generation": 148, "fitness": 0.23105561906553612, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.5679244296076158, 0.6354959181977015, 0.666089275378843, 0.6256425488595563, 0.6019276048518101, 0.6398267420723653, 0.653794081174711, 0.6933820829788372, 0.5851400078517431, 9.999999999998899e-05, 9.999999999998899e-05, 0.03586526579013283, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15407413612270704, 0.1791324686424305, 0.11815308399783175, 0.10366299643130295, 0.11894694252963678, 0.11884889839629464, 0.10001325321141308, 0.155584200020623, 0.1235098151050601, 0.10695788699475184, 0.07389020439244864, 0.07919318491195515, 0.08113285432399475, 0.06868547650975465, 0.08779483502827645, 0.08826403946441319, 0.0891369264316405, 0.0740529166292363, 0.8709907287872939, 0.9096830858182198, 0.9071378775561525, 0.8274510270785826, 0.8526432153298921, 0.8626954015193269, 0.8943712993260139, 0.8815156371498427, 0.9019074092070785, 0.2865894268137248, 0.2647179705673879, 0.19161652494511294, 0.2701070002477026, 0.25527585660862173, 0.23796979955371733, 0.2182808068030857, 0.24333637856332724, 0.2531605479349456, 0.2700098375417722, 0.3884428863701367, 0.22340372048237, 0.2706899726546145, 0.3764048279391967, 0.25953685103593016, 0.20702704603743616, 0.220226380209241, 0.22259374345147243, 0.19265414128359404, 0.1220358714108255, 0.1244833310987209, 0.12905782116188125, 0.15955528168611077, 0.185716615026442, 0.15438533342238336, 0.12373870421376965, 0.13505849106398415, 0.14613013778139017, 0.19700966793138341, 0.16565033458261735, 0.13145526543978336, 0.19582547043722043, 0.2577364095198581, 0.15339138334501456, 0.18666921596230146, 0.18730289640936826, 9.999999999998899e-05, 9.999999999998899e-05, 0.00035364647197488885, 0.10372102470838218, 0.09976337212031283, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.08564900424311328, 0.1274681488995245, 0.05301016864235297, 0.10091259080590465, 0.06373131602066262, 0.056814713292786645, 0.07058869393359368, 0.09234986597517347, 0.09928006169986603, 0.07598342484925602, 0.12971198120796712, 0.07636658516247385, 0.09718718323842646, 0.10995982897139178, 0.09916383726963596, 0.08315609301053095, 0.2607134967598993, 0.14676938729187117, 0.1171833973910118, 0.1863470120241535, 0.20544236259089943, 0.12176162688802128, 0.12079056870365334, 0.22433502263773164, 0.0942116275350694, 0.11702503647312146, 0.19004886296835477, 0.09602104839854475, 0.4292076549227275, 0.44637703668800066, 0.43023539063149907, 0.4363273669635561, 0.4347041989843833, 0.4543782803928077, 0.4801118495653496, 0.4399404979299163, 0.4143802925490262, 0.10407489763117206, 0.08420336307610854, 0.07311176071206649, 0.22527089775732168, 0.11655399802776578, 0.10689916163147828, 0.1032763846091288, 0.1396845251914528, 0.12404088539153768, 0.15734003677919428, 0.197567370062936, 0.15904483590010277, 0.23226424358777742, 0.3109942806835462, 0.21679801681629018, 0.2808750778826017, 0.24604201713663065, 0.1578823915943547, 0.3178538932464029, 0.32731135286370483, 0.30500079810688285, 0.36915792806976033, 0.33591413719939256, 0.28091964492941, 0.2503030522927644, 0.2713877259906856, 0.24228665541406957, 0.19135349377495747, 0.15788351507094978, 0.24149329138261266, 0.1976900240932321, 0.26979987095138536, 0.21950291156600865, 0.23179047039949963, 0.23624647504613583, 0.2190187160780691, 0.2199337177725934, 0.21950172494110454, 0.21643929282998342, 0.2118989685363578, 0.2069125999018998, 0.2231682021704645, 0.24705284662921034, 0.2250129175321841, 0.22135863099228859, 0.178392919699899, 0.177993030368083, 0.1753668951661611, 0.1866836216870268, 0.20303100670250196, 0.18269637826353546, 0.1889294184411624, 0.17764604056592548, 0.18311398424401426, 0.17076115177925044, 0.18545457745930816, 0.18485224919263865, 0.7168756186804763, 0.19911783690996343, 0.19853835234569872, 0.1410743845447281, 0.22806069123547645, 0.6331136105043036, 0.37427972945591936, 0.20877338872189188, 0.7170648038867709, 0.43873121093673073, 0.3046395402284021, 0.16657860575583128, 0.1686149784268226, 0.10465562956563912, 0.2880965338510135, 0.18240993547786333, 0.1835487676746982, 0.19066608228752058, 0.19142245612994424, 0.18603013427043058, 0.18410628196135892, 0.21980889701314454, 0.20138773688581413, 0.20455627960421918, 0.0785640430483936, 0.09059408513446054, 0.08753933395484781, 0.08427407150464894, 0.09374395656697598, 0.08775080116708345, 0.07438651129752216, 0.08859761471881633, 0.0888262725565464]}, "mutation_prompt": null}
{"id": "587c0212-bfda-4ff6-95ad-5afafba6e74d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.differential_evolution_rate = 0.1  # New differential evolution mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def differential_evolution(self, position, best_position):\n        mutation_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + mutation_vector * (best_position - position)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Differential evolution mechanism\n                if np.random.rand() < self.differential_evolution_rate * (1 - evaluations / self.budget):\n                    differential_position = self.differential_evolution(self.particles[i], self.global_best_position)\n                    differential_fitness = func(differential_position)\n                    evaluations += 1\n                    if differential_fitness < fitness:\n                        self.particles[i] = differential_position\n                        self.best_fitness[i] = differential_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], differential_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and a new \"Differential Evolution\" mechanism.", "configspace": "", "generation": 149, "fitness": 0.23308395399382478, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.6264292978157173, 0.6453197380156632, 0.6379470459768798, 0.6631911797557806, 0.6296251291690731, 0.6338406834319605, 0.5840216001862832, 0.6124449155572134, 0.6118477496212913, 9.999999999998899e-05, 0.02974862258705613, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00048015447786853294, 9.999999999998899e-05, 0.10544954952871244, 0.1535888148747021, 0.15655846463217693, 0.10522783615623432, 0.11358153292562945, 0.11321392207174463, 0.14426137628086266, 0.13580350338190328, 0.14529013490682408, 0.09860468616934537, 0.12014456916268623, 0.10540329133063009, 0.0924606391639109, 0.07368016546042477, 0.09554281016493371, 0.08484480330774657, 0.07976974740115361, 0.08818681009314022, 0.8781145341571974, 0.9191981614694036, 0.905201867895037, 0.9069084515540088, 0.8568999349030296, 0.8964943940433671, 0.9052033276975857, 0.8548283531835498, 0.9017324578019441, 0.2719047365524524, 0.2699353322739554, 0.2533409135022202, 0.26841753173424354, 0.27497893926004024, 0.2856207841411349, 0.2549627650147195, 0.24850425630099493, 0.25411075377448966, 0.22851049737939133, 0.20794801356650128, 0.20837302482073738, 0.3113405680991803, 0.346954874703994, 0.3472316199120383, 0.22932258855766685, 0.21309504076672647, 0.2954128449924691, 0.1238766119084781, 0.14038089098018003, 0.1990389592219859, 0.09992457284354894, 0.1437936147956359, 0.19880379792030078, 0.14706733557247476, 0.12615247476616298, 0.1410381448053415, 0.17260038422214852, 0.19214770039860551, 0.13785629548557443, 0.14743107041251258, 0.15769240530244677, 0.14359824138779387, 0.14418460935283406, 0.1393669111581114, 0.16811123480187762, 0.0323823076940567, 0.0036267763539014064, 0.09390063382830871, 0.07518787033984753, 0.10285609608491053, 0.02355855811562446, 0.036591179143067754, 9.999999999998899e-05, 0.036024404503425145, 0.1924952628850657, 0.07798970992291432, 0.10278280752343671, 0.06977729952204903, 0.14501831892674455, 0.0654227615587537, 0.09334512715166288, 0.10714700990083892, 0.1001408072156954, 0.11123716688104213, 0.10994203324152862, 0.07933272492415222, 0.07374781299053279, 0.06619876175447681, 0.08147507782808183, 0.0988582155695874, 0.1021700681464387, 0.07049369654609305, 0.16417023215575832, 0.188923132990225, 0.21601047272981633, 0.14127362577963354, 0.10000930691595145, 0.11015064130339891, 0.12167788006651481, 0.1869298614735987, 0.15087472595946805, 0.4514295017784672, 0.44302076976161775, 0.45276797685753767, 0.40726389635517235, 0.3970611175016715, 0.41285139564328266, 0.4641478094582052, 0.434045786404455, 0.46635766951701785, 0.11020758912363238, 0.11434884648248955, 0.07332771944323213, 0.14418202431133542, 0.13375336691709816, 0.14898876382370851, 0.14270972972061957, 0.14881557909398524, 0.10695359009655081, 0.224279246083387, 0.20642447629341176, 0.181732698282417, 0.3102343158042804, 0.27278084473984543, 0.24111496743583738, 0.22030692477312563, 0.13237604218401133, 0.15753672862249346, 0.2988922465249534, 0.31098302493499763, 0.28291061967523634, 0.31915187542353896, 0.38425546793372, 0.29188473145906935, 0.23964002058396194, 0.364518965229538, 0.24663498485494084, 0.24101664508564824, 0.23409062961007931, 0.29182511561586033, 0.32451094938977454, 0.24605925174416943, 0.27297471543749785, 0.22280638423723254, 0.24358704861794123, 0.18040903504022276, 0.2417830815473334, 0.22502573328191966, 0.22009279083582367, 0.23947242586258588, 0.289483749952094, 0.23133425336087177, 0.21500859841531872, 0.21990820743610262, 0.2308059286157479, 0.17734252206100432, 0.18170076077600017, 0.1697478675169587, 0.1938552778128193, 0.1846121796682243, 0.16983418199840472, 0.1751835021478848, 0.20510889695506684, 0.1808554084276358, 0.18593350727461877, 0.18676986580256094, 0.1860633927972396, 0.7149378220070282, 0.1996678181993916, 0.1714898479988215, 0.1413513690260203, 0.6792248803493401, 0.593691157488814, 0.4209769948710963, 0.20986734700101894, 0.10163756463332052, 0.42314035824430485, 0.3461115790850332, 0.16666911748818924, 0.16636478677582123, 0.11134726333988709, 0.3236903955337419, 0.1761027794504747, 0.20106695459127932, 0.1896313289372551, 0.21153878773827717, 0.18981151121757478, 0.17990303107323724, 0.21548614346644612, 0.1836534714287673, 0.19727103098141774, 0.07776517673183103, 0.08589215917811777, 0.08103231287331236, 0.08986040672505446, 0.11047572393906901, 0.08399320334592086, 0.07845810180201174, 0.09320700378575553, 0.08908044797678683]}, "mutation_prompt": null}
{"id": "8a5f418e-ed7e-4a79-8d87-7281b5f01736", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.01  # New quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling mechanism\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and a new \"Quantum Tunneling\" mechanism for enhanced convergence.", "configspace": "", "generation": 150, "fitness": 0.2274137790623347, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.6649406131027737, 0.649360278169671, 0.6292111775109985, 0.5756161593621981, 0.5509891913255642, 0.6948788985666149, 0.6756335551117023, 0.6128948501000504, 0.6073017296813121, 9.999999999998899e-05, 0.04260199298686096, 9.999999999998899e-05, 9.999999999998899e-05, 0.009808318655065151, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1361208402645563, 0.09953013495024732, 0.0844893330176969, 0.10949532036185738, 0.11307357484669933, 0.09568409394151245, 0.10923407025644427, 0.11820419412158967, 0.09873046104712735, 0.10434383395318636, 0.11475550734689755, 0.07931875830851476, 0.08900231245383061, 0.10045693725204985, 0.0898594652619007, 0.10524565898010096, 0.08286640420360969, 0.09917153818558289, 0.9011925182166654, 0.9156202868009997, 0.8191171257731963, 0.7970066413035137, 0.8031558327527939, 0.893893091541509, 0.906180970143421, 0.9055940770428104, 0.8572133142649836, 0.22838856729635326, 0.24586929527801638, 0.23765321472266865, 0.21677717358653614, 0.2672622993203426, 0.23179351957373162, 0.2669041427247849, 0.24571948333005544, 0.20399212642931253, 0.22067788610196126, 0.22868206652258172, 0.23027516350141186, 0.26318809953349587, 0.6665340750282915, 0.2028020340770682, 0.24629582494170066, 0.228320785550855, 0.3804433306431505, 0.12174052986977635, 0.129548893222593, 0.12062380449120025, 0.15296498759551758, 0.12307967785315721, 0.18916529129498028, 0.13088154236629213, 0.11832392777196021, 0.12419208588119968, 0.1572825174758813, 0.16923249896810577, 0.12600759959856045, 0.1452846209102452, 0.14296101929956018, 0.16409422361149173, 0.15606841121663384, 0.1737978263841118, 0.1748515811579887, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04273226654164575, 0.008135989632520046, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03619814426615853, 0.10868004857013924, 0.033619861681845054, 0.09331327791288169, 0.100982344939752, 0.06440926891049548, 0.10132183089569957, 0.10959531810630485, 0.07234732415398626, 0.07664424387048452, 0.15987121583373032, 0.0852138235196277, 0.09292608966921112, 0.08583280509674407, 0.12093327964812473, 0.048575660914876084, 0.14706829872535676, 0.07441632402352238, 0.0647257976562583, 0.13325947523571435, 0.1001983073775593, 0.12993652025988833, 0.12929796265039217, 0.11980471305336271, 0.09498347212844915, 0.24003460337125848, 0.09279387766030778, 0.10211090216553997, 0.47332648353580287, 0.40427485896441273, 0.4156073445932641, 0.4343840119119865, 0.4340659557051426, 0.4122565471611084, 0.5082723851101845, 0.40434501261737965, 0.43521328365604717, 0.10662914911884691, 0.10043909807096096, 0.09061114929018965, 0.10440849711557842, 0.13554839768001947, 0.09722885788464242, 0.10544104741943372, 0.14424269414774937, 0.10068959714789494, 0.16881122178534402, 0.2829114154657063, 0.17195251736004669, 0.1975707774603408, 0.26176704326390177, 0.22642780928675954, 0.1601661460460727, 0.22399489912341064, 0.1831310723435816, 0.3239705955122476, 0.3998318088904128, 0.3143868749994323, 0.32198379403237043, 0.3451780485207142, 0.36040204890737815, 0.29839786927254386, 0.26717279817810446, 0.24495953103812373, 0.22795124011113532, 0.28360093158822786, 0.24277328366572037, 0.240321181198501, 0.2515033459174548, 0.23149468286485175, 0.19869511119214012, 0.21400962022028247, 0.18222468042213558, 0.2432691653774144, 0.22512773223722482, 0.21123124293013906, 0.28435205400130015, 0.2289749057931132, 0.23575861490120964, 0.2242028289013155, 0.23219048010694177, 0.22961067734873397, 0.18268885584984595, 0.19009009234995466, 0.18254320687219117, 0.18218453250737854, 0.18020697322306078, 0.19146624123503486, 0.1835284652355168, 0.17750412346012212, 0.17419835926590133, 0.1842456571771086, 0.18561969429092273, 0.18574242134469965, 0.7428906624011669, 0.19960943504012563, 0.19745513030157624, 0.14102855457274033, 0.14793078156579453, 0.7005003871689348, 0.4097390918884599, 0.21016446038796854, 0.25200794175963837, 0.4346889212600763, 0.3796918906274306, 0.16645825168421546, 0.1675679149534106, 0.3817375086930922, 0.33338565681155974, 0.19921749531302013, 0.18540019500012062, 0.1885402775010634, 0.19063074029492655, 0.1851761675573702, 0.18434185248148938, 0.21769763864232994, 0.1879519118186761, 0.2141458868442817, 0.10652933647685692, 0.0852050145740515, 0.07996602979090917, 0.09768083251122683, 0.08848185655222418, 0.10213913602338232, 0.08391437185125594, 0.08479701322252509, 0.08265665091615937]}, "mutation_prompt": null}
{"id": "b423d9c9-1433-404c-8817-967c172c3b1b", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.gaussian_perturbation_rate = 0.05  # Added Gaussian perturbation rate\n        self.cauchy_mutation_rate = 0.05  # Added Cauchy mutation rate\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.cauchy_mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, with added Gaussian perturbation and Cauchy mutation.", "configspace": "", "generation": 151, "fitness": 0.23025052926585907, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.7321967511856577, 0.6968714935335516, 0.5964381719569105, 0.576101350455165, 0.5642979628775229, 0.6810150812933291, 0.6065454022612226, 0.6117109774136469, 0.664570223429567, 9.999999999998899e-05, 9.999999999998899e-05, 0.0232844026918958, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13827600626656222, 0.1355547706917114, 0.10410789189771552, 0.10155567564296597, 0.10675825860650767, 0.10960369569651973, 0.12896365500858686, 0.13819354159183184, 0.11294365871121481, 0.07950413003235812, 0.08113991748452187, 0.08925280761986798, 0.09770576979108614, 0.07971459481093535, 0.09631692019638338, 0.08662991174269552, 0.11229897457696536, 0.09962230236332104, 0.866669743494723, 0.9350189270475933, 0.8866822431688705, 0.8619810498190814, 0.8306406952074358, 0.8449678333896596, 0.9117260485990138, 0.9090493641975078, 0.8809154616432207, 0.2142049691368496, 0.21012265963723142, 0.22031203628553142, 0.24428547069314577, 0.3132270998505684, 0.24282513316226084, 0.21007653058841724, 0.26381654627241324, 0.2866667269448553, 0.29637779435404177, 0.891043074781277, 0.19558071448630276, 0.26914497563029804, 0.3747059737776113, 0.26327964488491695, 0.2164011835753522, 0.22422192909794958, 0.5616765575426872, 0.11918174596100539, 0.13965508100548907, 0.16090243369639678, 0.17724268162902357, 0.1580675176426335, 0.1881867832188272, 0.1608325765143951, 0.12391374150447154, 0.1416610402306947, 0.14842690393235392, 0.19460195034409034, 0.17896654111355637, 0.1412161807516723, 0.1373103222617501, 0.22365718941207846, 0.15099367578393308, 0.19223901699038748, 0.1527180529793024, 9.999999999998899e-05, 0.004657674860313432, 9.999999999998899e-05, 0.05447214363702735, 0.019135127118881656, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0035679441185000327, 0.1743062179651772, 0.06470771482551585, 0.09897051180262695, 0.057616577028095195, 0.10457327640511083, 0.043853358090765515, 0.07683764258884296, 0.10077949631792416, 0.07432133490319881, 0.12418722879494382, 0.08485991505468249, 0.10124254289226609, 0.1086090935641989, 0.10125757160073967, 0.08322200981033911, 0.12710725911246767, 0.13248996623555265, 0.12098880899745856, 0.17686906249232948, 0.1763309605629534, 0.11438754000685514, 0.1680905767432801, 0.18958477143950758, 0.09267538588528512, 0.11498684521969804, 0.1318463738616834, 0.08561320813430195, 0.45702229250888915, 0.4206924075365319, 0.44652946500224955, 0.3973385290918148, 0.42040383700389194, 0.419545265683381, 0.4266435981551464, 0.4336105851441602, 0.4175039343049427, 0.08050672251308244, 0.0874856366417407, 0.10758711802153897, 0.12349357172398068, 0.10535290509270945, 0.15584951076793474, 0.11587793844766658, 0.11593193859163908, 0.1363323048070133, 0.14776986117458402, 0.1462018070186557, 0.1517992011231447, 0.22527836856542294, 0.3420927458363543, 0.2568636695202938, 0.170505845960767, 0.28529266705318623, 0.19941028023388185, 0.33826612088510977, 0.2693454642943588, 0.34714716517116384, 0.26860544099766226, 0.3160951068532377, 0.2601393970038016, 0.2437348452384116, 0.28526658531902005, 0.24072492162610626, 0.19678348562393844, 0.25164412244466217, 0.20140350990517275, 0.24053598088833716, 0.23328143661363798, 0.25978516648480476, 0.2374178599245419, 0.2442918278564955, 0.2227761319797813, 0.2004194944506228, 0.22419226750680543, 0.21556083332061915, 0.21642641139541186, 0.2221248811528549, 0.21615351997039645, 0.24576516028422124, 0.22382153996058185, 0.22510636524093242, 0.18704642113075542, 0.1764174754007276, 0.19404785254225998, 0.18359269505087894, 0.19015097509441137, 0.17894347194735505, 0.19163045027317271, 0.18134865220812435, 0.18293694105728275, 0.170855399748855, 0.18469354457693787, 0.18404812684905947, 0.5745497922148523, 0.19784712941090965, 0.19658248621823227, 0.1409175388408639, 0.22803533949615584, 0.7521347606512144, 0.4316062157245456, 0.20926736547065772, 0.41306289475332403, 0.20376915169652654, 0.38501567864143416, 0.1659409861671467, 0.16831336367793082, 0.10457043535272625, 0.2524500368658239, 0.18798482699704366, 0.202779217990964, 0.19909689037950706, 0.1779361943754869, 0.1982354079262193, 0.21077375132463338, 0.18911784444311086, 0.17290972795112103, 0.19382032267889449, 0.10823387753915525, 0.08335505520968234, 0.08713927576189795, 0.09112531492881748, 0.08857266768506156, 0.11543424507690692, 0.09267744497856001, 0.09129755624276692, 0.09409620681465058]}, "mutation_prompt": null}
{"id": "2d043c43-17e9-45d5-8ea6-343443419e41", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and adaptive mutation rate.", "configspace": "", "generation": 152, "fitness": 0.23318842735008077, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.6202581273702146, 0.6395702002346241, 0.6244972767263693, 0.6187119810505484, 0.5428720367025094, 0.5860894759708235, 0.5843827215445486, 0.6055335140831888, 0.6258141197947782, 0.0075149523408697405, 9.999999999998899e-05, 0.017962981007928702, 0.062023689999999965, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11427708539472858, 0.10243717849371514, 0.09804264718326627, 0.11206291205185825, 0.11575430251692964, 0.11315314228313778, 0.10610440267548127, 0.10670932196455107, 0.15061395862583526, 0.11503671816582461, 0.08427278524792714, 0.09514023761936319, 0.08122406851972575, 0.07769583396826951, 0.09049186350218552, 0.10354933795080146, 0.08456670512920594, 0.08626042770873044, 0.8981454220049488, 0.8948554517162355, 0.88748173502841, 0.7984744079914391, 0.8537323937587666, 0.7807323976851009, 0.9008293826147071, 0.8996469962427396, 0.9119005820226317, 0.2504443826562578, 0.245918278586285, 0.24364849553004198, 0.24070035796927725, 0.24221735273995204, 0.2649651012525678, 0.2511209955341409, 0.24641064569116522, 0.2208853455685551, 0.5813393365546418, 0.3735435891219384, 0.22641579802883394, 0.27276494469458634, 0.2507359582907448, 0.19588803392830678, 0.28941349702326735, 0.2272662449146411, 0.22583621086621342, 0.12447851198721327, 0.12454995464932672, 0.1130597712644199, 0.12682873105001202, 0.21586864921084026, 0.29931358643580197, 0.15017136592921487, 0.12426477736912345, 0.1399942274681094, 0.15866878971082465, 0.1560311067877992, 0.15904987813767968, 0.166236641658159, 0.1579573537221215, 0.1898410620464258, 0.15434465501870986, 0.16292625498352664, 0.16558254445048004, 0.013516833157101615, 0.00825918317837182, 0.0015508823677610195, 0.021760420386315982, 0.09765997506606694, 9.999999999998899e-05, 0.0009211382588708572, 9.999999999998899e-05, 0.020185073828666633, 0.09704455814032242, 0.03405736165966611, 0.08522787915936858, 0.0645633456092386, 0.0986994233122247, 0.057692376586766625, 0.13360808597323137, 0.04311035946736774, 0.07861365711506263, 0.09600298365683324, 0.10556269690842468, 0.07138251760593173, 0.09474005963907273, 0.07048006719759237, 0.07420408654576183, 0.1883274265777093, 0.09954826573283171, 0.06687918154030303, 0.1481882259648648, 0.1460939993501652, 0.11912011338196882, 0.23503572522944838, 0.23880686954299069, 0.14426659279190768, 0.18296146580585915, 0.13306404907096314, 0.1414257217251581, 0.42181033886437813, 0.45936884002914213, 0.42259571978583865, 0.3903935391953781, 0.47878758748225314, 0.43568127882595586, 0.42661240323272964, 0.5088764871721936, 0.44077081108334437, 0.12341465500579485, 0.10728713162613512, 0.08331593364143686, 0.14926365657240404, 0.11012276528445131, 0.12372523358011733, 0.13825912249013217, 0.12105672894146613, 0.1077960504967177, 0.20924104786245512, 0.20695286055971773, 0.16744256907345212, 0.1988692808290604, 0.25623009648479533, 0.21983557097847428, 0.19405770451523208, 0.18395294653217742, 0.20238539809814082, 0.33192863723287214, 0.2847259281697738, 0.31816137098727026, 0.25664816483406305, 0.33574438089982317, 0.2653966902049354, 0.25061519674231225, 0.4225962082982194, 0.2572272167306521, 0.24022336506022934, 0.2033132522073452, 0.2904561377623812, 0.3013632733321139, 0.25634050462014535, 0.2747658842951477, 0.19175675597753028, 0.24030459281372063, 0.1834641156485568, 0.20983057418281337, 0.23897901115746367, 0.20650594218560292, 0.20495397585772734, 0.22476727259412843, 0.22220139992114196, 0.21890200045117958, 0.21240401308766055, 0.23202502692867844, 0.19327314430020148, 0.17484054732933185, 0.1869179963213129, 0.20905432382834266, 0.21103600013515245, 0.19844208308156375, 0.1888465983054084, 0.19114659635796893, 0.17285033028245866, 0.16974805634281398, 0.18622507980100445, 0.18576458596315792, 0.7978831108798948, 0.1981365415253008, 0.19784975362814994, 0.6013113767702851, 0.6590006617618653, 0.6169380033036527, 0.4897346264642015, 0.2102273356679878, 0.32937681298632815, 0.3734139943306959, 0.3046395402284021, 0.16738136137785953, 0.16842739441485388, 0.16260977419684386, 0.3616988123542232, 0.1754154446270204, 0.18247174680356815, 0.18977728554830187, 0.18640262474847424, 0.17847480707172347, 0.21222118595367767, 0.1799395936897803, 0.19706537758685883, 0.21476389196733403, 0.10378447922407563, 0.08270036087608545, 0.09519768551839536, 0.07750094619986325, 0.08467141580317872, 0.09095866872575176, 0.08690949245687318, 0.09266431474244996, 0.11683408644959092]}, "mutation_prompt": null}
{"id": "4fa7367c-3fdf-4545-843c-9d2c821bd9fa", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8Async:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.asynchronous_update_rate = 0.2  # New asynchronous update rate\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                if np.random.rand() < self.asynchronous_update_rate:\n                    continue\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8Async(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8Async", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and \"Asynchronous\" update of particles.", "configspace": "", "generation": 153, "fitness": 0.2308334295322341, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV8Async got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.5959491281739059, 0.6289535737995027, 0.6789083521269499, 0.6825007455382179, 0.5388401482484683, 0.6314907917979833, 0.6248591430324675, 0.6597150752335772, 0.6574920392131707, 0.023145803303049384, 9.999999999998899e-05, 0.01547090934323092, 9.999999999998899e-05, 0.03242557694929671, 9.999999999998899e-05, 9.999999999998899e-05, 0.02542796805072467, 9.999999999998899e-05, 0.11333773706237682, 0.14666116862448308, 0.10136684616766856, 0.12774261729072534, 0.09720461319805784, 0.11526999292242213, 0.08695118190234008, 0.12766888833512535, 0.0908213667141059, 0.0787426305194393, 0.11637825374440947, 0.06904626342789455, 0.08525137595337584, 0.08091825888275439, 0.09499753800931743, 0.09625220241840693, 0.08707506682345012, 0.0834967371769404, 0.8824219920987684, 0.931989906358389, 0.9247941480235194, 0.7807375047802425, 0.859112878012751, 0.8909239193734584, 0.9056598846577124, 0.881717500571955, 0.8870870946196143, 0.21708990991170918, 0.21134883420825223, 0.23857249066775943, 0.259475624635354, 0.27655353873225796, 0.252702867741324, 0.3136873156954134, 0.26732785045270835, 0.2707793453500842, 0.22404905784774443, 0.2276266198688799, 0.20044938703589388, 0.273091965444223, 0.3063002210671597, 0.21457580220921124, 0.2202708472595989, 0.23011903136426837, 0.27181221064848227, 0.20974426193756301, 0.12623404179962217, 0.16391592983647751, 0.14785288226871707, 0.24051943729781045, 0.1226658666042616, 0.14562762922769745, 0.15362248954997815, 0.16853461840545259, 0.18803622598396985, 0.12684006599431652, 0.13576241416951484, 0.1595296404275408, 0.21993252135496177, 0.15862579967645474, 0.17975626252392618, 0.22100415510110716, 0.2478638236361972, 9.999999999998899e-05, 0.0029908879943976174, 9.999999999998899e-05, 0.01093349985682579, 0.007698851808123575, 0.020831957531488476, 0.004337050525979991, 0.007616572605437022, 0.000437809718841331, 0.1417229873547109, 0.04785793620424916, 0.0885418018753713, 0.06884570732591822, 0.12995906559338732, 0.04930887871623568, 0.06673732699596746, 0.13038315928944444, 0.08596597767817515, 0.12674034450455618, 0.08839874407699644, 0.09742025922721043, 0.08653309943367038, 0.09703881204220854, 0.06599704365243819, 0.09101153890510283, 0.13378336535884716, 0.06865866952923594, 0.15819431151011953, 0.17501318316788894, 0.08434507029122074, 0.09905473190761405, 0.19365878064040154, 0.11140309833950235, 0.19578941159640817, 0.14255627878717025, 0.099292004698878, 0.4192519707437845, 0.4173246090321895, 0.43408824832347725, 0.41810592409325886, 0.4634080980030516, 0.4409790869425959, 0.45041044178622947, 0.46196578365239416, 0.4120084375672409, 0.1165175442006019, 0.11021181296331539, 0.0921967784675779, 0.11343533249717563, 0.09620208510244432, 0.1277287928562646, 0.10125360211485912, 0.15654131260752524, 0.0764288914398783, 0.1891106040012943, 0.18073395127110015, 0.14034613209222646, 0.19055148660631216, 0.2340320699679913, 0.20458018531963051, 0.22176616026549956, 0.17519759888661213, 0.24008649138390903, 0.3459920179074809, 0.3284341879324013, 0.31379002355312613, 0.22915545684762217, 0.29731895720155965, 0.3006832296921782, 0.32665048672726393, 0.2895917789814967, 0.23404064287543003, 0.25688035264289166, 0.29859540423539954, 0.230674372179955, 0.17715584284070862, 0.2780007268597433, 0.21963496956701134, 0.22503797035112416, 0.30359330592600287, 0.15310403810417517, 0.2727305089869553, 0.237437117304377, 0.22559076378935639, 0.23365982833408194, 0.22258301851720275, 0.22596586883724745, 0.2502265625123671, 0.2824121571864383, 0.21878518784507828, 0.21298956072192754, 0.1840097787137579, 0.17533751424133992, 0.2016128639300958, 0.19689550376025278, 0.1761267127270596, 0.1834339447275678, 0.1808401923648857, 0.1725968998045797, 0.18758371450445, 0.18635695232873284, 0.18518619858262886, 0.5574661056396573, 0.19928765849185293, 0.14609009239875992, 0.14063205471489582, 0.7865763225392737, 0.7107079753898389, 0.3862727847422158, 0.210436399852435, 0.2056836663937618, 0.4036409218198135, 0.2059581071866653, 0.16526660829585416, 0.3396688689684474, 0.3204726746473915, 0.4849330006350109, 0.23169295412201318, 0.18675530762831605, 0.18026088709095023, 0.1923386952229521, 0.19752113585571374, 0.17154958923121377, 0.19158669675584028, 0.1903221451398559, 0.2008016434405473, 0.09871660227775902, 0.0924905511422992, 0.09196495968820617, 0.09809289190159598, 0.1022449492875176, 0.07698321463639335, 0.09965632552723291, 0.09282788031782385, 0.0854970344859094]}, "mutation_prompt": null}
{"id": "f18320b4-bc42-41da-a4b4-82720d56820f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.archive_based_update_rate = 0.1  # New archive-based position update mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update mechanism\n                if np.random.rand() < self.archive_based_update_rate * (1 - evaluations / self.budget):\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and a new \"Archive-based\" position update mechanism with adaptive probability.", "configspace": "", "generation": 154, "fitness": 0.22982714516280808, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.6168770939365211, 0.5737262945729571, 0.6131700150579691, 0.6128424169560927, 0.592550176011267, 0.6058944635553972, 0.5656316766666225, 0.5761749223014707, 0.5657948050957753, 0.021965888136722067, 0.011275207824713251, 0.0006266605443444595, 9.999999999998899e-05, 0.0017514567581767837, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16659220831560373, 0.09848510018111045, 0.10218175814332808, 0.10408257038248958, 0.10429691457425905, 0.12746150836041437, 0.12030896880842246, 0.11771895436747215, 0.11074382560772156, 0.08100076660527755, 0.08520121289358251, 0.11355416823436393, 0.10529618125165585, 0.07315905396689792, 0.06092505953784566, 0.11399821156098677, 0.1005108751611048, 0.08261615934261102, 0.8797800378765837, 0.907831918540219, 0.9208632615883904, 0.7748093919021412, 0.7584081755282912, 0.8089087743086538, 0.9040538807997806, 0.88379426694764, 0.9188019776047551, 0.2476637818725339, 0.23252157159423215, 0.21501976793375555, 0.25454297747643084, 0.23915338029067623, 0.22150200603045678, 0.2333648471204507, 0.2850905998042079, 0.26855883726117913, 0.3253831858669377, 0.2177832134630514, 0.20489893044533314, 0.2757498140683159, 0.3508783367202597, 0.20596380792375413, 0.23954615610084884, 0.1764116028333187, 0.2106271970825161, 0.24127410285124784, 0.11129538107076842, 0.1842013202116899, 0.14298223572764668, 0.20124714088808593, 0.17702200624085185, 0.1897226644459774, 0.12315691956881514, 0.13548679639883887, 0.17510705635970192, 0.13911128572322473, 0.22214033418224877, 0.1350332890504483, 0.18189342142845677, 0.13763759688156008, 0.16130770396570204, 0.16538364808801342, 0.16693800376960777, 9.999999999998899e-05, 9.999999999998899e-05, 0.030477222136481963, 0.002188348957292363, 9.999999999998899e-05, 0.014496402786087104, 0.0002876517101770837, 9.999999999998899e-05, 0.02408530117137775, 0.17094417424086428, 0.030791397597627612, 0.1071370470287939, 0.055692106444700906, 0.10631801456211776, 0.040047209734, 0.1115599791447276, 0.08344506178189348, 0.08380224995313057, 0.1447053372723831, 0.09382772352001034, 0.06733338257091948, 0.07455755240458273, 0.0750683091281299, 0.127581152593361, 0.08733600250900142, 0.07450538610779622, 0.08888225326046884, 0.13997508474020792, 0.13935648661411892, 0.16308840936370683, 0.09579686945116772, 0.1519065773142112, 0.24854300355731052, 0.13895359534628204, 0.09456752889937836, 0.1481694173496959, 0.41889845153599004, 0.424427144851232, 0.409064055967577, 0.3987852370629813, 0.40946984505533657, 0.4256701548631979, 0.43616534862887424, 0.45107942121836675, 0.3780527816266678, 0.0818573591431585, 0.14328756452602953, 0.1325013342845366, 0.10931919062638462, 0.12076662287842665, 0.13868856360789628, 0.09502522805788971, 0.10469195914172091, 0.11377042444393015, 0.24501412659003752, 0.24836778777299995, 0.17789880970238847, 0.25954032886501255, 0.24973067530324777, 0.16508300589420455, 0.25527577104152055, 0.23994168949828176, 0.14878451509109403, 0.27868358958853, 0.28690720368495204, 0.3006269072950628, 0.33502552661124596, 0.2805419444014654, 0.32855018805523284, 0.2716361303215372, 0.28356510151433634, 0.2476553523323629, 0.23326287649062227, 0.27230808700575615, 0.2347849382990138, 0.2238351322516159, 0.24875321169787956, 0.2647977458854196, 0.1603427158557702, 0.2632755632344883, 0.19746429849291103, 0.2273648132790097, 0.20700460680701704, 0.23213335116074474, 0.21255305665211344, 0.21405199439862277, 0.2606450961477589, 0.24156983326433834, 0.24381614986367317, 0.21769921331226294, 0.17127261620553813, 0.1861300139023564, 0.18391120118883486, 0.19653591519857472, 0.19674773977961135, 0.18886720615121355, 0.2085647418886808, 0.17424998793836677, 0.17141402141800377, 0.18526142648954613, 0.1849019522342683, 0.18536891045721338, 0.6211802350902451, 0.200110868181264, 0.197616917135922, 0.14158774417004993, 0.819894616236215, 0.7451776824289471, 0.35884326228060437, 0.20918342050792016, 0.6095168908101409, 0.16452156140279806, 0.4339278718446047, 0.406183922480679, 0.1717852393491437, 0.39887367031111376, 0.4474254163142044, 0.17803774263566952, 0.20724719877202347, 0.1854196320143896, 0.20088415433416118, 0.19212006111368496, 0.20950875302041994, 0.18752947644311502, 0.18045110246560248, 0.18460438041581806, 0.08479783002599905, 0.08419194322410839, 0.10104731609339124, 0.08547058174450617, 0.09014079026306843, 0.08257958559020628, 0.08445589858280633, 0.0928751645288507, 0.10664124751716031]}, "mutation_prompt": null}
{"id": "8e3a6d9b-ed7b-4b28-981d-b369bdb80409", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.levy_flight_step_size = 0.1  # Adaptive Levy flight step size\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return self.levy_flight_step_size * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                    self.levy_flight_step_size *= 0.99  # Adaptive Levy flight step size\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9", "description": "Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and an adaptive Levy flight step size.", "configspace": "", "generation": 155, "fitness": 0.23342119609609088, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.6694281048275266, 0.631026602452216, 0.5775184929497187, 0.6395424985521657, 0.5878415077258073, 0.7222348574985709, 0.5830841070902273, 0.6398039079877853, 0.6725737656350053, 9.999999999998899e-05, 0.025345242004639834, 0.05922419995552153, 0.01874413177846035, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04390410362733632, 0.14361172721496518, 0.09096688071065906, 0.10467457513900713, 0.10747673642282785, 0.11525549813478286, 0.10304357993025792, 0.08699251915175732, 0.149261786220809, 0.09126515677169644, 0.095353996931821, 0.07816224596811694, 0.11581446810527762, 0.08985211691407657, 0.08568489816568925, 0.06970125980886699, 0.0821545061687653, 0.09424942206060882, 0.07780276471010406, 0.8704268731331402, 0.8905377438177664, 0.8844528961057552, 0.8030930075399484, 0.8506427546232715, 0.806042094554521, 0.911068874949031, 0.9000927096287996, 0.913110695860468, 0.24708121266803806, 0.24097251078092963, 0.26106041094069277, 0.23900393356131966, 0.2334348348266031, 0.26048112207816876, 0.243986725704053, 0.23421083317069813, 0.21450685928051116, 0.5725749416609467, 0.37148974760192544, 0.21706328813922904, 0.2711638330812045, 0.26412745000289406, 0.24717134249654749, 0.2081106884269428, 0.24482970373669377, 0.19390378667615704, 0.12584089784108599, 0.12063707101977705, 0.1223396016459195, 0.12678333705744005, 0.19634709156716368, 0.1710329039897135, 0.16568174550527714, 0.1213533927699103, 0.12614344256563959, 0.12933095974851494, 0.18795550603070532, 0.13197129479662728, 0.17494998288082864, 0.1395036959024596, 0.16242389463332096, 0.1583948310337404, 0.18056138547386813, 0.15914898736217187, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.019194637376698687, 0.0739939785593795, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.034854682423120176, 0.06324199581357348, 0.05597482523119701, 0.08703494952918922, 0.0713344919480311, 0.08790267968289789, 0.06260582267875214, 0.13176949407546568, 0.10475416658977899, 0.07220577750198498, 0.10054413453824762, 0.09198160697377167, 0.08739769934160213, 0.1160649490704565, 0.0810033266897342, 0.12580036912789472, 0.18973524364395933, 0.13105205736075476, 0.07509309535430364, 0.1687082873143696, 0.14903337184721954, 0.11299653413726574, 0.19708620944438648, 0.14954391282034718, 0.1251328319328472, 0.14915421343171187, 0.13988249807571007, 0.15047669395174867, 0.41724880940033726, 0.4345013992417551, 0.47143465512553373, 0.42260405047288885, 0.4053092294506472, 0.4449644179932205, 0.4351847241735485, 0.5135031820141098, 0.4250861329829779, 0.1015106823569617, 0.08756562586574035, 0.08606321050190924, 0.09236234406117905, 0.10593111229048957, 0.12230125169814854, 0.11942493099118823, 0.16118533139746194, 0.11606354558466703, 0.2940434071454855, 0.14195019924451624, 0.1655138008061785, 0.19531439537573192, 0.2647306052475714, 0.19528022573290482, 0.2605422363388916, 0.21490450766374725, 0.19473898600498218, 0.28932595364779534, 0.3520372409221273, 0.292521044698265, 0.28245856432771277, 0.2964403053781045, 0.2757671894159248, 0.2749010810629837, 0.34183131982438597, 0.22968470082743375, 0.21460584163597296, 0.3092575823298964, 0.2597005170643534, 0.2985165119206874, 0.28037831440932737, 0.26429564691093854, 0.22149056642851406, 0.265858573209352, 0.19064945756297347, 0.21698536121643552, 0.26410266825570605, 0.2639776895007445, 0.23176512657616033, 0.1963785325966666, 0.23674327467914758, 0.22228022108538448, 0.22547010840267945, 0.23640889593919867, 0.20370695731089294, 0.19785077154216946, 0.19234293514379175, 0.17752300675924948, 0.21100356404723075, 0.18240423170718834, 0.18582980630155588, 0.18888734349098535, 0.17388693713604608, 0.17089398661167632, 0.18622978487966524, 0.1855373901715076, 0.6412768064629719, 0.19794680627798356, 0.19746886601478641, 0.5973306510818017, 0.7290423870991078, 0.7368553630416887, 0.47584915858305077, 0.21010524166574185, 0.2622314132843768, 0.3423020335709439, 0.3046395402284021, 0.16742936472718117, 0.1684045216121498, 0.15468580276829458, 0.3479116116380947, 0.1946180942880349, 0.18247088988408, 0.19473986703872215, 0.1989906956874069, 0.17385556817761594, 0.20796576800189703, 0.18046903346670573, 0.19218502458295095, 0.1914158262195298, 0.11215483207433985, 0.08375852975827769, 0.08346564644528476, 0.09229024342225589, 0.08401936533980092, 0.09085290381794187, 0.10528455244743906, 0.09339421458862485, 0.09108463541265488]}, "mutation_prompt": null}
{"id": "f494822b-72c5-463f-aa00-c12a45fd2eba", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.social_learning_rate = 0.1  # New social learning mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def social_learning(self, particles):\n        social_centroid = np.mean(particles, axis=0)\n        return social_centroid\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Social learning mechanism\n                if np.random.rand() < self.social_learning_rate * (1 - evaluations / self.budget):\n                    social_position = self.social_learning(self.particles)\n                    social_fitness = func(social_position)\n                    evaluations += 1\n                    if social_fitness < fitness:\n                        self.particles[i] = social_position\n                        self.best_fitness[i] = social_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], social_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9", "description": "Novel Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and a new \"Social Learning\" mechanism.", "configspace": "", "generation": 156, "fitness": 0.2290494248012837, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.5548427340842932, 0.653939059129685, 0.612111028684492, 0.5591665552058058, 0.6563571583965151, 0.6790398815865006, 0.605478936154781, 0.5904738935836388, 0.5504785565487978, 9.999999999998899e-05, 0.029186293601887292, 9.999999999998899e-05, 9.999999999998899e-05, 0.0026229354834998997, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11093539742948721, 0.10238468401440404, 0.09863419583784239, 0.1281784037925059, 0.09262912133793144, 0.12004700110951927, 0.12036339774961036, 0.17746505339493757, 0.1137400037763413, 0.08872059190104897, 0.0941119190677604, 0.06924889258054978, 0.10676299631589792, 0.07362812430759713, 0.07040071914332524, 0.10500437800863205, 0.07632805860965286, 0.0918466636597648, 0.8856497379083538, 0.9108600756958407, 0.8313115441775889, 0.7922212275998873, 0.7214189401872775, 0.8504017377725887, 0.8738478817271289, 0.900441657616611, 0.8688668907758736, 0.2561032693066151, 0.2364507402158028, 0.23182694425952477, 0.24297988026617767, 0.2086494189907363, 0.23246188341281426, 0.27164946887811225, 0.2475445000110762, 0.2421587167395285, 0.3120588579423481, 0.22884519720641294, 0.22120592771280312, 0.26786489715030826, 0.8127935981105168, 0.2142281391637595, 0.2381766368915349, 0.22896484354420665, 0.22737483107140666, 0.21496568388311588, 0.15257885635538437, 0.11770414171288301, 0.14497559591216092, 0.12297435351481523, 0.11920287597382262, 0.1567981626454652, 0.13693967831063236, 0.13623136429888094, 0.18359529559856502, 0.18427239637779524, 0.143357042268911, 0.19931312023727332, 0.15545011598117509, 0.123949976514105, 0.18319943714488185, 0.1702957696944235, 0.17931245592914768, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05691790101910832, 0.013164707483709903, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02648047353588301, 0.14906223489932358, 0.04777255919443191, 0.10278428861064914, 0.0627434179657399, 0.04118400075888273, 0.02627778532965419, 0.11584263613387047, 0.11925924241060726, 0.07360480050161278, 0.08898856301246139, 0.07109132394215645, 0.08304250067677477, 0.10198511558196499, 0.12299093350003609, 0.09321386420101863, 0.09391067949966614, 0.1364987089122457, 0.07191487410570774, 0.23253218438481071, 0.11531790329323743, 0.110020871818994, 0.11480208975145578, 0.10608630286279264, 0.1441917942512113, 0.13452857488930714, 0.08374933774769378, 0.08332233662132871, 0.4799370957759834, 0.4228904264103701, 0.425757385782887, 0.4719454030111475, 0.46456289246300564, 0.4470130264038178, 0.44707580825339877, 0.44163498083726827, 0.4279299815250235, 0.125731229557681, 0.12522115943229928, 0.10905012149725102, 0.09332857271078643, 0.11155037994115014, 0.14821482195201574, 0.11520269827414142, 0.10628939153690575, 0.08982314402622982, 0.2832664195189877, 0.17192956523634217, 0.15205482373688028, 0.19226980963837026, 0.27499883583536533, 0.1612103064955276, 0.2810026716135562, 0.23176854443410555, 0.22214792233061764, 0.26259176431434295, 0.2846429979827929, 0.31218245212168483, 0.32458188885145256, 0.30666084512154246, 0.3076318652417267, 0.255666359036008, 0.29614494715984296, 0.26929764816055357, 0.17818587020065646, 0.2602414332059535, 0.22624322763566007, 0.20985900250530454, 0.2132692640617322, 0.21585918635422474, 0.20781065140662658, 0.20685728538465087, 0.21404877799358824, 0.24205380589021086, 0.22170650395474367, 0.23441395154962397, 0.2849685770066477, 0.254979626932774, 0.23726498661424877, 0.23686128632894698, 0.23248849344240496, 0.2485365826019681, 0.19617898950913926, 0.18596752027681396, 0.17132483484419425, 0.2068366976080389, 0.1786368681235312, 0.17513566294887495, 0.2041198428536971, 0.19773539563257403, 0.17375739331133844, 0.18461851720031341, 0.18560419308184406, 0.721943349228353, 0.6948511033361189, 0.19840917370876954, 0.1945944456289278, 0.14039581300455561, 0.15045496061474883, 0.6723185527806932, 0.5055919709566024, 0.20971038555298482, 0.42636399150624316, 0.3554196184704108, 0.3221225822141709, 0.16629884573593767, 0.16704495018019483, 0.321241793988677, 0.3361564388152669, 0.17694103919697335, 0.2006934261754164, 0.18905927217659702, 0.17799239918139376, 0.20369203039387973, 0.194869473113216, 0.19442284462777648, 0.19552060321992604, 0.19754953126055008, 0.10245426983922845, 0.08150344046121138, 0.08351528710756606, 0.08728626381566496, 0.08931278326796022, 0.08863101303055976, 0.08382916784545014, 0.09308731124960845, 0.08244260262893899]}, "mutation_prompt": null}
{"id": "873a1d1d-0820-4cf3-89b4-38099856775d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search.", "configspace": "", "generation": 157, "fitness": 0.23980933065810403, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV9 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.21.", "error": "", "parent_id": "5d1318c4-8cc6-406f-bc34-4a3f4bc1547d", "metadata": {"aucs": [0.6388761577095868, 0.6949831323371582, 0.6774632576332046, 0.712830766606666, 0.570780601709959, 0.7092653619007073, 0.6262682954215028, 0.6552956889254136, 0.5917322595555601, 0.008347417375555777, 0.030328406127399066, 0.001729485309341361, 9.999999999998899e-05, 0.0004010094810104059, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1377473980678744, 0.0992252434452634, 0.13481527452850828, 0.10362663988126752, 0.11165636444170379, 0.09605095280873388, 0.1645459047904838, 0.13766849647949897, 0.09341177432523473, 0.07815353501225641, 0.09363913673944413, 0.08116874245030359, 0.11751555389265178, 0.0880388633592396, 0.08843688928427396, 0.07446842508810292, 0.09291978686224533, 0.10202252596163963, 0.8862883078252074, 0.9370801703511664, 0.7786775686829607, 0.6642178368276352, 0.8948201347233677, 0.7771455306214063, 0.9061958652309449, 0.9084806348959552, 0.884200735555955, 0.29312537745134515, 0.30459913962054264, 0.24263665851586524, 0.31006721511508073, 0.29079613848801, 0.2603062116430078, 0.21902943143222142, 0.2586832241823023, 0.23179850717473915, 0.5582901618686635, 0.3662276261700719, 0.3086247536179745, 0.2785959766839773, 0.6300632690661596, 0.1970392238091393, 0.30860091847824356, 0.22672319947507003, 0.21875625075094673, 0.08914940943648986, 0.10902744956234633, 0.12377854906731667, 0.16757982049685272, 0.12567091170554834, 0.13673913004277305, 0.12748918872973158, 0.14991779043591302, 0.16576912204623118, 0.15970553084335737, 0.2290945778679373, 0.14042540167525497, 0.17088668394248685, 0.15545249452657028, 0.2342602816935363, 0.17919850625535727, 0.18003340662474965, 0.15244835473382357, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005172339353584743, 0.034169109161717226, 9.999999999998899e-05, 0.0029178170188902675, 9.999999999998899e-05, 0.021143990874480934, 0.12854278241014871, 0.04486303242944145, 0.12600986640145817, 0.10963864363002651, 0.1099903047732731, 0.03230138657660209, 0.10762204763928818, 0.10588622515086954, 0.08448298035856938, 0.09451651854553889, 0.10847541977078856, 0.13056121627424477, 0.0694578547793484, 0.1273411763949509, 0.08147249379163368, 0.1115697016948588, 0.0982788990426452, 0.08468030380566216, 0.2567026851448374, 0.12993409533415523, 0.20488617968232015, 0.08781734312690914, 0.1628281242261317, 0.13676989329865774, 0.16371144222610112, 0.11530804223541113, 0.12506554809482873, 0.4611790117786452, 0.416821495764939, 0.44597233883673104, 0.44523116827243525, 0.39865868639179003, 0.4486153318979631, 0.41650547383039027, 0.46875012599895094, 0.46999389274615355, 0.11268278431878376, 0.107928644232126, 0.11608644443462612, 0.24569454159423032, 0.08901180614204818, 0.1347793246704594, 0.10746684945782892, 0.10791069712321766, 0.09103213193063586, 0.31875664552190797, 0.1721153537536244, 0.16894166734852645, 0.20806222473675762, 0.321284911609789, 0.1949101748351435, 0.27182432010467905, 0.17626350368851618, 0.17885540212751316, 0.25709787608122714, 0.3523989881683548, 0.3228078030864904, 0.2660217715601899, 0.33636717302128494, 0.30724052008298497, 0.25185738604278485, 0.284494863471788, 0.25238399527555644, 0.2303622837084548, 0.307241621304718, 0.2569112044273375, 0.18076963097994958, 0.24480041570014255, 0.28678774363523485, 0.20761578615600362, 0.24529062500520504, 0.200263778820854, 0.22493963073212797, 0.22432694058162517, 0.2278122451616308, 0.2331391442024645, 0.23914157075430298, 0.23780982423715336, 0.2104545088938673, 0.21198638092176392, 0.21575141150596933, 0.19926412606468058, 0.1867058067565034, 0.18214708048129447, 0.18587771689795396, 0.19741267963257858, 0.1752322853676216, 0.167127136853513, 0.17822379291796897, 0.18261840643602878, 0.18020848772608256, 0.1864886118790262, 0.7433286228159696, 0.676738732350932, 0.19870422403986499, 0.19892480460398243, 0.6733302522208573, 0.1503118425572153, 0.6238432666420838, 0.5798341459234369, 0.20873207658055348, 0.37762804395557337, 0.4469045575872771, 0.4557831854113268, 0.16776100386915038, 0.1676072785687256, 0.33831277254981673, 0.3146122895006096, 0.1929295680665567, 0.18635941158516156, 0.18888872697174708, 0.23036050321992585, 0.19885239555925904, 0.19312766235159062, 0.21743794259951188, 0.1808168870838719, 0.17236108017336282, 0.09931421690637965, 0.08592832514255389, 0.0874125287562918, 0.09378581747352543, 0.09714760068740413, 0.09227907309546868, 0.09775281914865952, 0.08997735403131535, 0.08478271373597401]}, "mutation_prompt": null}
{"id": "bf578ff6-e27d-45ba-8bec-0dd41c2b54a6", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.self_adaptive_levy_flight_rate = 0.05  # New self-adaptive levy flight mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def self_adaptive_levy_flight(self, position):\n        levy_flight_vector = self.levy_flight(self.dim)\n        levy_flight_step_size = np.random.uniform(0, 1)\n        return position + levy_flight_vector * levy_flight_step_size\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Self-adaptive levy flight for enhanced global search\n                if np.random.rand() < self.self_adaptive_levy_flight_rate:\n                    self.particles[i] = self.self_adaptive_levy_flight(self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and \"Self-Adaptive Levy Flight\" for enhanced global search.", "configspace": "", "generation": 158, "fitness": 0.22868546483969224, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6087504438700464, 0.5989343965821662, 0.7010553735746152, 0.6128714837615894, 0.5678109284994153, 0.6955731500860936, 0.6747403690728015, 0.6115929578485584, 0.6645794394650666, 9.999999999998899e-05, 0.00693121876869196, 9.999999999998899e-05, 9.999999999998899e-05, 0.0007680235496480003, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13641449533984362, 0.09170131680333671, 0.09822267850934152, 0.11367417417625547, 0.10408812973993409, 0.08956833025088895, 0.11725881325383924, 0.1211659531735284, 0.13033848598239928, 0.0869571690072064, 0.1148743582304802, 0.06990487607999907, 0.08405443358208209, 0.09053569529184857, 0.09443503846837209, 0.09068733526271988, 0.1007530503987093, 0.10109882081742416, 0.8417080992760319, 0.9241352184276512, 0.8992340174199027, 0.7827081578216607, 0.8656217830078651, 0.8417762772317419, 0.8847127128786736, 0.8571727352205402, 0.8843430850677435, 0.2882657344053092, 0.26504105309908, 0.2645673665513735, 0.2929772345955506, 0.25514293520048137, 0.27251521728303607, 0.23255592674959302, 0.23482991684222843, 0.28050566739509264, 0.3576810401858739, 0.3741630193836154, 0.22219258579993384, 0.2753046706476301, 0.3149159780388471, 0.21376479447714358, 0.2411312821927496, 0.20388082793592388, 0.22790956346171454, 0.12246686644862748, 0.10728371902533906, 0.20530867615477943, 0.11918971974169312, 0.13118142328871785, 0.1378227241771487, 0.1467860908024059, 0.16612754645201566, 0.13430369824558186, 0.16106009404650667, 0.16985907040343484, 0.15180390222353524, 0.1543609589721231, 0.1528350929152199, 0.1368765943280268, 0.1660163088634159, 0.16821504919947716, 0.15925278979316349, 9.999999999998899e-05, 0.02053974759552546, 0.037882494209017015, 0.05430187349190041, 0.02633709496227421, 9.999999999998899e-05, 0.002564393625822947, 9.999999999998899e-05, 0.003318394022181037, 0.10923151028104094, 0.03654986396022575, 0.08529792967607497, 0.11099023624913129, 0.07437909930100772, 0.07401080050737652, 0.10743704391034337, 0.07306586661160286, 0.07260006801020114, 0.1455952473531148, 0.09803349646086867, 0.0637876309609926, 0.11107080319129958, 0.0948656926602911, 0.06404472784720272, 0.11823792231011099, 0.12974815739303536, 0.076479988367399, 0.18107400844544808, 0.11851972899664343, 0.22284164707101572, 0.09795856066016839, 0.18005727569096708, 0.08142022235615809, 0.14202856176205336, 0.10972202230080041, 0.09351250521519194, 0.45595033485607006, 0.44845122869089393, 0.4185338167914353, 0.4254548979394879, 0.43203903974999625, 0.4423766854445087, 0.41738889726182704, 0.4286735904666614, 0.4686314359856142, 0.102666137704719, 0.13007005274994266, 0.10102424196386495, 0.17903606549456275, 0.11111210464211985, 0.10567334299570941, 0.13239716914962685, 0.12288725035469639, 0.08146868862908974, 0.23207965645174233, 0.18267001015245354, 0.18768278950065387, 0.16759701016507933, 0.20469582977467948, 0.1911170240758835, 0.3302551658590126, 0.14216557143914, 0.21071014923539355, 0.24251783471978283, 0.2800818458842036, 0.31467102722861684, 0.30629751324125865, 0.31344142353522697, 0.25962836234294995, 0.2554352982807906, 0.34885534912716454, 0.2563791264808849, 0.2754913738022944, 0.23264236792056558, 0.2492600112421398, 0.22769464742864742, 0.22693318847499933, 0.28041857234428635, 0.21252857088626476, 0.1905859071119258, 0.1931923739805882, 0.21564955056905044, 0.2268316413460224, 0.2633874156486399, 0.25543657945309484, 0.24100687207384186, 0.2499053381563956, 0.21369747371758652, 0.2346581505410893, 0.21102081495838343, 0.18556373350588862, 0.203592681787914, 0.17276547705234158, 0.19392173825238734, 0.18015644248440854, 0.17570667024297892, 0.18255785467979335, 0.1949396768810464, 0.18244577894366898, 0.18492705882310445, 0.18711152727663094, 0.18626407423158797, 0.1773688568394105, 0.18907054132135503, 0.1456182503806449, 0.14107796798105188, 0.7030704934976666, 0.8573764074566972, 0.5003744370378347, 0.20955287613559725, 0.7030665803381781, 0.2051766119132209, 0.16696308871333454, 0.3512295331858514, 0.1677206085409152, 0.2574966151849847, 0.40800404038899374, 0.1983343640595715, 0.1858047726932347, 0.1944312840302519, 0.19326902213947483, 0.17714154030910756, 0.18282013293212418, 0.18332451390370985, 0.19549020047928112, 0.17280317168916626, 0.07988602529001965, 0.08477612288340008, 0.07625894063685068, 0.08467039588049008, 0.09178105481845156, 0.09762709148293014, 0.08703779437006143, 0.08914774659740832, 0.09052700949735648]}, "mutation_prompt": null}
{"id": "a8be634a-b46d-4d64-a0a7-de86bd7cfdef", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_optimization_rate = 0.1  # New multi-objective optimization mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def multi_objective_optimization(self, position):\n        objective1 = np.sum(position**2)\n        objective2 = np.sum((position - 1)**2)\n        return objective1, objective2\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-objective optimization for better exploration-exploitation trade-off\n                if np.random.rand() < self.multi_objective_optimization_rate * (1 - evaluations / self.budget):\n                    objective1, objective2 = self.multi_objective_optimization(self.particles[i])\n                    if objective1 < fitness and objective2 < fitness:\n                        self.particles[i] = self.particles[i] + np.random.uniform(-1, 1, size=self.dim)\n                        self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search and \"Multi-Objective Optimization\" for better exploration-exploitation trade-off.", "configspace": "", "generation": 159, "fitness": 0.22983318352814056, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6320937885373368, 0.6286320003948958, 0.614260799441898, 0.6091951398224997, 0.567121241437452, 0.7218003969221256, 0.5848579235170628, 0.6909894982815897, 0.5801598388574707, 0.01572487686985935, 0.14296439591796972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.027080077264590163, 9.999999999998899e-05, 0.13691834863297936, 0.09367616814334634, 0.08007331442870236, 0.11101447123245056, 0.10620663203494374, 0.11044749372395946, 0.09757531131147135, 0.1235126609952405, 0.150577805188861, 0.0887554210292506, 0.10009900636121716, 0.08882936828157018, 0.0790529754903988, 0.10778261341108297, 0.08240169270353292, 0.10359099649299952, 0.07945211992187129, 0.10022509220306308, 0.8774261869872567, 0.9550639427264999, 0.8432755874283568, 0.8281133908696594, 0.7638866665790571, 0.8021613012811284, 0.9019436009501002, 0.878037424307122, 0.9109424256834284, 0.30280597466204706, 0.2278089569796412, 0.23980140885879553, 0.22493584573718928, 0.2527738966265267, 0.2526435060042673, 0.3045962668311375, 0.22529761626993206, 0.22713348253546561, 0.2137650714059839, 0.30617816946081444, 0.30858985820913065, 0.2542029073799247, 0.36642409301670653, 0.19895653677359182, 0.22461593933348867, 0.2314572623170733, 0.22635578641986853, 0.10611001343421034, 0.11673799298565102, 0.11925218058111553, 0.11463819747512194, 0.1483516521805972, 0.2770836393623909, 0.14040365398835997, 0.21507073909059216, 0.14600655012905028, 0.16647317012946639, 0.13689984947670897, 0.17634283500638426, 0.13636868057135287, 0.1577669125026756, 0.14908797223436754, 0.20650748711217914, 0.17006777289553154, 0.13519353625367225, 0.022915622734159258, 0.0001729362579808713, 9.999999999998899e-05, 0.0465097602350123, 0.03880476022823698, 9.999999999998899e-05, 0.012039227225060456, 9.999999999998899e-05, 0.03699224425797143, 0.1578740596792888, 0.031217208603115054, 0.14371448442450363, 0.08366822602458956, 0.06242852817573907, 0.0455113245618326, 0.09735526700029495, 0.1020439087939552, 0.11608498385599464, 0.09025251133755485, 0.07621981677209899, 0.07964787942512375, 0.15158658996903396, 0.08627036730241411, 0.09854295444657224, 0.10282172251338129, 0.10509153157504991, 0.08173028421515205, 0.2268172137866009, 0.17931111329678773, 0.1636093085157425, 0.08568542199899298, 0.09108806366633926, 0.11675482176507379, 0.13630010101827117, 0.14353748797873978, 0.10895260525154848, 0.4532169719222203, 0.4531542593592137, 0.4862837867723665, 0.4290111830178692, 0.4379175539310257, 0.4529074985711733, 0.4788128492369892, 0.4515941383640607, 0.42251342370474154, 0.088974505881524, 0.10354991504399891, 0.12318933270371513, 0.09140294779877944, 0.13330099230194448, 0.09511672735752852, 0.11689886970595076, 0.10308947167558413, 0.11846842959909154, 0.2162148018586486, 0.14929801553454725, 0.18407152970121188, 0.1751726307373177, 0.234396040227434, 0.216430363459151, 0.19241195681397616, 0.14965712436505108, 0.18807030304922068, 0.28320656264359123, 0.3317605748295017, 0.370627664806951, 0.32791432241714324, 0.2818134150021592, 0.2934318472230911, 0.2500216158635139, 0.31511176548070896, 0.2366233216212278, 0.24595797198999958, 0.2227703131659602, 0.26208139011491627, 0.2548097616486015, 0.23382384502943254, 0.2533646981994112, 0.21627121411493777, 0.26089638190099895, 0.21085300791030037, 0.2398473024190082, 0.21273469011922042, 0.21334643036247225, 0.204643830312905, 0.22966369069198955, 0.20716333153257427, 0.23510222025758365, 0.20401810512299834, 0.21517239510555997, 0.22484423838352607, 0.1901913348530313, 0.19252984769476367, 0.1804002808416384, 0.18906726353348735, 0.18243003703541916, 0.17943454013505855, 0.19976132590565332, 0.17214253152544512, 0.18518448662608222, 0.1862369420755544, 0.697771406538784, 0.11812449137809511, 0.19858966899849617, 0.19816306605399414, 0.16673933513642858, 0.20726501890382898, 0.6321098771867593, 0.4380542799983589, 0.21212472628856538, 0.45483192950746887, 0.5371651936629225, 0.4040298517121832, 0.4838925850635515, 0.16640466539312038, 0.16446578270398515, 0.39143834502708175, 0.19743774295457528, 0.20294820253338508, 0.1858378814555831, 0.18517314210886815, 0.17846219730957458, 0.19105381401694288, 0.18617065386775422, 0.1969323479573376, 0.19112163513286906, 0.10461130844158029, 0.11315233849478012, 0.0861989406610717, 0.10955611872629145, 0.08283228681714139, 0.10986567314278195, 0.09682920417938079, 0.08913728907770802, 0.08001677366883231]}, "mutation_prompt": null}
{"id": "ea972e37-6dce-4116-8908-1f65e30e04f9", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.hybrid_exploration_rate = 0.1  # New hybrid-exploration mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def hybrid_exploration(self, position):\n        exploration_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + exploration_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Hybrid-exploration mechanism\n                if np.random.rand() < self.hybrid_exploration_rate * (1 - evaluations / self.budget):\n                    exploration_position = self.hybrid_exploration(self.particles[i])\n                    exploration_fitness = func(exploration_position)\n                    evaluations += 1\n                    if exploration_fitness < fitness:\n                        self.particles[i] = exploration_position\n                        self.best_fitness[i] = exploration_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], exploration_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Hybrid-Exploration\" mechanism.", "configspace": "", "generation": 160, "fitness": 0.2314174742236298, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6125824774325759, 0.5990155800405379, 0.5942703456911014, 0.6042542693238095, 0.5845178281213235, 0.660259563492832, 0.5961206249938704, 0.6350209086322897, 0.6197322266245386, 0.018541349854917955, 0.04378846500325251, 0.0020853975839251193, 0.006168904117033747, 0.02417029594857889, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13199821747675655, 0.09900934967579345, 0.11803608686199918, 0.08783804207449064, 0.10168677924281788, 0.11595617690735593, 0.10509759555579856, 0.1029785864900501, 0.15497964047657153, 0.06278616535787407, 0.11105848330980428, 0.10084139353626365, 0.0913014341052738, 0.07873546443706769, 0.09013001535685294, 0.12552845708078653, 0.09730089216819637, 0.0932067017807976, 0.8843738784953601, 0.9335834102564146, 0.8664238812462577, 0.7937522397484056, 0.8671174025940622, 0.8558136517005249, 0.8955552216846007, 0.9098469269921373, 0.8523981164385521, 0.3079991116055525, 0.2631934762992757, 0.25167634607010736, 0.30124540164435576, 0.28639317707816137, 0.2313402812958376, 0.27042593197048614, 0.2615155827728288, 0.28984463410417916, 0.3583296926177505, 0.7602457508424253, 0.22640180804819066, 0.27453532624516797, 0.27105657870806643, 0.27413904415609824, 0.2605555983002378, 0.21697118583521324, 0.4818256846712001, 0.11926337688901245, 0.27905427916660497, 0.11775715826819233, 0.22967702536172352, 0.15708305388428268, 0.15204747196790136, 0.15287697557716806, 0.12650788010390712, 0.1547157512178703, 0.18472576348201308, 0.17341924844343848, 0.15548814161062963, 0.17089925835825126, 0.15211395089352575, 0.12572301172507794, 0.27045305896133887, 0.16966339313195822, 0.17357620918335848, 0.048665779621226646, 9.999999999998899e-05, 0.0021655519550116686, 0.042532246079000524, 0.015408654534225352, 9.999999999998899e-05, 0.008220102456576228, 9.999999999998899e-05, 9.999999999998899e-05, 0.048189101895538045, 0.05594118854952923, 0.09755257859894462, 0.08417254344474445, 0.06733915983072147, 0.045179553528066796, 0.0735118300040043, 0.06593095137731197, 0.10443059854760228, 0.08722585771817992, 0.1015455888275354, 0.07427654525657323, 0.08507846989813805, 0.10901759834249092, 0.08314423786413738, 0.11036198506265338, 0.0685039492732672, 0.07871633971628211, 0.2068501986374227, 0.16334892371607823, 0.15629621576572028, 0.13401907872053398, 0.18059939447311557, 0.12788266261626413, 0.13233880736069292, 0.16608433837742764, 0.09598285244605853, 0.44566194122134717, 0.44440352122268223, 0.4335913180587053, 0.405160425147551, 0.4258142977540973, 0.4013501656077444, 0.48035330031248913, 0.42753856509563926, 0.4442076755129869, 0.10121843363611382, 0.1163251591225477, 0.11572423531975329, 0.12674955157186285, 0.11615645156297527, 0.10001066690757376, 0.08372151461815136, 0.09652267853144314, 0.07370329924328722, 0.2606266435397444, 0.2254516837884798, 0.16416507629755783, 0.24219257462756838, 0.27703067670812, 0.18300450948762637, 0.22022557672373722, 0.16829875151728102, 0.277848125938005, 0.34444759983158924, 0.3020685232462139, 0.32258419607281497, 0.31727328539910227, 0.3114816005727662, 0.3133535961825059, 0.24214087179905097, 0.27433997287635925, 0.30249023751315696, 0.23904272095365098, 0.2217849211005879, 0.27353209713440507, 0.2300291218771976, 0.19881501344359132, 0.24464445249590594, 0.22146871154784753, 0.20849255849958304, 0.2035474317770979, 0.2725793464629169, 0.22012641156838075, 0.20354492953783243, 0.22990914199974255, 0.2135732323171614, 0.20686745399332052, 0.21818312720016197, 0.21038130181636883, 0.20454765678767095, 0.20222697370259346, 0.19124931485257635, 0.2200975721529178, 0.1834431177780782, 0.1910944876266879, 0.1924952879337739, 0.1889929925616648, 0.19233977006959402, 0.18507418841042178, 0.12683334175673322, 0.1855362635278458, 0.18719912533444882, 0.5495707390038582, 0.19883955915694618, 0.19755357946233576, 0.1466076814029761, 0.1543066865148749, 0.8049610644772345, 0.45319136999156184, 0.17323669857377044, 0.36881924417554457, 0.41574249575169975, 0.20653066651305008, 0.16552881623306637, 0.16740014350115473, 0.2945631388201989, 0.3505670571589642, 0.18449150542714532, 0.1943450009034975, 0.21361266158159897, 0.1883760902979409, 0.18858148123118057, 0.18753466135465702, 0.19209844016836242, 0.19047977144430783, 0.1998347219788713, 0.09004092735852376, 0.09422909141670988, 0.10040142931692186, 0.1043106519114072, 0.08440876299657574, 0.09067917229532962, 0.10935626279767552, 0.08170647602135572, 0.08746466137742825]}, "mutation_prompt": null}
{"id": "c906cd13-1f89-40d7-8837-3d66d613fd8f", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  \n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  \n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  \n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  \n        self.swarm_restructuring_rate = 0.05  \n        self.quantum_tunneling_rate = 0.1  \n        self.randomized_dimensional_learning_rate = 0.1  \n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def randomized_dimensional_learning(self, position):\n        learning_vector = np.random.uniform(-1, 1, size=self.dim)\n        learning_mask = np.random.rand(self.dim) < self.randomized_dimensional_learning_rate\n        return position + learning_vector * learning_mask\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Randomized dimensional learning for improved exploration-exploitation balance\n                if np.random.rand() < self.randomized_dimensional_learning_rate * (1 - evaluations / self.budget):\n                    learning_position = self.randomized_dimensional_learning(self.particles[i])\n                    learning_fitness = func(learning_position)\n                    evaluations += 1\n                    if learning_fitness < fitness:\n                        self.particles[i] = learning_position\n                        self.best_fitness[i] = learning_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], learning_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and utilizing \"Randomized Dimensional Learning\" for improved exploration-exploitation balance.", "configspace": "", "generation": 161, "fitness": 0.2330134581128572, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6390561890979773, 0.6464611096036582, 0.6417832417235847, 0.620582745078464, 0.6733841798761284, 0.6682146661914261, 0.6531157725760915, 0.6036253054009205, 0.5305058831103762, 9.999999999998899e-05, 0.04304846100294912, 0.0055443753294497355, 9.999999999998899e-05, 0.004474046506100615, 9.999999999998899e-05, 9.999999999998899e-05, 0.005826191222795152, 9.999999999998899e-05, 0.10922463837867558, 0.09042580941293965, 0.08839322655780346, 0.11253955360017898, 0.09749658373303705, 0.10999476029505695, 0.11185475743707574, 0.11446553334355358, 0.13444252459008055, 0.10748715747091464, 0.10883733270173834, 0.10284231149818457, 0.09351661634287989, 0.09413519806818405, 0.10594209930250531, 0.08359446918155922, 0.08774530120052693, 0.07426877877750793, 0.904060172917671, 0.9333221014109205, 0.871383231462702, 0.7742774916698631, 0.8345404928160717, 0.8052482470846267, 0.9161661133658381, 0.8841336119813904, 0.8790402443684134, 0.266962296313523, 0.28687757795294555, 0.25577102417068, 0.28240773073884096, 0.23189486444318652, 0.25882615359286754, 0.23840987147191894, 0.2595099728033905, 0.2694363013302995, 0.4702292760019714, 0.22364797414523518, 0.29886943838702595, 0.289475754003786, 0.3610384087830204, 0.2751305045298298, 0.5300185660087997, 0.3545716938126652, 0.3158011937924824, 0.121801403848952, 0.22823404491312527, 0.1855369738139664, 0.12029592897955532, 0.14446270458096677, 0.1494168888219236, 0.15533239384113784, 0.21332346584882755, 0.161683463490931, 0.17031202069425877, 0.22539704022985985, 0.16179274347018147, 0.159371092466721, 0.17357380538084655, 0.14672474567628668, 0.15172628295535528, 0.17458073113156292, 0.14594031332805446, 0.00014154439070956926, 9.999999999998899e-05, 9.999999999998899e-05, 0.07704615444959217, 9.999999999998899e-05, 0.0025968583422337765, 0.027920002375991904, 9.999999999998899e-05, 0.049843436958445064, 0.09916920442401733, 0.04218559324937865, 0.09681306332287243, 0.0793745062695902, 0.06964436769450111, 0.043737811461722065, 0.10155735909110586, 0.09951228319822181, 0.07866474649815702, 0.13434790372399186, 0.10749966534799205, 0.08855527140052799, 0.07907197305580371, 0.149961707014587, 0.0826999636620307, 0.09655024846801752, 0.06765735717336974, 0.08241466637121686, 0.23005092040621689, 0.13679238459741372, 0.1426686606072044, 0.1120893280032591, 0.1783562516670094, 0.12110776641951837, 0.15477654643581606, 0.11330514137452496, 0.10421707494992638, 0.4157564133990409, 0.40757957673324774, 0.43497599770724504, 0.41458039305280825, 0.45798507839010705, 0.42863630274220454, 0.4682164301124221, 0.42783182220336435, 0.46273966673657774, 0.14843251365867904, 0.1045858366581679, 0.09289626325791667, 0.12311535387806294, 0.11458125413544473, 0.13816429002781605, 0.11178292925002498, 0.10567550545729643, 0.1276056918408751, 0.24318975832930767, 0.23958105590199652, 0.18422830718710426, 0.17018843102987757, 0.29002670589992763, 0.21373540391455959, 0.23128209491580698, 0.17336081502781686, 0.25274687875663027, 0.2635332865126685, 0.33345668873128387, 0.3318096334711087, 0.32021842372060005, 0.29189691107689375, 0.3066265750517658, 0.26623585051526055, 0.3123663808243553, 0.27701575428997494, 0.24746366768663997, 0.20996601971652373, 0.2724258489244319, 0.24480260485907857, 0.2182194390744181, 0.24966881341243674, 0.21523215943262575, 0.21762644536834064, 0.20211950338128604, 0.21510599430075994, 0.23897314614423226, 0.20255529584302767, 0.23040211204561778, 0.2483354265098685, 0.2221187099232116, 0.22408761150515455, 0.21776912287179717, 0.19980348357429234, 0.1765489114431934, 0.23931463329519398, 0.21577562385965932, 0.18313462843628114, 0.20056126677738417, 0.19246754138248656, 0.18330396683419026, 0.17930346191739077, 0.17422344760003305, 0.14620907687826334, 0.18494902011739112, 0.1872523363817018, 0.6648200192914815, 0.19823195015314066, 0.19781954765389032, 0.14530781114543556, 0.15899364752420075, 0.7114598921339773, 0.4883548522257747, 0.15366621182454399, 0.3759146367896423, 0.46047845616632366, 0.20640163254251376, 0.16544101642942222, 0.16683560035116773, 0.34273908002845144, 0.43676545897522023, 0.19833555956088122, 0.1762088440366355, 0.20163681006994572, 0.19518345087378297, 0.198685759700295, 0.19654672029144138, 0.1886615308277214, 0.19290251965672778, 0.1779270419589737, 0.08121613724063903, 0.0935259433139638, 0.07149580704882241, 0.1311503188919354, 0.09086797753234732, 0.09223176743902572, 0.0869534085167667, 0.08242492659784018, 0.10074808783930078]}, "mutation_prompt": null}
{"id": "29071960-25af-456f-bfe9-474eb4ead4f4", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.chaotic_mutation_rate = 0.05  # Novel chaotic mutation mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def chaotic_mutation(self, position):\n        chaotic_map = np.random.choice([0.2, 0.4, 0.6, 0.8], size=self.dim)\n        return position + chaotic_map * np.random.uniform(-1, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Chaotic mutation\n                if np.random.rand() < self.chaotic_mutation_rate * (1 - evaluations / self.budget):\n                    chaotic_position = self.chaotic_mutation(self.particles[i])\n                    chaotic_fitness = func(chaotic_position)\n                    evaluations += 1\n                    if chaotic_fitness < fitness:\n                        self.particles[i] = chaotic_position\n                        self.best_fitness[i] = chaotic_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], chaotic_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Chaotic Mutation\" mechanism.", "configspace": "", "generation": 162, "fitness": 0.23920007048381547, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.21.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6453770987625591, 0.6414217770136081, 0.6466736380802094, 0.5645881589043505, 0.65173840655752, 0.5887837494787247, 0.6343281736036126, 0.5603529143949108, 0.6402595221727447, 9.999999999998899e-05, 9.999999999998899e-05, 0.0024380818490350453, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15045630664333598, 0.10200351063706348, 0.14995694328584286, 0.13790130214566565, 0.07651078115207544, 0.1111708087850165, 0.12100002393821907, 0.11008802905640436, 0.12034606644122758, 0.08859332502199091, 0.09119744653575323, 0.0681323807091494, 0.09366365668417453, 0.09846521023471855, 0.09004916527764051, 0.09884343475495738, 0.07208992325055608, 0.10756718750382965, 0.8688915841386953, 0.9158782792713487, 0.8699920271142109, 0.8186856619699777, 0.8386903817746627, 0.853753820315312, 0.91253116951947, 0.9079937802908971, 0.8160453813615072, 0.2537720817560881, 0.25945490517914527, 0.24552328160130443, 0.2594442197787842, 0.24829693219178606, 0.23547273177406491, 0.25322180108179415, 0.23802088034936286, 0.2435548556198991, 0.6463927007301811, 0.33470885216956936, 0.22219881499002025, 0.7906365016644937, 0.24453081075235839, 0.2264253415481826, 0.2266314015097901, 0.22049997379836228, 0.22167849365537717, 0.19584629695072509, 0.12535833082626235, 0.23661971956576566, 0.13629304444370205, 0.16883517529738024, 0.12767636082785427, 0.1683195113422724, 0.1156472176466059, 0.11890825826483964, 0.1375212933584955, 0.14729266113834405, 0.13932945972245947, 0.15350231672557324, 0.14887116098986042, 0.13539837065361593, 0.15691086101145246, 0.2821514682849767, 0.20076333547937342, 0.008573192141694386, 0.0025925482591816484, 0.015589317984689322, 0.016759381710235388, 0.017909446433688747, 0.0001014587164492875, 0.001334531506441583, 9.999999999998899e-05, 9.999999999998899e-05, 0.10265052831941135, 0.04625079293736489, 0.07897450618870538, 0.07458576296188602, 0.0748154617122484, 0.10922338292626266, 0.11087330327990985, 0.058249922997263504, 0.07495472326887853, 0.10565653073746084, 0.10209539387823863, 0.12030424593490274, 0.09998422354032721, 0.052186302695918174, 0.08034979130997433, 0.09422767586473324, 0.1283078794734478, 0.10638725980750152, 0.19336248626857, 0.16241532384434487, 0.13985522953670826, 0.17195756822539532, 0.13630773389296358, 0.10058284531370243, 0.25527620760359626, 0.09983004950282337, 0.1181349895778987, 0.4644010062964682, 0.41360048825245, 0.43505432729544724, 0.4689761727081456, 0.43254339114481966, 0.4092977716943945, 0.4309930813081292, 0.4577937732443411, 0.4325698545692013, 0.13886539406757925, 0.09596743469244085, 0.10105997296942137, 0.13030135084165828, 0.10198792315109895, 0.24297213015952046, 0.1289314188109134, 0.1160465840606788, 0.09281200202284234, 0.27453289866850195, 0.25146929111199157, 0.16757934654099316, 0.17307455104623892, 0.3007193539873201, 0.23318182878032712, 0.23678440037152781, 0.2361697287252924, 0.16836848138181104, 0.2489324831501375, 0.26613026690561015, 0.3256388176227646, 0.2420141246296844, 0.3581218495829509, 0.2228641770283084, 0.2524587688135307, 0.29654060738972055, 0.3116796114946605, 0.25925305740781646, 0.2171077876545321, 0.23312987454674916, 0.20801186193700894, 0.24148067371093296, 0.2265377191626572, 0.23080912366695105, 0.24267286046960312, 0.16674878876020016, 0.23060622251959484, 0.2192812474785495, 0.2290794300883131, 0.2239115906051924, 0.22395391565900358, 0.2416208742236179, 0.2753564394682757, 0.22918299251045404, 0.2110862983700219, 0.18101416363167355, 0.19840491377171354, 0.18037961551389148, 0.2181753917484972, 0.1715767308817101, 0.18406430591993161, 0.23900065111339586, 0.187568429356347, 0.18258357385130308, 0.7205852966447014, 0.18701157970676818, 0.6739636571632373, 0.6618309838706178, 0.1998925068920656, 0.19612269610432354, 0.1402518476426733, 0.8119182390929507, 0.7537394971856188, 0.4466747403154663, 0.20866432668484713, 0.39820186499858123, 0.20458295432328055, 0.16559026176667502, 0.1668717198705344, 0.1662516167383472, 0.5518219437458427, 0.3806456445377928, 0.20094328129365235, 0.18853990035847668, 0.19211826282762712, 0.18348929444736883, 0.1898137104057488, 0.20063758051226743, 0.1933986601801586, 0.18643390183098074, 0.19813850018546164, 0.07484470303712554, 0.09646610941619804, 0.09807064316427172, 0.08277725713787554, 0.08498901276530801, 0.09518653564019319, 0.07791380111813395, 0.086386515861262, 0.0955844488249249]}, "mutation_prompt": null}
{"id": "965a4050-5477-408a-a9d9-f4a4c848ee50", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.98  # Changed from 0.99 to 0.98\n        self.adaptive_cooling_rate = 0.3  # Changed from 0.4 to 0.3\n        self.levy_flight_alpha = 1.2  # Changed from 1.5 to 1.2\n        self.levy_flight_beta = 1.5  # Changed from 1.8 to 1.5\n        self.opposition_based_learning_rate = 0.25  # Changed from 0.2 to 0.25\n        self.dynamic_opposition_based_learning_rate = 0.1  # Changed from 0.15 to 0.1\n        self.inertia_weight = 0.85  # Changed from 0.9 to 0.85\n        self.inertia_weight_damping_ratio = 0.995  # Changed from 0.99 to 0.995\n        self.mutation_rate = 0.12  # Changed from 0.1 to 0.12\n        self.mutation_step_size = 0.12  # Changed from 0.1 to 0.12\n        self.velocity_clustering_rate = 0.12  # Changed from 0.1 to 0.12\n        self.particle_filtering_rate = 0.22  # Changed from 0.2 to 0.22\n        self.adaptive_particle_filtering_rate = 0.055  # Changed from 0.05 to 0.055\n        self.archive_size = 12  # Changed from 10 to 12\n        self.exploration_rate = 0.55  # Changed from 0.5 to 0.55\n        self.exploitation_rate = 0.45  # Changed from 0.5 to 0.45\n        self.hybrid_repulsion_rate = 0.12  # Changed from 0.1 to 0.12\n        self.swarm_restructuring_rate = 0.055  # Changed from 0.05 to 0.055\n        self.quantum_tunneling_rate = 0.12  # Changed from 0.1 to 0.12\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.12, size=self.dim)  # Changed from 0.1 to 0.12\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.12 * np.random.uniform(-1, 1, size=self.dim)  # Changed from 0.1 to 0.12\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.12:  # Changed from 0.1 to 0.12\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.055:  # Changed from 0.05 to 0.055\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with probability 1 to change the individual lines of the selected solution to refine its strategy.", "configspace": "", "generation": 163, "fitness": 0.22757795940271755, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.5784121075641613, 0.652891133230167, 0.6481240795172074, 0.6523744803255493, 0.6487832834631448, 0.5726034108813265, 0.5662851038611758, 0.6133630514850466, 0.584916821451466, 0.016265198510373557, 0.0035955942313632416, 0.03820574791561171, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11916157358847945, 0.09653240887961456, 0.1277862385727785, 0.11515518903822197, 0.10756269522076778, 0.10269961203287037, 0.11241524036808037, 0.1438798120827316, 0.10049695617839793, 0.10621630767244661, 0.10762768692123337, 0.10749329544655972, 0.0909652143113231, 0.08702488892833093, 0.08741024004556275, 0.1008920254832798, 0.09516711334048356, 0.08022778418305732, 0.873543183603556, 0.9004456650769772, 0.8814162623113353, 0.846310597446068, 0.8882640191244635, 0.7704200304174704, 0.8713486660809461, 0.8416444068853096, 0.8584366744342034, 0.23795557410876367, 0.25343706668573185, 0.2657921349190405, 0.2823256819790001, 0.2581150881785115, 0.27819277408062726, 0.25946997958286067, 0.23428060123377414, 0.2457119706472244, 0.22573741243795042, 0.37244918644816727, 0.22118620017872348, 0.3245073576652512, 0.2069428370198575, 0.1930496818362103, 0.22197397578546552, 0.21867824936433478, 0.22645896929969145, 0.17191903750060022, 0.12292621683072191, 0.12888229698493758, 0.09196406471067253, 0.1649839238454831, 0.15818370386669134, 0.12349082263945654, 0.17662378817400026, 0.13064743149649571, 0.20302497706228329, 0.17492419112943514, 0.17374752159548645, 0.21690719410629145, 0.1871112578999088, 0.15399942032337277, 0.1541153634178739, 0.18156585233734068, 0.15262511635840914, 0.018504236809294028, 9.999999999998899e-05, 9.999999999998899e-05, 0.02434826488168451, 0.04292739283015379, 0.009024653540835037, 0.02416748676192071, 9.999999999998899e-05, 0.022720614419654006, 0.08742447063398229, 0.04379279045762596, 0.06229586784342678, 0.09262650211554468, 0.07089663902353838, 0.029256044409206705, 0.11007804131752874, 0.11129523587547718, 0.07263223391838325, 0.08085621144880573, 0.07799831725576145, 0.08891240116689791, 0.09234443811978599, 0.11214003695676622, 0.06806298350236739, 0.15114606630347538, 0.15241146502910363, 0.09093415182365772, 0.16749760710291595, 0.17159877070782337, 0.09331667508138874, 0.15172485655988044, 0.12331451271222815, 0.15330421511859205, 0.19876156972402537, 0.17125010341203217, 0.15628968579829994, 0.4819597244902024, 0.4792844130684676, 0.41228790002024684, 0.41853202221364194, 0.4156414112302177, 0.38332573771922607, 0.4367138942518829, 0.46016443587591416, 0.4106893391069206, 0.11646785128045922, 0.11688825118541502, 0.08732135289842058, 0.10621314683282412, 0.07685886895736183, 0.12745273275535474, 0.10783642223094592, 0.13612321570530916, 0.10995601722188109, 0.16745665030562884, 0.19518030333775616, 0.14203664403557192, 0.18081630188586784, 0.2883329335439925, 0.16972459650128602, 0.18448271679367567, 0.19317102923130414, 0.2062179676122392, 0.31196223951117485, 0.3278516699616366, 0.2991839310035659, 0.3212511684658308, 0.3501985563028347, 0.2905963783361919, 0.2975749573919494, 0.2537789694729341, 0.21749608308723978, 0.2309234199884992, 0.23380949895404057, 0.24040228511947082, 0.20855245745003792, 0.2908356973628603, 0.22919063297925935, 0.16439354201202971, 0.23247691226706702, 0.21149099676827776, 0.21772991101202954, 0.21747825668244658, 0.2310686533884334, 0.24485580176412802, 0.22403166050729462, 0.22364479633832057, 0.22073354030162273, 0.258093167637629, 0.22640751134904247, 0.18466373957155724, 0.1769130345961255, 0.17144722223189968, 0.2165263069501907, 0.18923909500669178, 0.17356198205583984, 0.17970537544271048, 0.20248681327707485, 0.17493618273237466, 0.18514286623780962, 0.185442868992298, 0.16776128746298202, 0.747896289988535, 0.19965606580744666, 0.19449741497600204, 0.15087468969973217, 0.17707390180979965, 0.7072612734179955, 0.5009551023084162, 0.21064578381657706, 0.3919931935770897, 0.49012416246758006, 0.7155909307504315, 0.16527849265979133, 0.16691892850514234, 0.16653020299805843, 0.34834330600914787, 0.1841455749909412, 0.18705655265915466, 0.18402747545955178, 0.19340459653123232, 0.19192601765457518, 0.18108292953024452, 0.18451652401236485, 0.18657038417688632, 0.18029901876118803, 0.116710322479611, 0.09675281760734034, 0.10203493580435463, 0.08416411318163153, 0.08506767182895514, 0.08744051826519261, 0.08951869755903741, 0.08972130244238763, 0.08875942448132668]}, "mutation_prompt": null}
{"id": "6bc08a60-5aa3-4d81-a14a-67133f924a05", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  \n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  \n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  \n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  \n        self.swarm_restructuring_rate = 0.05  \n        self.quantum_tunneling_rate = 0.1  \n        self.dynamic_archive_size_rate = 0.05  \n        self.adaptive_mutation_step_size_rate = 0.05  \n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            self.archive_size += int(self.dynamic_archive_size_rate * (self.budget - evaluations))\n            self.mutation_step_size += self.adaptive_mutation_step_size_rate * (self.budget - evaluations)\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with a new \"Dynamic Archive Size\" mechanism and \"Adaptive Mutation Step Size\" to further improve convergence speed and diversity of the swarm.", "configspace": "", "generation": 164, "fitness": 0.22968487350756772, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6367878052598558, 0.6615339041801274, 0.7377989047847678, 0.6397742144807039, 0.6380307636443474, 0.6569675085970684, 0.5764897825123872, 0.5916704469628633, 0.680801688050606, 0.009792232635853937, 0.02053854403554778, 9.999999999998899e-05, 9.999999999998899e-05, 0.007317926212888182, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13053602869610315, 0.09100870541566697, 0.12114222043150602, 0.10288953804261691, 0.08945733420270241, 0.10267347151364736, 0.11996447870761806, 0.12720746528505, 0.09990289950651055, 0.08237956571118032, 0.11674733822783911, 0.11609763262554496, 0.10360116335519165, 0.07117663375794092, 0.11292975854895504, 0.09273787890039498, 0.09187707550556767, 0.10762603198692466, 0.8757516395308931, 0.9112919661759624, 0.9117229524929965, 0.7215906605191276, 0.8857921993564433, 0.8754580485657077, 0.9024668716650788, 0.9259469533567721, 0.9070295336617027, 0.2875349182955428, 0.25977370221376395, 0.2254930356631839, 0.22789809429086194, 0.24870907911284068, 0.2882348686446524, 0.257551805127468, 0.22912502329953455, 0.23707184760235755, 0.344898178065259, 0.3559133641771506, 0.21275857259356612, 0.3055076696145689, 0.37346460808948123, 0.20072465827296793, 0.2301927758844774, 0.23065817401083955, 0.3242083235465695, 0.10278932129743412, 0.21211115992698837, 0.1431244698273425, 0.1501654947440717, 0.1423998798046665, 0.22759696805069685, 0.12786334727292326, 0.14024748733705406, 0.17852563377780828, 0.15171191219486513, 0.23263564011329796, 0.12464034496470977, 0.13976554145424525, 0.16223938142154182, 0.14181201767041673, 0.17829599637149784, 0.17985520946721412, 0.13849207556454735, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.006591214713362548, 0.02622730502410542, 0.0035065639417616312, 9.999999999998899e-05, 9.999999999998899e-05, 0.004960503352986034, 0.1085020557148777, 0.055841246115640564, 0.13514865154539035, 0.11862101165007732, 0.0775533077240409, 0.02893150345643858, 0.0996223187148555, 0.08741108169986578, 0.08689709859375705, 0.10417485200911103, 0.09236348989456822, 0.1359235836742253, 0.054417871887788016, 0.12204457723844864, 0.10045877810807502, 0.09883803583749617, 0.12297522910197112, 0.07339729167827225, 0.2212741603567595, 0.09668799992371968, 0.20240764529216781, 0.10856734937178558, 0.13200144444893736, 0.10592680165218116, 0.12403783221356846, 0.1139337115508069, 0.08689975571754371, 0.44904326997431243, 0.4266902167860841, 0.5000010799983784, 0.40213838750230757, 0.40793755485889027, 0.4520669092447841, 0.4265502594983267, 0.44197156926771053, 0.40984663732889626, 0.13730124367370444, 0.12989529328611316, 0.10720785029511459, 0.1428446614665918, 0.10395919753297966, 0.11515549119443824, 0.10885496010221263, 0.10848663647284806, 0.0908652805244039, 0.2454157573864424, 0.2566937588402035, 0.17265817481180856, 0.18804578405686012, 0.2535237806377746, 0.1871815962557717, 0.2273579386320138, 0.2170953685372985, 0.18121077502063854, 0.24334327788109866, 0.3374418876890386, 0.34522380331031643, 0.25202327696695215, 0.306301283328706, 0.305102515225005, 0.25837239661657463, 0.28693613233224946, 0.2671793791901439, 0.2620379693490288, 0.25083755895118975, 0.26576724041725364, 0.175124034692832, 0.20037863878216844, 0.24703536414696825, 0.21663744913966687, 0.24425417062636323, 0.219221787814053, 0.22261340403418195, 0.24161890781481998, 0.2157333535449284, 0.22354381921036903, 0.2743252533506645, 0.22373396420149883, 0.22466707138347752, 0.22420610215396797, 0.24832296926080266, 0.20342461185295557, 0.2012552284078707, 0.17962712878560427, 0.18990587282172, 0.1775202597745067, 0.17141275575057502, 0.17450496225310597, 0.1851379733979912, 0.18775571344549746, 0.13997477998977736, 0.18622692300219756, 0.1855911975431569, 0.5680885513137527, 0.19969312786889748, 0.19871866327655197, 0.1414971828766538, 0.15375105770060704, 0.7391816324610653, 0.4952931846436983, 0.20890725109395358, 0.4094582327694718, 0.42349876790911356, 0.4616886539923879, 0.1659902890592555, 0.17350802986079383, 0.2912303037171725, 0.3456304781836803, 0.19187091391406674, 0.18129493150339981, 0.18046898273669298, 0.1869676384179968, 0.1778231335527577, 0.19299622252379578, 0.17928043853714515, 0.18878871906356642, 0.18555915331297523, 0.0852596654319332, 0.07795305840236089, 0.08261645054529365, 0.08049119070810451, 0.08931302871317204, 0.08487176149464681, 0.10805041211940059, 0.1011499121164603, 0.10097718711396209]}, "mutation_prompt": null}
{"id": "ed433e0c-841b-4629-aa03-412577a55439", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.swarm_diversity_rate = 0.1  # New swarm diversity mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def swarm_diversity(self, particles):\n        diversity = np.mean(np.linalg.norm(particles[:, np.newaxis] - particles, axis=2), axis=0)\n        return diversity\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Swarm diversity mechanism\n                if np.random.rand() < self.swarm_diversity_rate * (1 - evaluations / self.budget):\n                    diversity = self.swarm_diversity(self.particles)\n                    if diversity < 0.5:\n                        self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                        self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Swarm Diversity\" mechanism.", "configspace": "", "generation": 165, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()').", "error": "ValueError('The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()')", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {}, "mutation_prompt": null}
{"id": "98ac7203-e6fe-44fd-85d7-e6337e1fd0dd", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget) * 1.2)  # Modified swarm size\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1 * (1 + 0.1 * np.random.rand())  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with modified swarm size, and adaptive mutation rate.", "configspace": "", "generation": 166, "fitness": 0.22600834988971916, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.558071468641109, 0.5781174211372728, 0.5941619108587464, 0.6461985208159194, 0.5504317867493945, 0.5034845087871687, 0.6133795467885295, 0.6101329446322827, 0.5811935759822298, 9.999999999998899e-05, 0.039429466063637064, 0.00301780189018086, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12491702912122948, 0.10549219854823932, 0.09761982348717102, 0.09634923104156368, 0.07272540138851746, 0.09279262342607708, 0.0888911374110517, 0.09482544644309532, 0.1395209957656618, 0.08707526474832905, 0.08853390436938158, 0.09521294900939414, 0.1235336131303213, 0.0787887199075028, 0.08844656191540212, 0.10521349169658445, 0.07486600455786485, 0.0828663504232593, 0.8695549343848715, 0.8871283288852835, 0.8458242992858978, 0.7697435177273662, 0.820110846405199, 0.8088183013810103, 0.8458502921343514, 0.8123417859011683, 0.8354569919317352, 0.271962881963811, 0.2837907958575303, 0.2467688560576844, 0.2682157865460485, 0.25876258782784045, 0.26496686599360275, 0.27357201066567616, 0.1943153818529878, 0.24971578411788287, 0.3555274631940901, 0.3585571870221351, 0.2273083745990193, 0.2666022629386845, 0.26428744987920705, 0.23879586359128835, 0.25577526616719837, 0.27507605689172576, 0.5815187752564761, 0.19269280244483322, 0.12821258155409254, 0.1549929792714947, 0.14767976740472366, 0.14222016974194285, 0.11982735018674828, 0.15121157623271975, 0.1490574672726439, 0.12786635350656328, 0.17966972371874712, 0.21569744155063508, 0.1992736995638883, 0.16802987845360562, 0.14459198919297067, 0.13848186940719776, 0.17731694277494303, 0.15452846418117483, 0.1736444438140825, 0.004577227278601326, 0.020692865014300676, 0.00014733097285024588, 0.05006018133366341, 0.005664600396217967, 0.012580476802057317, 0.0005510698757561494, 9.999999999998899e-05, 0.028094987487833567, 0.1086687168683591, 0.0699719136079513, 0.10456536740945543, 0.06026917328773873, 0.0742409435431498, 0.060070914614500204, 0.17170109640045617, 0.09693213899253517, 0.14858857282831106, 0.09188881993164544, 0.047931651501838535, 0.1293027873505196, 0.07050484041812377, 0.07831716848833803, 0.10017516605523413, 0.06320379216724048, 0.11569939229879578, 0.05912325483748759, 0.1717447824092676, 0.1424150989562457, 0.1177856003396004, 0.11275366970336032, 0.13145624838691727, 0.07945453949888948, 0.07118213692081021, 0.14828211217175524, 0.13614532430737236, 0.4243513821604399, 0.4687843627814716, 0.40107188789656156, 0.46273634870671376, 0.3591381667157246, 0.4149756840697445, 0.5090918513158826, 0.4286750374727547, 0.4489521838038728, 0.10163961031701929, 0.12974003468627393, 0.09913581269191085, 0.15197633022464452, 0.17305472284653844, 0.1186258652405684, 0.1627368965943521, 0.12688588165504733, 0.0787983432141276, 0.16009471940033781, 0.18058607615260358, 0.21475865403058547, 0.1909872883620597, 0.29602702312329787, 0.18075473076411452, 0.25603795219925274, 0.1877993211509621, 0.22055428357957563, 0.21677391597855145, 0.349159063964641, 0.34766540977450333, 0.24455770510696972, 0.2967985108060609, 0.2964157567914847, 0.2431962827794114, 0.2566660031576836, 0.24326287417437464, 0.27157198965602125, 0.23712671625967774, 0.21266914332218412, 0.26549195056368613, 0.24947010621459043, 0.2607700052023013, 0.2297741663497116, 0.24505727722107373, 0.1798372396201936, 0.22026384428665702, 0.24247552786101145, 0.22350809915292935, 0.2299820854125707, 0.2381237300860234, 0.2233080490868371, 0.21446207677966955, 0.22216578041112112, 0.23318484256249716, 0.1904094665476438, 0.19052166697973139, 0.179483686737947, 0.19296593355462877, 0.18766700597005592, 0.19404696991763326, 0.18354428174537873, 0.18832786115822464, 0.1716047388440296, 0.18436488813306684, 0.18455614998433434, 0.1856860611566138, 0.3901879636856763, 0.19803504234961555, 0.19814193788608447, 0.14113677683604475, 0.6148311244687203, 0.6108712392813139, 0.4247851982299772, 0.20809564575187856, 0.5120128516623009, 0.5454837354221702, 0.16569766237143924, 0.1657837833103205, 0.16720116439154786, 0.3859101689874245, 0.2470576575561001, 0.18578705816103924, 0.1983580361861791, 0.22158104192883776, 0.20128576964885014, 0.20748601183430004, 0.185235639426101, 0.18846133887829686, 0.2029822714223416, 0.18938170029923074, 0.08523441131361742, 0.08533977669542814, 0.0812459972729308, 0.08539638342858125, 0.07593791108401748, 0.08478178608740838, 0.09496879130922864, 0.0905801858965064, 0.10746208872059249]}, "mutation_prompt": null}
{"id": "962a18f5-b619-40d6-a30d-591579dc1074", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.num_swarms = 5  # New multi-swarm mechanism\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.num_swarms, self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.num_swarms, self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones((self.num_swarms, self.swarm_size))\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_swarm_rate = 0.1  # New multi-swarm mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for swarm_index in range(self.num_swarms):\n                for i in range(self.swarm_size):\n                    fitness = func(self.particles[swarm_index, i])\n                    evaluations += 1\n                    if fitness < self.best_fitness[swarm_index, i]:\n                        self.best_fitness[swarm_index, i] = fitness\n                        self.best_positions[swarm_index, i] = np.copy(self.particles[swarm_index, i])\n                        self.update_archive(self.particles[swarm_index, i], fitness)\n                        if fitness < self.global_best_fitness:\n                            self.global_best_fitness = fitness\n                            self.global_best_position = np.copy(self.particles[swarm_index, i])\n                    # Modified velocity update with adaptive acceleration coefficients\n                    self.velocities[swarm_index, i] = self.inertia_weight * self.velocities[swarm_index, i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[swarm_index, i] - self.particles[swarm_index, i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[swarm_index, i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                    velocity_centroids = self.velocity_clustering(self.velocities[swarm_index])\n                    if np.random.rand() < self.velocity_clustering_rate:\n                        self.velocities[swarm_index, i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[swarm_index, i] - velocity_centroids, axis=1))]\n                    self.particles[swarm_index, i] += self.velocities[swarm_index, i]\n                    self.particles[swarm_index, i] = np.clip(self.particles[swarm_index, i], self.lower_bound, self.upper_bound)\n                    self.velocities[swarm_index, i] = np.clip(self.velocities[swarm_index, i], -1, 1)\n                    # Levy flight for enhanced global search\n                    if np.random.rand() < 0.1:\n                        self.particles[swarm_index, i] += self.levy_flight(self.dim)\n                        self.particles[swarm_index, i] = np.clip(self.particles[swarm_index, i], self.lower_bound, self.upper_bound)\n                    # Dynamic opposition-based learning with adaptive rate\n                    if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                        opposition_position = self.opposition_based_learning(self.particles[swarm_index, i])\n                        opposition_fitness = func(opposition_position)\n                        evaluations += 1\n                        if opposition_fitness < fitness:\n                            self.particles[swarm_index, i] = opposition_position\n                            self.best_fitness[swarm_index, i] = opposition_fitness\n                            self.best_positions[swarm_index, i] = np.copy(self.particles[swarm_index, i])\n                            self.update_archive(self.particles[swarm_index, i], opposition_fitness)\n                    # Cauchy mutation and Gaussian perturbation\n                    if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                        mutated_position = self.cauchy_mutation(self.particles[swarm_index, i])\n                        mutated_position = self.gaussian_perturbation(mutated_position)\n                        mutated_fitness = func(mutated_position)\n                        evaluations += 1\n                        if mutated_fitness < fitness:\n                            self.particles[swarm_index, i] = mutated_position\n                            self.best_fitness[swarm_index, i] = mutated_fitness\n                            self.best_positions[swarm_index, i] = np.copy(self.particles[swarm_index, i])\n                            self.update_archive(self.particles[swarm_index, i], mutated_fitness)\n                    # Particle filtering for enhanced exploration\n                    if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                        particle_centroids = self.particle_filtering(self.particles[swarm_index])\n                        self.particles[swarm_index, i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[swarm_index, i] - particle_centroids, axis=1))]\n                    # Hybrid-repulsion mechanism\n                    if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                        repulsion_position = self.hybrid_repulsion(self.particles[swarm_index, i])\n                        repulsion_fitness = func(repulsion_position)\n                        evaluations += 1\n                        if repulsion_fitness < fitness:\n                            self.particles[swarm_index, i] = repulsion_position\n                            self.best_fitness[swarm_index, i] = repulsion_fitness\n                            self.best_positions[swarm_index, i] = np.copy(self.particles[swarm_index, i])\n                            self.update_archive(self.particles[swarm_index, i], repulsion_fitness)\n                    # Swarm restructuring mechanism\n                    if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                        restructuring_position = self.swarm_restructuring(self.particles[swarm_index])\n                        restructuring_fitness = func(restructuring_position)\n                        evaluations += 1\n                        if restructuring_fitness < fitness:\n                            self.particles[swarm_index, i] = restructuring_position\n                            self.best_fitness[swarm_index, i] = restructuring_fitness\n                            self.best_positions[swarm_index, i] = np.copy(self.particles[swarm_index, i])\n                            self.update_archive(self.particles[swarm_index, i], restructuring_fitness)\n                    # Quantum tunneling for enhanced local search\n                    if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                        tunneling_position = self.quantum_tunneling(self.particles[swarm_index, i])\n                        tunneling_fitness = func(tunneling_position)\n                        evaluations += 1\n                        if tunneling_fitness < fitness:\n                            self.particles[swarm_index, i] = tunneling_position\n                            self.best_fitness[swarm_index, i] = tunneling_fitness\n                            self.best_positions[swarm_index, i] = np.copy(self.particles[swarm_index, i])\n                            self.update_archive(self.particles[swarm_index, i], tunneling_fitness)\n                    # Exploration-exploitation balance mechanism\n                    if np.random.rand() < self.exploration_rate:\n                        self.particles[swarm_index, i] += np.random.uniform(-1, 1, size=self.dim)\n                        self.particles[swarm_index, i] = np.clip(self.particles[swarm_index, i], self.lower_bound, self.upper_bound)\n                    else:\n                        self.particles[swarm_index, i] += 0.5 * (self.best_positions[swarm_index, i] - self.particles[swarm_index, i]) + 0.5 * (self.global_best_position - self.particles[swarm_index, i])\n                        self.particles[swarm_index, i] = np.clip(self.particles[swarm_index, i], self.lower_bound, self.upper_bound)\n                    # Archive-based position update\n                    if np.random.rand() < 0.05:\n                        archive_index = np.random.randint(len(self.archive))\n                        self.particles[swarm_index, i] = self.archive[archive_index][0]\n                # Modified simulated annealing with adaptive cooling\n                if evaluations % (self.swarm_size // 2) == 0:\n                    for i in range(self.swarm_size // 2):\n                        new_position = np.copy(self.particles[swarm_index, i])\n                        new_position += np.random.uniform(-1, 1, size=self.dim)\n                        new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                        new_fitness = func(new_position)\n                        evaluations += 1\n                        if new_fitness < self.best_fitness[swarm_index, i] or np.random.rand() < np.exp((self.best_fitness[swarm_index, i] - new_fitness) / self.temperature):\n                            self.particles[swarm_index, i] = new_position\n                            self.best_fitness[swarm_index, i] = new_fitness\n                            self.best_positions[swarm_index, i] = np.copy(self.particles[swarm_index, i])\n                            self.update_archive(self.particles[swarm_index, i], new_fitness)\n                        self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n                # Dynamic inertia weight\n                self.inertia_weight *= self.inertia_weight_damping_ratio\n                # Multi-swarm mechanism\n                if np.random.rand() < self.multi_swarm_rate * (1 - evaluations / self.budget):\n                    other_swarm_index = np.random.randint(self.num_swarms)\n                    if other_swarm_index!= swarm_index:\n                        self.particles[swarm_index, i] = self.particles[other_swarm_index, i]\n                        self.best_fitness[swarm_index, i] = self.best_fitness[other_swarm_index, i]\n                        self.best_positions[swarm_index, i] = np.copy(self.particles[swarm_index, i])\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Multi-Swarm\" mechanism.", "configspace": "", "generation": 167, "fitness": 0.19086206045188955, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.14.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.4149059689044773, 0.45932301674786835, 0.41714733780064817, 0.41169147913816684, 0.3953694168385079, 0.38099809219567893, 0.39636197435004616, 0.41241403984983205, 0.38465768442950776, 9.999999999998899e-05, 0.00798740411350396, 0.03129256308078965, 9.999999999998899e-05, 0.07334137109948913, 9.999999999998899e-05, 9.999999999998899e-05, 0.04378189923647424, 9.999999999998899e-05, 0.10958248025236772, 0.09407569828355467, 0.10713997262458141, 0.11773352162451245, 0.09001625375111455, 0.08869253571702862, 0.09965764195080395, 0.11119775098661833, 0.1442131888753727, 0.07526254581053549, 0.073539293521513, 0.09057015527459567, 0.11089976829900494, 0.07234294981507194, 0.07658936434108377, 0.08980276403289267, 0.08953223378147357, 0.09376887828360869, 0.5079482593490815, 0.7009146768993082, 0.519309829691481, 0.4707160406790811, 0.7257978948827777, 0.421215564965287, 0.6269287308338152, 0.47912981041333047, 0.6806166901318943, 0.19710753197272757, 0.1697220590835835, 0.20532872507498667, 0.18397228180969716, 0.18443825478222076, 0.1378118029279749, 0.17214509839565362, 0.14515011946787093, 0.17526018998303694, 0.28620384188365855, 0.2900422518325474, 0.2103106788519904, 0.48210860163953106, 0.32829676169127486, 0.1935782052149041, 0.19407193440856185, 0.2992334542256323, 0.27262028053428433, 0.1973150510402848, 0.12017372397065706, 0.07847371340618303, 0.1431495073060296, 0.10959280217654555, 0.140653404702749, 0.11182760721568286, 0.08878260458458986, 0.10711216486224151, 0.14326612430744767, 0.1238378372342056, 0.13996959790623165, 0.17409940186460704, 0.12674994486968794, 0.16076626123195548, 0.1297280013464528, 0.14993600643236638, 0.11633703630496872, 0.04663022129439687, 9.999999999998899e-05, 0.04114614467286115, 0.00045521237901524625, 9.999999999998899e-05, 0.010880809728430751, 0.0017043374917928844, 0.01464027574620863, 0.0062609097348782505, 0.06818296703372928, 0.1461659840402333, 0.16840463450628762, 0.0883879447998217, 0.09555959093878119, 0.017910033385565294, 0.11471618237353798, 0.14719157795876547, 0.08752002949015136, 0.01775996743354391, 0.008628278662148658, 0.010617224774872147, 0.030849072206099892, 0.018936848022995445, 0.03817311501572529, 0.04176315923116525, 0.024542534838422725, 0.020016383659578918, 0.08559758211844981, 0.11653076588216704, 0.05291028316896773, 0.08844415247470183, 0.08902457916403195, 0.06887759363001966, 0.07072607499311312, 0.06475462137920474, 0.09567895687257733, 0.3543558776113296, 0.3874216257863018, 0.3724720973864669, 0.36590298069160276, 0.39201579855569235, 0.35555588252210024, 0.36352595943626675, 0.358135707716998, 0.3554178006704085, 0.08360974419267875, 0.11319287853196724, 0.08104067553307814, 0.10555961943085057, 0.10764333930436532, 0.12036917239994327, 0.12019629219124106, 0.0936314342483191, 0.10752808333996833, 0.17635989896357418, 0.12810193627597133, 0.18240482154305204, 0.18363752840116332, 0.24608322845671038, 0.18443703174744497, 0.1894981160344682, 0.17121740941455432, 0.1945286775095758, 0.2939622714362661, 0.24558976656437514, 0.26124341697831766, 0.26010483093670445, 0.27914799965410875, 0.24006362863797892, 0.2417974151833009, 0.27424703740165546, 0.2387701228680943, 0.19355111611811648, 0.16872152317767108, 0.20693271675820812, 0.1989499967058448, 0.23520171011531033, 0.2086535439198649, 0.1821216102133819, 0.18862303641788325, 0.16072173409788282, 0.21523898878783976, 0.22365735533713083, 0.2167327755588463, 0.21863913338125973, 0.20233280998398073, 0.2028230605115776, 0.22851928248430453, 0.21929639991221817, 0.2282805927021755, 0.17893059744532724, 0.17135315970483755, 0.1753881268419747, 0.1807111992639504, 0.18086001535213614, 0.17800665177004926, 0.1681601932745429, 0.18367541437034973, 0.17258886279851737, 0.17329893564581966, 0.39155775028961826, 0.31520516025972056, 0.18548356781027375, 0.18927007977395993, 0.3462482022402511, 0.46915623113427374, 0.4327571121810011, 0.48016976688514346, 0.41553595366154994, 0.20251924543036892, 0.3941210770357523, 0.4685751032288874, 0.36594618212362895, 0.3281864448072589, 0.1669253833742581, 0.2856786348638095, 0.3565236967827826, 0.2292589866134328, 0.21621965479403316, 0.2035512599131437, 0.19319452395947012, 0.1757298909969941, 0.19200310749548366, 0.19133064876847383, 0.17880615402940114, 0.2072345214492347, 0.08069532316237615, 0.0756325881880553, 0.1026998323427184, 0.08612574746836776, 0.08522775982951514, 0.08656304290954964, 0.08194516871363666, 0.08778779478137344, 0.08167115360040622]}, "mutation_prompt": null}
{"id": "02a4c809-1344-466f-a029-7cc4ab28dddb", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_modal_rate = 0.1  # New multi-modal exploration strategy\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def multi_modal_exploration(self, position):\n        modal_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + modal_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-modal exploration strategy\n                if np.random.rand() < self.multi_modal_rate * (1 - evaluations / self.budget):\n                    modal_position = self.multi_modal_exploration(self.particles[i])\n                    modal_fitness = func(modal_position)\n                    evaluations += 1\n                    if modal_fitness < fitness:\n                        self.particles[i] = modal_position\n                        self.best_fitness[i] = modal_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], modal_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Multi-Modal\" exploration strategy.", "configspace": "", "generation": 168, "fitness": 0.2314174742236298, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6125824774325759, 0.5990155800405379, 0.5942703456911014, 0.6042542693238095, 0.5845178281213235, 0.660259563492832, 0.5961206249938704, 0.6350209086322897, 0.6197322266245386, 0.018541349854917955, 0.04378846500325251, 0.0020853975839251193, 0.006168904117033747, 0.02417029594857889, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13199821747675655, 0.09900934967579345, 0.11803608686199918, 0.08783804207449064, 0.10168677924281788, 0.11595617690735593, 0.10509759555579856, 0.1029785864900501, 0.15497964047657153, 0.06278616535787407, 0.11105848330980428, 0.10084139353626365, 0.0913014341052738, 0.07873546443706769, 0.09013001535685294, 0.12552845708078653, 0.09730089216819637, 0.0932067017807976, 0.8843738784953601, 0.9335834102564146, 0.8664238812462577, 0.7937522397484056, 0.8671174025940622, 0.8558136517005249, 0.8955552216846007, 0.9098469269921373, 0.8523981164385521, 0.3079991116055525, 0.2631934762992757, 0.25167634607010736, 0.30124540164435576, 0.28639317707816137, 0.2313402812958376, 0.27042593197048614, 0.2615155827728288, 0.28984463410417916, 0.3583296926177505, 0.7602457508424253, 0.22640180804819066, 0.27453532624516797, 0.27105657870806643, 0.27413904415609824, 0.2605555983002378, 0.21697118583521324, 0.4818256846712001, 0.11926337688901245, 0.27905427916660497, 0.11775715826819233, 0.22967702536172352, 0.15708305388428268, 0.15204747196790136, 0.15287697557716806, 0.12650788010390712, 0.1547157512178703, 0.18472576348201308, 0.17341924844343848, 0.15548814161062963, 0.17089925835825126, 0.15211395089352575, 0.12572301172507794, 0.27045305896133887, 0.16966339313195822, 0.17357620918335848, 0.048665779621226646, 9.999999999998899e-05, 0.0021655519550116686, 0.042532246079000524, 0.015408654534225352, 9.999999999998899e-05, 0.008220102456576228, 9.999999999998899e-05, 9.999999999998899e-05, 0.048189101895538045, 0.05594118854952923, 0.09755257859894462, 0.08417254344474445, 0.06733915983072147, 0.045179553528066796, 0.0735118300040043, 0.06593095137731197, 0.10443059854760228, 0.08722585771817992, 0.1015455888275354, 0.07427654525657323, 0.08507846989813805, 0.10901759834249092, 0.08314423786413738, 0.11036198506265338, 0.0685039492732672, 0.07871633971628211, 0.2068501986374227, 0.16334892371607823, 0.15629621576572028, 0.13401907872053398, 0.18059939447311557, 0.12788266261626413, 0.13233880736069292, 0.16608433837742764, 0.09598285244605853, 0.44566194122134717, 0.44440352122268223, 0.4335913180587053, 0.405160425147551, 0.4258142977540973, 0.4013501656077444, 0.48035330031248913, 0.42753856509563926, 0.4442076755129869, 0.10121843363611382, 0.1163251591225477, 0.11572423531975329, 0.12674955157186285, 0.11615645156297527, 0.10001066690757376, 0.08372151461815136, 0.09652267853144314, 0.07370329924328722, 0.2606266435397444, 0.2254516837884798, 0.16416507629755783, 0.24219257462756838, 0.27703067670812, 0.18300450948762637, 0.22022557672373722, 0.16829875151728102, 0.277848125938005, 0.34444759983158924, 0.3020685232462139, 0.32258419607281497, 0.31727328539910227, 0.3114816005727662, 0.3133535961825059, 0.24214087179905097, 0.27433997287635925, 0.30249023751315696, 0.23904272095365098, 0.2217849211005879, 0.27353209713440507, 0.2300291218771976, 0.19881501344359132, 0.24464445249590594, 0.22146871154784753, 0.20849255849958304, 0.2035474317770979, 0.2725793464629169, 0.22012641156838075, 0.20354492953783243, 0.22990914199974255, 0.2135732323171614, 0.20686745399332052, 0.21818312720016197, 0.21038130181636883, 0.20454765678767095, 0.20222697370259346, 0.19124931485257635, 0.2200975721529178, 0.1834431177780782, 0.1910944876266879, 0.1924952879337739, 0.1889929925616648, 0.19233977006959402, 0.18507418841042178, 0.12683334175673322, 0.1855362635278458, 0.18719912533444882, 0.5495707390038582, 0.19883955915694618, 0.19755357946233576, 0.1466076814029761, 0.1543066865148749, 0.8049610644772345, 0.45319136999156184, 0.17323669857377044, 0.36881924417554457, 0.41574249575169975, 0.20653066651305008, 0.16552881623306637, 0.16740014350115473, 0.2945631388201989, 0.3505670571589642, 0.18449150542714532, 0.1943450009034975, 0.21361266158159897, 0.1883760902979409, 0.18858148123118057, 0.18753466135465702, 0.19209844016836242, 0.19047977144430783, 0.1998347219788713, 0.09004092735852376, 0.09422909141670988, 0.10040142931692186, 0.1043106519114072, 0.08440876299657574, 0.09067917229532962, 0.10935626279767552, 0.08170647602135572, 0.08746466137742825]}, "mutation_prompt": null}
{"id": "071ecf0f-a8c0-4a2d-8be3-80b444d68b0e", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  \n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  \n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  \n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  \n        self.swarm_restructuring_rate = 0.05  \n        self.quantum_tunneling_rate = 0.1  \n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Adaptive velocity update with opposition-based learning\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim) + 0.1 * (self.opposition_based_learning(self.particles[i]) - self.particles[i]) * np.random.uniform(0, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive velocity update and opposition-based learning.", "configspace": "", "generation": 169, "fitness": 0.18838496425532852, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.19 with standard deviation 0.14.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.612684638836358, 0.6423505223053415, 0.546030182160756, 0.3555495773878855, 0.5033050483501096, 0.45845270542523153, 0.47602031071192485, 0.5145824893521371, 0.45560702019814314, 0.010950873952332074, 0.007743293127353668, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1443141252830863, 0.09045231908668161, 0.14092449606570412, 0.09358152300839229, 0.10076746428396022, 0.08202343908224596, 0.09988922186787463, 0.12268052432023868, 0.09825913194055169, 0.06480597422088807, 0.08321548474978391, 0.07977674331369267, 0.10065681291353668, 0.07748888820724298, 0.07528324217574422, 0.10680190698083003, 0.08560012934974726, 0.07385508941744756, 0.14156061764972294, 0.2544312488586201, 0.17135502790161883, 0.21521998123781116, 0.6660413882660818, 0.1722824166275052, 0.21517694875916293, 0.2630795489340815, 0.21655417724053727, 0.24272289203501451, 0.2023972841279993, 0.19206080947574733, 0.18258827894446872, 0.18381584128697903, 0.17207437472966047, 0.2092474963487423, 0.2666554803587563, 0.19873188785753193, 0.23034106144237776, 0.3845279774984508, 0.22094885972984668, 0.27236660436048044, 0.6328903365187633, 0.2190273297212847, 0.3383113520285107, 0.20826998750991332, 0.22170126684113978, 0.2088271464432252, 0.15787384140032334, 0.13779768883800247, 0.1157408776852128, 0.14215951414238048, 0.24933247010765147, 0.16016031567134725, 0.1982903639324901, 0.1328749207092622, 0.1524377721149569, 0.18962453576318639, 0.16394430968560103, 0.15815626980938413, 0.16005527987602908, 0.12751688410378315, 0.18431982419123938, 0.1706089988692131, 0.15106248724316151, 9.999999999998899e-05, 0.005733409283121937, 9.999999999998899e-05, 0.07976515798026995, 0.015337677967772967, 9.999999999998899e-05, 0.01975460347437452, 0.0059988615566062276, 9.999999999998899e-05, 0.11794872177337823, 0.09142265144960293, 0.12489923557396743, 0.06726710545561199, 0.047058261574310034, 0.035992751644045695, 0.09498122856304125, 0.08961682321923803, 0.11083218819678275, 9.999999999998899e-05, 0.06485368549967552, 0.07161303743088043, 0.1063651180196108, 0.07669732885967728, 0.010696641866750678, 0.028965416911454267, 9.999999999998899e-05, 0.09215199813138264, 0.13326036316656154, 0.10315241962677268, 0.07839140073710893, 0.11204750123587348, 0.13592940864596237, 0.08566799352086851, 0.09959216941914584, 0.07417185543717353, 0.10481423367354947, 0.4038471035738044, 0.4481949145127384, 0.458383303319314, 0.44539526272217556, 0.3751563844251019, 0.4267786612741099, 0.4449302850786484, 0.4398671538828448, 0.45778771912388194, 0.09354394787741216, 0.105846312425945, 0.07655298417718037, 0.11719651602143388, 0.09332672806275677, 0.11784376033866606, 0.0805115884511608, 0.10994546698924201, 0.09501138757245531, 0.15872945952922668, 0.26565797800296664, 0.18206136944405893, 0.17041376409058284, 0.27939786263192656, 0.1682132960848587, 0.2659823300006817, 0.16396352230723565, 0.21802396663956958, 0.294419467283083, 0.25523707075272384, 0.3019494171996633, 0.3441474573460537, 0.28324726790028665, 0.28225832872726586, 0.22696972264181414, 0.24334713603770264, 0.2635005013302988, 0.2206381534252907, 0.13399195596260594, 0.24930295330839203, 0.21183098127254152, 0.18844942357683525, 0.24740770419760783, 0.21579959660405112, 0.2371010671280145, 0.23417262394240412, 0.22190318198599657, 0.22305951177395678, 0.23798160081168973, 0.21847997026160826, 0.21756072020275596, 0.21500671064160792, 0.21326032982106913, 0.2598966975557889, 0.26848998931769696, 0.1728361765288915, 0.17129647667929548, 0.19552272927313874, 0.2128848949663974, 0.19482672972888593, 0.17443473953015476, 0.18961712721193968, 0.17806426422169097, 0.17251425678803822, 0.1860689768319439, 0.18597158201955688, 0.18820451130086568, 0.3945805149854996, 0.19937284000464728, 0.18212428509152878, 0.14116994750978684, 0.14583406347845052, 0.5884867490163428, 0.372070106061135, 0.20832081171766204, 0.5575360471281862, 0.4228449821317195, 0.16628561874420733, 0.167180356483693, 0.16609382974447595, 0.29115473221092203, 0.3015023370796941, 0.1969736371646198, 0.1956997886711621, 0.1864960996157341, 0.21712489872429264, 0.19424933106741415, 0.18262374774848056, 0.18878107363641128, 0.19074237629363755, 0.17741443353823083, 0.08194129734845645, 0.08665223028291857, 0.09788569288261662, 0.08368484074285099, 0.08773170583207046, 0.09613819705156146, 0.09537390499779708, 0.10377589546025578, 0.08399446720787185]}, "mutation_prompt": null}
{"id": "7bfef265-e145-4db1-8257-1d672e8d5810", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.evolution_strategy_rate = 0.1  # New evolution strategy mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def evolution_strategy(self, position):\n        evolution_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + evolution_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Evolution strategy for individual update\n                if np.random.rand() < self.evolution_strategy_rate * (1 - evaluations / self.budget):\n                    evolution_position = self.evolution_strategy(self.particles[i])\n                    evolution_fitness = func(evolution_position)\n                    evaluations += 1\n                    if evolution_fitness < fitness:\n                        self.particles[i] = evolution_position\n                        self.best_fitness[i] = evolution_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], evolution_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with a new \"Evolution Strategy\" for individual update.", "configspace": "", "generation": 170, "fitness": 0.2314174742236298, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6125824774325759, 0.5990155800405379, 0.5942703456911014, 0.6042542693238095, 0.5845178281213235, 0.660259563492832, 0.5961206249938704, 0.6350209086322897, 0.6197322266245386, 0.018541349854917955, 0.04378846500325251, 0.0020853975839251193, 0.006168904117033747, 0.02417029594857889, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13199821747675655, 0.09900934967579345, 0.11803608686199918, 0.08783804207449064, 0.10168677924281788, 0.11595617690735593, 0.10509759555579856, 0.1029785864900501, 0.15497964047657153, 0.06278616535787407, 0.11105848330980428, 0.10084139353626365, 0.0913014341052738, 0.07873546443706769, 0.09013001535685294, 0.12552845708078653, 0.09730089216819637, 0.0932067017807976, 0.8843738784953601, 0.9335834102564146, 0.8664238812462577, 0.7937522397484056, 0.8671174025940622, 0.8558136517005249, 0.8955552216846007, 0.9098469269921373, 0.8523981164385521, 0.3079991116055525, 0.2631934762992757, 0.25167634607010736, 0.30124540164435576, 0.28639317707816137, 0.2313402812958376, 0.27042593197048614, 0.2615155827728288, 0.28984463410417916, 0.3583296926177505, 0.7602457508424253, 0.22640180804819066, 0.27453532624516797, 0.27105657870806643, 0.27413904415609824, 0.2605555983002378, 0.21697118583521324, 0.4818256846712001, 0.11926337688901245, 0.27905427916660497, 0.11775715826819233, 0.22967702536172352, 0.15708305388428268, 0.15204747196790136, 0.15287697557716806, 0.12650788010390712, 0.1547157512178703, 0.18472576348201308, 0.17341924844343848, 0.15548814161062963, 0.17089925835825126, 0.15211395089352575, 0.12572301172507794, 0.27045305896133887, 0.16966339313195822, 0.17357620918335848, 0.048665779621226646, 9.999999999998899e-05, 0.0021655519550116686, 0.042532246079000524, 0.015408654534225352, 9.999999999998899e-05, 0.008220102456576228, 9.999999999998899e-05, 9.999999999998899e-05, 0.048189101895538045, 0.05594118854952923, 0.09755257859894462, 0.08417254344474445, 0.06733915983072147, 0.045179553528066796, 0.0735118300040043, 0.06593095137731197, 0.10443059854760228, 0.08722585771817992, 0.1015455888275354, 0.07427654525657323, 0.08507846989813805, 0.10901759834249092, 0.08314423786413738, 0.11036198506265338, 0.0685039492732672, 0.07871633971628211, 0.2068501986374227, 0.16334892371607823, 0.15629621576572028, 0.13401907872053398, 0.18059939447311557, 0.12788266261626413, 0.13233880736069292, 0.16608433837742764, 0.09598285244605853, 0.44566194122134717, 0.44440352122268223, 0.4335913180587053, 0.405160425147551, 0.4258142977540973, 0.4013501656077444, 0.48035330031248913, 0.42753856509563926, 0.4442076755129869, 0.10121843363611382, 0.1163251591225477, 0.11572423531975329, 0.12674955157186285, 0.11615645156297527, 0.10001066690757376, 0.08372151461815136, 0.09652267853144314, 0.07370329924328722, 0.2606266435397444, 0.2254516837884798, 0.16416507629755783, 0.24219257462756838, 0.27703067670812, 0.18300450948762637, 0.22022557672373722, 0.16829875151728102, 0.277848125938005, 0.34444759983158924, 0.3020685232462139, 0.32258419607281497, 0.31727328539910227, 0.3114816005727662, 0.3133535961825059, 0.24214087179905097, 0.27433997287635925, 0.30249023751315696, 0.23904272095365098, 0.2217849211005879, 0.27353209713440507, 0.2300291218771976, 0.19881501344359132, 0.24464445249590594, 0.22146871154784753, 0.20849255849958304, 0.2035474317770979, 0.2725793464629169, 0.22012641156838075, 0.20354492953783243, 0.22990914199974255, 0.2135732323171614, 0.20686745399332052, 0.21818312720016197, 0.21038130181636883, 0.20454765678767095, 0.20222697370259346, 0.19124931485257635, 0.2200975721529178, 0.1834431177780782, 0.1910944876266879, 0.1924952879337739, 0.1889929925616648, 0.19233977006959402, 0.18507418841042178, 0.12683334175673322, 0.1855362635278458, 0.18719912533444882, 0.5495707390038582, 0.19883955915694618, 0.19755357946233576, 0.1466076814029761, 0.1543066865148749, 0.8049610644772345, 0.45319136999156184, 0.17323669857377044, 0.36881924417554457, 0.41574249575169975, 0.20653066651305008, 0.16552881623306637, 0.16740014350115473, 0.2945631388201989, 0.3505670571589642, 0.18449150542714532, 0.1943450009034975, 0.21361266158159897, 0.1883760902979409, 0.18858148123118057, 0.18753466135465702, 0.19209844016836242, 0.19047977144430783, 0.1998347219788713, 0.09004092735852376, 0.09422909141670988, 0.10040142931692186, 0.1043106519114072, 0.08440876299657574, 0.09067917229532962, 0.10935626279767552, 0.08170647602135572, 0.08746466137742825]}, "mutation_prompt": null}
{"id": "4b786146-4738-456b-82a3-f8bed1dcf408", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.98  # Improved adaptive cooling\n        self.adaptive_cooling_rate = 0.3  # Improved adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.12  # Improved dynamic opposition-based learning rate\n        self.inertia_weight = 0.85  # Improved dynamic inertia weight\n        self.inertia_weight_damping_ratio = 0.995  # Improved dynamic inertia weight damping ratio\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with improved adaptive cooling and dynamic inertia weight.", "configspace": "", "generation": 171, "fitness": 0.23414231360611631, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.5904995922297852, 0.7265041947784312, 0.662475692208184, 0.5535184768506538, 0.6019504745427249, 0.6764665758714772, 0.5601671196717761, 0.630930015642388, 0.5795877647335774, 0.02612645149462567, 0.013634917775852018, 0.007743792054310528, 9.999999999998899e-05, 0.031096819121681385, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13067540966898417, 0.10637680043989517, 0.10227485613591725, 0.10882049398409233, 0.1051195797036516, 0.12497913060378019, 0.10923179381901604, 0.1243013673436022, 0.09928534593540772, 0.10279187887592667, 0.08708642029680957, 0.08293569151570368, 0.1256453245528797, 0.08074454868239811, 0.058445719921467965, 0.07329840246788066, 0.09097811100458819, 0.07426826656352636, 0.8823259584334455, 0.937056286823019, 0.8343968356773045, 0.7011461914963016, 0.8937263626932503, 0.835590775448493, 0.9057599653071153, 0.9234633877590752, 0.8859678661229649, 0.28434032627372297, 0.2630936687934753, 0.24323115056465772, 0.25237963417068743, 0.2817973943861142, 0.26707416601519374, 0.2292592422874571, 0.23673427874442476, 0.27013881592653466, 0.2799908200534609, 0.3278189349108014, 0.27446419896968277, 0.2771419178461072, 0.36948394465443546, 0.19469305846060236, 0.2717455507465022, 0.22466267573249166, 0.23035041627296904, 0.09627871526413312, 0.18011712776502575, 0.12376885367419255, 0.14935089636202115, 0.1276134468566379, 0.1195186272676263, 0.12593770440444152, 0.14308256267722352, 0.18070415533478557, 0.17116544019196822, 0.21966212560762655, 0.14484995554444902, 0.1728231371245723, 0.17102783665123955, 0.23065754241348646, 0.18023226623073407, 0.17899840651249366, 0.18266074720343417, 0.0019629038765549556, 0.0007689959854872974, 9.999999999998899e-05, 0.0030553489259209643, 0.10529069070557129, 9.999999999998899e-05, 0.0001333857287770801, 9.999999999998899e-05, 0.028913550651053055, 0.06603995106331872, 0.054193094782760465, 0.1060694608346352, 0.08910789182599288, 0.07675668782585876, 0.02160435319947429, 0.13755128188597132, 0.16016906636452588, 0.08626057272449983, 0.11013397454436924, 0.10481397691356431, 0.17476246698652653, 0.06274739138198315, 0.12541621430661487, 0.08142612320016485, 0.10947170370972237, 0.09799618878798266, 0.08378933682718559, 0.2208917713756292, 0.13284768709114636, 0.15404731762525747, 0.09179205410584312, 0.09802883961986097, 0.1308998974381932, 0.14628230922683028, 0.11664624615027375, 0.10684939724008091, 0.4480730336783971, 0.4642747596583333, 0.439014112812785, 0.41260055973617626, 0.3919760136333499, 0.4172659641246742, 0.4432249721800955, 0.43899998261880013, 0.4802151495734972, 0.11697882317147268, 0.09015481814648352, 0.10680264666729578, 0.1447693248962303, 0.1071559017549516, 0.12372117469610511, 0.09626154993931846, 0.14677315524314127, 0.08871567573573669, 0.2074374332526796, 0.16843078850893345, 0.16788098900836246, 0.220566125767776, 0.3165486871147609, 0.20357822463032982, 0.2494828175696564, 0.1795341192269463, 0.2456263082973542, 0.279350382985349, 0.3356093519508351, 0.316694583634166, 0.2617390109715304, 0.28799705840703604, 0.3040862167594427, 0.2718311546173172, 0.29668457016512284, 0.24760699816841136, 0.22031797373921136, 0.30080988299162914, 0.24729606962760586, 0.21963911707651929, 0.20810836715129744, 0.24931412800348074, 0.21359815994092157, 0.23294121485525132, 0.20903918308894454, 0.26892555889896896, 0.20431883995544553, 0.2505574306098183, 0.23590583636731022, 0.2059888457921285, 0.22656017832759068, 0.22116742452025395, 0.21203213873064475, 0.20103984545476417, 0.16469120786474833, 0.18730190840367889, 0.1734081658105806, 0.18228784753421878, 0.1921308662242619, 0.17674167435370036, 0.16660348979463724, 0.1855170702448642, 0.1732415077268562, 0.17996534305779788, 0.18652550271166546, 0.5723362238063121, 0.707172865612267, 0.19865394803393455, 0.1986254125184761, 0.7570670664847012, 0.14844639107907298, 0.5999332937577969, 0.6269911658132072, 0.20781637940913023, 0.5025842129691149, 0.4702712255928533, 0.44402295894999133, 0.1678143789944635, 0.16725855603579198, 0.3434844122517481, 0.35367362235940414, 0.19259282828987545, 0.1854233370365267, 0.190999883649127, 0.1827325500513527, 0.1875524229819987, 0.1945649015185399, 0.2005129470314455, 0.18857137498326904, 0.20486325259709504, 0.08222313327347452, 0.08644262525700774, 0.08837967805591584, 0.08295261013678756, 0.08276855102812075, 0.07370942672788094, 0.07797316915038843, 0.09031121934063013, 0.0906119629227734]}, "mutation_prompt": null}
{"id": "ef73940c-76ca-430f-93ca-67862974fbc3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective approach\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_objective_approach(self, position):\n        # Define multiple objectives\n        objectives = [np.sum(position**2), np.sum(np.abs(position))]\n        # Calculate Pareto front\n        pareto_front = []\n        for i in range(len(objectives)):\n            for j in range(i+1, len(objectives)):\n                if objectives[i] < objectives[j]:\n                    pareto_front.append(position)\n                    break\n        return pareto_front\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-objective approach\n                if np.random.rand() < self.multi_objective_rate * (1 - evaluations / self.budget):\n                    pareto_front = self.multi_objective_approach(self.particles[i])\n                    if len(pareto_front) > 0:\n                        self.particles[i] = pareto_front[0]\n                        self.best_fitness[i] = func(self.particles[i])\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], self.best_fitness[i])\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Multi-Objective\" approach.", "configspace": "", "generation": 172, "fitness": 0.23340114641587792, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.663650352461591, 0.6078558250223212, 0.6992999222171922, 0.662319794185231, 0.6014259202964428, 0.5608083251921259, 0.5848579235170628, 0.6909894982815897, 0.5801598388574707, 0.06914884364730156, 0.024419130791170196, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1393143588079212, 0.07208224333988122, 0.0845468390353381, 0.08828108157169767, 0.10183609586142739, 0.10383534218289259, 0.206012548909293, 0.13166292057892948, 0.0992246266550143, 0.1081996208819983, 0.09277571296831066, 0.11115242971280004, 0.13499606958826493, 0.08650491400639182, 0.1004470726797253, 0.11979315955057557, 0.08684180244896522, 0.07027148241601411, 0.8620066247419303, 0.9287344346277776, 0.9136394019846102, 0.8453873638516907, 0.8537629747337386, 0.9104938332553858, 0.8639099093985378, 0.8798679101762331, 0.8545135383656509, 0.2770073397583883, 0.3004960049926064, 0.29052704889366765, 0.23211046878288544, 0.29182311793718074, 0.2704723038358381, 0.2586885755446118, 0.24672698771984802, 0.24095202714614183, 0.29053043046138327, 0.7575992159115711, 0.2240749156234244, 0.2186791617276268, 0.2652691128704904, 0.272971479780719, 0.5943765242857244, 0.30306180634588176, 0.24558583628317843, 0.12289278991429942, 0.13834158024315424, 0.1466032364692761, 0.05285074534791179, 0.14130056571700755, 0.2426792785843218, 0.19878841665813074, 0.19462427741640798, 0.1947473128736742, 0.2059799389077447, 0.15341340640247458, 0.12478756977012928, 0.15295727252955427, 0.16453488082363366, 0.14645700610272505, 0.13123650623526095, 0.20259582669325993, 0.17149740260921553, 9.999999999998899e-05, 9.999999999998899e-05, 0.016967575027756365, 0.03622879896688502, 0.04504533696743784, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04221371379043526, 0.11776746684212791, 0.04563614957500506, 0.11476067881410146, 0.09628076874542735, 0.08638192579604964, 0.0911758013088898, 0.08998491634788608, 0.08773389051202252, 0.10889661174643861, 0.16027167012109422, 0.08828833424734694, 0.12607198834967315, 0.09603682377317946, 0.14119130910965505, 0.04922786976235605, 0.08144258716438346, 0.10736020351667863, 0.09090041837779883, 0.18008638760054985, 0.16275844802010542, 0.09065281647727919, 0.18873626835978408, 0.18581327473300324, 0.19754446266142034, 0.1196520571856321, 0.20628515476840836, 0.09229667457045887, 0.4517507745356176, 0.5232689130896292, 0.41807360524224646, 0.43422525845408266, 0.40553060896411586, 0.4077384285472285, 0.4206420401153679, 0.47721302606122673, 0.4063238180796993, 0.12015595457429684, 0.11712892949576947, 0.11874304635935173, 0.09937060462944336, 0.11387308906345583, 0.12518708536911705, 0.1338246844609876, 0.1016053530387604, 0.13601775919774428, 0.2974416037815242, 0.14087244813491584, 0.16200326382018393, 0.17439070991425365, 0.23407339370786873, 0.22351962327407615, 0.24349462247827092, 0.15048326635563058, 0.2274047794428672, 0.2852693600606754, 0.2950178557986807, 0.27140762731049695, 0.2631252164529988, 0.35326233209786406, 0.28907105566673386, 0.2419650392471575, 0.3239604403019639, 0.2292751009028834, 0.21230815811083426, 0.21169789510599935, 0.2689855861570041, 0.21263117223464356, 0.30920886803952985, 0.2515628824279399, 0.21218684023065248, 0.233943281021185, 0.2335101433281822, 0.226240392990255, 0.2371232827769696, 0.24708404750651847, 0.2223588225075489, 0.2329383627246957, 0.2030559065105223, 0.24527399591914112, 0.25058690936488637, 0.20917216125027394, 0.17004640167262608, 0.17945786884093762, 0.18404353247020655, 0.217589092860764, 0.19611430408584662, 0.18857330585473941, 0.18540592550719226, 0.20063303705656277, 0.17300653468423866, 0.1852726781477354, 0.18702083469414854, 0.18565082458255144, 0.7198740303574086, 0.19744544790195473, 0.19699543763028204, 0.1667145478498684, 0.15134041744298177, 0.6302295588577591, 0.4239757405909057, 0.21212461128643967, 0.5175254204592816, 0.44835976322524607, 0.16512283681430528, 0.16592026722300157, 0.16631665019301178, 0.1669453746176991, 0.2877338347650277, 0.1980826411663812, 0.19683480319205204, 0.20376247159173055, 0.17693359589893976, 0.17558114223282395, 0.1794917899555254, 0.18090146061287626, 0.19160479953924903, 0.19439873938793006, 0.1149521589284006, 0.08098328345756711, 0.09396712617182279, 0.08480827845599015, 0.09348721191617992, 0.07291172943069091, 0.08104122948841253, 0.08315615717578273, 0.09857086008146998]}, "mutation_prompt": null}
{"id": "e4373dee-bb5a-40f8-86b6-6f687023d0c5", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  \n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  \n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  \n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  \n        self.swarm_restructuring_rate = 0.05  \n        self.quantum_tunneling_rate = 0.1  \n        self.differential_evolution_rate = 0.1  \n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        return position + np.random.uniform(-1, 1, size=self.dim) * (self.particles[r1] - self.particles[r2])\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                if np.random.rand() < self.differential_evolution_rate * (1 - evaluations / self.budget):\n                    differential_position = self.differential_evolution(self.particles[i])\n                    differential_fitness = func(differential_position)\n                    evaluations += 1\n                    if differential_fitness < fitness:\n                        self.particles[i] = differential_position\n                        self.best_fitness[i] = differential_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], differential_fitness)\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with a new \"Differential Evolution\" mechanism.", "configspace": "", "generation": 173, "fitness": 0.2293366981664821, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6340772521483212, 0.679976885299435, 0.6528498429146619, 0.6518709201985594, 0.6636905942707322, 0.6489971062796054, 0.6199429435078274, 0.5697539560235608, 0.663668768030439, 9.999999999998899e-05, 0.0304437698604062, 9.999999999998899e-05, 9.999999999998899e-05, 0.03291597735787888, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13976286145209893, 0.11198181921965078, 0.08601604771539373, 0.10648671003252641, 0.09306315571892376, 0.13742672794046484, 0.1407374920140737, 0.12019995006750794, 0.143355523347921, 0.0955061432214005, 0.08908897610999134, 0.09242913507917816, 0.11753135995074504, 0.0640048619352106, 0.05786015358848251, 0.08809131306599616, 0.1025116637700807, 0.08939822046663815, 0.8548981229596005, 0.9179034209100417, 0.854394152235999, 0.81855975110691, 0.8366177961936544, 0.8898061513254933, 0.9327705667189832, 0.9050595947034773, 0.8703276041359947, 0.25337420328149096, 0.2685251311212501, 0.3167604590853561, 0.23824254873109207, 0.2537071323903234, 0.26032468975687384, 0.2672901931705953, 0.2612393025291916, 0.2724614143160933, 0.3717702147357522, 0.22781177366965677, 0.2746765351897087, 0.27320839303010025, 0.3500148555606185, 0.20438109075529698, 0.27027595770809143, 0.20123072331428205, 0.2111992148765468, 0.12702671564161827, 0.15678904780112313, 0.09674046783914436, 0.15108523973558308, 0.14092089014745401, 0.12197549069427749, 0.14386246443517992, 0.21038670349941846, 0.12555767886302915, 0.14721135044715428, 0.1677403177827167, 0.12339529959292506, 0.164935520628405, 0.16788736633059598, 0.15250174793894766, 0.15933730517976363, 0.15828956210320155, 0.209279153292796, 0.006918948947732817, 0.006548077700304411, 9.999999999998899e-05, 0.0181161044298922, 0.053135857086292204, 9.999999999998899e-05, 9.999999999998899e-05, 0.014660396724970992, 9.999999999998899e-05, 0.1135632003557776, 0.07428974882348138, 0.10423801682172107, 0.08433104126432067, 0.06908202651439699, 0.06764453888456556, 0.1530391546160167, 0.09997395787010643, 0.07763220460573461, 0.08483491784585717, 0.1114874708989817, 0.08861104554091848, 0.0783196916302824, 0.09632290104489982, 0.08630704235578746, 0.10455522287281271, 0.09080973003735782, 0.06352500139100825, 0.17634852807528767, 0.23777401006906707, 0.09729759392614612, 0.10331868435470548, 0.1430654509128808, 0.1340992108746517, 0.2470931778168972, 0.13103667182857937, 0.09499199934482261, 0.4920822702068003, 0.4232542363744364, 0.45033510668914967, 0.4131164371844043, 0.41999499572815624, 0.47588333559523244, 0.5279973387682877, 0.42901014807399906, 0.48728861763323994, 0.10608362264053972, 0.11750924718887401, 0.10432735833794526, 0.11754957371445873, 0.124097446414144, 0.09819890582980806, 0.09625447458764369, 0.10928336449109988, 0.10532552969721842, 0.1656083977324212, 0.20250237357575207, 0.18292172227884507, 0.17284327344086725, 0.2308392909181095, 0.19345340638948783, 0.19283953219300065, 0.16876657073517654, 0.2304892225430576, 0.3126913232762778, 0.3105551158383447, 0.32094951649526704, 0.2838499982329741, 0.2725965427896375, 0.33683923367763313, 0.2360949750179293, 0.36247735102630074, 0.2376226460956382, 0.22202089235035494, 0.22127925801073856, 0.2413341740840137, 0.2099417565524746, 0.19832293344256657, 0.32789001699052345, 0.21303458657232555, 0.22256990064976168, 0.1938667003720811, 0.24806473643738514, 0.2391090054684416, 0.22276575870744064, 0.22747180577910076, 0.21451241518273545, 0.2432795244141086, 0.22862506710790886, 0.2222025276883164, 0.24719638819475198, 0.17751556953151226, 0.17702540473681527, 0.1922149122153639, 0.19139168850730393, 0.16993256742176088, 0.18059353079649354, 0.17739611529314336, 0.17878548409957273, 0.17920647759376374, 0.18640196502568362, 0.1863406284572937, 0.18636452578513285, 0.7202078856690963, 0.19803165202539663, 0.1253653338852848, 0.14136696102533375, 0.14921949449752758, 0.8656901524562666, 0.44563550108484173, 0.2090398145657687, 0.5288218891676916, 0.3883183689314875, 0.16570111064719928, 0.16701140750112387, 0.16509705178273637, 0.29420922695548957, 0.32282214942696696, 0.18059364841197767, 0.1827559394421675, 0.19994498039009223, 0.20201904614975852, 0.19094968015681435, 0.188872401789287, 0.20074853400605075, 0.19355239080988307, 0.19957476717814104, 0.09600978270409954, 0.10622697315291285, 0.082935827774827, 0.08381356485291402, 0.11001739980445313, 0.08192563385055252, 0.0953177203982446, 0.10407336601333139, 0.09320325705160781]}, "mutation_prompt": null}
{"id": "a3fea57f-4842-432d-a16b-97d20d8cf6c8", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.gaussian_perturbation_rate = 0.05  # Adaptive Gaussian perturbation rate\n        self.cauchy_mutation_rate = 0.05  # Adaptive Cauchy mutation rate\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.cauchy_mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel metaheuristic algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive Gaussian perturbation and Cauchy mutation rates.", "configspace": "", "generation": 174, "fitness": 0.23509122371781427, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.7232843005308378, 0.5968111348043683, 0.6696875010813517, 0.6475314551485076, 0.5595154676968932, 0.6399360979282518, 0.6211881749131938, 0.6004429078363324, 0.6900168308176029, 0.028249708396460682, 0.009145948874946241, 0.030662395762352523, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.17128510557169752, 0.10740735205581908, 0.10649192229676041, 0.10491739920732301, 0.08894895341115094, 0.10932613456023443, 0.12394460069029589, 0.13565180544482824, 0.10721475309352013, 0.0767937661258955, 0.11433840305665566, 0.08530385984664102, 0.09082944181481922, 0.07158029717996162, 0.06330012215790937, 0.08713214435451377, 0.08766536505980971, 0.08037864296736752, 0.8744900026640117, 0.9282766730406724, 0.9050285226304435, 0.8163066137294859, 0.8514651565332889, 0.8819175819532429, 0.8912578265995541, 0.9275264883779692, 0.903783653096236, 0.2318286240277675, 0.23173432138172034, 0.2352492266892917, 0.29677729356118066, 0.26977782040174036, 0.25851738866572516, 0.2468957438350169, 0.22948165929046938, 0.2491729513565446, 0.27077143545014304, 0.3725378804184528, 0.24431338958516724, 0.2751459090998053, 0.33571102635772354, 0.2024989541477955, 0.23804990973633466, 0.19776911139880404, 0.22719221724666372, 0.2216752204814808, 0.16320239252647462, 0.1230777010710502, 0.10955412165975231, 0.14010430728384893, 0.19342322343691098, 0.16013801104721648, 0.1290044582719243, 0.1799217738974197, 0.14879512202142864, 0.15376757992763546, 0.19125447484474567, 0.1619576366027663, 0.15083821521916274, 0.15718440417131863, 0.17564248119106596, 0.2306044704742376, 0.13934517539291047, 0.05117295283317125, 0.06252200485107584, 9.999999999998899e-05, 0.023840936571139393, 0.0960131168419932, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.013646940355487414, 0.15003333846593614, 0.11256823169873864, 0.14878429304603868, 0.10934431015615809, 0.06823360970074832, 0.03368600756036744, 0.1448990996231403, 0.07975970164213197, 0.06904976595708046, 0.1483217975019666, 0.1212737175764792, 0.06187936996831045, 0.07946699822708725, 0.08631315169774245, 0.07035827281459928, 0.12941772938703144, 0.13024758089377197, 0.06748085110569302, 0.17410579793035363, 0.15892523889072085, 0.17642647634192254, 0.11516133832396791, 0.10351298414229881, 0.092124150960185, 0.11057906929253059, 0.11482097280944614, 0.1007922451593164, 0.3936734725657729, 0.45684152009313606, 0.4623778293006807, 0.41514657957776835, 0.4087032580521339, 0.41987562210164064, 0.4605622146362671, 0.4332570762519956, 0.4608546521244109, 0.1277573793101756, 0.11132910238592741, 0.08478412367605104, 0.1152334969412866, 0.11648010615145254, 0.12718301490379413, 0.14072467603248473, 0.1475720414065771, 0.08830850991781192, 0.23359878924344613, 0.15036439841953775, 0.1725921305792565, 0.2797360903397059, 0.28473048633659415, 0.22037723315711533, 0.24958995711001886, 0.18641515025010835, 0.2874649499744065, 0.2824118911065042, 0.26515303197277207, 0.3487985013961151, 0.2968471040948667, 0.31071418687387964, 0.29857010549834306, 0.26125320457890366, 0.2959031070141377, 0.2333508271812742, 0.20792761510658464, 0.3637193517475109, 0.22786202538011735, 0.21960322363841256, 0.23938063429812384, 0.3579567669506214, 0.19328661071110564, 0.22653878710884323, 0.21256222542969838, 0.22822121201671886, 0.24187022988911178, 0.23754189305978668, 0.2634157940477543, 0.24721803766505512, 0.2112191489784936, 0.20711144972206985, 0.24241859760567874, 0.22257252338306777, 0.19462428212530503, 0.1794577265776628, 0.18158204347725904, 0.2617444853951477, 0.17819450990615004, 0.17260135269669574, 0.20637192137507154, 0.18625303546214023, 0.18195833941239092, 0.17944615004856646, 0.18562452877378754, 0.6126919198107137, 0.7141066572982788, 0.19943982628122858, 0.1716432827914206, 0.1410904585413888, 0.8404552530380239, 0.5339235333540745, 0.43329130064916477, 0.2101178976696142, 0.07338607009300702, 0.3929990498022712, 0.31227901513366985, 0.34100133907375163, 0.16653528912087368, 0.3349318012887852, 0.34451783462885777, 0.19359525546487621, 0.19314371669228803, 0.18337185359748298, 0.18560253055691067, 0.18507660361740053, 0.19001959404846702, 0.1812592754989314, 0.17724033252874705, 0.1895761223509833, 0.09290350265226477, 0.08825519843341356, 0.09987026153302103, 0.10156734173175497, 0.0866526975987657, 0.09145001838361022, 0.09356738547938825, 0.08147480208871061, 0.09813478386092123]}, "mutation_prompt": null}
{"id": "35d31195-09a2-4178-910d-805f1d0acef2", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.2  # Modified levy flight distribution\n        self.levy_flight_beta = 1.5\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.diversity_enhanced_rate = 0.1  # New diversity-enhanced mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def diversity_enhanced(self, position):\n        diversity_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + diversity_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Diversity-enhanced mechanism\n                if np.random.rand() < self.diversity_enhanced_rate * (1 - evaluations / self.budget):\n                    diversity_position = self.diversity_enhanced(self.particles[i])\n                    diversity_fitness = func(diversity_position)\n                    evaluations += 1\n                    if diversity_fitness < fitness:\n                        self.particles[i] = diversity_position\n                        self.best_fitness[i] = diversity_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], diversity_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with a modified levy flight distribution and a new \"Diversity-Enhanced\" mechanism.", "configspace": "", "generation": 175, "fitness": 0.23141169575130394, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6235870145461515, 0.6468995662453554, 0.6226391293200613, 0.7033713486021778, 0.6499829577424064, 0.6571651446928461, 0.6140048229729125, 0.663723853278944, 0.5991391195539, 0.04270575137184751, 0.031140891490657352, 9.999999999998899e-05, 0.0118465958961822, 0.026237267112852014, 0.008498511045055612, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1368232213707966, 0.08078155186132063, 0.09857549469774751, 0.0954276749537134, 0.10100661245831544, 0.10834647576120371, 0.11117525006035545, 0.1107802379443854, 0.17230601037736282, 0.09591466592472897, 0.10926654077749731, 0.10146574885156878, 0.10875821999104351, 0.08022739217838204, 0.08466001050788818, 0.09841574405130649, 0.08632738453909172, 0.07472227965312217, 0.8843425975278124, 0.9335834906313305, 0.8662320695645997, 0.7947193196638465, 0.8343417228807317, 0.8558134155561774, 0.895486125579751, 0.9098469023108964, 0.8627919431787273, 0.2878564741115548, 0.2916149448789752, 0.2322042409550239, 0.2677129238533841, 0.26678340292406044, 0.258656317729526, 0.2818152918615283, 0.23981044309073107, 0.240847700169041, 0.33739479223739455, 0.7928819334546391, 0.22647069185439994, 0.27453532624516797, 0.27054470056188895, 0.27413904415609824, 0.22620068031516294, 0.250497151871089, 0.3249194928613681, 0.11907274920482958, 0.2626598906291172, 0.11742310709087056, 0.15309282614768216, 0.150326438127648, 0.1455588783955436, 0.15224058833664167, 0.1265897719076029, 0.1496836467952728, 0.1844844464135933, 0.17215621584886198, 0.15517356951554884, 0.17064712618960964, 0.15291198333464784, 0.12558222527985796, 0.27026879685048333, 0.17063132412679627, 0.18337470536294953, 0.03297620619724295, 0.010814861254768715, 0.000330484778206519, 0.03531537806375895, 0.015380561790255487, 9.999999999998899e-05, 0.03642828754355576, 9.999999999998899e-05, 0.0026589195583129888, 0.042872589713353615, 0.04139180192535463, 0.09755926598163189, 0.09307851168692871, 0.06363563151267704, 0.05357868823295886, 0.0793645882667251, 0.0528321784480702, 0.11436246072767431, 0.08648086546606626, 0.09295944904816111, 0.0750185176286885, 0.08988656542555329, 0.1067144613513008, 0.09292463142081875, 0.10781608370275497, 0.06708709206707175, 0.06236180197780816, 0.2009100558562138, 0.17498132328794092, 0.14283386661963848, 0.13238663711220033, 0.18684032374964543, 0.12804180680884036, 0.15498910094499552, 0.16114453112197447, 0.0962659225896545, 0.4512268799308383, 0.4390369273229233, 0.4316151430087145, 0.43895318810509065, 0.44897658588902245, 0.4185833293827931, 0.48245080748205027, 0.43114113957550915, 0.4704343522158527, 0.10179022314559638, 0.11380235382871562, 0.09709213538305972, 0.12526751071183406, 0.11573932148578514, 0.09210557858242285, 0.09836454522538207, 0.12524352554134843, 0.0717009997675998, 0.23534854999852273, 0.2271372555742659, 0.1649912139891394, 0.3048776670750555, 0.28777861915448666, 0.22870057286011902, 0.23480768395915153, 0.17419254047750232, 0.2422953572567197, 0.27040235029429704, 0.2962873287287352, 0.2826979830362849, 0.3156683101999508, 0.34055334648043645, 0.31578001409864587, 0.25127211705300057, 0.2722622269492253, 0.28732486111304667, 0.2566093020008765, 0.21188974399305271, 0.255208243237375, 0.30215978919166775, 0.2212043061828416, 0.22138705580462437, 0.2272572179436413, 0.21555850908221397, 0.21982145997585978, 0.20425580148639833, 0.2083683634575807, 0.2472161507217725, 0.22700131481321428, 0.23235198154389414, 0.22519200739490475, 0.23525785701585733, 0.22644806777352577, 0.2122560614292286, 0.19908351638086808, 0.1924983368893597, 0.2195333420683956, 0.19106901749375238, 0.18634982056972693, 0.1924612736925524, 0.18822152222818544, 0.17984792201606925, 0.1861172073421492, 0.12799682009044322, 0.18552329012902802, 0.18719568670247144, 0.60040783593812, 0.19882385862404872, 0.19758155848945702, 0.14664565901498516, 0.1569258162656677, 0.7390706429264182, 0.4420654420026684, 0.15262762284209452, 0.3384535172878511, 0.38855772111937503, 0.206399089080746, 0.165760606667528, 0.16746796408876052, 0.3074736402203647, 0.3401312513507899, 0.19419665825627852, 0.18232404545036085, 0.1981006875681891, 0.1863893696442458, 0.19200044243755543, 0.18543087245812617, 0.18318402229779363, 0.18597846599916779, 0.22700493846123748, 0.08354695753719843, 0.09240542957985287, 0.0780247924000782, 0.0968759787350234, 0.08610361336946315, 0.08335782355551802, 0.09143024883568118, 0.09405148772871141, 0.09221731723918525]}, "mutation_prompt": null}
{"id": "8f06f449-d515-41e1-91a7-16423cd23c8b", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.98  # Modified cooling rate\n        self.adaptive_cooling_rate = 0.3  # Modified adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.15  # Modified opposition-based learning rate\n        self.dynamic_opposition_based_learning_rate = 0.1  # Modified dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.98  # Modified inertia weight damping ratio\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1\n        self.swarm_restructuring_rate = 0.05\n        self.quantum_tunneling_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with a modified adaptive cooling schedule, and an adaptive opposition-based learning rate.", "configspace": "", "generation": 176, "fitness": 0.23915022853721815, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.21.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6324615979098773, 0.704385119503983, 0.704957406410887, 0.6292510027023188, 0.6368591301027451, 0.647256209521858, 0.6451356275816348, 0.6846900300950636, 0.6257329090540633, 0.013175772183891654, 9.999999999998899e-05, 0.0004284184659775203, 9.999999999998899e-05, 0.0012615800451912795, 0.03852684086539737, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12738832720537652, 0.09786367334911139, 0.1020601433133006, 0.11324545340277659, 0.09148639525093294, 0.07617391822478004, 0.11023425380865115, 0.10652324232322685, 0.1309370962164812, 0.12238628530834339, 0.09191927764860353, 0.10304130169179793, 0.12332575730450424, 0.08584794285420916, 0.10949380732835412, 0.08090545642363378, 0.08833149620290837, 0.08137248167977873, 0.8866651792207166, 0.9279019513876756, 0.7489318559908411, 0.73492643217496, 0.8701706095597697, 0.8183248025587269, 0.909404136193209, 0.8954621076691256, 0.8846747499135997, 0.2506457451588687, 0.25418039477192966, 0.2393773942403905, 0.29344818434161135, 0.2580616541732098, 0.25533862637290694, 0.22577383281290309, 0.25620665971264733, 0.23187725115541125, 0.3246834133623655, 0.7329229714634734, 0.2116155934756444, 0.27690704649370035, 0.6221078626198788, 0.2000128716361611, 0.2312920677232777, 0.2312375276431451, 0.22828432629213302, 0.20739954180026077, 0.19752138378311923, 0.1236655063181864, 0.13077306306202885, 0.14270164146615094, 0.12297001882813041, 0.12709442163547502, 0.1385135369888485, 0.1787968164784266, 0.1644155771082897, 0.21040354003636597, 0.12556993694572538, 0.15721922349582673, 0.14745724206827127, 0.2276476503772238, 0.16375352112057429, 0.17692572355871528, 0.17487175763654972, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.004294380101899198, 0.03679939174882074, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0004715457149732094, 0.13233033555642437, 0.03961402640879408, 0.12399366625015684, 0.13029747600647335, 0.08000429630730266, 0.03156630189594112, 0.10912442713103554, 0.09325846026979634, 0.10233300902583309, 0.15222864831719196, 0.06869626898885395, 0.13575426425278625, 0.07153354692507363, 0.12087518832839961, 0.06792461374679992, 0.10891228894880023, 0.10832333958228246, 0.083671284332138, 0.23719812495483028, 0.16300527097960715, 0.18055149671127835, 0.088793085756534, 0.20956265243237238, 0.14274020575534507, 0.15928495675388354, 0.13333317146283863, 0.10466052454219987, 0.45510183609351895, 0.49515128083154925, 0.41505398917656044, 0.40063989770520425, 0.4402398000035813, 0.4691361281690881, 0.4506215961776634, 0.4681654127581394, 0.44680679094660736, 0.11371326898031875, 0.12525006184532472, 0.10021144154757167, 0.12575938951675236, 0.10866724403127082, 0.1266883746019597, 0.10108717304373627, 0.10016256075938312, 0.09142904478442049, 0.2084467024630754, 0.15409495278668928, 0.18217194311472162, 0.21797137006323086, 0.3203811789449865, 0.23749313903401403, 0.3014861521643081, 0.2178570963757781, 0.2137079415371953, 0.32313237416472507, 0.28138227451137365, 0.3512317383475987, 0.2525813165560259, 0.2858902291610921, 0.30384694794971256, 0.2449785826963672, 0.3481102741963519, 0.23682099152526348, 0.20152678640800414, 0.21805575419075618, 0.2760860661308092, 0.22344050845645047, 0.22276745810216558, 0.26256582239681325, 0.197153675619669, 0.25872774509076946, 0.20608575343102653, 0.22544601977792467, 0.21560395959701972, 0.23522182258793656, 0.2319847694139877, 0.24453095146844273, 0.2086111657162668, 0.2401473818673011, 0.2305706044408179, 0.22730298763264223, 0.20376247409646753, 0.1868146184585151, 0.18495472209812225, 0.19295366623539734, 0.18152363378211744, 0.17711770735617516, 0.1740127882148147, 0.18217701304274914, 0.17349634836239514, 0.18054200906577988, 0.18621911621763387, 0.6324583131469305, 0.6277967708296486, 0.19937331314790374, 0.19914148251179908, 0.6844589691622738, 0.14730967936522998, 0.7817123225317206, 0.6042795290941689, 0.21039920199846052, 0.4402008077216215, 0.4245258165001151, 0.4793934984605833, 0.16790151614457305, 0.1674322329987037, 0.3213148220967448, 0.26972527455905504, 0.18085911287989642, 0.18577016623769382, 0.203201150114533, 0.19868850779536118, 0.18700610416114194, 0.19431729845462342, 0.19204858410778258, 0.18195457155724482, 0.19036228227079366, 0.08260882825571969, 0.09138264695088039, 0.0769422985103334, 0.07703479737291419, 0.0873383015290139, 0.08189654188885376, 0.11019274916380761, 0.08086768839717884, 0.0846508043029045]}, "mutation_prompt": null}
{"id": "ee030e22-670f-415b-9488-fa4b5b1271d1", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.diversity_enhanced_rate = 0.05  # New diversity-enhanced mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def diversity_enhanced(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        closest_index = np.argmin(distances)\n        return particles[closest_index] + np.random.uniform(-1, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Diversity-enhanced mechanism\n                if np.random.rand() < self.diversity_enhanced_rate * (1 - evaluations / self.budget):\n                    diversity_position = self.diversity_enhanced(self.particles)\n                    diversity_fitness = func(diversity_position)\n                    evaluations += 1\n                    if diversity_fitness < fitness:\n                        self.particles[i] = diversity_position\n                        self.best_fitness[i] = diversity_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], diversity_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Diversity-Enhanced\" mechanism to improve the diversity of the swarm.", "configspace": "", "generation": 177, "fitness": 0.2319904444811801, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.5683489038763487, 0.6968511978363974, 0.6361560670478148, 0.6678688785579887, 0.5823876903209764, 0.6601456034117413, 0.6258722258901659, 0.5987566575945861, 0.5730475889150815, 0.07599683535116297, 0.009322546211690708, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15927097795375122, 0.14074413129829189, 0.1061014886354511, 0.08184977797892412, 0.12956849779669832, 0.10500683301554437, 0.14337961525281095, 0.09929480157348847, 0.11050584155631438, 0.09183687849462563, 0.08312893460886661, 0.10073737033891816, 0.08659283698582365, 0.08619216092195059, 0.08104938117006, 0.08679240034890368, 0.08387609756754666, 0.12635187804086456, 0.8896501914292083, 0.8734711787758892, 0.8723270426426686, 0.7897840144725378, 0.7918660671154608, 0.8609814616510291, 0.9016035033359817, 0.8851168702157687, 0.9036291387548949, 0.2529021126507398, 0.28331359228316044, 0.24582682395951838, 0.22981042668550822, 0.23046700237544004, 0.23516398297565333, 0.3308390982949464, 0.259034002534848, 0.239689325783083, 0.2629617961023081, 0.2747586962937909, 0.21687580449748933, 0.2709093844874, 0.26444533405669124, 0.2758794669984329, 0.25706243116763083, 0.18269690434264874, 0.239670869056537, 0.15377610765957905, 0.12102477985918336, 0.12352506183700318, 0.16089802358204575, 0.3028537306711664, 0.21923964408083407, 0.157695810577132, 0.16061610204553833, 0.15106031575066814, 0.13507838599370403, 0.1978258149250811, 0.16905860369898762, 0.16369241210497754, 0.16556911556948495, 0.1648651793938538, 0.12660693773563947, 0.14902836812902753, 0.15633843535423098, 0.04521538270403358, 9.999999999998899e-05, 9.999999999998899e-05, 0.01957344859000787, 0.010018269851949979, 0.011774068000344418, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1050272623156121, 0.03106990271228116, 0.16456244774848205, 0.06983952787682668, 0.08798734741376357, 0.04813219905200239, 0.12110690500307442, 0.08414747698659741, 0.0845231836067527, 0.1293463661673957, 0.10406997917275351, 0.11018099676376147, 0.10667482570106457, 0.09598639497479822, 0.09443903143957266, 0.148637018337629, 0.06272471832774285, 0.13543882258236883, 0.2205166466812727, 0.1561077412568277, 0.09323798805535877, 0.22609354678718607, 0.13739738910274024, 0.07921091181937523, 0.15421758075228698, 0.12229125450233402, 0.11725323356021833, 0.3955260130019106, 0.49942954073797363, 0.48640921804468773, 0.40388341577133646, 0.4433413644693589, 0.4310732909912147, 0.48135511640574036, 0.4322881538429618, 0.48280829422288074, 0.10668085702072405, 0.10356811047496628, 0.07115489963699095, 0.12089856504602081, 0.1273429108080798, 0.11354407712959147, 0.10494813114183088, 0.08536742308940215, 0.09839956798842253, 0.21792960089690327, 0.21424706323077725, 0.16900534683777624, 0.18570447459416994, 0.2443598021079768, 0.17365129872490814, 0.21537561053952559, 0.14917822754319987, 0.23404960880777137, 0.24692304713638447, 0.3387013951436112, 0.2915382091592106, 0.2462228636686743, 0.39975145450230987, 0.3812452542010356, 0.30842772822976683, 0.3331921164160885, 0.20020370045726932, 0.20072619035417627, 0.2273853845683943, 0.25132095195459947, 0.23830626712289882, 0.28693952635417996, 0.24455610103403835, 0.20595425045129623, 0.20765116725344945, 0.20747868329974473, 0.23910632625439499, 0.2352236180682028, 0.2210413708836042, 0.22669667849550867, 0.23497086304006132, 0.23291793556179297, 0.21272636500094277, 0.20942111554994425, 0.21607962970084327, 0.19011672083678077, 0.18391454007813512, 0.1948354885713115, 0.17919985624989254, 0.19323400645893685, 0.18499359592898135, 0.1845772248556754, 0.18887195704462645, 0.18333491414610625, 0.1863550123683838, 0.18673185560292682, 0.18698305451302144, 0.6300470856844216, 0.19904739652145942, 0.1967590485879641, 0.7425430521383924, 0.1532244815960737, 0.8415291335056576, 0.5699724343208812, 0.2105010321312668, 0.4632439593807237, 0.3840562519299018, 0.16461758037275542, 0.1654614176967929, 0.16704058017606527, 0.3401863069617389, 0.3391984589983382, 0.17632139190603668, 0.19971962744952132, 0.19811385505950452, 0.19157282605200765, 0.18327270795419282, 0.2056430151030274, 0.19310531768692452, 0.20362203203701668, 0.19888978333683405, 0.09271518967341885, 0.08424154358124725, 0.10013623449985865, 0.0996089533260569, 0.09334066337846891, 0.08631281903077093, 0.08713279380910299, 0.09493676890867608, 0.09992054320889965]}, "mutation_prompt": null}
{"id": "62708791-059f-4f0b-a18d-019e0388b0a4", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.archive_based_position_update_rate = 0.05  # New archive-based position update rate\n        self.velocity_clustering_based_position_update_rate = 0.05  # New velocity clustering-based position update rate\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < self.archive_based_position_update_rate:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Velocity clustering-based position update\n                if np.random.rand() < self.velocity_clustering_based_position_update_rate:\n                    velocity_centroids = self.velocity_clustering(self.velocities)\n                    self.particles[i] = velocity_centroids[np.argmin(np.linalg.norm(self.particles[i] - velocity_centroids, axis=1))]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio * (1 - evaluations / self.budget)\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with modified dynamic inertia weight and adaptive cooling rate, and new \"Archive-Based Position Update\" and \"Velocity Clustering-Based Position Update\" strategies.", "configspace": "", "generation": 178, "fitness": 0.22551122177336982, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.742794248853899, 0.7202070109952581, 0.6324366930472602, 0.6327342825961183, 0.6735253257920606, 0.5708037218021772, 0.6680861694097971, 0.6424580413415009, 0.615021683240559, 0.06960216910626837, 9.999999999998899e-05, 0.0017329043565846858, 9.999999999998899e-05, 9.999999999998899e-05, 0.11127369205326798, 9.999999999998899e-05, 9.999999999998899e-05, 0.0026782790700279335, 0.16128034927299684, 0.08787384409614385, 0.11575404563573688, 0.11721082288626061, 0.09530914539475521, 0.1069502087760742, 0.150928849297692, 0.10216528498838762, 0.12117621305811188, 0.09173713956656537, 0.1361721374982522, 0.09574754654623452, 0.09457015736247054, 0.10281998700638906, 0.07999666600056865, 0.08955087136351736, 0.0691567167973266, 0.07202780297489475, 0.8690066047692473, 0.8955050460393842, 0.5676056389295037, 0.6386331744395728, 0.7585024433194906, 0.6539676885977742, 0.8998382564384553, 0.895217200486421, 0.8916612088967115, 0.27769537106002873, 0.31027231169275127, 0.30091621957320414, 0.3075466331236263, 0.28890706357559526, 0.25401725794604013, 0.24091159849419064, 0.23948560286930465, 0.30989500727690644, 0.3314521012178583, 0.26787225189570374, 0.1794714417174551, 0.27062689824057395, 0.33350636724594407, 0.26657530399252405, 0.3381551230995946, 0.19875175417109048, 0.21202933598361762, 0.17952499582635717, 0.13305944791394153, 0.10954179741628922, 0.13704242881571993, 0.12529481326391068, 0.2199600822520431, 0.16601705444921244, 0.16185281480606428, 0.16159679863486875, 0.16961542481316538, 0.20400547547506287, 0.16323600626944024, 0.19893417578788009, 0.21037649654254398, 0.15187175004761988, 0.19691001761530025, 0.23414573168416863, 0.19111831971295834, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10400386807371909, 0.020250680877186622, 9.999999999998899e-05, 9.999999999998899e-05, 0.0006954332064297297, 0.0025363841404547616, 0.118933530049537, 0.05953624803059754, 0.13529652298397743, 0.10862865442702863, 0.07178860362132433, 0.01528726330329011, 0.12857516289407545, 0.08719098289599192, 0.08046404144331376, 0.10189094361006668, 0.09333744792517262, 0.07411088766797691, 0.08876828285695515, 0.11830801380896405, 0.10945352295061639, 0.11975452079992244, 0.07053407580856641, 0.12991511809942746, 0.1402163988341577, 0.1747305171292226, 0.09460375521915099, 0.06518149147816743, 0.13317211446766863, 0.10916938173249324, 0.15186036961896188, 0.129801069825344, 0.1318090472589134, 0.43526888097894645, 0.4587819467728719, 0.44264679025656406, 0.49849897889688277, 0.4506132475215737, 0.41335225955191557, 0.4748326854898852, 0.4175158418210857, 0.44555747899930565, 0.1376371293292461, 0.12488072294723696, 0.06707772005133905, 0.12853279549098373, 0.08727867157560709, 0.11109653935713903, 0.1349925127091024, 0.12394072287204305, 0.11935571907120301, 0.1839918842820374, 0.1785245695239086, 0.15882501901702417, 0.17365706187152463, 0.23912215241495005, 0.20685105108143242, 0.19856342510672853, 0.16145379717563535, 0.24702779994298796, 0.3097366653331992, 0.2830883913193679, 0.3134943935255493, 0.3444767067909499, 0.25900491787664603, 0.2862999695530677, 0.2433582950709302, 0.31174461321453395, 0.22629012578887364, 0.2198495420326534, 0.21438282904003714, 0.2574864174708621, 0.1875314265768686, 0.21686353099300004, 0.2832650941992625, 0.1816276238723774, 0.20373891818252343, 0.22341652712193083, 0.24472755691255466, 0.23650435002796188, 0.26833155706795053, 0.21705911975093728, 0.22180509043956098, 0.24992019121268605, 0.24255626177806422, 0.2415926881375129, 0.21620944300193579, 0.18863490058323074, 0.17728547317142218, 0.17299317539300862, 0.18178584172471135, 0.19622842881002478, 0.19441450220361478, 0.1752207262435519, 0.20711985900125607, 0.17299522683506108, 0.12805485013364137, 0.18622039158745174, 0.18635210506623978, 0.6394389947334851, 0.19864231916815278, 0.19757841552383326, 0.14072318369970038, 0.15797011546546214, 0.5647578521847483, 0.416146617453666, 0.2111344903460225, 0.5754058768943626, 0.20763666938779668, 0.13263091518508885, 0.16549935087109957, 0.16615636993414462, 0.338275173919208, 0.2851441097209456, 0.18940644771959292, 0.18057319077749268, 0.1822444886796727, 0.20609021207465994, 0.17817163441670436, 0.1941994531396274, 0.18995508977756537, 0.21155224561565933, 0.1782169802569451, 0.0998551458272765, 0.09794821584054114, 0.10230635522270226, 0.10544212567832179, 0.08139284008896486, 0.11139058841134297, 0.07639654635663606, 0.09055986816933659, 0.08932200770800358]}, "mutation_prompt": null}
{"id": "3431c287-7877-4794-828f-14761c7b2f7d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.adaptive_swarm_size_rate = 0.1  # Adaptive swarm size adjustment\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            # Adaptive swarm size adjustment\n            if np.random.rand() < self.adaptive_swarm_size_rate * (1 - evaluations / self.budget):\n                self.swarm_size = int(np.sqrt(self.budget - evaluations))\n                self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n                self.velocities = np.zeros((self.swarm_size, self.dim))\n                self.best_positions = np.copy(self.particles)\n                self.best_fitness = np.inf * np.ones(self.swarm_size)\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive swarm size adjustment.", "configspace": "", "generation": 179, "fitness": 0.23339465219156505, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6393444042741685, 0.6523461991939514, 0.6865735404371182, 0.5821887160357491, 0.5723436781390255, 0.557629766975821, 0.6322263766843441, 0.5918997550170549, 0.6410222257129028, 0.02725798306747751, 0.014802477521265955, 0.055020069898743196, 0.012658738615146437, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10684293779612253, 0.10135994643926971, 0.15170639107403017, 0.11964590293769584, 0.09978632932627896, 0.14814369225844226, 0.12077645567363449, 0.14432330568226936, 0.10893631557199168, 0.09178112811027406, 0.09375903617356729, 0.08127010482106611, 0.09415185534133175, 0.088211860506208, 0.08630676830916839, 0.10271686589942453, 0.10134768573163377, 0.0974256556934131, 0.8286670516201422, 0.9204845254476864, 0.8565146704093928, 0.7937406679080345, 0.8258022400445848, 0.8804356684730201, 0.896511665992702, 0.87573098971831, 0.8963074036310228, 0.2747871622585595, 0.25015685184051994, 0.23263445649751047, 0.26095099529438526, 0.2641281875787369, 0.25686369887277183, 0.239517583246733, 0.24148582169700872, 0.24005551415209403, 0.3026858198220037, 0.2285674780011, 0.6701933667570368, 0.2715552537311017, 0.27341450434826053, 0.2019802826138143, 0.2454766183756416, 0.23488614268903607, 0.271372541943402, 0.12188420010657774, 0.10311514335265715, 0.12999097465707343, 0.1488961404469994, 0.24950426266827574, 0.19761220045872063, 0.146468827697814, 0.13881052663341475, 0.1353005515329292, 0.14738410921677625, 0.1879470295595348, 0.1603776958920191, 0.1423876512593284, 0.20059061111110543, 0.1600755321781857, 0.15710326786556217, 0.18932077283938964, 0.19184825493071955, 9.999999999998899e-05, 0.04533913196223471, 0.000454835834697187, 0.018417760339188627, 0.016279891736026397, 0.017296162297825268, 0.0007864965123682843, 9.999999999998899e-05, 0.007557395293629865, 0.10703224617018059, 0.061649498861316876, 0.1420959097863248, 0.08005972791418703, 0.0918272659287026, 0.024750900275151033, 0.10501208945869589, 0.10735610087998337, 0.09044559238750605, 0.1406745751287135, 0.08862377123537957, 0.10270808160353895, 0.12098117945301601, 0.13516497240931535, 0.11711195916372397, 0.12382687680529547, 0.10975825235388037, 0.13738638248583435, 0.16542125761786997, 0.10544527066273424, 0.16402153514579387, 0.15064950229672813, 0.09209163585010449, 0.09182386314998825, 0.2109219930720726, 0.16310918709462585, 0.13651340435517156, 0.4482491276312838, 0.43784924650085844, 0.4139724372279082, 0.4016883636310298, 0.41479822341571393, 0.4168890675686161, 0.4625397541403756, 0.393381376173387, 0.4033457759165878, 0.14614747095910607, 0.11526511500510728, 0.11205025945147173, 0.11572749682081918, 0.09785623772547647, 0.11827584177738026, 0.11872681517384875, 0.15382312342300353, 0.0913276968843606, 0.20519327696899015, 0.16305798500860058, 0.24499788740871375, 0.2227265005686797, 0.29886280357002093, 0.17723906578301507, 0.24421534053522764, 0.2075123173325728, 0.17866631703475522, 0.3141410455361139, 0.276397799413987, 0.33584432969954814, 0.2462531620139996, 0.2450361922901363, 0.27516152354564605, 0.262944306545273, 0.3518074456901632, 0.2326663395823998, 0.2038961052504643, 0.25620379840872753, 0.25505630621866116, 0.2129380407617123, 0.23714489476834966, 0.25358790511192, 0.2140140760689484, 0.257434858927012, 0.17526290930512, 0.2236708521597882, 0.22480736103157395, 0.21243297549786044, 0.2193415644088289, 0.24374249903713707, 0.22676647399940952, 0.2368395691440628, 0.3716768105059457, 0.24896301044216584, 0.18058563367478841, 0.1909871494611759, 0.23773103016006902, 0.18241890336933975, 0.191143098678479, 0.1834535595168325, 0.18145902117960822, 0.17857208317643503, 0.17623256864248982, 0.17840030014594455, 0.3549557744882904, 0.18610055248864021, 0.18188460828345088, 0.22555780374976298, 0.19878800837974053, 0.2781874640184624, 0.18256476195856874, 0.8162437380127321, 0.6261720903604124, 0.20996759533174858, 0.197739935628526, 0.5454768428718169, 0.41025740533579946, 0.48699991968573364, 0.1662325823310573, 0.4779716214909696, 0.3271890117783587, 0.18552838872007726, 0.193188237156509, 0.19473012034523385, 0.20281828072490138, 0.19812757050763197, 0.1975547805311052, 0.1847388514389836, 0.19385623320057943, 0.17972275188634979, 0.08413751166296879, 0.08351736609820948, 0.08904689016467981, 0.09389751127144386, 0.08470764237402306, 0.0941957856441129, 0.07924743964951486, 0.09049496387224387, 0.09141861511629035]}, "mutation_prompt": null}
{"id": "68efaf1c-fff5-4a93-9698-e4ec6698ebe7", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.differential_evolution_rate = 0.1  # Novel differential evolution mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def differential_evolution(self, position):\n        mutant_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + mutant_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Differential evolution for enhanced global search\n                if np.random.rand() < self.differential_evolution_rate * (1 - evaluations / self.budget):\n                    mutant_position = self.differential_evolution(self.particles[i])\n                    mutant_fitness = func(mutant_position)\n                    evaluations += 1\n                    if mutant_fitness < fitness:\n                        self.particles[i] = mutant_position\n                        self.best_fitness[i] = mutant_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutant_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and \"Differential Evolution\" for enhanced global search.", "configspace": "", "generation": 180, "fitness": 0.2314174742236298, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6125824774325759, 0.5990155800405379, 0.5942703456911014, 0.6042542693238095, 0.5845178281213235, 0.660259563492832, 0.5961206249938704, 0.6350209086322897, 0.6197322266245386, 0.018541349854917955, 0.04378846500325251, 0.0020853975839251193, 0.006168904117033747, 0.02417029594857889, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13199821747675655, 0.09900934967579345, 0.11803608686199918, 0.08783804207449064, 0.10168677924281788, 0.11595617690735593, 0.10509759555579856, 0.1029785864900501, 0.15497964047657153, 0.06278616535787407, 0.11105848330980428, 0.10084139353626365, 0.0913014341052738, 0.07873546443706769, 0.09013001535685294, 0.12552845708078653, 0.09730089216819637, 0.0932067017807976, 0.8843738784953601, 0.9335834102564146, 0.8664238812462577, 0.7937522397484056, 0.8671174025940622, 0.8558136517005249, 0.8955552216846007, 0.9098469269921373, 0.8523981164385521, 0.3079991116055525, 0.2631934762992757, 0.25167634607010736, 0.30124540164435576, 0.28639317707816137, 0.2313402812958376, 0.27042593197048614, 0.2615155827728288, 0.28984463410417916, 0.3583296926177505, 0.7602457508424253, 0.22640180804819066, 0.27453532624516797, 0.27105657870806643, 0.27413904415609824, 0.2605555983002378, 0.21697118583521324, 0.4818256846712001, 0.11926337688901245, 0.27905427916660497, 0.11775715826819233, 0.22967702536172352, 0.15708305388428268, 0.15204747196790136, 0.15287697557716806, 0.12650788010390712, 0.1547157512178703, 0.18472576348201308, 0.17341924844343848, 0.15548814161062963, 0.17089925835825126, 0.15211395089352575, 0.12572301172507794, 0.27045305896133887, 0.16966339313195822, 0.17357620918335848, 0.048665779621226646, 9.999999999998899e-05, 0.0021655519550116686, 0.042532246079000524, 0.015408654534225352, 9.999999999998899e-05, 0.008220102456576228, 9.999999999998899e-05, 9.999999999998899e-05, 0.048189101895538045, 0.05594118854952923, 0.09755257859894462, 0.08417254344474445, 0.06733915983072147, 0.045179553528066796, 0.0735118300040043, 0.06593095137731197, 0.10443059854760228, 0.08722585771817992, 0.1015455888275354, 0.07427654525657323, 0.08507846989813805, 0.10901759834249092, 0.08314423786413738, 0.11036198506265338, 0.0685039492732672, 0.07871633971628211, 0.2068501986374227, 0.16334892371607823, 0.15629621576572028, 0.13401907872053398, 0.18059939447311557, 0.12788266261626413, 0.13233880736069292, 0.16608433837742764, 0.09598285244605853, 0.44566194122134717, 0.44440352122268223, 0.4335913180587053, 0.405160425147551, 0.4258142977540973, 0.4013501656077444, 0.48035330031248913, 0.42753856509563926, 0.4442076755129869, 0.10121843363611382, 0.1163251591225477, 0.11572423531975329, 0.12674955157186285, 0.11615645156297527, 0.10001066690757376, 0.08372151461815136, 0.09652267853144314, 0.07370329924328722, 0.2606266435397444, 0.2254516837884798, 0.16416507629755783, 0.24219257462756838, 0.27703067670812, 0.18300450948762637, 0.22022557672373722, 0.16829875151728102, 0.277848125938005, 0.34444759983158924, 0.3020685232462139, 0.32258419607281497, 0.31727328539910227, 0.3114816005727662, 0.3133535961825059, 0.24214087179905097, 0.27433997287635925, 0.30249023751315696, 0.23904272095365098, 0.2217849211005879, 0.27353209713440507, 0.2300291218771976, 0.19881501344359132, 0.24464445249590594, 0.22146871154784753, 0.20849255849958304, 0.2035474317770979, 0.2725793464629169, 0.22012641156838075, 0.20354492953783243, 0.22990914199974255, 0.2135732323171614, 0.20686745399332052, 0.21818312720016197, 0.21038130181636883, 0.20454765678767095, 0.20222697370259346, 0.19124931485257635, 0.2200975721529178, 0.1834431177780782, 0.1910944876266879, 0.1924952879337739, 0.1889929925616648, 0.19233977006959402, 0.18507418841042178, 0.12683334175673322, 0.1855362635278458, 0.18719912533444882, 0.5495707390038582, 0.19883955915694618, 0.19755357946233576, 0.1466076814029761, 0.1543066865148749, 0.8049610644772345, 0.45319136999156184, 0.17323669857377044, 0.36881924417554457, 0.41574249575169975, 0.20653066651305008, 0.16552881623306637, 0.16740014350115473, 0.2945631388201989, 0.3505670571589642, 0.18449150542714532, 0.1943450009034975, 0.21361266158159897, 0.1883760902979409, 0.18858148123118057, 0.18753466135465702, 0.19209844016836242, 0.19047977144430783, 0.1998347219788713, 0.09004092735852376, 0.09422909141670988, 0.10040142931692186, 0.1043106519114072, 0.08440876299657574, 0.09067917229532962, 0.10935626279767552, 0.08170647602135572, 0.08746466137742825]}, "mutation_prompt": null}
{"id": "73f5d1d4-1a98-4d05-a41c-7952681cd765", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.memory_based_rate = 0.05  # Novel memory-based position update\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def memory_based_position_update(self, position):\n        memory_position = np.random.choice(self.archive)[0]\n        return position + np.random.uniform(-1, 1, size=self.dim) * (memory_position - position)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Memory-based position update\n                if np.random.rand() < self.memory_based_rate * (1 - evaluations / self.budget):\n                    memory_position = self.memory_based_position_update(self.particles[i])\n                    memory_fitness = func(memory_position)\n                    evaluations += 1\n                    if memory_fitness < fitness:\n                        self.particles[i] = memory_position\n                        self.best_fitness[i] = memory_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], memory_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and \"Memory-Based\" position update.", "configspace": "", "generation": 181, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (10, 2) + inhomogeneous part.').", "error": "ValueError('setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (10, 2) + inhomogeneous part.')", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {}, "mutation_prompt": null}
{"id": "f01ee29e-28ee-4354-8128-bd5e8dbf7e2a", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective approach\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def pareto_dominance(self, position1, fitness1, position2, fitness2):\n        if fitness1 < fitness2:\n            return True\n        elif fitness1 > fitness2:\n            return False\n        else:\n            return np.random.rand() < 0.5\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if self.pareto_dominance(self.particles[i], fitness, self.global_best_position, self.global_best_fitness):\n                        self.global_best_position = np.copy(self.particles[i])\n                        self.global_best_fitness = fitness\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-objective approach\n                if np.random.rand() < self.multi_objective_rate * (1 - evaluations / self.budget):\n                    multi_objective_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n                    multi_objective_fitness = func(multi_objective_position)\n                    evaluations += 1\n                    if self.pareto_dominance(multi_objective_position, multi_objective_fitness, self.particles[i], fitness):\n                        self.particles[i] = multi_objective_position\n                        self.best_fitness[i] = multi_objective_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], multi_objective_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Multi-Objective\" approach with Pareto dominance.", "configspace": "", "generation": 182, "fitness": 0.22894642400755916, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.5692451898440137, 0.6125760562239237, 0.653898701760037, 0.6720928172138789, 0.6512794391174298, 0.5856109713393189, 0.6040928791757578, 0.5695548766510616, 0.6364389148702201, 0.0025867148694500575, 0.07748404713567347, 0.028769064471788952, 0.0004276673347403115, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.041002955442398736, 9.999999999998899e-05, 0.16826303358225447, 0.12631944380837135, 0.12036869360768665, 0.10972976222707698, 0.11621011693049133, 0.14222335447655754, 0.12884755255139135, 0.10172390403993592, 0.1353634973467429, 0.09031005243075363, 0.09279846368901379, 0.07558768865962173, 0.08948205893744254, 0.10615514971573081, 0.08636311928112483, 0.10571975686386925, 0.07737971903689189, 0.10020159111625038, 0.8299747161484464, 0.9145917130810607, 0.8678002410916764, 0.8268354831011496, 0.8011954048107734, 0.751245534749172, 0.8935199761815363, 0.8459410777808531, 0.8723089916777774, 0.25400087128081805, 0.24138307058076292, 0.27094464121857376, 0.23467924557445674, 0.27093527129874106, 0.2442253325682776, 0.2468913757303124, 0.24740511222246275, 0.2624786994176417, 0.2539787476672002, 0.3703904600807829, 0.2409492058904832, 0.27354919944559375, 0.5395328722168227, 0.254146123232008, 0.21336293818380714, 0.2361718558327509, 0.26875453378050984, 0.1068791948266018, 0.11883368848213127, 0.12273449457355567, 0.13421636999875863, 0.2028163651179078, 0.12395919185355309, 0.151755296202711, 0.21715942308241598, 0.12812005583451025, 0.15980071872080714, 0.18242903395772103, 0.15503996471445058, 0.2165773108796919, 0.15163017103535348, 0.15164832374182202, 0.19521718924439635, 0.16232654251175882, 0.12322861679093844, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02917144972890451, 0.004039563350213715, 9.999999999998899e-05, 0.0012506653676309654, 9.999999999998899e-05, 9.999999999998899e-05, 0.13265360682427596, 0.034152420913474035, 0.15402637537943886, 0.07418945784632724, 0.04646405233399964, 0.07288292828599718, 0.07436591197943254, 0.09261702224731017, 0.05948615517477396, 0.06889502214047172, 0.10859509813958124, 0.10307167639167547, 0.10511838816927555, 0.06495567644295952, 0.089618049714558, 0.06946094795321933, 0.09397008554379593, 0.05365554005952633, 0.18278706397581346, 0.17720015840260073, 0.18276060031932484, 0.09313785601461821, 0.10930253126203937, 0.1102964455308062, 0.1317402581069197, 0.15414127831306323, 0.16084648640204213, 0.426616511488327, 0.4380375432981294, 0.4427395586496897, 0.40627997420579964, 0.41242244609062995, 0.4218818785132762, 0.4603791763062053, 0.41174019113023985, 0.4929788811202611, 0.09800715220492218, 0.09795793347520687, 0.12502523039103997, 0.14735416098604404, 0.11807612920220745, 0.09233293108600249, 0.10881680722550469, 0.14920092020628162, 0.12050088478147158, 0.25996221342609105, 0.1762419622260455, 0.14539383919860482, 0.1721233577488459, 0.19874398426188944, 0.19078930866987132, 0.21871234028894337, 0.27545974094729164, 0.19305453642952553, 0.26732994316155845, 0.30029836130504395, 0.3823143541417716, 0.2945329858314032, 0.29379892417736075, 0.2950125889204731, 0.2546343575781066, 0.312714843390557, 0.2727756067507703, 0.18682367618001405, 0.18972008535284146, 0.30671615336219515, 0.26806141928828786, 0.2648167752829774, 0.24954599916925357, 0.1750843485078729, 0.3037827713786223, 0.2283744427307033, 0.21315292995180823, 0.23041294116838262, 0.2506472259962359, 0.20893357032589133, 0.21928398672073446, 0.23654644833155614, 0.247471221275116, 0.22014649280630771, 0.21484167783940866, 0.1967194358206199, 0.17653273375174994, 0.18876670471652768, 0.17928249218675596, 0.1960923645375543, 0.17256103033419345, 0.18537222972578749, 0.19769180053564706, 0.17227966258768845, 0.23678167108196613, 0.18625060384486647, 0.5855696749135022, 0.5844898653743802, 0.1983474776729537, 0.1951386845759544, 0.14452117903318118, 0.30407133413063814, 0.6195914431104135, 0.40196104720934855, 0.20857638396042677, 0.41696881035213684, 0.39763826065295993, 0.4069924708589169, 0.16903132722401693, 0.16716670828751645, 0.163285177344196, 0.333427397594257, 0.1828537883098883, 0.18321205426245735, 0.1932332537853183, 0.1701033157608719, 0.18888713620119935, 0.20850409323997943, 0.19240839230891527, 0.19684951956893992, 0.1780457483231247, 0.08826158207268908, 0.08790347706313517, 0.10688238809811479, 0.09352273160885616, 0.09668813335125759, 0.095505774583033, 0.09910614741129087, 0.08650880949114492, 0.08471487181229476]}, "mutation_prompt": null}
{"id": "e5e2ea60-4f9b-44fa-b12b-074245a8b9f4", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.adaptive_gaussian_mutation_rate = 0.05  # New adaptive Gaussian mutation rate\n        self.adaptive_cauchy_perturbation_rate = 0.05  # New adaptive Cauchy perturbation rate\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Adaptive Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_position = mutated_position + np.random.normal(loc=0, scale=self.adaptive_gaussian_mutation_rate * (1 - evaluations / self.budget), size=self.dim)\n                    mutated_position = mutated_position + np.random.standard_cauchy(size=self.dim) * self.adaptive_cauchy_perturbation_rate * (1 - evaluations / self.budget)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel metaheuristic algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive Gaussian mutation and Cauchy perturbation rates.", "configspace": "", "generation": 183, "fitness": 0.23103070561239647, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.572643594996284, 0.7572897609434892, 0.6624090959533524, 0.6683974198836049, 0.5789031490918772, 0.6805043482846381, 0.5808979390430284, 0.5406798185023267, 0.536103532147175, 9.999999999998899e-05, 0.00014403804538598575, 0.0330772537360674, 9.999999999998899e-05, 0.00299211605066263, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00024390673217700165, 0.14329077483793795, 0.10329874168131359, 0.10877593563303511, 0.10781086355983605, 0.07532127841355574, 0.08274890962395365, 0.1068709607642584, 0.10980615346487499, 0.1185408560417831, 0.1064193887346071, 0.09028470917698272, 0.08282040654346856, 0.1014160711952169, 0.07890695141481574, 0.08278128410070329, 0.1270482252277203, 0.07337062513718007, 0.0925710475087933, 0.8746011015322744, 0.918823860096756, 0.8304008560529831, 0.7978162896294034, 0.8124223881064772, 0.8247856447880891, 0.9098502591441641, 0.933932153985054, 0.8841067199842282, 0.2160796492206749, 0.23710065940107994, 0.25174594811160456, 0.26880350702723743, 0.2662609303247834, 0.22679031794182014, 0.23970522273632255, 0.2192314526767707, 0.2618132472873209, 0.740114505355737, 0.2280779028675678, 0.2127331752737427, 0.27455860387797415, 0.27065119050722364, 0.1906166079865036, 0.5498181029319356, 0.19685105402174696, 0.240672463200021, 0.12223330463668769, 0.15300893562761742, 0.22080754439003247, 0.1125729878950762, 0.2566196088201962, 0.23708838726008985, 0.17264938642480265, 0.12134639982382855, 0.17765132181356325, 0.20421804146137157, 0.15148069562999322, 0.16065544586008074, 0.18849587764415932, 0.1663939482733635, 0.2906391789142606, 0.22749102583033298, 0.23089236756795772, 0.16547866459156468, 0.05917526989630639, 9.999999999998899e-05, 0.017809417131812944, 0.008153858533204716, 0.06192264568323591, 0.010088388194455233, 9.999999999998899e-05, 9.999999999998899e-05, 0.0013378586094914269, 0.08590955765965314, 0.054390478607040826, 0.12907620802681607, 0.08372455841846116, 0.05950294849488402, 0.04658614991238297, 0.20049822294167918, 0.08550587618840999, 0.1648052858640756, 0.10695785679960312, 0.08839486600286417, 0.14866910363756614, 0.08413226879381475, 0.07954758759816283, 0.045116504927803724, 0.08902112436149878, 0.09925064468910583, 0.0758836794846871, 0.2333485956419269, 0.10340909123501785, 0.16610371277563385, 0.15426152433829599, 0.13409042234544666, 0.1175473857629804, 0.13925950573206158, 0.0970418530864936, 0.08183884799214336, 0.412986296930264, 0.42085551422247025, 0.39627922509964697, 0.41598562167103814, 0.4048092915143712, 0.42248692838149504, 0.42876023845889, 0.4640452454105447, 0.417943550141727, 0.11023648186621426, 0.10699535042891184, 0.08403085025638424, 0.10579805222378547, 0.09377825196192824, 0.12452062974342148, 0.11729693044099532, 0.12902083203178394, 0.08274859756288555, 0.2271723040298368, 0.19487909863390973, 0.18964093775051172, 0.16711554636735548, 0.28946656223187994, 0.20136928628434836, 0.31224342491763213, 0.17680431325514656, 0.20589055973395798, 0.2768568156780279, 0.3743801448096933, 0.3360376865189192, 0.27817367878734345, 0.36583729837142465, 0.27137206964309646, 0.31078200117044696, 0.3211334412828394, 0.26915752607595056, 0.2782666071682174, 0.24921149377787521, 0.2081600669688507, 0.20318138456706403, 0.29474642784311833, 0.23693409086284534, 0.20705064001668272, 0.23475846413111368, 0.21127996779708325, 0.2176403158312471, 0.24042273189691854, 0.21853418898158483, 0.23469499678254424, 0.24248908444966, 0.2307088728959551, 0.2089655342873672, 0.21758552615797988, 0.21166088772416647, 0.178611233295071, 0.16891181877535832, 0.16930482153263016, 0.19547875077865307, 0.18400960530213983, 0.1786935442256885, 0.18694748121278248, 0.2000953393750493, 0.17900053273797134, 0.18411726956422858, 0.1854855724118496, 0.18665566532793976, 0.5599873652815452, 0.19953597598591521, 0.19818303996451636, 0.14128586735693538, 0.16659780482076458, 0.7670401799802392, 0.44081176013629986, 0.21076225271646432, 0.3928972822659177, 0.3956563774403917, 0.3291896762626677, 0.1673597285417382, 0.2073669447910702, 0.2943622130765512, 0.3319657964580319, 0.17959180777873285, 0.17676734665945637, 0.1766839457209639, 0.18559256196002516, 0.1940207424751793, 0.1860552926297251, 0.2042379619052319, 0.18695143522892754, 0.18850619116496603, 0.09533030313175661, 0.07283899756000067, 0.08614370392422277, 0.09437215037723434, 0.09194139277241176, 0.09169745021470477, 0.11110023182832351, 0.08468079484183522, 0.08500694408458187]}, "mutation_prompt": null}
{"id": "7c809805-a794-4376-a64b-1f98b37b43bc", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_objective_strategy(self, position):\n        # Simple multi-objective strategy: minimize the sum of squares of the coordinates\n        return np.sum(position**2)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Multi-objective strategy\n                if np.random.rand() < self.multi_objective_rate * (1 - evaluations / self.budget):\n                    multi_objective_position = self.particles[i]\n                    multi_objective_fitness = self.multi_objective_strategy(multi_objective_position)\n                    if multi_objective_fitness < fitness:\n                        self.particles[i] = multi_objective_position\n                        self.best_fitness[i] = multi_objective_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], multi_objective_fitness)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with a new \"Multi-Objective\" strategy.", "configspace": "", "generation": 184, "fitness": 0.22437279077812586, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.19.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6660194106784172, 0.5764764236343931, 0.6240462753617233, 0.5688683600283422, 0.6292899567279981, 0.6054516711914586, 0.6050517272207356, 0.6452040838344545, 0.6063842291178817, 0.0447714774628275, 0.03691231362739922, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1350262708809682, 0.1007792607332405, 0.0994128917297954, 0.10077699545111352, 0.1067631983492523, 0.10897310764682644, 0.09333213824076791, 0.10955330571420285, 0.11446425662672022, 0.0709123039326307, 0.09601382390284785, 0.07614105191119347, 0.0881009263429332, 0.08907314299346658, 0.075437804374481, 0.0925264897559599, 0.07413255193428614, 0.0665706209879432, 0.8725751771274142, 0.9338868880108655, 0.8668952149524788, 0.6684043281306964, 0.8194011963601244, 0.83754240158352, 0.8958169164385182, 0.8865315902336706, 0.899706994638123, 0.25283326630799907, 0.23945929260338739, 0.22877097869259544, 0.22000461397967652, 0.23923742617066168, 0.25199772155025235, 0.27879788255490956, 0.25319356597698084, 0.2564109063237351, 0.22778672893786311, 0.22645148408283178, 0.26931986050349577, 0.3354645966072076, 0.2619793508485969, 0.18374179813408398, 0.33611428832922474, 0.19931912005031083, 0.23518419787177214, 0.12329249356909566, 0.13079492536956727, 0.08846898740951925, 0.09395029559671475, 0.30455415635795324, 0.15814073349032065, 0.12574239517855879, 0.2520517271786945, 0.12708647107161763, 0.16942422866010365, 0.16562735239529736, 0.16612710317781454, 0.1874305729426078, 0.18823103921820883, 0.19803319653752582, 0.177628520599878, 0.14694532190913523, 0.18668953264704036, 0.008645639753673828, 9.999999999998899e-05, 0.0013257095280263531, 0.13012551905267478, 9.999999999998899e-05, 9.999999999998899e-05, 0.014051461655879227, 9.999999999998899e-05, 0.042938477368812844, 0.14537064096979213, 0.05462103216759373, 0.10023300134877045, 0.07756158635616828, 0.039076828646681716, 0.029712797763357, 0.06148061054320275, 0.08586036263386998, 0.09023895064964649, 0.14800028300662993, 0.07571218266730517, 0.0570834942972781, 0.08024508374950312, 0.08333863769719996, 0.07198699347381621, 0.16545389761407536, 0.08578563167838893, 0.06977742080124949, 0.1553334155453041, 0.1542984804004378, 0.10348364399161691, 0.12875116782908613, 0.15370372002188182, 0.14523168553930632, 0.137872012468225, 0.11083914127177741, 0.13332702975170418, 0.41577371602671054, 0.4560885170021438, 0.42032588224079104, 0.44206086253593035, 0.42030470081058946, 0.4456215139723768, 0.40129163370059007, 0.4555517235842135, 0.4031604157859866, 0.12358132328555971, 0.10600222434932527, 0.08261440229556027, 0.10933241392806159, 0.133892889289975, 0.10529500728656516, 0.1466113126805738, 0.13339249154529131, 0.09020273838421056, 0.17847878354663194, 0.1892435924108219, 0.16480708741126437, 0.17494601914934882, 0.282928517835372, 0.15799593811458268, 0.21332001084664276, 0.16336912413354843, 0.21314640760246095, 0.3049568806642081, 0.30640642071914126, 0.2968951905742533, 0.34228170821268755, 0.3178017544400217, 0.3310110536075864, 0.25583445016496364, 0.31824808305807395, 0.2529415379508595, 0.2251792116318, 0.2672528855130738, 0.25261600372812454, 0.21752284212696538, 0.17945329918342812, 0.23259478903175723, 0.18352795979020675, 0.24852646010391277, 0.23795224510392943, 0.20570125467563471, 0.25871322527048657, 0.2208389631871024, 0.22138948269190173, 0.21283763853180993, 0.2125896023544016, 0.23270772990193223, 0.21785634532008336, 0.21371870395236447, 0.1661328774941343, 0.17023143542759356, 0.17758931038970038, 0.19748183324469393, 0.18736687130974594, 0.17360604063679852, 0.18403229182912395, 0.16974777244073014, 0.18692466379020767, 0.18635423352145863, 0.1776511285620027, 0.5242044643729606, 0.6802538647938379, 0.1970243038254873, 0.19424101767455237, 0.1416212153767823, 0.14774629016361995, 0.6691164347755669, 0.4621488414760706, 0.21042891130912655, 0.4113206736059726, 0.3922392647519546, 0.1654339156278649, 0.165423545768013, 0.16644599726583253, 0.30916807412729697, 0.31133969401526196, 0.1916044151768147, 0.19183272369257043, 0.18341711935715754, 0.19973924307450175, 0.20120698055992992, 0.1886838437627102, 0.2003752249120586, 0.1862292794948902, 0.19874854573569767, 0.088960693949656, 0.07973292465008086, 0.07445372848501453, 0.07939871763297002, 0.09347871717937084, 0.09542740696990426, 0.09066409620370519, 0.07967312618514755, 0.10284663128293414]}, "mutation_prompt": null}
{"id": "8c9701c6-a995-4975-8e7c-63aaea42fcf0", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.adaptive_levy_flight_rate = 0.1  # New adaptive levy flight rate\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def adaptive_levy_flight(self, position):\n        levy_flight_vector = self.levy_flight(self.dim)\n        return position + levy_flight_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Adaptive levy flight for enhanced global search\n                if np.random.rand() < self.adaptive_levy_flight_rate * (1 - evaluations / self.budget):\n                    self.particles[i] = self.adaptive_levy_flight(self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and \"Adaptive Levy Flight\" for enhanced global search.", "configspace": "", "generation": 185, "fitness": 0.23108799286609683, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6366903829797279, 0.6085983803384095, 0.5908352696361194, 0.6663867579583254, 0.6401880949581694, 0.6546496607238784, 0.6079305331379368, 0.6541684693015486, 0.5908483909718514, 0.013718187947754257, 0.047547900534650966, 0.014915191680435202, 0.006401503547669218, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0333642607971919, 9.999999999998899e-05, 0.1090166976610848, 0.13159826114363327, 0.13529716227827815, 0.10816676092795863, 0.09524676314502467, 0.11004776180164211, 0.11634750921816561, 0.1343907383371623, 0.11217989065357559, 0.09063907167044893, 0.10328330405648989, 0.06641434476059926, 0.10926015472982342, 0.06580970145694187, 0.08525524999465328, 0.10617580197181542, 0.06948496227712408, 0.07480764871508105, 0.824240852259301, 0.9084368327195183, 0.8695625527857923, 0.788903955606097, 0.8488170302321836, 0.8266395628713408, 0.8795313794159242, 0.9035632014684081, 0.9078901343092106, 0.2650493745218271, 0.23614161140162215, 0.2163486877761731, 0.23625354871955273, 0.23943227856334626, 0.2626053404120612, 0.2272693292710264, 0.24742216740267398, 0.2780440154864602, 0.22687222166087617, 0.2704534897752068, 0.29134659316809763, 0.2722707842443248, 0.3099554934614991, 0.207319857838698, 0.22380785485399723, 0.1902252999623969, 0.26068690477237766, 0.1837990819321903, 0.12493272192617533, 0.12001837080316813, 0.1646672501209987, 0.12411827695238076, 0.12652440920955488, 0.15712754454818845, 0.12106381036762337, 0.128770495508012, 0.16859615938027694, 0.1778548944625976, 0.23048355403109377, 0.15154308083247103, 0.14807779139392185, 0.14062735109639213, 0.14407467576341337, 0.1574032063323677, 0.21784975717345267, 9.999999999998899e-05, 9.999999999998899e-05, 0.14084377625246436, 0.09858984450416886, 0.06919178840651563, 0.013070046402014812, 9.999999999998899e-05, 9.999999999998899e-05, 0.005100520814461551, 0.1545198924393808, 0.046901901345320796, 0.15476505413228347, 0.05579547192582268, 0.06514196080211809, 0.028443830219799793, 0.17249694677299687, 0.051802690186858125, 0.03186027176636419, 0.07255789602932095, 0.11332456878636676, 0.059087217672960435, 0.07093571126567533, 0.10027114671633686, 0.07107569440157879, 0.11231041436919709, 0.12018884896974324, 0.10714222538228191, 0.20487983165760237, 0.20933005682674644, 0.08885099970024057, 0.19532843433518154, 0.14725390984762476, 0.20524036620246866, 0.10998240356162947, 0.08722490334181765, 0.14455512422297268, 0.5405698206558069, 0.4351445081197638, 0.4152321988684532, 0.41375122684668286, 0.4828072169248321, 0.40002973290768695, 0.4457074492254196, 0.44921680128831387, 0.4562928236049886, 0.10406913657586248, 0.08761134858638375, 0.09632540384203603, 0.10582344215978523, 0.12815440870411765, 0.12306704587894857, 0.09092480584418716, 0.09972136342636573, 0.10470746290444954, 0.16267687910139195, 0.18495067810103005, 0.15615715261201835, 0.21510217424209255, 0.27845655575061223, 0.27325304451809274, 0.18410242491845952, 0.18534702216150367, 0.2706501202871938, 0.3579995650291965, 0.3259681610920483, 0.3531153753348796, 0.286261299974335, 0.36248437450455917, 0.2578997975993105, 0.28359676769359843, 0.2830333500599912, 0.2520678137272808, 0.27786496998300303, 0.2724209252924197, 0.24005467466479624, 0.2580781059487933, 0.19445883784509865, 0.2407352637369815, 0.19717428134198556, 0.22611733710928072, 0.1518170508629264, 0.2142511911554943, 0.22070634195181105, 0.23156506784066788, 0.23437260043827324, 0.2341071178271753, 0.23372599431905905, 0.20488426793870818, 0.2408497108450871, 0.200526700029259, 0.1746798198514793, 0.17593877064476604, 0.19437958496182361, 0.1928709600681081, 0.20443787615105735, 0.1747549472899529, 0.16829865386278475, 0.1824420520677511, 0.18349279901493265, 0.18535681813139737, 0.17803155003483695, 0.18586843095267336, 0.7229395135766807, 0.19944865010462465, 0.19602048423354768, 0.6318524475860792, 0.18183409910929693, 0.7623436769836954, 0.4254190898967024, 0.16784311077236946, 0.5612386227468524, 0.4767140881590134, 0.3508930028952909, 0.1661154505890854, 0.1687031032323837, 0.16455782257301033, 0.3886715783204847, 0.18624966098889817, 0.18741032913448052, 0.17797795779335557, 0.20412037293240937, 0.1931981871582894, 0.18118454524475536, 0.19302572120867978, 0.19045345324679952, 0.19998186792382777, 0.08355589987235323, 0.08968915932176791, 0.08238531787695824, 0.08958223315511205, 0.10183770120253344, 0.09011843976360234, 0.08617652086470284, 0.08542163014376603, 0.09634995986368344]}, "mutation_prompt": null}
{"id": "01b9daa5-a80e-484e-8149-909cc7a82d73", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.adaptive_quantum_tunneling_rate = 0.05  # New adaptive quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def adaptive_quantum_tunneling(self, position, evaluations):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim) * (1 - evaluations / self.budget)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Adaptive quantum tunneling for enhanced local search\n                if np.random.rand() < self.adaptive_quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    adaptive_tunneling_position = self.adaptive_quantum_tunneling(self.particles[i], evaluations)\n                    adaptive_tunneling_fitness = func(adaptive_tunneling_position)\n                    evaluations += 1\n                    if adaptive_tunneling_fitness < fitness:\n                        self.particles[i] = adaptive_tunneling_position\n                        self.best_fitness[i] = adaptive_tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], adaptive_tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with a new \"Hybrid-Repulsion\" mechanism and a new \"Swarm Restructuring\" mechanism, and a new \"Adaptive Quantum Tunneling\" mechanism.", "configspace": "", "generation": 186, "fitness": 0.227412683423537, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6441822177829895, 0.627567287269877, 0.630295044764924, 0.5840879028018022, 0.621221121828446, 0.5899256155147732, 0.5842242683723631, 0.5822359518517022, 0.650771119072177, 0.14025323565619097, 0.04954770825094801, 0.007531659917830114, 9.999999999998899e-05, 0.028335454820725636, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10961118402595149, 0.123000963659463, 0.1018462256611481, 0.09913940870605131, 0.11421437917191546, 0.07969945204997841, 0.08549396154122257, 0.11716288322584367, 0.12540607615823407, 0.09786133054706425, 0.09902788343738189, 0.10337811365906169, 0.1344135547966263, 0.08412231030879935, 0.07866327063384793, 0.10237550144141438, 0.08911109689495078, 0.09064184963548427, 0.8882403849142307, 0.9300630322647194, 0.8805457106261019, 0.7913171165250592, 0.9278598699152419, 0.8132083443628895, 0.8580343952401684, 0.8907900466412814, 0.829427358711514, 0.27425010532175575, 0.25008747914904883, 0.255028182634791, 0.25303759046302043, 0.27094190530335605, 0.29972080981109517, 0.28372628080718076, 0.21991307792476944, 0.21920735319777263, 0.663987164309757, 0.2265373285422414, 0.3645187649751169, 0.27131983548122685, 0.7780725684723926, 0.2086985561682202, 0.2710755088695431, 0.18822448975936035, 0.2852197796805884, 0.12093553701865589, 0.14277865830079373, 0.17544993293655808, 0.16588532750683938, 0.2630385337780857, 0.12387919353573884, 0.13589345352718607, 0.1953194876904245, 0.1368348997312232, 0.17040307978700586, 0.14271338966611435, 0.17198609628879769, 0.1437326625539841, 0.16326735790346647, 0.12847515071641424, 0.16189144490778218, 0.2156692178707178, 0.1710241554484735, 0.037804168724812515, 0.010950390539848698, 9.999999999998899e-05, 0.028154346708016642, 0.0502738320805427, 9.999999999998899e-05, 0.0029276546551545435, 9.999999999998899e-05, 0.04287730898690412, 0.10019201558108903, 0.051240498200606055, 0.0814236248848943, 0.06470196590708133, 0.07810684541001389, 0.014395227283148015, 0.1536921380131061, 0.14460846219523193, 0.06745072840364719, 0.07883932929568638, 0.10238265588594475, 0.08824493676751588, 0.08991461581294047, 0.09115530809843897, 0.04597694397087704, 0.10945802918621195, 0.06474657845856835, 0.0716792765562887, 0.1632191761823184, 0.21073251684492966, 0.12652624483188868, 0.09149429026622713, 0.23143615101923898, 0.09076271269910141, 0.17969345516698287, 0.18809767034040648, 0.11241805487984491, 0.43029995543994215, 0.41529220708957815, 0.4276815924111069, 0.4782742932870061, 0.44726760869740534, 0.3984748675094324, 0.45963450243161763, 0.46210911068316685, 0.4167582256887581, 0.10024288964409955, 0.12813448790399384, 0.1019810699422471, 0.1055568112349119, 0.10111362007795344, 0.1512765341671506, 0.0872207533552306, 0.09603556581288963, 0.07762498783233374, 0.17616763053454199, 0.21656067465588913, 0.17557723478317688, 0.18061775128825708, 0.2146185875756631, 0.24345357101554743, 0.1762002244465093, 0.1784593873566962, 0.27412328936714847, 0.2750712863263638, 0.31776411013180494, 0.28090583496443855, 0.269195071960176, 0.3361302220570146, 0.2701258495037362, 0.23089810240694097, 0.29858010234786647, 0.2378735211957087, 0.26494533969643885, 0.2223580844212133, 0.23634315558953922, 0.300651354349611, 0.26893268605731646, 0.2044918113587212, 0.1857534561720917, 0.2521378615765202, 0.19509575233372844, 0.220518948205363, 0.21454562409182454, 0.21168117140987552, 0.2720522082806558, 0.20114538735901266, 0.21214740361750184, 0.24696291430575734, 0.23634448176974543, 0.2502967736357865, 0.1926829292224328, 0.1905892110662033, 0.196475072387291, 0.17882488364663474, 0.20748276267527477, 0.17888994027120186, 0.17388376588968601, 0.17296026355882965, 0.21703594847550844, 0.18637091121832539, 0.18622073337993006, 0.18665726563254725, 0.16344392436525446, 0.19836248732520367, 0.16774412093795454, 0.1671335991489037, 0.12947118198508056, 0.6929507506628534, 0.37934801687917175, 0.167841208987068, 0.12592560833380773, 0.3803071691725367, 0.2086947237664356, 0.16487835851124377, 0.1664480400897954, 0.2858727446390936, 0.5527112395149667, 0.18964915880235111, 0.2005884577298337, 0.1932792301869769, 0.19595280085221722, 0.17457664611147627, 0.19765934305993438, 0.1859868817070014, 0.1971895614480783, 0.18082416558501113, 0.07258288835917504, 0.09428184916247118, 0.07751673696741035, 0.08641361441908957, 0.09601378963608331, 0.10299176649892727, 0.08310578747417563, 0.0905162420842558, 0.0851420817618771]}, "mutation_prompt": null}
{"id": "3c1e99b2-c631-4003-a755-7ad5cc7ce74d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_explorer_rate = 0.1  # New multi-explorer strategy\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def multi_explorer(self, position):\n        explorer_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + explorer_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-explorer strategy\n                if np.random.rand() < self.multi_explorer_rate * (1 - evaluations / self.budget):\n                    explorer_position = self.multi_explorer(self.particles[i])\n                    explorer_fitness = func(explorer_position)\n                    evaluations += 1\n                    if explorer_fitness < fitness:\n                        self.particles[i] = explorer_position\n                        self.best_fitness[i] = explorer_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], explorer_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Multi-Explorer\" strategy for enhanced exploration.", "configspace": "", "generation": 187, "fitness": 0.2314174742236298, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6125824774325759, 0.5990155800405379, 0.5942703456911014, 0.6042542693238095, 0.5845178281213235, 0.660259563492832, 0.5961206249938704, 0.6350209086322897, 0.6197322266245386, 0.018541349854917955, 0.04378846500325251, 0.0020853975839251193, 0.006168904117033747, 0.02417029594857889, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13199821747675655, 0.09900934967579345, 0.11803608686199918, 0.08783804207449064, 0.10168677924281788, 0.11595617690735593, 0.10509759555579856, 0.1029785864900501, 0.15497964047657153, 0.06278616535787407, 0.11105848330980428, 0.10084139353626365, 0.0913014341052738, 0.07873546443706769, 0.09013001535685294, 0.12552845708078653, 0.09730089216819637, 0.0932067017807976, 0.8843738784953601, 0.9335834102564146, 0.8664238812462577, 0.7937522397484056, 0.8671174025940622, 0.8558136517005249, 0.8955552216846007, 0.9098469269921373, 0.8523981164385521, 0.3079991116055525, 0.2631934762992757, 0.25167634607010736, 0.30124540164435576, 0.28639317707816137, 0.2313402812958376, 0.27042593197048614, 0.2615155827728288, 0.28984463410417916, 0.3583296926177505, 0.7602457508424253, 0.22640180804819066, 0.27453532624516797, 0.27105657870806643, 0.27413904415609824, 0.2605555983002378, 0.21697118583521324, 0.4818256846712001, 0.11926337688901245, 0.27905427916660497, 0.11775715826819233, 0.22967702536172352, 0.15708305388428268, 0.15204747196790136, 0.15287697557716806, 0.12650788010390712, 0.1547157512178703, 0.18472576348201308, 0.17341924844343848, 0.15548814161062963, 0.17089925835825126, 0.15211395089352575, 0.12572301172507794, 0.27045305896133887, 0.16966339313195822, 0.17357620918335848, 0.048665779621226646, 9.999999999998899e-05, 0.0021655519550116686, 0.042532246079000524, 0.015408654534225352, 9.999999999998899e-05, 0.008220102456576228, 9.999999999998899e-05, 9.999999999998899e-05, 0.048189101895538045, 0.05594118854952923, 0.09755257859894462, 0.08417254344474445, 0.06733915983072147, 0.045179553528066796, 0.0735118300040043, 0.06593095137731197, 0.10443059854760228, 0.08722585771817992, 0.1015455888275354, 0.07427654525657323, 0.08507846989813805, 0.10901759834249092, 0.08314423786413738, 0.11036198506265338, 0.0685039492732672, 0.07871633971628211, 0.2068501986374227, 0.16334892371607823, 0.15629621576572028, 0.13401907872053398, 0.18059939447311557, 0.12788266261626413, 0.13233880736069292, 0.16608433837742764, 0.09598285244605853, 0.44566194122134717, 0.44440352122268223, 0.4335913180587053, 0.405160425147551, 0.4258142977540973, 0.4013501656077444, 0.48035330031248913, 0.42753856509563926, 0.4442076755129869, 0.10121843363611382, 0.1163251591225477, 0.11572423531975329, 0.12674955157186285, 0.11615645156297527, 0.10001066690757376, 0.08372151461815136, 0.09652267853144314, 0.07370329924328722, 0.2606266435397444, 0.2254516837884798, 0.16416507629755783, 0.24219257462756838, 0.27703067670812, 0.18300450948762637, 0.22022557672373722, 0.16829875151728102, 0.277848125938005, 0.34444759983158924, 0.3020685232462139, 0.32258419607281497, 0.31727328539910227, 0.3114816005727662, 0.3133535961825059, 0.24214087179905097, 0.27433997287635925, 0.30249023751315696, 0.23904272095365098, 0.2217849211005879, 0.27353209713440507, 0.2300291218771976, 0.19881501344359132, 0.24464445249590594, 0.22146871154784753, 0.20849255849958304, 0.2035474317770979, 0.2725793464629169, 0.22012641156838075, 0.20354492953783243, 0.22990914199974255, 0.2135732323171614, 0.20686745399332052, 0.21818312720016197, 0.21038130181636883, 0.20454765678767095, 0.20222697370259346, 0.19124931485257635, 0.2200975721529178, 0.1834431177780782, 0.1910944876266879, 0.1924952879337739, 0.1889929925616648, 0.19233977006959402, 0.18507418841042178, 0.12683334175673322, 0.1855362635278458, 0.18719912533444882, 0.5495707390038582, 0.19883955915694618, 0.19755357946233576, 0.1466076814029761, 0.1543066865148749, 0.8049610644772345, 0.45319136999156184, 0.17323669857377044, 0.36881924417554457, 0.41574249575169975, 0.20653066651305008, 0.16552881623306637, 0.16740014350115473, 0.2945631388201989, 0.3505670571589642, 0.18449150542714532, 0.1943450009034975, 0.21361266158159897, 0.1883760902979409, 0.18858148123118057, 0.18753466135465702, 0.19209844016836242, 0.19047977144430783, 0.1998347219788713, 0.09004092735852376, 0.09422909141670988, 0.10040142931692186, 0.1043106519114072, 0.08440876299657574, 0.09067917229532962, 0.10935626279767552, 0.08170647602135572, 0.08746466137742825]}, "mutation_prompt": null}
{"id": "a47b876d-59fa-4bc7-b5dd-cb0e16385d81", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_swarm_rate = 0.2  # New multi-swarm strategy\n        self.swarm_splitting_rate = 0.1  # New swarm-splitting mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def multi_swarm(self, particles):\n        swarm_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        swarm_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - swarm_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[swarm_clusters == i]\n            if len(cluster_particles) > 0:\n                swarm_centroids[i] = np.mean(cluster_particles, axis=0)\n        return swarm_centroids\n\n    def swarm_splitting(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-swarm strategy\n                if np.random.rand() < self.multi_swarm_rate * (1 - evaluations / self.budget):\n                    swarm_centroids = self.multi_swarm(self.particles)\n                    self.particles[i] = swarm_centroids[np.argmin(np.linalg.norm(self.particles[i] - swarm_centroids, axis=1))]\n                # Swarm-splitting mechanism\n                if np.random.rand() < self.swarm_splitting_rate * (1 - evaluations / self.budget):\n                    splitting_position = self.swarm_splitting(self.particles)\n                    splitting_fitness = func(splitting_position)\n                    evaluations += 1\n                    if splitting_fitness < fitness:\n                        self.particles[i] = splitting_position\n                        self.best_fitness[i] = splitting_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], splitting_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and \"Hybrid-Swarm\" mechanism with \"Multi-Swarm\" strategy and \"Swarm-Splitting\" mechanism.", "configspace": "", "generation": 188, "fitness": 0.22455074133105435, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6485686137370001, 0.554033611567444, 0.6160617489635518, 0.6790517572243585, 0.6392296427753446, 0.5650033915371664, 0.6322976651162238, 0.6139065125067771, 0.6558556152619184, 9.999999999998899e-05, 0.008025746910310771, 0.002859838938023662, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10446481798860185, 0.08950038976139063, 0.10222060771705033, 0.09912222998504128, 0.13079852730807306, 0.09215574444943886, 0.13842963791651564, 0.09178374750408769, 0.09826601127592272, 0.09108598568445814, 0.09465847072577449, 0.08672242892598658, 0.10591947028753834, 0.08748389289842251, 0.07723161271858081, 0.12409663493913303, 0.09008445159132261, 0.09848084865953566, 0.7748773487312339, 0.9178603393383241, 0.907521334593694, 0.7118186882387483, 0.8197181036307526, 0.8503103847454775, 0.887026837738045, 0.8882559746750869, 0.8830803372930569, 0.26859137241631015, 0.2605326636835593, 0.2233077648731805, 0.2288455865380472, 0.2781060175068575, 0.24611818719559808, 0.2454338772896768, 0.21754616271868354, 0.21832954521689862, 0.31489766402004493, 0.3624181873027026, 0.22288983102309057, 0.27103149425383466, 0.34455610355678423, 0.22414106387252908, 0.21266928326086387, 0.2029244776957494, 0.23473494556219698, 0.1269671706527301, 0.08584358405694315, 0.22446969625970892, 0.10021199866580577, 0.12940564162335744, 0.12720137161769052, 0.14927153320495112, 0.15734670065963452, 0.16487687994266853, 0.15395621169349905, 0.16186583171718627, 0.15914715502653287, 0.14287697434758462, 0.12859720760374949, 0.1253268527806789, 0.12762757734399532, 0.20508267492406396, 0.16635101201606828, 9.999999999998899e-05, 0.0009609438283186833, 0.002141448420889369, 0.018933833198249483, 9.999999999998899e-05, 9.999999999998899e-05, 0.002690293258825305, 9.999999999998899e-05, 0.022571045562936654, 0.09423141921251732, 0.04740538115887216, 0.1555441342726277, 0.07370661602286033, 0.08082140967197671, 0.04156920371670547, 0.06566166046810418, 0.06578022835309894, 0.07323301999825749, 0.11706731053626174, 0.07983832201141305, 0.0750038460466027, 0.08185948923402464, 0.10695399756512303, 0.06724159060782875, 0.10942474898768573, 0.10774864059243117, 0.07718784876317353, 0.1999339520030159, 0.2118372312609359, 0.07584555519335623, 0.1253797978313398, 0.24975256231836762, 0.11767527882818174, 0.1816258889595076, 0.11806705887748015, 0.14549153632240597, 0.4558608868673669, 0.43363487539493406, 0.4245382581999352, 0.3844031434815227, 0.4350036320141296, 0.4025915270102449, 0.45667888538640444, 0.4442415655360391, 0.4458012562862713, 0.11992776588829634, 0.11725719225419018, 0.08604780755453922, 0.08970588064235996, 0.13680075214383947, 0.143160358146317, 0.12324849538126492, 0.11769661378257479, 0.08800174820328466, 0.21988816371046205, 0.1854732801896889, 0.17539262489252871, 0.15470584110413022, 0.24952858626426666, 0.19239281074551395, 0.26047330332275453, 0.21025529266130738, 0.19722712191939296, 0.29849791693737837, 0.29530927421522135, 0.3483320873647524, 0.24641746072616333, 0.3115268383855251, 0.2548127734413097, 0.23812930246263653, 0.34936792925913474, 0.2944237024374633, 0.22536842677394253, 0.23471292416879985, 0.2562181027258047, 0.25183296385747056, 0.22941952856633985, 0.2225939186441891, 0.18918787813354943, 0.23136976781140184, 0.19808352001485785, 0.21429894389474546, 0.27096601480493376, 0.21524579037151537, 0.21975230559993775, 0.20643825935503346, 0.2350275334726145, 0.22862032299686408, 0.22877461640758456, 0.20278265495821557, 0.18062198343305902, 0.17213889899383483, 0.19634183860415855, 0.2077216087142919, 0.19709039278096996, 0.17740978356516168, 0.17942425446495947, 0.19848577627693875, 0.17306137973795066, 0.16308113212918884, 0.18531524465464388, 0.18444169465730753, 0.600526418620892, 0.19687112531381412, 0.1653152979060134, 0.5376904113017378, 0.14282695005285262, 0.778744402564385, 0.4878735833985747, 0.21014684182642163, 0.562803775159062, 0.2031298093921119, 0.1654154418965167, 0.1656915780438687, 0.16652344751565173, 0.251930103911685, 0.3578327345116793, 0.19091224925295125, 0.18673348161061365, 0.18974936355761585, 0.18482561336565317, 0.189678898157551, 0.21223474501384731, 0.1939717334710256, 0.18883315634087217, 0.19309405275751346, 0.11360341668968321, 0.08494845075718382, 0.0968445564632624, 0.08869897257972992, 0.08265810774576021, 0.08818027586193167, 0.09648935343165232, 0.09974363834928668, 0.10020112683668392]}, "mutation_prompt": null}
{"id": "914f3a9a-8934-43c9-b303-9271997e09ae", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = int(0.1 * self.swarm_size)  # Adaptive archive size\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism with adaptive rate\n                if np.random.rand() < self.exploration_rate * (1 - evaluations / self.budget) * (1 + self.exploitation_rate * (evaluations / self.budget)):\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with modified exploration-exploitation balance mechanism and adaptive archive size.", "configspace": "", "generation": 189, "fitness": 0.23416184547863741, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6824721403876872, 0.6106926125696852, 0.6352569085121491, 0.6242516818809472, 0.6734729554948926, 0.6159884684861736, 0.5759582027845774, 0.6299316237206152, 0.6589763709723885, 9.999999999998899e-05, 0.0780914871786057, 0.027447849248233624, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.008787002089730378, 9.999999999998899e-05, 9.999999999998899e-05, 0.16729465117036924, 0.08072437218675754, 0.10499929666738717, 0.11022667340451031, 0.0822953480418519, 0.08643593983610864, 0.13623475579703503, 0.12228694311012478, 0.10924254933804989, 0.09195517639028639, 0.09060394229903523, 0.09820795078303124, 0.0841675652601438, 0.08835803201668946, 0.08166503659063906, 0.09487746871255642, 0.08830479532664182, 0.07570999837251113, 0.8828034524714754, 0.925723576961016, 0.8564759678739723, 0.7227534403844782, 0.8794729409540116, 0.8153152070749976, 0.9050119996971628, 0.8742203852340753, 0.8808208110350635, 0.2471913054946755, 0.27707203281798354, 0.23897513213431876, 0.23447929476451967, 0.2601982662750545, 0.23143871147766792, 0.2651738068630418, 0.240825134212723, 0.21360868139123712, 0.32512095644767214, 0.34413421295386526, 0.21758918234601876, 0.31575491926704025, 0.3468079011903762, 0.20417004091042723, 0.28252311723809553, 0.18542097352379527, 0.18047331361559626, 0.15725182635546953, 0.20417898817591817, 0.16271229259021347, 0.10150879049210448, 0.23218813468820532, 0.12293943183056, 0.17620379750443482, 0.1624622745972487, 0.1468403620251687, 0.18419675809402525, 0.21290745766426467, 0.12994283355366276, 0.2282150379791379, 0.1832104893897003, 0.22966972377242745, 0.17495326951462353, 0.13210307361850027, 0.17661557082174495, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03485762606993903, 0.016909520370387843, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02119484194395138, 0.21846791579918556, 0.0480403074527016, 0.09251207875763412, 0.06217890622086775, 0.11177225372527644, 0.04622620507886188, 0.05875725500163209, 0.10900964572180782, 0.10732849801400168, 0.12740077560094143, 0.06585730414045687, 0.1416756375996132, 0.08976388333563923, 0.10879581642841263, 0.0948621720124665, 0.06759617213953939, 0.12306030887363906, 0.07247505350110528, 0.20301113712727892, 0.16868144916151395, 0.19088079479281606, 0.22207717645394764, 0.19831836781157486, 0.16490962208278492, 0.2289319090669738, 0.14301320822402597, 0.08462801805497344, 0.4668490256012192, 0.47986841644418643, 0.5047003400550073, 0.40739461789889475, 0.41506896127211534, 0.4549548480775101, 0.48669763301013214, 0.48657183793664605, 0.4315111043384646, 0.10749686035978834, 0.10475933316274932, 0.08442560120636755, 0.12822101704871236, 0.12560572214763854, 0.1253359665741044, 0.08996475040337482, 0.10655552543348201, 0.09952687543294336, 0.22435633502246044, 0.1458952645338759, 0.2612910422796153, 0.24958374795159965, 0.198508617163616, 0.18282196083439284, 0.2727224238585222, 0.269074954996271, 0.17156904709547294, 0.301533169499543, 0.31940523009986543, 0.3103042386928566, 0.29923627846559453, 0.28651820203629585, 0.3043410966258425, 0.2228331346589858, 0.2922911333723973, 0.2329663930367849, 0.22553518736130618, 0.2515545406766633, 0.30357623700070857, 0.22770384106761865, 0.2319218542117898, 0.3096670343768687, 0.1956776894129837, 0.23684199972061548, 0.22721459812033706, 0.23144130304638877, 0.22454905274561487, 0.23804634100158095, 0.2547170204472119, 0.224952648369515, 0.21539824911065253, 0.23313162740985216, 0.24868755285287691, 0.21881767017995435, 0.1782144051565847, 0.1923615270150355, 0.19609583011350662, 0.19730187268618316, 0.17841498404845202, 0.17959766082258988, 0.1699316518893531, 0.17726452802249948, 0.1733141347572773, 0.14657328102065603, 0.18632360588720398, 0.6800030284529777, 0.48773020115262644, 0.1991817504829455, 0.1983766834484475, 0.14138039752084153, 0.15751823470736237, 0.719340998879406, 0.5294722691985527, 0.21046852443735675, 0.48703246262818667, 0.42626145899209733, 0.3831765878450638, 0.1676088127291252, 0.16699792384140055, 0.3554297544789038, 0.31896577290878736, 0.21064029385394234, 0.1810504554949861, 0.19871534662570844, 0.18822685979032416, 0.1943508618295665, 0.1890765526456749, 0.19846734954155132, 0.18028965601590352, 0.19842576947178758, 0.09145155689902018, 0.07835092424905543, 0.0832661764850634, 0.07684344583462988, 0.08631347277932777, 0.08948765623798449, 0.08563052958159656, 0.08907381045635288, 0.09379787225878278]}, "mutation_prompt": null}
{"id": "6425cc15-25a4-46d7-a695-97fa2a852cf6", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.fractal_dimension_rate = 0.42  # New fractal dimension mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def fractal_dimension(self, position):\n        fractal_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + fractal_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Fractal dimension mechanism\n                if np.random.rand() < self.fractal_dimension_rate * (1 - evaluations / self.budget):\n                    fractal_position = self.fractal_dimension(self.particles[i])\n                    fractal_fitness = func(fractal_position)\n                    evaluations += 1\n                    if fractal_fitness < fitness:\n                        self.particles[i] = fractal_position\n                        self.best_fitness[i] = fractal_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], fractal_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Fractal Dimension\" mechanism to refine the strategy with a probability of 42.", "configspace": "", "generation": 190, "fitness": 0.22573821141577535, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6285418242762879, 0.5930070269023173, 0.5700739880435906, 0.639376189902402, 0.6319418644293731, 0.523093769908425, 0.5852517201270118, 0.6103459723277171, 0.5438920775713876, 9.999999999998899e-05, 0.046927827551508594, 9.999999999998899e-05, 0.027452895266428468, 0.010263458508146917, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14594654527034923, 0.10412629737813295, 0.12621748421413637, 0.1513773195347181, 0.11247872569830719, 0.0987230558291401, 0.08676356920870221, 0.1379707113983244, 0.24504563685638792, 0.10205097488322568, 0.0978329312429349, 0.07329346951780513, 0.10742604992578675, 0.07281650122189243, 0.08595614081003367, 0.12211426198379138, 0.10318713740343277, 0.08926573268028826, 0.8725206079971504, 0.925322501133349, 0.8564554604961898, 0.7673618310342512, 0.8750890178564497, 0.8558786571979669, 0.8976310800082936, 0.8752051100349171, 0.8756299612548744, 0.2832336477285404, 0.256508668830564, 0.28015519258551447, 0.24595654693175428, 0.2678519502527812, 0.27659167386643413, 0.2519314172692597, 0.23374035520163428, 0.27553753763011346, 0.3388593152362961, 0.34901823043006175, 0.2168643567659987, 0.22385530911806029, 0.21987611886071456, 0.19199242017955653, 0.35973729821431666, 0.1811316931926531, 0.21926670812251137, 0.14866568500470334, 0.12389659226449856, 0.12874517721426748, 0.17147308208368506, 0.12093644141322679, 0.14292943654596124, 0.12850217543595044, 0.1773927923412255, 0.1408925702981484, 0.19608565637376607, 0.18246503984624385, 0.1453313729019492, 0.1645268088681593, 0.13754417900393368, 0.1439346969937837, 0.1634038850548759, 0.22429479915985973, 0.1901076332324707, 0.03656018913217285, 9.999999999998899e-05, 0.051615648142386616, 0.021415736592191426, 0.009168442928760512, 0.007606898924377714, 0.002478044382636102, 9.999999999998899e-05, 0.037252722133549465, 0.17766419879605733, 0.08345373001627687, 0.15624634990671815, 0.06233194673629483, 0.06127991511785946, 0.031907527842221506, 0.11775405017139673, 0.047193995060588856, 0.07062416241599367, 0.10832313384745063, 0.06318286180473365, 0.09501694451103049, 0.06827394402561071, 0.1165909863428557, 0.06146494259561219, 0.1304470380662911, 0.14348153263240981, 0.07885730802291924, 0.2504558240163761, 0.1642063808995715, 0.2391536754698529, 0.18381864825532135, 0.11016168125817583, 0.08620667347887523, 0.14818524575961545, 0.10869847459843218, 0.09448955768287237, 0.4573884501118999, 0.4044302678623585, 0.41422213495866833, 0.3742416505065699, 0.40307929432244294, 0.407064016571282, 0.41306971465033016, 0.3970483909168975, 0.39987311336005327, 0.10903557857654267, 0.09002420506406583, 0.0824307325221274, 0.12619217019533846, 0.09554756496722527, 0.11691490435816632, 0.09804868742464645, 0.10466576534792726, 0.0958741709517269, 0.24887928618331134, 0.1620515063031278, 0.17653522123941345, 0.1956680337037957, 0.27719074775287533, 0.22865449022199935, 0.15761017807215616, 0.18722839433201466, 0.22745553376516026, 0.2866099404547433, 0.26895394102904846, 0.36288002534164354, 0.2819621162958541, 0.30810825660244423, 0.27536024447251617, 0.26960516759881603, 0.2563720662048896, 0.25289658218441813, 0.2149438464819018, 0.1977608621993603, 0.2752733241178833, 0.27783945734243265, 0.239961455915902, 0.25058463990052304, 0.2302005754474732, 0.23423427258965202, 0.1927068293242622, 0.22984498413743648, 0.22260150110304766, 0.2232572222494843, 0.24594471806788543, 0.2332097271572644, 0.2172265108516075, 0.23722073306789715, 0.19162947896508076, 0.2120041855159538, 0.19211382682208822, 0.1776770279346741, 0.20619849016259317, 0.19088798339728175, 0.18277184237766886, 0.17962297114529158, 0.19672851791522772, 0.1853915946439303, 0.17557814941465189, 0.18542263296734196, 0.18572108435163637, 0.18452015219937334, 0.7924739912263202, 0.19857382358283693, 0.1974186478985368, 0.14067608200495252, 0.14607714379861214, 0.5805464952734154, 0.48475896764229576, 0.21021330221285683, 0.5163752732720507, 0.4049397799838408, 0.19798089993906665, 0.16500199584287312, 0.16629277232847905, 0.355372532467797, 0.2689667926711401, 0.17087149826333592, 0.19217865230438635, 0.20244199155969922, 0.19097188341735616, 0.20071280954371373, 0.193735429665998, 0.19801201837783733, 0.18539905798634382, 0.1874043850311906, 0.09620833081746727, 0.0897267024219236, 0.08812754990836635, 0.09124112421730768, 0.09871313369373058, 0.08852106973111495, 0.09744461509613356, 0.08399240279709375, 0.09237110572970963]}, "mutation_prompt": null}
{"id": "2d9e0b65-4dfa-4195-8ffe-ba881c64e384", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            # Adaptive velocity update\n            if np.random.rand() < 0.1:\n                self.velocities[i] = np.random.uniform(-1, 1, size=self.dim)\n            # Adaptive opposition-based learning probability\n            if np.random.rand() < 0.1:\n                self.opposition_based_learning_rate = np.random.uniform(0, 1)\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive velocity update and opposition-based learning probability.", "configspace": "", "generation": 191, "fitness": 0.2257406249257194, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6569327567508786, 0.5910645731459129, 0.6279041931777067, 0.6289731257221787, 0.6226875029804099, 0.5890173324074606, 0.5796102233807745, 0.6251156240020145, 0.5909744209581065, 0.0015624167089279828, 0.03513189266350414, 0.010740089236556227, 0.011290207574355504, 0.006731788068960687, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12088463374192815, 0.10428551071929137, 0.1275834772020047, 0.12830081825293638, 0.11608808802611637, 0.09307335586833232, 0.13548442380183023, 0.12019608540494586, 0.12502688790927918, 0.10460998041814096, 0.08899740656140709, 0.08432086386766646, 0.08457717422401911, 0.08106554563259583, 0.10415591966656934, 0.11097541798060107, 0.06373105323566675, 0.10565195339680977, 0.8761664972624471, 0.9387870224539245, 0.8346243696250535, 0.6985940556660628, 0.7826750685950586, 0.8083445473770704, 0.9201108405390311, 0.9192781751107842, 0.8559779346589942, 0.3003413722336886, 0.26131281531109196, 0.21119538993685172, 0.2428049698336583, 0.23616216343732233, 0.25263134375538354, 0.2588633750405266, 0.22439824561638178, 0.23776453856646806, 0.3422308829216658, 0.3878579119331864, 0.22040294246683056, 0.3575526470210111, 0.21089777959646205, 0.2051045061490293, 0.25486380813523357, 0.23019817828338207, 0.2177108385790011, 0.15774528759397488, 0.10518656704588991, 0.11541027469553988, 0.13796053931504848, 0.19629118763776687, 0.12260897507441482, 0.13964019119892168, 0.14481367263647993, 0.13318220311122786, 0.17015583891851183, 0.20169260448481607, 0.17638210299295498, 0.14862666035312866, 0.19604917955151546, 0.1652144154118811, 0.164301449418768, 0.1632040190767604, 0.1621715541520805, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.06260489821968407, 0.00015754388278987896, 0.006671326705276037, 0.001369509820673187, 9.999999999998899e-05, 0.00466119589914582, 0.15038935005848653, 0.05721427210606722, 0.14733136183576612, 0.0776320777579389, 0.07863661232861374, 0.022587866250163957, 0.05513379551221309, 0.10780712500372924, 0.06213372740791234, 0.08678184433867686, 0.08499359841151877, 0.10618279720771517, 0.0919010014094882, 0.12093357544127337, 0.07880418525207955, 0.10645813114829927, 0.1285956829393704, 0.05531321372249565, 0.12113767422556299, 0.21329934587640875, 0.19047631498651774, 0.08273479617484913, 0.19213353681300882, 0.17386297236966153, 0.18120171798482387, 0.14744272104886658, 0.0743800859272471, 0.5045214023804852, 0.4140036085348182, 0.42432815158401216, 0.4032583718585816, 0.43318199726916284, 0.4209478080358837, 0.45459167314264315, 0.41726064355861936, 0.4447289818815333, 0.10773857456064473, 0.13945927097749877, 0.08516667801644306, 0.12129073781819188, 0.10886485606137852, 0.1486053185832712, 0.12756014650213854, 0.10733192730057839, 0.09848210058896167, 0.18656089222852723, 0.14677070319503327, 0.15368178840978286, 0.19968836463242567, 0.27189107463038886, 0.20685363870788376, 0.23042695676676805, 0.15709301976491175, 0.15091784389002172, 0.2571801801857446, 0.36343759146119314, 0.3245279632933832, 0.2870941311348235, 0.2976591757622662, 0.30496984042764586, 0.21849073673940356, 0.29511838715231165, 0.24792738525058233, 0.22602342335263248, 0.27388517900527176, 0.23773179844196413, 0.20682848209159843, 0.24484160819185563, 0.25899991545593903, 0.19291665641213251, 0.20511410800612628, 0.21275486310190073, 0.25911702723579044, 0.25652731242595317, 0.2721273350129204, 0.21291386202925844, 0.23854646919802647, 0.2304354958083199, 0.26544958582527756, 0.21941838181970774, 0.23490079913233763, 0.17003920942455786, 0.18346521196960297, 0.17369425810089545, 0.20118212213993003, 0.24996218638522905, 0.18301318559515312, 0.19236057457284272, 0.19335700228148478, 0.18258760613205882, 0.1844511819769128, 0.1868075303201, 0.18622780356419044, 0.6398595844299484, 0.19889892863383973, 0.1979354955418502, 0.14182666067387395, 0.14900555882280986, 0.7817965504960287, 0.35188219200729076, 0.20945741094562287, 0.33887828083452454, 0.4349717317782338, 0.3575963465151666, 0.16367671688401386, 0.19879582435414367, 0.34615592140598195, 0.26746918306753065, 0.18397003966522651, 0.18520485294770583, 0.19694992160888902, 0.1901527924861589, 0.21482145161694566, 0.19436480961431546, 0.19373001866486395, 0.18752543136904953, 0.19913737808645082, 0.09293462862132695, 0.09832175099373142, 0.07827135198356194, 0.0898678201421802, 0.08472529578016841, 0.08394713382418284, 0.09413904036586096, 0.09220309169148111, 0.0882121472750177]}, "mutation_prompt": null}
{"id": "c1aebdf8-3885-4bbe-a3a1-18dda9b9677a", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective strategy\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Multi-objective strategy\n                if np.random.rand() < self.multi_objective_rate * (1 - evaluations / self.budget):\n                    multi_objective_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n                    multi_objective_fitness = func(multi_objective_position)\n                    evaluations += 1\n                    if multi_objective_fitness < fitness:\n                        self.particles[i] = multi_objective_position\n                        self.best_fitness[i] = multi_objective_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], multi_objective_fitness)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Multi-Objective\" strategy to balance exploration and exploitation.", "configspace": "", "generation": 192, "fitness": 0.22533486024182597, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.5737538917121765, 0.6056694665907916, 0.6707508964465934, 0.6346882900021982, 0.622547151257124, 0.6136022284109035, 0.5854230029752165, 0.6594518890785172, 0.61607016213133, 0.09323707233308975, 0.04699578931324433, 0.035559455620013836, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0035547504204965774, 9.999999999998899e-05, 0.10734669125912677, 0.11929727346451058, 0.13519864189958242, 0.11333957305007936, 0.09197063118950322, 0.11375526781701506, 0.13324186563923723, 0.13600045154467022, 0.11937192822067777, 0.1001495687371915, 0.08753390061559763, 0.11326546809459015, 0.09170079719056723, 0.0781099463785544, 0.0878343800182414, 0.14961922754252432, 0.06682425760645927, 0.08016629158426769, 0.8142867512149798, 0.9055363962369901, 0.8453494683686038, 0.8295573505129603, 0.8220939771713276, 0.8589708851532873, 0.907903312029862, 0.9079472923220658, 0.8195969739760288, 0.2757855557284725, 0.23092864422418302, 0.2619373988753704, 0.26175886779621693, 0.23157932827822625, 0.23607466608241834, 0.2135633290583282, 0.21120395887222154, 0.2921466216603541, 0.2376663497432765, 0.34136609790865247, 0.22048950025254677, 0.27532978947388187, 0.34178624093262167, 0.21417258387537086, 0.2571815375885601, 0.205908987347459, 0.24841278300991132, 0.10553395131803534, 0.13170341446365674, 0.2613284000111895, 0.03171922416531159, 0.12302408742894566, 0.1263235707238064, 0.19020860037490084, 0.19898360391291892, 0.1439217184773235, 0.14133846797343375, 0.15456242398525266, 0.13297457069664465, 0.17713981555151326, 0.14529328729366753, 0.1794402080353057, 0.14414038141725416, 0.13034672648809753, 0.19752391078430132, 0.035446545453379996, 9.999999999998899e-05, 9.999999999998899e-05, 0.024707361412881768, 0.0030738331062417634, 0.0226990092720476, 0.0065553532124049685, 9.999999999998899e-05, 0.021540019245734232, 0.12208293393598146, 0.06625545949663314, 0.09015934919894031, 0.10410328769270205, 0.08660124126167046, 0.036292799458533254, 0.1327287945955803, 0.08663639367596587, 0.08076420427433006, 0.10737385412598766, 0.0630267008016201, 0.08390226056499728, 0.19366325821716224, 0.09099038478677957, 0.07094229067588476, 0.19041730511296595, 0.1103413682293467, 0.052811359628075816, 0.15948303408106312, 0.1517065647060899, 0.15771522479252198, 0.11362541962822414, 0.07789399798430352, 0.15148466894171364, 0.12626026041708915, 0.10669897745973844, 0.10293885366432609, 0.43669833066235064, 0.41121087239176, 0.43712770198521556, 0.41601650542778823, 0.400021463962807, 0.4150705563192987, 0.4452468175671698, 0.4202426881033904, 0.456469552259834, 0.10641709878002381, 0.11051078351212751, 0.09461323921408238, 0.11972572193553566, 0.11510440095925079, 0.10853031015733361, 0.10894992562528438, 0.10530900526398201, 0.09657841001158796, 0.23758652178605277, 0.17980510836588615, 0.1971659805768058, 0.18112053887010382, 0.26312241455592766, 0.22544402090030702, 0.2580547789825246, 0.25616460136513164, 0.24122720164716016, 0.24851366657337592, 0.28833086522664, 0.31530337665186114, 0.30475978044310703, 0.27488531241310465, 0.2964454330643924, 0.2637759049132419, 0.268330883729085, 0.27946601607699906, 0.2288425402023493, 0.24415301242650622, 0.2653356907305736, 0.25166285753699047, 0.24975728257908392, 0.20224326587408137, 0.16749958134361842, 0.2624480228453606, 0.22749076111461075, 0.22223935948103057, 0.21140044191667184, 0.2594730511247114, 0.24202717594886358, 0.23976826821644615, 0.22610125254230007, 0.24463089043007857, 0.25854032277278605, 0.27130170925678443, 0.17198021743166736, 0.18552220746830728, 0.18231098513676836, 0.18634678952861405, 0.19669979459876719, 0.18174034074234147, 0.17455482018567292, 0.1874423042086356, 0.1721436444029696, 0.18407078627346718, 0.18610501884790842, 0.1861225103019658, 0.6813616260369542, 0.1981706618054112, 0.1994041389571125, 0.17149452999579662, 0.17102797629610123, 0.22030505626442232, 0.5692963566280707, 0.1685495159291559, 0.41135227720756984, 0.3930221815201371, 0.21418878288722532, 0.36567573621465777, 0.16637473401588454, 0.27077881082984645, 0.3334340454253162, 0.18279458755915934, 0.19636688378500744, 0.19445081087794747, 0.18910014595898195, 0.18928460399301383, 0.21925161331224963, 0.1858609900055701, 0.22310947480692744, 0.18246900679137912, 0.0906419472369897, 0.09151204505924104, 0.08654161259917159, 0.08226854420294771, 0.09934777774191639, 0.08921452629687576, 0.10459776132550669, 0.08097987312099308, 0.09500689374566207]}, "mutation_prompt": null}
{"id": "98282617-69db-42e4-9ce7-b6b51c17932b", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n            # Opposition-based learning rate adaptation\n            self.opposition_based_learning_rate *= (1 - evaluations / self.budget)\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with modified opposition-based learning and adaptive inertia weight.", "configspace": "", "generation": 193, "fitness": 0.23850536180213713, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.21.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.625870908217665, 0.7042085248066552, 0.633115738541532, 0.6928542862663947, 0.5891902702650651, 0.7340751004633443, 0.6553038257899338, 0.5781287256434284, 0.5810101332408567, 0.008002569189449638, 0.04001214666560149, 0.0004625760125842593, 9.999999999998899e-05, 0.02202261509837211, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13734855563305992, 0.09590177877560202, 0.13065548217166978, 0.10335262574057746, 0.10247720011172679, 0.09487041429181553, 0.16723099745617476, 0.13407967212728267, 0.10124376589778916, 0.08071127625567964, 0.09986597857843027, 0.08373100565574565, 0.10802042676310941, 0.08934296954152565, 0.09589446926528522, 0.08368055952797371, 0.0934416318828486, 0.08785626924186085, 0.8884724675154758, 0.9374013431013557, 0.7720868093675208, 0.7338209378475619, 0.9002704357777176, 0.7814700138594902, 0.9076953140959465, 0.9100392570048709, 0.8862103596731388, 0.2852438902600841, 0.274674451799643, 0.25073007130788205, 0.23126522203732625, 0.27767944338229944, 0.25894050868905527, 0.24639929712674513, 0.24405379510750913, 0.251449016608584, 0.7459426824519835, 0.36983660805596863, 0.31404315201237865, 0.27504922882763416, 0.5671233005382437, 0.2017174765687847, 0.33649934620847466, 0.2200904754365296, 0.2463640218924229, 0.09567856506528893, 0.11278423971608187, 0.12335247240740532, 0.14362599357053696, 0.13050305923943217, 0.1300231584459416, 0.1276020384070884, 0.1514668113280231, 0.16374720091162087, 0.1645787618637412, 0.2307290779307084, 0.1267568592202749, 0.1431908565666392, 0.15677276593658518, 0.2285454917554739, 0.18014185643025615, 0.18566852869494388, 0.16085189550301926, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.002018031680771082, 0.006532810631213248, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.043339337475643114, 0.15326050652177403, 0.05573523679402059, 0.1400492473907632, 0.14007206281833118, 0.07724588194660542, 0.031795435375094216, 0.0982823334260533, 0.11324998939307784, 0.09830657327898806, 0.09035901633716281, 0.09368079048643063, 0.14208131174714744, 0.07775839311122767, 0.10964941034699882, 0.08262123666982935, 0.10900430142664375, 0.08236010980000374, 0.08684097051089035, 0.2694001148690559, 0.13508633479157506, 0.20911207881307792, 0.08977282845402601, 0.16414341430823443, 0.1363836215215377, 0.1573065862088039, 0.12040755275248016, 0.12177122569013243, 0.4781603924208653, 0.47743131294981334, 0.4417768850331766, 0.4452319724724413, 0.39675168834455565, 0.4493631861023055, 0.4234244848105344, 0.4655810066743725, 0.4592122211301447, 0.11900922541510806, 0.11131488661842637, 0.09077948169960326, 0.21163181901432537, 0.09396425586188595, 0.13750589961092996, 0.12965789626883428, 0.10709737327627411, 0.0907274533547574, 0.25075226818395857, 0.1631281265804928, 0.17491194339865268, 0.20141553883642715, 0.3282517722311229, 0.16257831397908484, 0.27947189574590237, 0.16274500769049594, 0.18923317173801135, 0.25159011583343904, 0.35188548089454186, 0.34423947565609325, 0.2681743868559918, 0.33789996432301095, 0.31117900868875126, 0.256383118129639, 0.2835862521570205, 0.2563654376490043, 0.23763812808037899, 0.25769458111654986, 0.25457476457984074, 0.18597611256561553, 0.21188222875569274, 0.29319637246033725, 0.20033558493877768, 0.2475485766716844, 0.2049859779240315, 0.21511737425737643, 0.20690004578743804, 0.21227592011629692, 0.2538750850429867, 0.20913123816945212, 0.2013122735225863, 0.2150199961248116, 0.2360740810925488, 0.20425144887236435, 0.19923079140778066, 0.1858604373292082, 0.18525070914333008, 0.18937462465043986, 0.1987341978574978, 0.17395587684907965, 0.17057625810458144, 0.1883513764864343, 0.1737718877596055, 0.18058327587453205, 0.18647306420222498, 0.5452791092102027, 0.6747596616125704, 0.19888919098638824, 0.19896416997542643, 0.6985586155674217, 0.14699364673555715, 0.7035836083318856, 0.4665160545796324, 0.20906991542673914, 0.43985506019593745, 0.41733588262431665, 0.46904522574397867, 0.16777446683408725, 0.16746709486592903, 0.32369620626424844, 0.29370861181787833, 0.1965285261104437, 0.18960472119684924, 0.19212745741197146, 0.23018188136386264, 0.1840740014601222, 0.18866823381996045, 0.18710521838487848, 0.1862660177309654, 0.18523209542899344, 0.08601086665533308, 0.09045748820093447, 0.08328786669738797, 0.08069590063864507, 0.09578734867835514, 0.08772033883327635, 0.10880001512586568, 0.09252118386182262, 0.08494965427195289]}, "mutation_prompt": null}
{"id": "befa0e34-a9dc-4471-8298-45d495f1b814", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective approach\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def multi_objective_approach(self, position):\n        # Define multiple objectives\n        objectives = [np.sum(position**2), np.sum(np.abs(position))]\n        # Calculate Pareto front\n        pareto_front = np.array([objectives])\n        for i in range(self.swarm_size):\n            new_objectives = [np.sum(self.particles[i]**2), np.sum(np.abs(self.particles[i]))]\n            if np.all(new_objectives <= pareto_front) and np.any(new_objectives < pareto_front):\n                pareto_front = np.append(pareto_front, [new_objectives], axis=0)\n        # Select best position from Pareto front\n        best_position = self.particles[np.argmin(np.linalg.norm(pareto_front, axis=1))]\n        return best_position\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-objective approach\n                if np.random.rand() < self.multi_objective_rate * (1 - evaluations / self.budget):\n                    multi_objective_position = self.multi_objective_approach(self.particles[i])\n                    multi_objective_fitness = func(multi_objective_position)\n                    evaluations += 1\n                    if multi_objective_fitness < fitness:\n                        self.particles[i] = multi_objective_position\n                        self.best_fitness[i] = multi_objective_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], multi_objective_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Multi-Objective\" approach.", "configspace": "", "generation": 194, "fitness": 0.2293225024943475, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.58890461059231, 0.663910259404724, 0.6217358955172767, 0.6131892314342237, 0.6147823583166592, 0.5444457639989113, 0.6679693669547249, 0.5825713359943872, 0.5852087169510631, 0.04796731693302336, 0.015176933093948186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.15057503244875592, 0.10733207983457338, 0.12041297511048665, 0.08769756250696414, 0.11037864892455751, 0.1071634231453873, 0.12170793398205715, 0.1120696813201717, 0.13119067069737944, 0.09053384416182653, 0.09684868696748616, 0.08860503571429923, 0.08296470976914383, 0.07339257559917256, 0.09821760434226923, 0.08758776142596747, 0.07396838286604779, 0.07192999997693406, 0.8565118213618557, 0.9336953512621227, 0.8753581627803301, 0.8396731032422362, 0.8746834904385414, 0.8949844688209676, 0.90334037558149, 0.8448696694378148, 0.8319870285088463, 0.2476604935788992, 0.27782335003415015, 0.23160623544940429, 0.27979501682142427, 0.23490343728975438, 0.2616358987099684, 0.2964433808610426, 0.25092126983158114, 0.20363701510957788, 0.35580004629801354, 0.31629195585228365, 0.22097288032603268, 0.2520336924767468, 0.49169774705852254, 0.2687855983641292, 0.7472736329839925, 0.25703729111107865, 0.21466978227141664, 0.11728250306578447, 0.1427825373640682, 0.12434262123112017, 0.07580846130952645, 0.2646184156708704, 0.13289181403255657, 0.19826872155629982, 0.18133317416683992, 0.1886593681323836, 0.19204894758681634, 0.20759901290858618, 0.12344682271829566, 0.17274664686691454, 0.12249276019600297, 0.14261032291063802, 0.12998454514710356, 0.17641166865819036, 0.1423433921163596, 9.999999999998899e-05, 0.0004903249478293015, 9.999999999998899e-05, 0.03288286549554198, 0.06053329823079878, 0.009864523869389408, 9.999999999998899e-05, 9.999999999998899e-05, 0.021727721866184768, 0.09044873837435585, 0.06339102733494906, 0.08105937384687312, 0.0698817390795402, 0.048263573824807504, 0.08146446682986275, 0.08278489590177174, 0.08916458169458952, 0.06042096240032735, 0.16026038782375895, 0.08831580291726915, 0.08433032630344683, 0.0841114068213239, 0.12835639610781724, 0.061896963766831736, 0.08859753474504073, 0.10399766561689139, 0.10297284587073685, 0.17533947220035284, 0.23150834412553345, 0.12630161102742354, 0.1970621903484686, 0.20258608385367682, 0.13749739649059634, 0.18246993602905603, 0.16612770257412646, 0.10763453889298813, 0.40555811094427574, 0.4174910854881074, 0.45517239185519065, 0.41688088191914763, 0.4253069343544478, 0.39507346326400516, 0.4161344769506926, 0.44757070324216686, 0.4323384337147659, 0.1154029095761443, 0.12961252447440552, 0.11752618455860397, 0.09202626988822249, 0.08037737085944341, 0.1458405954663058, 0.11292979843446915, 0.1335116113551894, 0.12054799415404827, 0.24859763638898147, 0.137771383458817, 0.15168300346216734, 0.1699963039260396, 0.284514992376264, 0.22257018531306516, 0.2757994913590298, 0.19171656017566874, 0.1759843472245497, 0.2610193137259429, 0.3057320055661906, 0.27333100527750753, 0.2692388804424377, 0.3076937752807074, 0.24678724363101423, 0.25336368383649255, 0.28836518366429886, 0.21836836903470125, 0.23792197507389312, 0.2627993688248236, 0.2730075241778289, 0.22465788563010014, 0.23429833884678974, 0.24308605759140622, 0.21280847073426212, 0.23584603433487417, 0.22493440635695838, 0.21088972835153763, 0.23102586220436272, 0.24542149360880716, 0.2395796599032377, 0.24237286279579662, 0.21788227863213416, 0.21289656934708512, 0.22167659351964475, 0.21667274941106218, 0.1902409211921039, 0.18004497199265335, 0.1753462379639945, 0.21371087174305403, 0.1817835395370856, 0.1914175416712366, 0.20876464829755448, 0.3048687195553732, 0.17186253040470234, 0.18477402178855196, 0.18640854992371914, 0.18517762426471807, 0.6294882664517722, 0.1986109327105987, 0.19708309231944665, 0.16710366147745515, 0.23259979852370682, 0.6358140087379375, 0.3886428688409401, 0.21031088622233118, 0.46274234346421483, 0.4077144774165171, 0.16548366950413274, 0.16565181636598303, 0.16588903687996936, 0.16688760867738184, 0.3123749549677062, 0.1930993842834875, 0.20066926741402147, 0.18466864831435292, 0.19119560481120879, 0.1885604377208212, 0.18908042836054872, 0.1821841752517115, 0.19981699545278087, 0.19260739023889473, 0.09438195678746675, 0.09796920775836915, 0.09216598655122288, 0.1090456533385501, 0.1526643781683611, 0.08930019221978436, 0.0867964022649399, 0.09338214660813737, 0.10461468965397724]}, "mutation_prompt": null}
{"id": "eff95f6d-756d-43b2-8165-a6646d873ce3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.cauchy_mutation_rate = 0.05  # Adaptive Cauchy mutation rate\n        self.gaussian_perturbation_rate = 0.05  # Adaptive Gaussian perturbation rate\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.swarm_contraction_rate = 0.05  # New swarm contraction mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.cauchy_mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_contraction(self, particles):\n        centroid = np.mean(particles, axis=0)\n        return centroid + np.random.uniform(-1, 1, size=self.dim) * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Swarm contraction mechanism\n                if np.random.rand() < self.swarm_contraction_rate * (1 - evaluations / self.budget):\n                    contraction_position = self.swarm_contraction(self.particles)\n                    contraction_fitness = func(contraction_position)\n                    evaluations += 1\n                    if contraction_fitness < fitness:\n                        self.particles[i] = contraction_position\n                        self.best_fitness[i] = contraction_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], contraction_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel metaheuristic algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive Cauchy mutation and Gaussian perturbation rates, and a new \"Swarm Contraction\" mechanism.", "configspace": "", "generation": 195, "fitness": 0.22504912596304846, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.7118984286933356, 0.6880702390624236, 0.6386242817948389, 0.6446023173797099, 0.6378439608514999, 0.6256042440412382, 0.6208419312823927, 0.6379978855441863, 0.6178662569756297, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.030163286666514022, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12158496062252544, 0.0956118384205682, 0.11283644264580439, 0.08736206701588312, 0.07751899239277193, 0.11967292943944774, 0.1398226174890409, 0.15011500536461986, 0.11993570105948015, 0.0989681007510409, 0.11110514345853184, 0.10498246725147697, 0.10085363766152056, 0.08201720534009616, 0.11846580435646226, 0.09590731497032723, 0.07849557821330344, 0.07688685855561561, 0.8715717124903913, 0.929911062027241, 0.8735001513643477, 0.7205756037515624, 0.8206138490836925, 0.8367056849193406, 0.8412021299590791, 0.8908884344525021, 0.8719943462866061, 0.25495268002758065, 0.2516770298101857, 0.2091486476631781, 0.24468980557386288, 0.2757838777756011, 0.28412552596466667, 0.27438238518760705, 0.25024702688679923, 0.21340534794322674, 0.23010313255263104, 0.24313028320473729, 0.20593254143337114, 0.24955828160257865, 0.3679284559598851, 0.19163949325304053, 0.24604545434944658, 0.20982631585791656, 0.2174885786513281, 0.12709397235729647, 0.14220218777277427, 0.11940521742536625, 0.12949979853102156, 0.2562998390296989, 0.12715202272149384, 0.13074497382552075, 0.197851323382235, 0.13719784564099868, 0.15775792979440828, 0.14010231086890668, 0.13590300798363264, 0.14876899051159975, 0.153717966896584, 0.15262142459761452, 0.1788473146518621, 0.2012734068957358, 0.16217891021684294, 0.024630402098298476, 0.004861291878483498, 0.005251717698608438, 0.044925203642858236, 0.049350056517176055, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01750290919674513, 0.08880372402771208, 0.0386458220759367, 0.14035354852819515, 0.05061847379993778, 0.06842837690637205, 0.02681806674817999, 0.07701492437796553, 0.10752778401350027, 0.0869905432768886, 0.11945560502324315, 0.11594354349503722, 0.08971716669858765, 0.09716513153557893, 0.12363629823706923, 0.04763123988518114, 0.10608497482224521, 0.07432563579464735, 0.14312411432404404, 0.14409689535514847, 0.17147949938841944, 0.17413605552353129, 0.09383806904547987, 0.16272206761384844, 0.13455775990725616, 0.15187083263555667, 0.1839362886149397, 0.08840131514086402, 0.44119630431158285, 0.41230134214931713, 0.42362042783585996, 0.45834114338121623, 0.3915165639431186, 0.43284319722183706, 0.4407499642789575, 0.4762507233500334, 0.4127539490830425, 0.0928712744327731, 0.09169757974888759, 0.0962621278577328, 0.1285768801365994, 0.12704330986396195, 0.12526277735762015, 0.0900045618434766, 0.09918546856702337, 0.09174396937297513, 0.2044041975379829, 0.18906042538930123, 0.16881285220762443, 0.19505898529548582, 0.23064849200026905, 0.39612267834052983, 0.18739767973549348, 0.15692584046187497, 0.2017176698126758, 0.2632211238605817, 0.3168549096024095, 0.2841097779676782, 0.2525172024065848, 0.30987122497333686, 0.26625655623945765, 0.23814832302386246, 0.3126330177883134, 0.24657349445287824, 0.2159584465897848, 0.21567233689243992, 0.2506703345468385, 0.3225806478608617, 0.20050901809273758, 0.22598642284501436, 0.1698542369264755, 0.23426083974489098, 0.21900065697181625, 0.22097937006044788, 0.2356255545270587, 0.21937515373238559, 0.21764032641114017, 0.2324160001627028, 0.207555500811886, 0.2148043449719681, 0.2273062667618948, 0.2023582496596712, 0.19142924590571697, 0.24183574632797822, 0.18999582757722, 0.17814526991261026, 0.19976242190371263, 0.1891795618933274, 0.18051633036698733, 0.1859507139594052, 0.18312733606523812, 0.18623116936930595, 0.18623744432982525, 0.18658367083905358, 0.6829576709542773, 0.198154023182174, 0.1670354594238439, 0.16720294597630658, 0.13971016403792824, 0.6903610671362672, 0.3772335179470664, 0.16778264884196503, 0.3736059038074745, 0.1972652151524621, 0.20910302070581333, 0.5171619618964891, 0.1657023127382774, 0.2995633917392676, 0.43014107010150493, 0.18202461502350975, 0.1923936221068041, 0.20140224374659632, 0.19384775294630485, 0.18286466557482495, 0.1825178711812867, 0.1847823121720702, 0.21938490826988843, 0.2002379186437534, 0.0862845831661927, 0.08588852936815872, 0.10238075960566784, 0.0886160023768301, 0.08777274919817246, 0.10218571510077656, 0.09940801238037766, 0.09478221124175434, 0.08050478415781459]}, "mutation_prompt": null}
{"id": "76f32adc-e591-4b44-9b8a-c529159887cc", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.diversity_rate = 0.1  # New diversity-based mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def diversity_based_mutation(self, position):\n        diversity_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + diversity_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Diversity-based mutation\n                if np.random.rand() < self.diversity_rate * (1 - evaluations / self.budget):\n                    diversity_position = self.diversity_based_mutation(self.particles[i])\n                    diversity_fitness = func(diversity_position)\n                    evaluations += 1\n                    if diversity_fitness < fitness:\n                        self.particles[i] = diversity_position\n                        self.best_fitness[i] = diversity_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], diversity_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Diversity-Based\" mechanism to further enhance the diversity of the swarm.", "configspace": "", "generation": 196, "fitness": 0.2314174742236298, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6125824774325759, 0.5990155800405379, 0.5942703456911014, 0.6042542693238095, 0.5845178281213235, 0.660259563492832, 0.5961206249938704, 0.6350209086322897, 0.6197322266245386, 0.018541349854917955, 0.04378846500325251, 0.0020853975839251193, 0.006168904117033747, 0.02417029594857889, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13199821747675655, 0.09900934967579345, 0.11803608686199918, 0.08783804207449064, 0.10168677924281788, 0.11595617690735593, 0.10509759555579856, 0.1029785864900501, 0.15497964047657153, 0.06278616535787407, 0.11105848330980428, 0.10084139353626365, 0.0913014341052738, 0.07873546443706769, 0.09013001535685294, 0.12552845708078653, 0.09730089216819637, 0.0932067017807976, 0.8843738784953601, 0.9335834102564146, 0.8664238812462577, 0.7937522397484056, 0.8671174025940622, 0.8558136517005249, 0.8955552216846007, 0.9098469269921373, 0.8523981164385521, 0.3079991116055525, 0.2631934762992757, 0.25167634607010736, 0.30124540164435576, 0.28639317707816137, 0.2313402812958376, 0.27042593197048614, 0.2615155827728288, 0.28984463410417916, 0.3583296926177505, 0.7602457508424253, 0.22640180804819066, 0.27453532624516797, 0.27105657870806643, 0.27413904415609824, 0.2605555983002378, 0.21697118583521324, 0.4818256846712001, 0.11926337688901245, 0.27905427916660497, 0.11775715826819233, 0.22967702536172352, 0.15708305388428268, 0.15204747196790136, 0.15287697557716806, 0.12650788010390712, 0.1547157512178703, 0.18472576348201308, 0.17341924844343848, 0.15548814161062963, 0.17089925835825126, 0.15211395089352575, 0.12572301172507794, 0.27045305896133887, 0.16966339313195822, 0.17357620918335848, 0.048665779621226646, 9.999999999998899e-05, 0.0021655519550116686, 0.042532246079000524, 0.015408654534225352, 9.999999999998899e-05, 0.008220102456576228, 9.999999999998899e-05, 9.999999999998899e-05, 0.048189101895538045, 0.05594118854952923, 0.09755257859894462, 0.08417254344474445, 0.06733915983072147, 0.045179553528066796, 0.0735118300040043, 0.06593095137731197, 0.10443059854760228, 0.08722585771817992, 0.1015455888275354, 0.07427654525657323, 0.08507846989813805, 0.10901759834249092, 0.08314423786413738, 0.11036198506265338, 0.0685039492732672, 0.07871633971628211, 0.2068501986374227, 0.16334892371607823, 0.15629621576572028, 0.13401907872053398, 0.18059939447311557, 0.12788266261626413, 0.13233880736069292, 0.16608433837742764, 0.09598285244605853, 0.44566194122134717, 0.44440352122268223, 0.4335913180587053, 0.405160425147551, 0.4258142977540973, 0.4013501656077444, 0.48035330031248913, 0.42753856509563926, 0.4442076755129869, 0.10121843363611382, 0.1163251591225477, 0.11572423531975329, 0.12674955157186285, 0.11615645156297527, 0.10001066690757376, 0.08372151461815136, 0.09652267853144314, 0.07370329924328722, 0.2606266435397444, 0.2254516837884798, 0.16416507629755783, 0.24219257462756838, 0.27703067670812, 0.18300450948762637, 0.22022557672373722, 0.16829875151728102, 0.277848125938005, 0.34444759983158924, 0.3020685232462139, 0.32258419607281497, 0.31727328539910227, 0.3114816005727662, 0.3133535961825059, 0.24214087179905097, 0.27433997287635925, 0.30249023751315696, 0.23904272095365098, 0.2217849211005879, 0.27353209713440507, 0.2300291218771976, 0.19881501344359132, 0.24464445249590594, 0.22146871154784753, 0.20849255849958304, 0.2035474317770979, 0.2725793464629169, 0.22012641156838075, 0.20354492953783243, 0.22990914199974255, 0.2135732323171614, 0.20686745399332052, 0.21818312720016197, 0.21038130181636883, 0.20454765678767095, 0.20222697370259346, 0.19124931485257635, 0.2200975721529178, 0.1834431177780782, 0.1910944876266879, 0.1924952879337739, 0.1889929925616648, 0.19233977006959402, 0.18507418841042178, 0.12683334175673322, 0.1855362635278458, 0.18719912533444882, 0.5495707390038582, 0.19883955915694618, 0.19755357946233576, 0.1466076814029761, 0.1543066865148749, 0.8049610644772345, 0.45319136999156184, 0.17323669857377044, 0.36881924417554457, 0.41574249575169975, 0.20653066651305008, 0.16552881623306637, 0.16740014350115473, 0.2945631388201989, 0.3505670571589642, 0.18449150542714532, 0.1943450009034975, 0.21361266158159897, 0.1883760902979409, 0.18858148123118057, 0.18753466135465702, 0.19209844016836242, 0.19047977144430783, 0.1998347219788713, 0.09004092735852376, 0.09422909141670988, 0.10040142931692186, 0.1043106519114072, 0.08440876299657574, 0.09067917229532962, 0.10935626279767552, 0.08170647602135572, 0.08746466137742825]}, "mutation_prompt": null}
{"id": "334179c9-dbb3-4fa5-a31c-df50970ace12", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.differential_evolution_rate = 0.1  # New differential evolution mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        difference_vector = self.particles[r1] - self.particles[r2]\n        return position + 0.5 * difference_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Differential evolution mechanism\n                if np.random.rand() < self.differential_evolution_rate * (1 - evaluations / self.budget):\n                    differential_position = self.differential_evolution(self.particles[i])\n                    differential_fitness = func(differential_position)\n                    evaluations += 1\n                    if differential_fitness < fitness:\n                        self.particles[i] = differential_position\n                        self.best_fitness[i] = differential_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], differential_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Differential Evolution\" mechanism.", "configspace": "", "generation": 197, "fitness": 0.23273630349368765, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6291939189832378, 0.5812813041976933, 0.6714684162880665, 0.6150538048970522, 0.6635115167594918, 0.6412128394564702, 0.5806587567844312, 0.5523247898373655, 0.5839957989560678, 9.999999999998899e-05, 0.026158685574364404, 0.009229707344125981, 0.0024332176307502174, 0.031868281860512604, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1434697408950879, 0.09681981389262495, 0.1196581198535025, 0.1035634123692929, 0.09745984750602199, 0.12958522853991672, 0.1278982533120825, 0.12883095571865144, 0.15158480979719247, 0.1007481952475493, 0.08364161974453177, 0.0863794539448769, 0.11277187075204254, 0.08089214275650847, 0.08579456105405403, 0.09334878464451069, 0.09646380923358866, 0.09892841830417165, 0.8975983291982059, 0.9126361191048405, 0.7746735551251662, 0.7413723526641096, 0.7973935564610203, 0.8900032745796561, 0.9218215469909676, 0.8808253553970867, 0.8418945478132935, 0.28600549103136075, 0.23413497017004825, 0.2754168897076291, 0.2690567627053626, 0.2988454768645574, 0.28682681307762803, 0.21913654460866505, 0.2604665769735981, 0.26909211708158376, 0.38335437712097287, 0.28389264220060983, 0.230618218822907, 0.2709273228106782, 0.5114660202417419, 0.20295964731298588, 0.3480843057343167, 0.20845472200592263, 0.33216992886311614, 0.11098549090692866, 0.12116037249865041, 0.12047549902517207, 0.14811251761376154, 0.21750875272429848, 0.13230888292322884, 0.14969703603857853, 0.21191405255303797, 0.13175855649475143, 0.12928860573281653, 0.1818489548340655, 0.15767737924915515, 0.15749101317343506, 0.16553392016571267, 0.13783934789699748, 0.16338637479017248, 0.25169234563900433, 0.2064037417424872, 0.019792120935749558, 0.009023254554437532, 9.999999999998899e-05, 0.04862892409330566, 0.038197933317991595, 9.999999999998899e-05, 0.045175039544373075, 0.010728403343120196, 0.0018216382686534471, 0.09602800489014751, 0.1280864041001376, 0.07907001921302503, 0.06759102435909115, 0.07328106061559503, 0.06764453888456556, 0.14888703345781074, 0.10508330469023675, 0.0709158254085287, 0.05982535275268419, 0.1155004459071004, 0.08158923156210507, 0.15893263199462815, 0.09375634425990209, 0.10357687509238145, 0.1189989373917908, 0.09681470273552917, 0.0719729042477395, 0.20001741329021439, 0.15840111966421733, 0.10299786867924954, 0.1001219306734179, 0.12850053664233696, 0.14626144877781955, 0.19511439789816798, 0.10021229832805856, 0.10036955822031446, 0.47396636745162524, 0.4381936871802711, 0.42352009192311346, 0.3982714877102558, 0.42532992824436133, 0.46069895575591113, 0.4796320342294338, 0.42777151728244645, 0.44738386998485535, 0.10504648032313268, 0.10568438020666493, 0.08200966944726784, 0.12936570143360604, 0.1371979874618322, 0.10512486838440072, 0.11059342220876855, 0.14408061022209262, 0.11066179128371623, 0.18340387690857018, 0.2651344470584449, 0.1892182445577929, 0.19128227275702492, 0.2879001638416141, 0.19378147014710267, 0.18529475579068755, 0.1808413330265557, 0.22661625120703843, 0.3410656244374549, 0.31578846246545667, 0.28705347787781743, 0.29749982098839556, 0.26716796983160207, 0.2921071306752919, 0.24474760946040264, 0.25421318593234143, 0.22351459737994406, 0.2382393138190294, 0.21290956458651267, 0.2921755549953202, 0.2431292022189545, 0.1828994951065771, 0.2786429792857904, 0.2102037858109631, 0.22603887800752986, 0.2146238935755631, 0.25079977471984505, 0.2527482678304426, 0.2554868404937132, 0.22330380834549124, 0.24600294295283898, 0.22278681303613668, 0.22623834633109796, 0.271491540564881, 0.22967390725135994, 0.1867976487151527, 0.18194959857281479, 0.1677016156579506, 0.1962128295987543, 0.17822832947351763, 0.1886762678504007, 0.1773838189802358, 0.1970262279433873, 0.1800174512732985, 0.5661297968138601, 0.18652437936755606, 0.18685458946304556, 0.6065932114247439, 0.19766546110995542, 0.13427116465729128, 0.14137055051897618, 0.14670671981498495, 0.819336221220222, 0.5632425957407845, 0.20920729946073557, 0.46810306242686406, 0.3844739753733385, 0.3921092945783702, 0.1664101806950612, 0.16564012167110054, 0.3114314086840788, 0.3362013643200348, 0.1836152837949936, 0.2111357674042924, 0.18777353722990897, 0.20227655209475626, 0.19360536821719265, 0.18156326470431727, 0.18841007289710632, 0.20169862292010865, 0.17561000585269504, 0.09786114386813005, 0.08671151789739817, 0.07898025193535962, 0.09548898849061227, 0.0966542877791493, 0.08374182596254398, 0.08165668507961743, 0.08740066661102086, 0.09797515988092331]}, "mutation_prompt": null}
{"id": "4a44c882-fa02-44e6-b1f1-d30a3aebf6c9", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.fitness_based_update_rate = 0.1  # New fitness-based position update\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def fitness_based_update(self, position, fitness):\n        if np.random.rand() < self.fitness_based_update_rate * (1 - fitness / self.global_best_fitness):\n            return self.best_positions[np.argmin(self.best_fitness)]\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Fitness-based position update\n                self.particles[i] = self.fitness_based_update(self.particles[i], fitness)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and a new \"Fitness-Based\" position update.", "configspace": "", "generation": 198, "fitness": 0.22419490703652048, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6521055211678569, 0.6580284661992116, 0.6146344269138577, 0.5670820987100278, 0.6156042510354108, 0.5920840640025977, 0.609038808287852, 0.6019827752798073, 0.6914996683621855, 0.009475939927370725, 0.020695785109251075, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003894306389598423, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14566396403334636, 0.08582294421586811, 0.09702521098068906, 0.09022722509348091, 0.12041062778577016, 0.11514692182843067, 0.13048663230861623, 0.14299219129435692, 0.11555857987493379, 0.10980792601034117, 0.10562684264137512, 0.08614090343510183, 0.09065352708930241, 0.07882675380463933, 0.09290012253639457, 0.09268998283891305, 0.07615307939607485, 0.0892386517965037, 0.873439400706554, 0.934814356335628, 0.8702966686457483, 0.7003796424195028, 0.8195264911602955, 0.8505815627299746, 0.8786472737987648, 0.8866536502331515, 0.9009639665432557, 0.27057931223891707, 0.2837122336740756, 0.29208579624839426, 0.23636631811126885, 0.24422003638050105, 0.298443130255859, 0.19988853094489034, 0.19861900509077257, 0.23873433966227586, 0.33602513974096004, 0.22934617954482184, 0.21474572529869707, 0.35110559910913175, 0.27160807100954476, 0.19384997587227837, 0.242112879551327, 0.17452074681551388, 0.2579249131996644, 0.12685711991120296, 0.14195617046660314, 0.15908084466559635, 0.11730550962893138, 0.17568010674782075, 0.20189686352424951, 0.1255935091745488, 0.26910613510332226, 0.13105090004713416, 0.17094708800392566, 0.18490662427991633, 0.14610345785979828, 0.20751389453944136, 0.17606485929592275, 0.15210008398795838, 0.18484190408787715, 0.14117042124024648, 0.17603420589675012, 0.0027891007283674663, 9.999999999998899e-05, 9.999999999998899e-05, 0.033718287530205115, 9.999999999998899e-05, 0.027851413257762192, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.12501435328573351, 0.04751759538974898, 0.10764040348763082, 0.0733130182212608, 0.040448163690841255, 0.031162223855335847, 0.07263066035075894, 0.0967910765293638, 0.07939484321967871, 9.999999999998899e-05, 0.016490392516050667, 9.999999999998899e-05, 0.08191485713618929, 0.029054603354744857, 0.0005225681164662266, 0.15470304262916867, 0.12068370311227339, 0.12563317152040732, 0.1648762006243365, 0.18782434072117493, 0.09394925663809828, 0.05627368883771067, 0.10405454334349085, 0.05424827354561623, 0.14380162522040607, 0.12246856645821613, 0.152654246467538, 0.4672332095698267, 0.5278395885445056, 0.45186279259288586, 0.4263554271344394, 0.4513990576222703, 0.41055651540296234, 0.4201451725784222, 0.4483492186167609, 0.4356704826510637, 0.1272607835753048, 0.1097434586942263, 0.08092753983219736, 0.08967371648722255, 0.08561534801380644, 0.1206085746963248, 0.1036115356816728, 0.11721689361426946, 0.10095307984321589, 0.19528421995864087, 0.1686214011736793, 0.1743861569880346, 0.18228067362364775, 0.3215484146234896, 0.22449502228414486, 0.2346991118379601, 0.20155535051170614, 0.25329829342210064, 0.3024633527721482, 0.3411589646535059, 0.2917988072737532, 0.3172796425147194, 0.2565523048921373, 0.34697818254626156, 0.23951578267554552, 0.38181457336118363, 0.27632604910149283, 0.22821019437818602, 0.23482233342379621, 0.2121563835021648, 0.21260072683245912, 0.17953893566292156, 0.32854582984702285, 0.1745276383883131, 0.21092808439424737, 0.21542037666457614, 0.20743262877163915, 0.22109667483374607, 0.21766098618895857, 0.23822515287905766, 0.2304787447963922, 0.2327293091416327, 0.2141912725246139, 0.21219333911582527, 0.22163328080362843, 0.17266270913233495, 0.18840339110019366, 0.18256210792748773, 0.18698309195719331, 0.21079089771066573, 0.17695800295608333, 0.17645744711387656, 0.18098964437591913, 0.18665051835235535, 0.1866981931267242, 0.17761311303190463, 0.7094494258809367, 0.6558198528217188, 0.19306808867318392, 0.1921423270946464, 0.14139821589758672, 0.144215286155278, 0.5079610678063942, 0.4700347009851428, 0.21033920450740828, 0.4723520742842149, 0.47114547687058717, 0.1659040254324805, 0.1652368520754064, 0.1811392016154899, 0.16361541137658553, 0.27099620205876296, 0.18795483848762184, 0.18299410303043506, 0.18571009311060938, 0.19864866864075037, 0.1807939700159077, 0.1984686877451901, 0.2003752249120586, 0.1860427819699153, 0.18594774086607735, 0.08574945496345066, 0.08580245263572817, 0.08351952581888422, 0.0970191123316041, 0.0895536986124098, 0.09542740696990426, 0.09042782204379796, 0.09243963096570518, 0.09244452301234707]}, "mutation_prompt": null}
{"id": "048839a1-ec17-49e7-9b4b-0c8c3f578040", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.memory = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.memory_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def update_memory(self, position):\n        if len(self.memory) < self.memory_size:\n            self.memory.append(position)\n        else:\n            self.memory[np.random.randint(len(self.memory))] = position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    self.update_memory(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                        self.update_memory(self.particles[i])\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                        self.update_memory(self.particles[i])\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                        self.update_memory(self.particles[i])\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                        self.update_memory(self.particles[i])\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                        self.update_memory(self.particles[i])\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Memory-based position update\n                if np.random.rand() < 0.05:\n                    memory_index = np.random.randint(len(self.memory))\n                    self.particles[i] = self.memory[memory_index]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                        self.update_memory(self.particles[i])\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and \"Memory-Based\" strategy to utilize the historical best positions.", "configspace": "", "generation": 199, "fitness": 0.23367620544942985, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6779122383628868, 0.6296912665719163, 0.7184072811085813, 0.6948010121044722, 0.6903048988331397, 0.6406120173040242, 0.5581809388475326, 0.6579669355597317, 0.645879071116347, 0.008088141090962342, 0.03489908275643594, 0.003907104767052028, 0.04186119675378941, 0.02064434425098549, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.14725496654761194, 0.09893049468022286, 0.10688350880097675, 0.09742287292216367, 0.10809849222618972, 0.09991675413595202, 0.13654225894099514, 0.11072025742598979, 0.1083941023138506, 0.10395964600871033, 0.13470417826987813, 0.09055106886383057, 0.1099341792220232, 0.10281976003319815, 0.0788961666378506, 0.12711270650690587, 0.08115919696231266, 0.08696411371247936, 0.8666872233416482, 0.9184648541567142, 0.9060866177873612, 0.7972884487925298, 0.7924799562192173, 0.8720482613578933, 0.8891435583708054, 0.9156880030851582, 0.8206272690254646, 0.3165382578279424, 0.2636644494590463, 0.28098473522041345, 0.22365324703142764, 0.22662420124631177, 0.24844771703708868, 0.27792295305690573, 0.247225447263264, 0.22022520875748564, 0.3683092259364511, 0.8716501952402145, 0.22242067034886281, 0.2728758699667869, 0.2738608801855218, 0.2187455990706596, 0.2322700408454882, 0.21996083897117003, 0.22416624260819296, 0.13448769248219528, 0.11866164413726532, 0.11796236506933622, 0.12321127442682411, 0.12836534345241468, 0.12684966274976572, 0.20044922273235144, 0.12000631777410997, 0.12149691148777342, 0.13839380627161513, 0.17183860515103588, 0.1332961041025792, 0.1707136601287066, 0.1581990035158506, 0.12288713848285093, 0.2321411368254701, 0.18695593418349088, 0.18097193657091037, 9.999999999998899e-05, 0.0009370816967640971, 0.013015271172998055, 0.005316689811253883, 0.023450292325725597, 9.999999999998899e-05, 0.0006731232693389932, 0.0009770608834742678, 0.05730951285784447, 0.10043318968634773, 0.06096257093303026, 0.10991132507292567, 0.07570736270952438, 0.05672558158190588, 0.03246996170007055, 0.1865536441319896, 0.06858472045897357, 0.07881987917764433, 0.16684759544537187, 0.08122886280878794, 0.11954228223953, 0.08696933657142303, 0.1428861875461176, 0.07831983139531418, 0.10510229508225422, 0.11508030923144563, 0.0726724397020122, 0.14423852957547256, 0.20565364251677998, 0.11068147371068204, 0.08756074439644179, 0.14748903317597417, 0.1287533418785608, 0.15121760319844946, 0.14035832215780775, 0.11294770612457306, 0.4767316107202999, 0.43632119513144674, 0.41683918549169996, 0.4164501844274696, 0.39449987504521455, 0.42365024872351575, 0.43024775302542095, 0.45041259389244226, 0.4323449273761246, 0.1027358651457897, 0.13385115207739273, 0.09760705240131595, 0.1480293379911316, 0.12551004650377184, 0.14000177589897977, 0.09818070656459388, 0.11266134720057164, 0.08124357347362365, 0.15605067278091722, 0.20507963380097627, 0.18589317612979483, 0.2405169281045647, 0.24859177254702958, 0.23277961402947134, 0.2161058769312979, 0.1896766523871971, 0.17974867321408705, 0.33224023281731996, 0.247369494516122, 0.31611769383743804, 0.2920597377663974, 0.3451420800295931, 0.2816806610885222, 0.27818830244509796, 0.305979482503838, 0.25192938317032953, 0.22659582603511297, 0.23682498652207618, 0.282970528323474, 0.22532250624555872, 0.204804737439659, 0.24705003084018407, 0.1714546841565967, 0.21087280878659498, 0.2244721507152574, 0.24682346979781478, 0.1959980891329336, 0.2262722327222768, 0.22784817869357554, 0.2002630280929787, 0.25998234403174936, 0.2185612132920456, 0.21124424462247904, 0.2263441531985697, 0.17762876114400428, 0.1743677092977547, 0.19743945121917628, 0.22716705013222538, 0.1857812885433212, 0.17523586225789167, 0.20549407496060967, 0.19322022970269148, 0.18703161874132435, 0.16715695566966993, 0.18637022808007353, 0.18551097472544376, 0.7513767912445275, 0.19890045434844006, 0.19647596797005973, 0.7207805833158564, 0.20779612735816022, 0.5779413523363495, 0.5348219737737334, 0.2100797556209666, 0.357035410586362, 0.4063783517275762, 0.21601445893444104, 0.1684858175244035, 0.16573312941425722, 0.3213695087857724, 0.376885862313334, 0.19388008604865503, 0.18609517235283768, 0.21443313863060076, 0.18760565444781907, 0.20076461912116572, 0.23090084077366835, 0.21302919786160524, 0.20389533230102863, 0.19323582765712333, 0.07932016612923021, 0.08424390774862622, 0.09312810078674616, 0.08111899238579878, 0.08705022393132844, 0.09657672968452957, 0.10216894509677754, 0.09525776151336829, 0.09433742941739653]}, "mutation_prompt": null}
{"id": "a0bedd9f-07a0-4eee-b78a-3c16393a734d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim) * np.random.uniform(0.1, 0.5, size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim) * np.random.uniform(0.1, 0.5, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim) * np.random.uniform(0.1, 0.5, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim) * np.random.uniform(0.1, 0.5, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with modified mutation and perturbation operators.", "configspace": "", "generation": 200, "fitness": 0.22385790564802205, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.19.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6238922696467846, 0.6217889433388035, 0.6662099266734296, 0.679761547344794, 0.6253869116923465, 0.6132666262880143, 0.6914740619880524, 0.5627201849085247, 0.5795198240810915, 0.007067518583363963, 0.05710769134170934, 0.0017858876723976236, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11182349196867158, 0.14868549654101626, 0.13433819749183495, 0.08493119861969367, 0.11897748893495086, 0.11202100780431334, 0.12481632512261809, 0.12056407330736363, 0.08565169687769936, 0.0659252346799658, 0.08826073098999276, 0.09363777580365407, 0.10357224256238973, 0.10358594703414492, 0.07867131567783203, 0.09607974000944464, 0.10746229151041498, 0.08394899327014904, 0.8774065050272498, 0.9248752083813688, 0.8021314865977521, 0.8173378024234124, 0.8308157891234891, 0.792861966745255, 0.9218698656041047, 0.9033730998941166, 0.9122024003956787, 0.2692777458027438, 0.2513453980470215, 0.3007118702274937, 0.29790522446490686, 0.2853622203846681, 0.25837969951779827, 0.25224954530540444, 0.27484756288048984, 0.2603867564536336, 0.31976005244375316, 0.35122447591524364, 0.3108179588499296, 0.24970786073501794, 0.3746707751178142, 0.227227559931093, 0.2393427835877876, 0.23350218286307944, 0.25101884186669476, 0.1239725637943424, 0.10963536080585146, 0.2074478905642273, 9.999999999998899e-05, 0.35787220990202717, 0.30105582355080074, 0.1406420632230556, 0.25846270581764386, 0.14466205882882255, 0.17012400872669875, 0.16309093538803354, 0.1519884286647475, 0.15806406098441317, 0.14436450317697092, 0.12716076631354367, 0.16439250594715193, 0.11974106625856529, 0.1449959649533734, 0.006283342273069814, 0.023984414532677856, 0.016216517107857875, 0.01753203090765998, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007823912734425953, 0.16018667173093948, 0.05866842992225285, 0.15192321549121335, 0.06687461259974459, 0.06595658619855371, 0.035586749180898325, 0.12580963406705648, 0.06328472174508426, 0.051580230866437926, 0.11348461622560957, 0.08630581633014445, 0.14847714991235827, 0.07652951719623546, 0.09564252014726737, 0.06805744288865245, 0.2442432367707703, 0.16550509081819076, 0.0678274046106877, 0.17825548477324826, 0.25098140002298763, 0.20623716132439884, 0.1847534927590978, 0.17913403653244808, 0.18095702813298553, 0.18790249974186934, 0.11003153786847342, 0.13132774134718872, 0.43259183464169815, 0.41765419833191764, 0.4563019063275019, 0.38102308331718293, 0.4118191524383181, 0.44417891244707686, 0.42803327463006036, 0.4213621094186003, 0.4127038905019088, 0.13160214651231694, 0.16908589847232436, 0.07912232758107296, 0.14645760743959668, 0.12796323904275508, 0.10931033620958497, 0.11427342169766108, 0.139692851580975, 0.12019203840157555, 0.16568003217434868, 0.20073246689651592, 0.1628301737598178, 0.1646713161692831, 0.30935491837142304, 0.14872515814271903, 0.20747122165615994, 0.17631047626468122, 0.21179239816404027, 0.3071234750456503, 0.34189130946144164, 0.3134423973223456, 0.29878385147733166, 0.29278516703254154, 0.27778503440058266, 0.24883052433751063, 0.31491071994011666, 0.25635669227934366, 0.22919229045861067, 0.18351273514377686, 0.2251367090814399, 0.2814741957313053, 0.23427591384225643, 0.25378267254710063, 0.19089143213694837, 0.23026404015789825, 0.20632287230210566, 0.2152729127817884, 0.23871148378182505, 0.21697733331473334, 0.20083035901464996, 0.22726008700165345, 0.2350784986198351, 0.21763595966785165, 0.22620945161738537, 0.2300566885582782, 0.18289539787780706, 0.20143942582325658, 0.19202677512265287, 0.22095061628680868, 0.1821855709377488, 0.18275497842780386, 0.17373477239519175, 0.18051609549682213, 0.17399442869423032, 0.1843886037209037, 0.18532914401243283, 0.18606235600100918, 0.16797166362392368, 0.19908069891329694, 0.1956558280388565, 0.14115075458621051, 0.11734760505242559, 0.16485358852666954, 0.3787538927756987, 0.20997728049911868, 0.07332093011484264, 0.5141136882911878, 0.3202703531551243, 0.1668172347822845, 0.16725865946583784, 0.16478512398702916, 0.2797091840122914, 0.20113243406935655, 0.18761366256122614, 0.18400744669074232, 0.20809891149065118, 0.18893666246535135, 0.2002360156804771, 0.19040218871921277, 0.18751365894703076, 0.1919660825757592, 0.0863373879350049, 0.09658855131305644, 0.08219130681152564, 0.08354014664863862, 0.08823111691280883, 0.09343148852594763, 0.07972883291255206, 0.10496856357031736, 0.1056228698609919]}, "mutation_prompt": null}
{"id": "35dcb4e6-8dcf-432d-8e3d-c131478b23cf", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.differential_evolution_rate = 0.1  # New differential evolution mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        while r1 == r2:\n            r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        mutant_position = self.particles[r1] + 0.5 * (self.particles[r2] - position)\n        return mutant_position\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Differential evolution for enhanced exploration\n                if np.random.rand() < self.differential_evolution_rate * (1 - evaluations / self.budget):\n                    mutant_position = self.differential_evolution(self.particles[i])\n                    mutant_fitness = func(mutant_position)\n                    evaluations += 1\n                    if mutant_fitness < fitness:\n                        self.particles[i] = mutant_position\n                        self.best_fitness[i] = mutant_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutant_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, and \"Differential Evolution\" for enhanced exploration.", "configspace": "", "generation": 201, "fitness": 0.23183371472431583, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6443229751003332, 0.6299225035511751, 0.7433518402977826, 0.6180950023631496, 0.6063634037811791, 0.5619568611543349, 0.61383603524842, 0.6162483144251752, 0.604272506227614, 0.0015854326124188356, 9.999999999998899e-05, 0.03284299180750827, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.00041129101676218305, 9.999999999998899e-05, 0.14467132032867336, 0.11098572019565767, 0.15879003890850107, 0.09710395172734876, 0.0953650122323183, 0.10303516576148031, 0.12747375636990788, 0.12637925369249337, 0.0963867920467435, 0.08106145259743625, 0.07352778641297386, 0.07060259471564079, 0.09935386594564266, 0.07812290027262903, 0.0957051924901614, 0.08748386996688462, 0.07012509137218037, 0.07994836840990538, 0.885540000207733, 0.9390843125931196, 0.8699688996786935, 0.8026183966079952, 0.7752727958275709, 0.7549326763037641, 0.9210110038666982, 0.9038481997604456, 0.9097151454503045, 0.2686567016265621, 0.2409015134596807, 0.2849416754284817, 0.2884276118311452, 0.24438667225173716, 0.275856848047641, 0.24180791040119187, 0.25480468651429544, 0.26537739711898334, 0.21824596922261308, 0.23855196451631977, 0.2827623909865402, 0.8597558458861221, 0.30876177723181264, 0.20387348553819362, 0.26856687538970714, 0.23139380295765, 0.22735888496578804, 0.13513065371818633, 0.14622489672197425, 0.24712181501483277, 0.09073829172509673, 0.1435991108800403, 0.12413601389224316, 0.1297834535078004, 0.12264970994624413, 0.14750271897939038, 0.14953823533614086, 0.17127188255407966, 0.14594042131055174, 0.20482128009046907, 0.14401428857100906, 0.21215352098811158, 0.17136923732937426, 0.1737159583725646, 0.15026299428774237, 0.02057660426299668, 9.999999999998899e-05, 9.999999999998899e-05, 0.03503522568108475, 9.999999999998899e-05, 9.999999999998899e-05, 0.0011722194555935372, 0.004684509427470007, 0.009191630031336495, 0.1273661187360321, 0.08752136144113298, 0.1128590278238416, 0.09182954070113358, 0.06844573667292575, 0.04262308783881252, 0.0743870406879259, 0.039144898883983426, 0.10013917822921925, 0.11574773154549023, 0.06433008920896388, 0.08746427114324373, 0.10597186716296714, 0.13232999074710083, 0.061315756435056934, 0.11864344480868072, 0.12301139492819058, 0.07917906121682261, 0.171533681344326, 0.1851681901294141, 0.09014743800192859, 0.0968739338315685, 0.1145552148338369, 0.10841979671511548, 0.16667998082363522, 0.09292202980649344, 0.08646900519378664, 0.4549101621456557, 0.41702953940149534, 0.4006789964832186, 0.44494607765488126, 0.4515925087738206, 0.4057951656438368, 0.42572550219289473, 0.44354634545745864, 0.43193874971635915, 0.11775542432222796, 0.1490119032431787, 0.0745884773362182, 0.14271494726431921, 0.14809839852809492, 0.14655749037916344, 0.10951975414674031, 0.11015351054017897, 0.08978943216046331, 0.16086769759650854, 0.29318642020223484, 0.2675679471289485, 0.24733425572474932, 0.23950092538093737, 0.21741723045640915, 0.21070621885407892, 0.1831137783432114, 0.17345503983706878, 0.26601324278046823, 0.3265404450849091, 0.3536167714249293, 0.24370402834567062, 0.3441812060322983, 0.26550792392393163, 0.24885791321916395, 0.3101925638272155, 0.29985595004205245, 0.21703692732890745, 0.28161282750561123, 0.3167789722608587, 0.22228882961597496, 0.24779284334232277, 0.22490121129567697, 0.17980580967201043, 0.22431967366447403, 0.22991831290185805, 0.2309876418183241, 0.2504327335624159, 0.2111688901424208, 0.2329671714418149, 0.21790351566634192, 0.258011365001505, 0.24116999886772317, 0.2316444939684894, 0.23471126065207604, 0.1728617884511625, 0.19729058374919628, 0.17765704621996448, 0.1781951631169466, 0.21533190649260625, 0.17895819049761508, 0.19232601554817452, 0.17753840076195504, 0.18009148771908623, 0.18550427889116694, 0.18610251689200796, 0.18510930458539043, 0.757305021090505, 0.19967463676321962, 0.19568738109014816, 0.14073133076591837, 0.15563854176762126, 0.812185159390859, 0.44178507001184464, 0.16770319257553423, 0.37143869921922845, 0.2152018823317252, 0.5098462001279416, 0.16492233840633785, 0.2917207338029588, 0.5016600533451855, 0.4075596599562399, 0.1819727426676413, 0.18797236868209655, 0.18575138585351536, 0.1905726776952058, 0.20728501611760286, 0.1911141284749086, 0.18902177175233392, 0.19465829958737535, 0.19354982388056519, 0.09083316466611746, 0.1470784062281928, 0.08835970279697247, 0.08913731753607257, 0.10322485610979859, 0.0916578879043407, 0.07698032039855607, 0.08963686916879687, 0.0853563593786093]}, "mutation_prompt": null}
{"id": "73057caa-68af-45bb-8345-89f928846769", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate.", "configspace": "", "generation": 202, "fitness": 0.24090831989383463, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV10 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.21.", "error": "", "parent_id": "873a1d1d-0820-4cf3-89b4-38099856775d", "metadata": {"aucs": [0.6386249390574341, 0.7122559126350987, 0.6377788659493873, 0.6926209547226799, 0.6520114253709631, 0.7132067766020316, 0.6348534504478678, 0.6191901567215805, 0.592465320228737, 0.024679519786949267, 0.03645690910483612, 0.0011111814915557572, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13780630048902842, 0.09656645551993936, 0.13477204270905874, 0.10362598445282112, 0.11196036955602429, 0.09609079672859444, 0.1600486979847574, 0.13646991844454037, 0.09825969987080807, 0.07966456970704416, 0.07914817408856056, 0.08186795349707832, 0.10825888174600751, 0.08823557191291898, 0.09001495494345979, 0.08196498366181348, 0.09266047127583787, 0.10285068433318378, 0.8862883078252074, 0.9370801703511664, 0.7786775686829607, 0.7099685084022584, 0.8948201347233677, 0.7771455306214063, 0.9061958652309449, 0.9084806348959552, 0.884200735555955, 0.2949993598015107, 0.2691909428999455, 0.24652896345225206, 0.26704882447951817, 0.2635789254825356, 0.27909839814763493, 0.2662552216626275, 0.22798515108484485, 0.24305752710412998, 0.3196442234111221, 0.6366063661149386, 0.3086247536179745, 0.27474859568369936, 0.6247469688421821, 0.20135108083119535, 0.3467394195217376, 0.21849297623132258, 0.21875625075094673, 0.09199466458308703, 0.10960178281087829, 0.12132244540659232, 0.16463625689459183, 0.12396790928063006, 0.13731320590841856, 0.1273176594485279, 0.22726809062643205, 0.16201407112745692, 0.16617042130310933, 0.2414306241810703, 0.15201196128535044, 0.1719929348283067, 0.1551664833610934, 0.23295941103456252, 0.18034042503631464, 0.18879785855949194, 0.1518720696230348, 9.999999999998899e-05, 0.0011020093610936144, 9.999999999998899e-05, 0.008718793500386846, 0.01747849900090881, 9.999999999998899e-05, 0.003128726440912888, 9.999999999998899e-05, 0.033275590690664436, 0.13331936829673052, 0.05971427866010004, 0.12629717914505634, 0.10470182812258988, 0.0951911167954026, 0.03186737676150586, 0.14987521507451496, 0.09855362398076395, 0.07826258906797501, 0.08671533006602372, 0.11215062981948554, 0.13041068206852013, 0.0710494306819377, 0.11437037765416591, 0.08169589076673966, 0.10604583598994288, 0.08743970009638957, 0.08836336386713306, 0.21393494888326325, 0.13607340861518247, 0.20756819657504544, 0.08691832265740107, 0.18081510774518017, 0.1368374349608461, 0.15291986617899234, 0.11652459860980358, 0.12446182175435805, 0.463372102538255, 0.433399625218018, 0.44247201782309564, 0.4300868766305954, 0.41200024774359767, 0.4505319333867429, 0.4575187811924477, 0.456986903673513, 0.47993352778037557, 0.135035565593993, 0.11305789328124116, 0.11743959890592104, 0.22472954864688022, 0.11294422207352095, 0.13518145315863161, 0.11045755864263851, 0.10651225820585553, 0.0933995473088084, 0.31388794094739236, 0.17409371795952067, 0.16839356973102093, 0.21334749466293967, 0.3676312157930425, 0.19530001770475347, 0.2702252734580408, 0.16141544450109502, 0.17720496451230916, 0.250808305199376, 0.36020270217042005, 0.3248689229871, 0.26665990517830485, 0.32839280700564777, 0.3092224933994562, 0.24783167866926648, 0.2805906445728925, 0.254357002711626, 0.23141387219830412, 0.265171409315334, 0.257138216300028, 0.1805067883060396, 0.24267916024545833, 0.29197838868016357, 0.20783052408924596, 0.2387047009595069, 0.1992739628340786, 0.20447583091976307, 0.2126109805172448, 0.2278122451616308, 0.23041290754116184, 0.2523945838387811, 0.23294071637726754, 0.22614231776713145, 0.2045073137044331, 0.21575141150596933, 0.199066436276213, 0.1864197664552707, 0.19394138111960313, 0.19093778297581276, 0.19754426797922975, 0.17520784627725483, 0.17380063588568195, 0.1785446481692997, 0.18684271240727313, 0.18022952568681505, 0.1864715566537517, 0.7380177452688015, 0.5676752474156956, 0.19874542375478388, 0.19892518810395055, 0.7241386789126847, 0.14660819109946133, 0.6749239209028202, 0.5633322954044908, 0.20865044712138725, 0.3755431124902271, 0.46578815615210967, 0.4562485731097481, 0.16776094890266813, 0.16756363149122766, 0.3368885032926522, 0.3284222275383408, 0.19241443488296017, 0.19700028818297055, 0.1890545384704404, 0.23036050321992585, 0.1874895760699652, 0.1906825018984044, 0.21714723145583792, 0.20324663537176346, 0.1802820347758487, 0.09592521735176573, 0.08106894997339698, 0.08741510025611055, 0.09308135181278099, 0.08559172428634287, 0.09227907309546868, 0.09295188380897035, 0.09715264870431928, 0.08478271373597401]}, "mutation_prompt": null}
{"id": "5020faf0-8cdf-4d05-b5fa-2af6fdbcd723", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_directional_search_rate = 0.1  # New multi-directional search mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def multi_directional_search(self, position):\n        search_directions = np.random.uniform(-1, 1, size=(5, self.dim))\n        search_positions = position + search_directions\n        search_positions = np.clip(search_positions, self.lower_bound, self.upper_bound)\n        return search_positions\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-directional search mechanism\n                if np.random.rand() < self.multi_directional_search_rate * (1 - evaluations / self.budget):\n                    search_positions = self.multi_directional_search(self.particles[i])\n                    search_fitness = [func(position) for position in search_positions]\n                    evaluations += len(search_positions)\n                    best_search_index = np.argmin(search_fitness)\n                    if search_fitness[best_search_index] < fitness:\n                        self.particles[i] = search_positions[best_search_index]\n                        self.best_fitness[i] = search_fitness[best_search_index]\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], search_fitness[best_search_index])\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel metaheuristic algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Multi-Directional Search\" mechanism.", "configspace": "", "generation": 203, "fitness": 0.2274675493437432, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.5573393815205459, 0.6283972297327883, 0.6098708450729013, 0.5510526825619708, 0.6581236853712888, 0.5714971456233566, 0.5162601890283958, 0.5338372330635193, 0.5882191096891598, 0.036541645426409586, 0.055221495106706264, 0.01000222145525298, 0.0020265635670162485, 0.011892180951270759, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10487106249775113, 0.15404548475567148, 0.09116784415680812, 0.10126892229935969, 0.09032750122388766, 0.13986494059246468, 0.12216653815113843, 0.12120545884779788, 0.11925519744542268, 0.09220995285778077, 0.0979059719524974, 0.0864979770382257, 0.09072153182014886, 0.08358121423077824, 0.09112104633279983, 0.10766081963378582, 0.08154433259012006, 0.08367914622705797, 0.8012170515795516, 0.9090934517529075, 0.8826734818986157, 0.7194933522711171, 0.8068099863006419, 0.8668009678632242, 0.9137853516484529, 0.8658058038503254, 0.8006693391092065, 0.23686801247360223, 0.21804343295723572, 0.21855284970638778, 0.23075585831942302, 0.24481770930253532, 0.23813196385113367, 0.23728201464592857, 0.23570170937100543, 0.2220610790316757, 0.2762764804308796, 0.2999834501946955, 0.21889729709602812, 0.2707376201619839, 0.3512081547338325, 0.2251656570961551, 0.22349109227696662, 0.22321428211457028, 0.26287248902663285, 0.16462591351195155, 0.12423098281961242, 0.11027150872330571, 0.11166896212338084, 0.1259134184203261, 0.12968727538193525, 0.1462448980287805, 0.13798595284626936, 0.11906860901268446, 0.3246961448543294, 0.13892666754848448, 0.15293918400706075, 0.1320949269517805, 0.17993168388565495, 0.16704379347062293, 0.16746620871207574, 0.170910290954137, 0.12981480795496614, 0.016437971348057134, 0.039759706287140206, 9.999999999998899e-05, 0.06847811332856113, 0.03235393050112345, 9.999999999998899e-05, 0.01784563759231428, 9.999999999998899e-05, 0.019878628940913634, 0.11415317081935406, 0.06527520144525112, 0.08985655469023424, 0.08768645864701541, 0.09718403578260115, 0.03706989487882473, 0.11424075102837994, 0.10409105062706892, 0.11593454396909841, 0.05150148240365815, 0.059165439517665286, 0.12018622079588126, 0.13261032664302552, 0.15613372913066637, 0.06094631852461774, 0.10715882132330357, 0.0846760738130099, 0.07477852448263189, 0.21233609950356547, 0.14632654176395676, 0.09896892373439059, 0.09163336443641257, 0.18900878907300833, 0.13885584054707756, 0.10134506214598837, 0.1508113665259354, 0.08139999987975333, 0.4526541961438588, 0.42273830216102115, 0.4297981272895014, 0.3946341135268815, 0.4375894259352475, 0.42044481809100165, 0.4195033646433457, 0.3939814808501192, 0.44949985546487525, 0.09554613223611741, 0.13206157047860578, 0.10125017476918241, 0.09160839784507513, 0.09905232797176211, 0.1038400257622728, 0.09830436826605671, 0.12960565594745876, 0.11152225127524051, 0.23299951634105776, 0.1581315021382418, 0.1787640230744313, 0.1907265828500465, 0.27695807275373063, 0.21191677821038657, 0.2230791868178208, 0.15525010923303273, 0.2014384847917886, 0.2656758023043865, 0.2940175096576312, 0.30270286174168437, 0.29634369359255563, 0.29027002252284506, 0.28875711136633586, 0.2616859016286671, 0.32055329130211263, 0.23770555409181537, 0.22938440384605596, 0.2953967951975671, 0.2741454951306137, 0.2419259424321557, 0.2681732858922319, 0.25431865123185504, 0.22543008808417497, 0.26217870391146325, 0.20180084205063353, 0.24257891905094897, 0.2247639478563508, 0.24532402134989673, 0.23757864123996464, 0.23025872730687202, 0.20983986812904765, 0.21763437837408306, 0.2449145022414958, 0.2292653106791751, 0.1797914429710621, 0.1884222034624754, 0.17851027115477913, 0.18212063846197646, 0.17533184627429088, 0.19503444446981255, 0.19949314396829543, 0.18723358359783515, 0.1724191897203422, 0.7191710331997893, 0.1845425029992408, 0.18442757305991164, 0.5793194895331465, 0.19854339369011542, 0.19321303805288204, 0.14047533721814653, 0.1677302281489399, 0.7385450631508903, 0.5818553833730153, 0.20736268459576845, 0.4127325858251879, 0.556454182665298, 0.16642998041818646, 0.4541133345016797, 0.3423352709545583, 0.3192723025830927, 0.3389652036330656, 0.1834655015518527, 0.1898874382416169, 0.18543617658910938, 0.18196661156275162, 0.2032973797117863, 0.19382324733573897, 0.18772277969350526, 0.19064650881741418, 0.1940919469668041, 0.09220156892239861, 0.08422286973020687, 0.08250765488582545, 0.07406793120185462, 0.09097721504621459, 0.08453626526143032, 0.08773875133310338, 0.09266535621434124, 0.08227069319136593]}, "mutation_prompt": null}
{"id": "5debefbc-ccce-4e50-a1d3-5c7bb3d41a10", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective approach\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_objective_approach(self, particles):\n        f1 = np.sum(particles**2, axis=1)\n        f2 = np.sum((particles - 2)**2, axis=1)\n        return np.argmin(f1 + f2)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Multi-objective approach\n                if np.random.rand() < self.multi_objective_rate * (1 - evaluations / self.budget):\n                    best_index = self.multi_objective_approach(self.particles)\n                    self.particles[i] = self.particles[best_index]\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Multi-Objective\" approach to balance exploration and exploitation.", "configspace": "", "generation": 204, "fitness": 0.2272028907644249, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6125456249023405, 0.6720402568468005, 0.6177494165821986, 0.6447296803629847, 0.60303965675693, 0.5097521755681167, 0.6107911371729444, 0.6406476065072169, 0.5717075988180484, 0.03492066905270563, 0.04500298814767245, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.005473571070861771, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13613404456816192, 0.08110973496975626, 0.07431373002161512, 0.10698811726625723, 0.0903206738638146, 0.16668482240160587, 0.11544696620476047, 0.12053764761128283, 0.13611872603832564, 0.07164347876989197, 0.08724221764854301, 0.0702645113410697, 0.09070072064617707, 0.09695270761212682, 0.08494984676292039, 0.09248243896575425, 0.07522239431830113, 0.08408924364269299, 0.8724957779329077, 0.9213881519765229, 0.8652524885999322, 0.6720212314094499, 0.8150936213190156, 0.8427235291868914, 0.8718313660569259, 0.8864080726996176, 0.9090522973089419, 0.256545466052438, 0.28610240910218476, 0.3002841325173917, 0.2471831293758845, 0.2491487630203455, 0.27056503987854186, 0.2981394466487135, 0.23971087391382884, 0.24570170797582047, 0.3075364688394632, 0.2632951657771132, 0.22634026701861487, 0.3316339351147486, 0.3505731723965484, 0.19770135595505922, 0.31289532312720425, 0.22506514236693653, 0.2333053239654317, 0.12537894769434954, 0.14538870529727188, 0.13707805118405192, 0.09139747295894363, 0.31348843291249373, 0.11817686260839677, 0.12416684416590829, 0.3544963129623161, 0.12584737932702306, 0.19107962916695842, 0.1738024274622577, 0.16097320887572952, 0.17152256689245826, 0.17502191333246686, 0.17314406900771595, 0.1600733878280307, 0.16392084452805133, 0.17610412456433733, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.020535382831221582, 9.999999999998899e-05, 9.999999999998899e-05, 0.04948371011416852, 9.999999999998899e-05, 0.015812694233321434, 0.1508269530792975, 0.03973846920676083, 0.09431237384021807, 0.07622902218962568, 0.05294291996109679, 0.03392591630291153, 0.05287356174417024, 0.07359834166284895, 0.08009768583228483, 0.14347102182789517, 0.07983495040476885, 0.053194957428113976, 0.09349193369146236, 0.10350688783819861, 0.10826431816213677, 0.15025617630787635, 0.09189064362123978, 0.07262400998436569, 0.1650023308956997, 0.17121290329614147, 0.09390824612763404, 0.13808479145571217, 0.14115311278281129, 0.14915699906199498, 0.14584920008456614, 0.20169591756821081, 0.18343159313631874, 0.4570194239501597, 0.457690860210451, 0.44433816482722643, 0.4293490731363572, 0.3886754294828382, 0.41690411177878073, 0.4054905335419887, 0.4225318317289243, 0.43208019320889823, 0.10442011530412199, 0.09265679188882914, 0.08180815917145468, 0.09174452714240289, 0.10555280426584701, 0.1045893396924843, 0.10759516231417166, 0.12832730026507377, 0.0887788279070224, 0.18486088890356334, 0.1745785071350694, 0.1593148693078481, 0.16425977831726435, 0.27624542463270607, 0.23627921316791778, 0.2558411800758539, 0.18761973685602673, 0.24168836132171623, 0.34751438725442074, 0.3137085861299814, 0.2746291817808969, 0.3294408275051023, 0.25705387453663875, 0.291065601606738, 0.25077615264990316, 0.26402206632251757, 0.26372326828209547, 0.208217380008205, 0.28964969724879597, 0.22843809024868633, 0.1958721848446915, 0.20109924579217764, 0.2800072424396237, 0.21180431283986678, 0.19496746395166875, 0.20926988941866653, 0.24099161321673723, 0.2229928867751767, 0.20897368319928533, 0.24651392037524134, 0.2114851124865854, 0.2123383989373785, 0.21351564988554417, 0.2260810310648932, 0.24158409436638706, 0.18116160125968117, 0.1815692377972178, 0.19271186285331998, 0.18670468530058493, 0.18722754641711248, 0.18094078604473085, 0.1847008401459167, 0.20622880283620337, 0.17169605070938376, 0.1863626321249663, 0.17812994311105357, 0.7157472826485952, 0.7328468528316919, 0.19651638190982623, 0.19402054188348505, 0.17554483815812505, 0.2130599462054621, 0.5830746052660043, 0.4453431551954067, 0.2098727567851303, 0.5745866463134668, 0.3544476311004523, 0.16573834817328625, 0.1654769958257617, 0.16731600607103758, 0.13494125594212125, 0.25777360398099547, 0.1903238126878526, 0.19315142208428138, 0.1893321247600085, 0.19387629674108353, 0.1791342373870719, 0.1863273795713466, 0.20258175700103598, 0.1879071274704095, 0.18663720999556976, 0.08556851855521797, 0.09296998804869583, 0.09602593746832677, 0.08561077000917394, 0.08889767886269051, 0.09761811704916712, 0.08917511026361713, 0.08583658886872403, 0.08886876927739651]}, "mutation_prompt": null}
{"id": "59129202-7678-4d64-8445-a113a7291111", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.covariance_matrix = np.eye(self.dim)\n        self.covariance_matrix_adaptation_rate = 0.1\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def covariance_matrix_adaptation(self, position):\n        self.covariance_matrix = (1 - self.covariance_matrix_adaptation_rate) * self.covariance_matrix + self.covariance_matrix_adaptation_rate * np.outer(position, position)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Covariance matrix adaptation\n                self.covariance_matrix_adaptation(self.particles[i])\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.multivariate_normal(mean=np.zeros(self.dim), cov=self.covariance_matrix)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Covariance Matrix Adaptation\" mechanism for enhanced exploration.", "configspace": "", "generation": 205, "fitness": 0.219174280032524, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.5332852534120338, 0.6150080895347401, 0.6176350516488693, 0.5489133396601807, 0.4991894798229888, 0.4897671563989058, 0.4809631889526401, 0.595105651172676, 0.5785801787541629, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.1042267071124916, 0.1215636498645839, 0.10326781939251162, 0.08437517017392204, 0.11085351549791578, 0.0944524049620099, 0.11578850856696332, 0.14141779004557553, 0.12377008497485154, 0.06674300028930924, 0.10343939609387931, 0.07647512153346292, 0.09778255843795391, 0.08311948654631118, 0.10244578839305774, 0.13500838671833426, 0.05844132451845563, 0.07744304145844294, 0.9449491066354014, 0.9656957695545777, 0.9361747866339203, 0.931975084714523, 0.8668959404453426, 0.8959101261447114, 0.9540839255633269, 0.9530277937341964, 0.9434248220629011, 0.22539414162882387, 0.1647993777652086, 0.2525181224323336, 0.2186256584144477, 0.25113626492474717, 0.2064772037440693, 0.22168790306685637, 0.17646172337866994, 0.2263255812150976, 0.4363373844590036, 0.3830179274768697, 0.2910937756745757, 0.21322075457023426, 0.33191519745599785, 0.1949097472440371, 0.2004799916838893, 0.2300038129471682, 0.21038863320741796, 0.11980733513543351, 0.13244716352669417, 0.1347090980134873, 0.12486106532132457, 0.23353208004025172, 0.1376395220623281, 0.17941553512602293, 0.11062284042597403, 0.16145444288400324, 0.18158873729295832, 0.16778195640325289, 0.16015567477736092, 0.16483925527946863, 0.1543777197332049, 0.16824368360403952, 0.17324227022253214, 0.19321812254245496, 0.13870282094058062, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.02606006186120635, 9.999999999998899e-05, 9.999999999998899e-05, 0.06883625976548191, 9.999999999998899e-05, 0.00525965238841597, 0.07782199721936245, 0.030135082377181766, 0.08557858189095569, 0.1606597948303532, 0.07721181101063579, 0.04530985117301389, 0.057125400246169966, 0.08015388832851145, 0.09955249467509875, 0.12205228789586875, 0.059120445935709864, 0.09174439727946226, 0.06610779335104489, 0.06598065163412392, 0.1572474321045889, 0.0815743041887772, 0.0377899616841072, 0.05555346782981563, 0.20737840676312957, 0.14594639376905705, 0.15485312639182958, 0.10068526070860118, 0.10306461494323471, 0.1257316948441004, 0.11915928414688604, 0.08903774229689465, 0.11644612032783352, 0.46712650301205916, 0.41945115557279555, 0.4192571627280295, 0.45034832086901766, 0.4217130283892562, 0.36488785599139484, 0.5337607294848754, 0.40242099153661437, 0.4270285601789947, 0.09763707603379956, 0.1570367576099445, 0.07334472966456773, 0.07995930204738666, 0.1529265147566159, 0.10629370692847484, 0.0769894378067505, 0.09240406693206116, 0.07425863187393866, 0.19955131969493056, 0.17722705622981028, 0.28757928978076097, 0.16302309183713715, 0.3104435003816721, 0.1665104077681936, 0.2369754676529655, 0.1553531190941565, 0.2016288088044611, 0.2646295027986577, 0.25748561406774173, 0.27408846212922977, 0.2727481654826769, 0.2834068064986872, 0.3215434428858923, 0.25970442268384075, 0.3119359934957503, 0.25150726314687133, 0.20893957658820572, 0.22568021906894875, 0.24322545358681513, 0.2090536143206475, 0.3120263974378339, 0.21479834528039188, 0.1501269843007753, 0.20346072871462006, 0.17637431218999466, 0.233047912619204, 0.20933834831795928, 0.22648889768024116, 0.23513986426335098, 0.23375065739488954, 0.23508402880312007, 0.22252763704376088, 0.20725849671257124, 0.2192593210529329, 0.17079284281951967, 0.19148628165750026, 0.2008146595326864, 0.1919359969375688, 0.17988115235409752, 0.18708132955558188, 0.1954366320491978, 0.17011061149397577, 0.1816496319559905, 0.1823378763504777, 0.17446154036707284, 0.18595132491804045, 0.5498260452695705, 0.19798576429765458, 0.19521625535768072, 0.14132725148305358, 0.12643193458735424, 0.38062010885985564, 0.3722400004953391, 0.21060571598797173, 0.47972825385060835, 0.40648850110438717, 0.29231262621374376, 0.17065665407150676, 0.16589345126526556, 0.31066453366127667, 0.24854592935927777, 0.20900748863118557, 0.2017525542080041, 0.20263163889200209, 0.20556385827431745, 0.1911262706555099, 0.18531936625190715, 0.17319958250798406, 0.19090272359581972, 0.17341366908606437, 0.09514331061122194, 0.09847697646706488, 0.08663777698534736, 0.11750903007864766, 0.0912128687293593, 0.08592896907663872, 0.07794601112020005, 0.09058383396808944, 0.08972930489488695]}, "mutation_prompt": null}
{"id": "72800f63-f251-4d35-b699-ece98accdf83", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective rate\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_objective_update(self, position, fitness):\n        if np.random.rand() < self.multi_objective_rate:\n            new_position = np.copy(position)\n            new_position += np.random.uniform(-1, 1, size=self.dim)\n            new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n            new_fitness = np.sum(new_position**2)\n            if new_fitness < fitness:\n                return new_position, new_fitness\n        return position, fitness\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Multi-objective update\n                self.particles[i], fitness = self.multi_objective_update(self.particles[i], fitness)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and using a new \"Multi-Objective\" approach to balance exploration and exploitation.", "configspace": "", "generation": 206, "fitness": 0.22993038410911099, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6642544210122404, 0.6657620545656641, 0.6681363549718762, 0.6123345534375106, 0.5515704490863442, 0.5843793956380399, 0.5970904021775149, 0.6196864612187138, 0.6341879553003082, 0.011855098302643974, 0.01003151613732467, 0.001590741917039451, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05025566070199261, 9.999999999998899e-05, 0.12263316333627206, 0.08807392090535049, 0.139988540170512, 0.11522896925182358, 0.09495638835257758, 0.14686774993138318, 0.13039599625788922, 0.12245769392838046, 0.10147995442842761, 0.0895965052919202, 0.10570984032299524, 0.08383961306263232, 0.07025232745544074, 0.07774047095330339, 0.10358210412602331, 0.15532151369776404, 0.08232842563859066, 0.09765678471846717, 0.8766182067257018, 0.8976545276674036, 0.8846703699117675, 0.8418530445384949, 0.8219463851685059, 0.8763580715416123, 0.9217758422578752, 0.8934818250670469, 0.8727366204209684, 0.26382215612174076, 0.25940568808732944, 0.2576727079076191, 0.34316341581294396, 0.2635585621373816, 0.23975313761764128, 0.24990342918479835, 0.19212078658646348, 0.25119216558307367, 0.22821418400769278, 0.3343308597694993, 0.23279636322560615, 0.2759539226950577, 0.37401190003820517, 0.20165399163244468, 0.2304085078221243, 0.24070933405578765, 0.2267382089854294, 0.10103359789565569, 0.10732974791680172, 0.11776668657448386, 0.08382030393082873, 0.2577669426953957, 0.15949368666631347, 0.2258648961598283, 0.2252544862244803, 0.1335891220745954, 0.20078006519439828, 0.15483073881471066, 0.14675019337162887, 0.1580301660563055, 0.1621585253070813, 0.15164297447802022, 0.154326020698488, 0.13632022771932373, 0.2319091403968463, 9.999999999998899e-05, 0.0019651925462434994, 9.999999999998899e-05, 0.017844770960498302, 9.999999999998899e-05, 0.0021956717225295463, 0.041130738477480056, 9.999999999998899e-05, 9.999999999998899e-05, 0.15845572223887683, 0.060624951508362446, 0.11148915422511907, 0.12158088169186199, 0.05689964607376574, 0.038982220366864384, 0.10885305525757871, 0.06421825093191069, 0.08143967137207764, 0.13387125060693672, 0.1108706287409652, 0.11269302080763832, 0.12587478500094618, 0.10795062019012325, 0.06823183053486648, 0.17306669630079652, 0.10742607522139458, 0.048205773334701774, 0.24734549813219697, 0.11766773844586931, 0.1473923363944466, 0.21535432753328865, 0.1070860589285616, 0.08794722653789488, 0.16884041994396048, 0.16655620416763817, 0.12343625443421424, 0.47529343273933966, 0.46648919497139607, 0.42398469036352227, 0.42196809453446704, 0.3781713092981589, 0.4104271362120274, 0.43653658896924363, 0.40273404196259754, 0.43362306922959604, 0.10296672293868836, 0.11532798294244473, 0.11144737603987687, 0.14689577271221133, 0.11932498384576762, 0.10280753630043504, 0.1608872850133405, 0.09027074776596689, 0.13183318917752695, 0.28999980066575404, 0.1713900502639557, 0.19529030303892347, 0.172401872828562, 0.31025910342978613, 0.30548570179191714, 0.27362709052460543, 0.2387975459207059, 0.19068794901551467, 0.3112223303658962, 0.2873350294905439, 0.2631752041371702, 0.32962577405146865, 0.3215317486626804, 0.26969935361387076, 0.2656820037007941, 0.27194749426125053, 0.26481167468219613, 0.21834287005145314, 0.24284922341856408, 0.2967393319245988, 0.1812385842927564, 0.2655992071419654, 0.2562280921253387, 0.1854145741635802, 0.2500860299446799, 0.227924865292083, 0.20604460555825255, 0.24138083086067097, 0.21653714824079462, 0.24154803210621056, 0.20719439508697246, 0.22195764859791267, 0.22037614750775614, 0.2061916058128298, 0.23694981675359905, 0.1698698222784666, 0.19347084976306472, 0.18086612816777492, 0.17849178303574897, 0.18858736945822052, 0.1876739356048862, 0.18865543521321004, 0.19182737290730134, 0.17343479968020925, 0.6120147040029784, 0.18617103570970317, 0.18707546759426774, 0.7729502400537006, 0.19845290455683617, 0.1456918107753321, 0.14149630061420848, 0.15039889886944524, 0.2204610142084117, 0.6341995045463912, 0.20849346675443636, 0.1675053608494005, 0.3772485502317897, 0.21326298403621857, 0.44725333414126023, 0.16625950404766376, 0.16884536339196454, 0.38400427855909813, 0.1920722398800513, 0.19402894424876682, 0.17765031287928446, 0.19784056060001753, 0.18974375948825095, 0.21100642046027474, 0.1914271249458387, 0.17541856389882726, 0.1997891185860271, 0.07763438360707331, 0.07863998612446177, 0.08623890550756474, 0.08989239883188838, 0.11223876506721209, 0.09684220702013768, 0.07972400803906399, 0.09662534378279652, 0.10001207553425451]}, "mutation_prompt": null}
{"id": "dae67d4b-940d-4502-a6b8-4f763c59d79b", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.differential_evolution_rate = 0.05  # New differential evolution mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        return position + 0.5 * (self.particles[r1] - self.particles[r2])\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Differential evolution mechanism\n                if np.random.rand() < self.differential_evolution_rate * (1 - evaluations / self.budget):\n                    differential_position = self.differential_evolution(self.particles[i])\n                    differential_fitness = func(differential_position)\n                    evaluations += 1\n                    if differential_fitness < fitness:\n                        self.particles[i] = differential_position\n                        self.best_fitness[i] = differential_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], differential_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Differential Evolution\" mechanism.", "configspace": "", "generation": 207, "fitness": 0.2320501609789748, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6625044680345613, 0.6007631909380593, 0.6805463586706744, 0.6845476322085613, 0.6543834761075317, 0.5809417504178427, 0.6361420587227695, 0.6941836462960009, 0.6256075881952133, 9.999999999998899e-05, 9.999999999998899e-05, 0.022665592647269084, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10616426980139682, 0.09295988088706786, 0.08937331013233396, 0.10623987738436713, 0.07735165843078706, 0.13219808388054277, 0.14207491314478937, 0.1412877161398286, 0.1172463879894402, 0.09605348914504941, 0.10616508484473197, 0.09182958493249893, 0.14837007969275895, 0.08232622262249811, 0.10990558160487507, 0.1302539409651441, 0.08804852663542861, 0.0688173591795539, 0.8980546975576199, 0.9441877188877077, 0.8051786191778997, 0.7256489252363671, 0.8824064174170259, 0.8834327173150525, 0.9062297562029625, 0.8980353792993582, 0.8307720322790333, 0.2522012970160826, 0.2462671458285779, 0.2182047162909424, 0.27674335149390394, 0.2589864916924781, 0.239856505115437, 0.2733050831271987, 0.2058057501329812, 0.2501289050280109, 0.24019446784652598, 0.23960634163469707, 0.3276462616929653, 0.27646702184002736, 0.8125685827449184, 0.20696381186974688, 0.2934247452664176, 0.22868092354878455, 0.2321208928573868, 0.2165004306169792, 0.1132999529020019, 0.11565608916196146, 0.10600932320432999, 0.2536710090851987, 0.2621875313669054, 0.14050517845892485, 0.217947652363637, 0.12938553105991868, 0.14094269069273346, 0.15696158195995302, 0.15797538637808262, 0.14059146979426151, 0.14050252653672668, 0.20534770432724325, 0.26166892605695213, 0.12234144646646605, 0.14225561828644717, 9.999999999998899e-05, 0.06525691409349421, 9.999999999998899e-05, 0.07009685705533031, 0.0889661164917186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05291017215674021, 0.08243009050487582, 0.043701119787700526, 0.12376312492417474, 0.06946456147837798, 0.11459460812809463, 0.021874620666985534, 0.08037746859931227, 0.110080104947889, 0.10145537368051649, 0.1333269848295382, 0.15957817207862968, 0.07831797262995843, 0.08953187027820897, 0.08837988606879077, 0.061770823911769135, 0.08788329940569672, 0.11962686745304818, 0.16200192193770802, 0.1572927276067163, 0.14303239427691894, 0.14938017732279119, 0.08029737943289095, 0.16061189994548386, 0.0895108669690784, 0.08514235083432864, 0.13737355710054255, 0.08134510621830637, 0.46797437627773375, 0.4589507994563322, 0.45972971037186994, 0.4054334866774011, 0.40540282441092446, 0.4032332946952585, 0.45308731631405696, 0.440786879636345, 0.4710180234470538, 0.11184098875254622, 0.09694375036583203, 0.06913717830068056, 0.1096012927206289, 0.10302078249275315, 0.15161961203794494, 0.14968107884025017, 0.12133183765397093, 0.11141567457679558, 0.2120006773649028, 0.18578381978090297, 0.21764840591993506, 0.1990341936271216, 0.23440361146494948, 0.20719731201064473, 0.24846958531147945, 0.21961208014079003, 0.1562908922617895, 0.380495123100139, 0.3184808525714037, 0.27912827211894886, 0.2582859241078299, 0.3423745571904978, 0.26681832030638764, 0.25899170408289585, 0.36036345149500437, 0.2517572319514536, 0.20128112709323354, 0.2973095418607138, 0.2631689454672047, 0.26315304243285464, 0.2707133751426871, 0.21526227725838454, 0.209026479696247, 0.22829684159099783, 0.21722471153774592, 0.20911536471763326, 0.21096420403652316, 0.2354035165453291, 0.22476878432906733, 0.21488368301010308, 0.21412478078309294, 0.231087148900062, 0.21920176286146054, 0.24544494130756644, 0.18639363275960663, 0.17125582270908468, 0.18494132223324455, 0.2103954235640505, 0.184724487231815, 0.18356356754238345, 0.187962284003806, 0.20746617841750348, 0.17223598398075823, 0.18598000237802292, 0.1749408426298873, 0.18484023193195864, 0.7277021455666666, 0.19838146548172408, 0.196671987781047, 0.16221249341764998, 0.1552185286147626, 0.6793063616272, 0.43872748411215046, 0.21067038169561703, 0.5659966934327011, 0.20229593460590845, 0.38753892518102007, 0.16656891963826215, 0.16750414004163472, 0.2727039264330675, 0.3640052918896526, 0.20975967820260244, 0.18202668341604933, 0.18429948296081766, 0.1818873617951765, 0.1766474998773332, 0.1908752661237786, 0.17987063417316917, 0.19256003191003834, 0.1839380155245507, 0.09602167130567962, 0.08293117578428477, 0.09873528415673316, 0.07558400265395471, 0.09695723247177035, 0.08162880220854318, 0.08995946550421419, 0.09349395919750281, 0.10118288729877911]}, "mutation_prompt": null}
{"id": "b241a13f-c63d-48d9-8135-4b6db1789a01", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.differential_evolution_rate = 0.05  # New differential evolution mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        return position + 0.5 * (self.particles[r1] - self.particles[r2])\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Differential evolution mechanism\n                if np.random.rand() < self.differential_evolution_rate * (1 - evaluations / self.budget):\n                    differential_position = self.differential_evolution(self.particles[i])\n                    differential_fitness = func(differential_position)\n                    evaluations += 1\n                    if differential_fitness < fitness:\n                        self.particles[i] = differential_position\n                        self.best_fitness[i] = differential_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], differential_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Differential Evolution\" mechanism.", "configspace": "", "generation": 208, "fitness": 0.2320501609789748, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6625044680345613, 0.6007631909380593, 0.6805463586706744, 0.6845476322085613, 0.6543834761075317, 0.5809417504178427, 0.6361420587227695, 0.6941836462960009, 0.6256075881952133, 9.999999999998899e-05, 9.999999999998899e-05, 0.022665592647269084, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10616426980139682, 0.09295988088706786, 0.08937331013233396, 0.10623987738436713, 0.07735165843078706, 0.13219808388054277, 0.14207491314478937, 0.1412877161398286, 0.1172463879894402, 0.09605348914504941, 0.10616508484473197, 0.09182958493249893, 0.14837007969275895, 0.08232622262249811, 0.10990558160487507, 0.1302539409651441, 0.08804852663542861, 0.0688173591795539, 0.8980546975576199, 0.9441877188877077, 0.8051786191778997, 0.7256489252363671, 0.8824064174170259, 0.8834327173150525, 0.9062297562029625, 0.8980353792993582, 0.8307720322790333, 0.2522012970160826, 0.2462671458285779, 0.2182047162909424, 0.27674335149390394, 0.2589864916924781, 0.239856505115437, 0.2733050831271987, 0.2058057501329812, 0.2501289050280109, 0.24019446784652598, 0.23960634163469707, 0.3276462616929653, 0.27646702184002736, 0.8125685827449184, 0.20696381186974688, 0.2934247452664176, 0.22868092354878455, 0.2321208928573868, 0.2165004306169792, 0.1132999529020019, 0.11565608916196146, 0.10600932320432999, 0.2536710090851987, 0.2621875313669054, 0.14050517845892485, 0.217947652363637, 0.12938553105991868, 0.14094269069273346, 0.15696158195995302, 0.15797538637808262, 0.14059146979426151, 0.14050252653672668, 0.20534770432724325, 0.26166892605695213, 0.12234144646646605, 0.14225561828644717, 9.999999999998899e-05, 0.06525691409349421, 9.999999999998899e-05, 0.07009685705533031, 0.0889661164917186, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.05291017215674021, 0.08243009050487582, 0.043701119787700526, 0.12376312492417474, 0.06946456147837798, 0.11459460812809463, 0.021874620666985534, 0.08037746859931227, 0.110080104947889, 0.10145537368051649, 0.1333269848295382, 0.15957817207862968, 0.07831797262995843, 0.08953187027820897, 0.08837988606879077, 0.061770823911769135, 0.08788329940569672, 0.11962686745304818, 0.16200192193770802, 0.1572927276067163, 0.14303239427691894, 0.14938017732279119, 0.08029737943289095, 0.16061189994548386, 0.0895108669690784, 0.08514235083432864, 0.13737355710054255, 0.08134510621830637, 0.46797437627773375, 0.4589507994563322, 0.45972971037186994, 0.4054334866774011, 0.40540282441092446, 0.4032332946952585, 0.45308731631405696, 0.440786879636345, 0.4710180234470538, 0.11184098875254622, 0.09694375036583203, 0.06913717830068056, 0.1096012927206289, 0.10302078249275315, 0.15161961203794494, 0.14968107884025017, 0.12133183765397093, 0.11141567457679558, 0.2120006773649028, 0.18578381978090297, 0.21764840591993506, 0.1990341936271216, 0.23440361146494948, 0.20719731201064473, 0.24846958531147945, 0.21961208014079003, 0.1562908922617895, 0.380495123100139, 0.3184808525714037, 0.27912827211894886, 0.2582859241078299, 0.3423745571904978, 0.26681832030638764, 0.25899170408289585, 0.36036345149500437, 0.2517572319514536, 0.20128112709323354, 0.2973095418607138, 0.2631689454672047, 0.26315304243285464, 0.2707133751426871, 0.21526227725838454, 0.209026479696247, 0.22829684159099783, 0.21722471153774592, 0.20911536471763326, 0.21096420403652316, 0.2354035165453291, 0.22476878432906733, 0.21488368301010308, 0.21412478078309294, 0.231087148900062, 0.21920176286146054, 0.24544494130756644, 0.18639363275960663, 0.17125582270908468, 0.18494132223324455, 0.2103954235640505, 0.184724487231815, 0.18356356754238345, 0.187962284003806, 0.20746617841750348, 0.17223598398075823, 0.18598000237802292, 0.1749408426298873, 0.18484023193195864, 0.7277021455666666, 0.19838146548172408, 0.196671987781047, 0.16221249341764998, 0.1552185286147626, 0.6793063616272, 0.43872748411215046, 0.21067038169561703, 0.5659966934327011, 0.20229593460590845, 0.38753892518102007, 0.16656891963826215, 0.16750414004163472, 0.2727039264330675, 0.3640052918896526, 0.20975967820260244, 0.18202668341604933, 0.18429948296081766, 0.1818873617951765, 0.1766474998773332, 0.1908752661237786, 0.17987063417316917, 0.19256003191003834, 0.1839380155245507, 0.09602167130567962, 0.08293117578428477, 0.09873528415673316, 0.07558400265395471, 0.09695723247177035, 0.08162880220854318, 0.08995946550421419, 0.09349395919750281, 0.10118288729877911]}, "mutation_prompt": null}
{"id": "4c990cdd-14ba-4fd3-a1cd-ff4f6bc5567e", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective approach\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Multi-objective approach\n                if np.random.rand() < self.multi_objective_rate * (1 - evaluations / self.budget):\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                    fitness = func(self.particles[i])\n                    evaluations += 1\n                    if fitness < self.best_fitness[i]:\n                        self.best_fitness[i] = fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], fitness)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Multi-Objective\" approach to balance exploration and exploitation.", "configspace": "", "generation": 209, "fitness": 0.22628168649487698, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.19.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.626909042169657, 0.5807473553298411, 0.6798293807176695, 0.5703238715765491, 0.6144118473366593, 0.6197772188469584, 0.6286110301054237, 0.6060811906887009, 0.6487940062264614, 0.05081083746157511, 0.01290309496750397, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04531150352059832, 9.999999999998899e-05, 0.1666312895484573, 0.08391190884331823, 0.12046467102127612, 0.10188727040286938, 0.10957996948400506, 0.1410032180876648, 0.10657270633212756, 0.14092814033162415, 0.1120702522146999, 0.10373204614031495, 0.07966919514532944, 0.11021747510348323, 0.09665567720135082, 0.10088202684723879, 0.10072969036338586, 0.12557548056145773, 0.07137216566529536, 0.09260760447021021, 0.8499841317795136, 0.8903824049973535, 0.793965605554949, 0.7838286668174157, 0.8432002680684496, 0.8563378655752533, 0.9085231535197353, 0.9181148838182538, 0.8193854425550949, 0.242418358831599, 0.2721881889408111, 0.22866446278637564, 0.20047789611394584, 0.24883644508759717, 0.23052812291330138, 0.20689624140527307, 0.2587980779277963, 0.26300005134003346, 0.2692728271354363, 0.3823650184961398, 0.20429548767983852, 0.27496586975726045, 0.37715570699954415, 0.20665664660229133, 0.2308973334330804, 0.20289634274271073, 0.22375919110078024, 0.10138567984255298, 0.11801313058387097, 0.1243787234269692, 0.15682953321293025, 0.1265068593961841, 0.13165837135713332, 0.2559891203332342, 0.16945076612561083, 0.13272997119894048, 0.1476204213377863, 0.1610760037404083, 0.1461069932934944, 0.13613676500616423, 0.21840476355008476, 0.23449721016311242, 0.14678144000347526, 0.16905286973607236, 0.15959210006314428, 0.0005713913829733519, 0.003649171635519033, 9.999999999998899e-05, 0.010015929833353532, 9.999999999998899e-05, 9.999999999998899e-05, 0.0068227241232349245, 9.999999999998899e-05, 0.0016623362000557362, 0.12237858266445312, 0.04188366614754302, 0.09716735664704212, 0.095553758829786, 0.07973680630381696, 0.033328419239565865, 0.11070157279001236, 0.0705092126985033, 0.06568145033706152, 0.13645242085782816, 0.10905976554582775, 0.05562571960396967, 0.09661099777746007, 0.09604440283032656, 0.07384959614594067, 0.1562854441690641, 0.11926170123897595, 0.06047680615012563, 0.18450774998425146, 0.11189944753629588, 0.13753237573815735, 0.15392452388719735, 0.22619425397323567, 0.09516189627123406, 0.18522072323570615, 0.10603358284748665, 0.12404542728068135, 0.49038169737914894, 0.43435631432291355, 0.45992959055802907, 0.45399785858353703, 0.4162652919980575, 0.4038664108139549, 0.4018655762264064, 0.4377905603273867, 0.5317153938672536, 0.11954235308034455, 0.13311045159728907, 0.08931590074647844, 0.13284137983966138, 0.12117298143666233, 0.08348609010036057, 0.10948360653095823, 0.08148324115723737, 0.1074358992816935, 0.2523803533512565, 0.2360736641828587, 0.19971636358367073, 0.17490504826270048, 0.2623873868464278, 0.1700454005491987, 0.2811344670484991, 0.20726579751382646, 0.29189503503086844, 0.29688983172807015, 0.31265018694249036, 0.2984435060763465, 0.3669614214309247, 0.2672296395747841, 0.281329875294844, 0.27329621335362553, 0.27669793369270823, 0.2341725365187084, 0.21781400346653967, 0.21025064572169017, 0.26737808847537303, 0.17794889892901478, 0.17072415320102086, 0.2474760302415625, 0.17148898967102, 0.25534031402222956, 0.22412500096951293, 0.20723938885167714, 0.23018806229087418, 0.27917991999942193, 0.22840413520630776, 0.22044615776121423, 0.24621276494574273, 0.29134478457973334, 0.20519163272101482, 0.2122953368536855, 0.17186046090491147, 0.18130673686074184, 0.181945313889726, 0.173637138780245, 0.19962018625378497, 0.17617464371209712, 0.1845018461331266, 0.20623806416023838, 0.17363687467109978, 0.1847446486376968, 0.1862152360114655, 0.18714358485575755, 0.7178962805671734, 0.19866559382707905, 0.14579044413254594, 0.1405044409949403, 0.2024549291114346, 0.7281176226797353, 0.5012069400106299, 0.16846412008341283, 0.37242968059248294, 0.3782088091283231, 0.21418878288722532, 0.3599568418545436, 0.16619769821184383, 0.16832886342032505, 0.30774126558498605, 0.17464975561117246, 0.19570577021397606, 0.19374846379111643, 0.18964625653942735, 0.1947651707960154, 0.18724272682972964, 0.1826043325399399, 0.18967199113967337, 0.1807647311646755, 0.07886721334174474, 0.10567193158356836, 0.09129774329537088, 0.08347335751438134, 0.08817820162796253, 0.0966638390054857, 0.09367785891387481, 0.08747548951829631, 0.08914303980324056]}, "mutation_prompt": null}
{"id": "c04e42cc-461a-48c0-9683-f86bb3d355b3", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.differential_evolution_rate = 0.1  # New differential evolution mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        while r1 == r2:\n            r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        mutation_vector = self.particles[r1] + 0.5 * (self.particles[r2] - position)\n        return mutation_vector\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Differential evolution mechanism\n                if np.random.rand() < self.differential_evolution_rate * (1 - evaluations / self.budget):\n                    differential_position = self.differential_evolution(self.particles[i])\n                    differential_fitness = func(differential_position)\n                    evaluations += 1\n                    if differential_fitness < fitness:\n                        self.particles[i] = differential_position\n                        self.best_fitness[i] = differential_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], differential_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Differential Evolution\" mechanism.", "configspace": "", "generation": 210, "fitness": 0.2320642684405668, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6109639902698869, 0.7092337146362642, 0.7495612606404467, 0.6131544782589498, 0.6271773823975313, 0.5952977879810517, 0.6130956172644317, 0.6543403517993039, 0.6313752757634512, 0.0026173299268990036, 9.999999999998899e-05, 0.0043236954843208775, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003143112926795366, 9.999999999998899e-05, 0.12872914571899274, 0.10527851254151355, 0.14598486555659507, 0.09597088850941504, 0.09906346718078407, 0.10962291396847645, 0.13970958050087812, 0.12703206417957047, 0.09723004404507396, 0.07974940007138298, 0.0731026546112633, 0.07004367155691338, 0.07987178745504464, 0.07945327606250174, 0.09498054756807106, 0.11107397065637781, 0.07507965736878741, 0.09319878270077975, 0.8723382267689146, 0.9390843125931196, 0.8699688996786935, 0.8154071925619149, 0.7453259197801683, 0.7455447474727104, 0.9070610093394202, 0.9040720015687129, 0.9097151454503045, 0.25713739755320464, 0.23992537792501112, 0.24351245112616993, 0.2540665410202442, 0.2893350700291185, 0.2815953721604201, 0.26188466018509304, 0.27957468919873796, 0.2720574807468492, 0.2443638459048021, 0.3370659427421302, 0.2705652393723452, 0.8584416021297484, 0.2712448655694141, 0.219260312539304, 0.2692306071190117, 0.23181390339731156, 0.31233969513450865, 0.14875032251930786, 0.13529428054965542, 0.24377418051173694, 0.11132528218052817, 0.14504059163921834, 0.12161692583191142, 0.1302060342852286, 0.13606349961054642, 0.14516384370248903, 0.13655501463059516, 0.16768598202772156, 0.15953720141670524, 0.19149529568395052, 0.15227610985953655, 0.211998536930747, 0.20572367443565442, 0.1748605338056235, 0.1523040834025865, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03306639236371245, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009610141805437289, 0.09181329731562815, 0.0825381094149088, 0.08911868394997413, 0.13231557495442725, 0.07694604467608646, 0.04131776330349801, 0.09102110334734081, 0.08322732141621314, 0.10395978626619129, 0.15067475018080245, 0.06117818831119515, 0.0865829308832119, 0.11125497201375478, 0.09895790752653122, 0.07542798349919844, 0.08901939303310757, 0.1521630185906626, 0.0784687643206351, 0.1804937845250193, 0.1614108882041705, 0.09029385031733905, 0.09432407811277588, 0.10453599660021629, 0.11516137495809686, 0.1547345756053854, 0.16600726430371016, 0.08647005749885028, 0.42263030497109544, 0.4311496667314294, 0.4219046276845245, 0.4406558226593047, 0.46236601872082805, 0.42050000877291027, 0.4275070961013179, 0.4467902806256304, 0.4364320253972116, 0.11447777731413045, 0.09414313894850124, 0.0772354004537934, 0.12209631667988563, 0.13904633444896586, 0.14961134412494426, 0.10676068702198427, 0.11968310422674189, 0.09087120210212685, 0.14519983028099248, 0.29451061336530826, 0.26614408020248126, 0.23504937289403238, 0.30611998255350736, 0.21146160676805847, 0.20883257798322818, 0.20108414836658617, 0.16438406733346222, 0.2566904246375651, 0.30405829515344984, 0.30661232464312205, 0.24770424379774036, 0.33571645820547436, 0.2589928491259198, 0.27014481966100934, 0.3106818906097384, 0.2899742494616363, 0.21544994134733542, 0.19114692826096213, 0.2995245970292122, 0.2347477078340343, 0.2554387299132016, 0.2224524924443534, 0.1645530305491546, 0.20817834414967185, 0.22925807238558082, 0.22884963821731985, 0.2510813638049303, 0.22308278096325962, 0.24055751909220147, 0.23118173020166766, 0.258011365001505, 0.24990623947422375, 0.23666771125373753, 0.20482764550434385, 0.17257381046109255, 0.19831992925308017, 0.18870338497468098, 0.17572337637273194, 0.1995048888865083, 0.18113812551877284, 0.21569579881149514, 0.17314427790153708, 0.1779093651587862, 0.18548739858061158, 0.18610430174238812, 0.18511655532319327, 0.7535667494376205, 0.19971218702064497, 0.19576083310673442, 0.14050962057986416, 0.15188767551534343, 0.8096998577217773, 0.39629208080440825, 0.16770331397643, 0.3414773609668931, 0.2152018823317252, 0.48480837067757154, 0.1649224328890756, 0.27230779471171596, 0.4766166354229924, 0.3689311140716187, 0.18313873310548456, 0.19232950688949257, 0.20032921981609597, 0.18506494832592812, 0.20057181387670342, 0.19244516348003704, 0.18893370425138734, 0.19252106118361234, 0.18747270883417233, 0.08490918337109032, 0.10712745389615119, 0.098053765149962, 0.09376204433622459, 0.10226205155136048, 0.0916578879043407, 0.08959499194167708, 0.10180056842858454, 0.08849209815454306]}, "mutation_prompt": null}
{"id": "45442653-1ecb-4402-ab50-9fbc257a4450", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.memory = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.memory_size = 5\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.memory_reuse_rate = 0.05  # New memory-based mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def update_memory(self, position, fitness):\n        if len(self.memory) < self.memory_size:\n            self.memory.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.memory])\n            if fitness < self.memory[worst_index][1]:\n                self.memory[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    self.update_memory(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                        self.update_memory(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                        self.update_memory(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                        self.update_memory(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                        self.update_memory(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                        self.update_memory(self.particles[i], tunneling_fitness)\n                # Memory-based mechanism\n                if np.random.rand() < self.memory_reuse_rate * (1 - evaluations / self.budget):\n                    memory_index = np.random.randint(len(self.memory))\n                    self.particles[i] = self.memory[memory_index][0]\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                        self.update_memory(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and with an additional \"Memory-Based\" mechanism to store and reuse previously found good solutions.", "configspace": "", "generation": 211, "fitness": 0.23094400761608308, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6894069484916192, 0.593274303222703, 0.6666091700863175, 0.6450617357425945, 0.6239776737298326, 0.6549656317667805, 0.567277490315671, 0.6361799869284879, 0.6553218383388423, 0.037240164440044854, 0.004392958037543915, 0.00011383590911651087, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.07338309025011747, 0.08851432319584707, 0.12231994673486513, 0.1076585731918207, 0.10546368349148616, 0.14973556423960488, 0.13719998419467827, 0.13242497217547422, 0.14438955774418338, 0.08707175652332988, 0.10824368772981052, 0.09659573905952334, 0.0965753775136331, 0.0805070970760593, 0.09337434195736583, 0.10381443730820505, 0.13433562708885982, 0.07577711121778452, 0.9064114755281462, 0.9284160249414559, 0.8744210247739261, 0.8172971615163952, 0.8720584257459387, 0.855867357545634, 0.8968699130494108, 0.8593714775831877, 0.8703723769035652, 0.2761177072411395, 0.27324171644199746, 0.2257365755205435, 0.24828422357324165, 0.2748887360602251, 0.25196103637395717, 0.2186666697881866, 0.22492516033795618, 0.2187258177220207, 0.35283744727759103, 0.7078022310274972, 0.21284685933363612, 0.27665522246070007, 0.27998314932491053, 0.24845384517468394, 0.3085823026865607, 0.21106452089147976, 0.3223358897004128, 0.1960112209186825, 0.10962711591141194, 0.1272219829125294, 0.18330237503295654, 0.14144303383031254, 0.14521992340936052, 0.12285566174879459, 0.11193794420713599, 0.14658584616492276, 0.15293491377496216, 0.16698931149232998, 0.15238545149020066, 0.16597430584805883, 0.1799395542699771, 0.1401135740081687, 0.21460827819495998, 0.1527149369839519, 0.15244323114932945, 9.999999999998899e-05, 9.999999999998899e-05, 0.03003355394097329, 0.07619001604940145, 0.0004871117540004022, 0.012473724296670485, 9.999999999998899e-05, 9.999999999998899e-05, 0.03553286815959422, 0.11745501544671355, 0.050823801884461006, 0.05757403470940847, 0.08145078233557301, 0.051038270108709316, 0.017871407815395868, 0.09976354961524303, 0.070059781078183, 0.13955743720054892, 0.10046741042226026, 0.06455729618041683, 0.09139175998861049, 0.08206215173384512, 0.11295611553478324, 0.06607862534664777, 0.08985484474567151, 0.13843841573996507, 0.11970622254220886, 0.12529556412815057, 0.12912972974349302, 0.09233846659758005, 0.08443835400448774, 0.1293024436072452, 0.10753973180995768, 0.12899321783156847, 0.12511984044847235, 0.1662513062103762, 0.47151453660092113, 0.4278685420498338, 0.42425086393824174, 0.4361287475609308, 0.4417445396295089, 0.40143354555378596, 0.455157739490733, 0.4400103992410913, 0.4375214401364619, 0.11729996611869842, 0.11602931355283652, 0.08429944592903171, 0.10102973893607192, 0.10442320961868956, 0.13591663053615688, 0.11719182038845777, 0.11357721713072355, 0.08784784530523193, 0.20817863666273828, 0.22204285277888947, 0.18465210109884056, 0.1673116603796041, 0.2548610736677227, 0.22209188239947075, 0.1863303137889628, 0.17418608424091053, 0.23449427628470598, 0.2644117743497343, 0.32317977765961703, 0.31355261023905956, 0.29974932800271614, 0.27930746133640805, 0.33895622107965306, 0.25398062179903647, 0.25763427400567573, 0.22043870089987572, 0.28503028222361004, 0.2240494649253103, 0.23178076491048005, 0.26184662899590416, 0.3110049482364545, 0.25888036259664615, 0.18604341397186241, 0.22480273937363404, 0.21965060721785357, 0.20877075717802762, 0.22492104926984913, 0.2224397422768032, 0.2030498999308361, 0.2157270026651522, 0.20991858629016436, 0.2142317467914996, 0.2378494397976898, 0.22008080295783006, 0.18788438461030232, 0.1844685818961077, 0.18573394670546517, 0.20353962551843607, 0.19332226504095107, 0.18125520996011757, 0.1794594855777677, 0.1756898557216524, 0.19107902522942455, 0.18285790419954195, 0.18681226641801618, 0.15522233780246864, 0.6977087592152138, 0.1989342574402515, 0.19681788630201846, 0.14142176789402638, 0.7287668339981459, 0.7074952650511657, 0.44942664894273576, 0.21206005435352504, 0.2793449857083593, 0.33687568913432864, 0.16587344857764785, 0.6348634192583116, 0.16615486901645304, 0.16382706850376494, 0.27015936208013935, 0.19472342806109155, 0.18382224269289738, 0.19599642413177154, 0.1832381106777473, 0.2196189606158555, 0.1883419614929558, 0.17535909932901417, 0.2003384764941296, 0.18925678253624734, 0.08406729686382675, 0.08412054146037551, 0.09892997822395733, 0.11527378593896098, 0.10150010509745555, 0.08906456012730612, 0.08467166279630256, 0.08777418822874539, 0.0891269355630655]}, "mutation_prompt": null}
{"id": "0a031bef-b33e-4443-bcfc-6a4df35c16b2", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.memory = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.memory_rate = 0.1  # New memory-based mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def update_memory(self, position):\n        if len(self.memory) < 10:\n            self.memory.append(position)\n        else:\n            self.memory[np.random.randint(len(self.memory))] = position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    self.update_memory(self.particles[i])\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Memory-based mechanism\n                if np.random.rand() < self.memory_rate * (1 - evaluations / self.budget):\n                    memory_position = self.memory[np.random.randint(len(self.memory))]\n                    memory_fitness = func(memory_position)\n                    evaluations += 1\n                    if memory_fitness < fitness:\n                        self.particles[i] = memory_position\n                        self.best_fitness[i] = memory_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], memory_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Memory-Based\" mechanism to store and utilize the best positions found so far.", "configspace": "", "generation": 212, "fitness": 0.22397126560215774, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.22 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6524592130559115, 0.671624738669864, 0.6157197146733537, 0.6598571898233765, 0.5957717955787488, 0.6249381910273132, 0.5786467431174547, 0.572536009152876, 0.5381098610854207, 0.02909716158627529, 0.0501278787742806, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.16596720366297668, 0.1033391709556798, 0.11098356198348014, 0.10869230103722038, 0.08270918784224124, 0.11340030893932884, 0.12251863015103204, 0.1385897676695237, 0.10632102614040084, 0.10394956255200427, 0.11455703651610072, 0.06880913070198769, 0.12091571657176514, 0.07555779001659957, 0.08242496660299226, 0.10464661632204475, 0.09810441656013413, 0.11287619952453187, 0.8666877809855406, 0.9046556833134735, 0.7889527004697647, 0.8676162290442127, 0.7498633448533774, 0.7928375546779332, 0.9067635316779503, 0.900712194154667, 0.8812483219350514, 0.27681411941608614, 0.2440660236933403, 0.26876106993005877, 0.23493236910967885, 0.2757975317476157, 0.22368325815117573, 0.22213388515201982, 0.23575845673219564, 0.2428007415263579, 0.3561572119323796, 0.3866003394940042, 0.3012736762406403, 0.2730649050779431, 0.27025826771877426, 0.20862363902108128, 0.3290593985390692, 0.2813238267014885, 0.21496382874918674, 0.2188490486955713, 0.10681520585129223, 0.10739328438651952, 0.19266533260933816, 0.13099767168102427, 0.20008060429833563, 0.1551772153827371, 0.12248809972912655, 0.15337398330683194, 0.1531080802361825, 0.126220433503742, 0.14682317046976046, 0.17018486263659893, 0.14712835786084566, 0.1268315624140447, 0.2097111713917087, 0.18720910178310246, 0.18573818495518557, 9.999999999998899e-05, 9.999999999998899e-05, 0.005887339224948329, 0.0181282452937207, 0.05881769044763874, 0.0012479679750696526, 9.999999999998899e-05, 9.999999999998899e-05, 0.013112743695469886, 0.09505291387226167, 0.05826716488220518, 0.10978830678660201, 0.07221274204075812, 0.03664050397473806, 0.021850118968675947, 0.10779104917514304, 0.08716461613721116, 0.0635908685315506, 0.08354154846330819, 0.04155454357152688, 0.1594531541949884, 0.07873213006011737, 0.11700127445200903, 0.09336164280600368, 0.12558200735799596, 0.07585345279678513, 0.06824338945767339, 0.16608395425628464, 0.20418971356099147, 0.1363626332241754, 0.12619060404121496, 0.16135738318418769, 0.08739127996847706, 0.1255562838395694, 0.11106191200710269, 0.12873235360234392, 0.48558182252341664, 0.47930330788326325, 0.4680637246543804, 0.4145952817252132, 0.38728646193192917, 0.3959396746328513, 0.4335023614526885, 0.43299553974439553, 0.4279173916566912, 0.11015277075852592, 0.13335718987864698, 0.09190309203822766, 0.11845697001702571, 0.09754908779319171, 0.12613726849133233, 0.1064425550852679, 0.10399722628152008, 0.09923916547686129, 0.25022916591857447, 0.2325326894347931, 0.182511803942078, 0.21637780454676048, 0.20525252573597985, 0.19028192778524688, 0.20649943466328757, 0.18265592571212697, 0.22583168749703464, 0.27902435749341725, 0.2597146668893805, 0.2895355823795064, 0.27490967676793465, 0.2832760555158832, 0.29373309541379744, 0.24808955094864926, 0.25790417900888174, 0.27805190621007725, 0.190559812049501, 0.26893739594679955, 0.23252277563313728, 0.24686804810087848, 0.20988266551406254, 0.25760027715819633, 0.20403032632514018, 0.2041663485997286, 0.20735846307854577, 0.20168179178190193, 0.23024053223305996, 0.24151476483764545, 0.21755879611813922, 0.2502393561611246, 0.20485575477479134, 0.24901997677556575, 0.2384211732084054, 0.22206243758238464, 0.17097170101151182, 0.1913779864214793, 0.18761999061340517, 0.188647302054762, 0.18145985474852033, 0.17149851169514674, 0.19501935665132353, 0.18462118837129726, 0.18030897449543648, 0.18828876270710737, 0.1868198768965924, 0.1860875827344468, 0.6283061754816521, 0.20025737289188072, 0.1976902509598153, 0.14145842508188122, 0.630670212400831, 0.7424228191839668, 0.6416064601178754, 0.21149195946219856, 0.07862713034219682, 0.20449666270857414, 0.15402555809791119, 0.16539844691812955, 0.16707700020824545, 0.16625553432151552, 0.3003704679018965, 0.17710269722972793, 0.20107586032660152, 0.1745561402478334, 0.17919851869066838, 0.17951336156722886, 0.1883802696923944, 0.18283135578807863, 0.2007501772061021, 0.19888772605617333, 0.0878264503441607, 0.09727718636483518, 0.08309504955091707, 0.08486980464550975, 0.08438460170988638, 0.07881043274157162, 0.09708606140788345, 0.09394124509674862, 0.08861935976962831]}, "mutation_prompt": null}
{"id": "c4be49da-cbb7-4682-9dc6-a46f12f578b2", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.pareto_dominance_rate = 0.1  # Multi-objective optimization\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def pareto_dominance(self, position1, position2):\n        fitness1 = np.sum(position1**2)\n        fitness2 = np.sum(position2**2)\n        if fitness1 < fitness2:\n            return position1\n        elif fitness1 > fitness2:\n            return position2\n        else:\n            return np.random.choice([position1, position2])\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Pareto dominance\n                if np.random.rand() < self.pareto_dominance_rate:\n                    self.particles[i] = self.pareto_dominance(self.particles[i], self.global_best_position)\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and introducing \"Multi-Objective\" optimization with Pareto dominance.", "configspace": "", "generation": 213, "fitness": -Infinity, "feedback": "An exception occurred: ValueError('a must be 1-dimensional').", "error": "ValueError('a must be 1-dimensional')", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {}, "mutation_prompt": null}
{"id": "5e547f26-fe7d-415a-a585-a96eddf0380c", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_modal_exploration_rate = 0.1  # New multi-modal exploration mechanism\n        self.diversity_preserving_rate = 0.05  # New diversity-preserving mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def multi_modal_exploration(self, position):\n        exploration_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + exploration_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def diversity_preserving(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-modal exploration mechanism\n                if np.random.rand() < self.multi_modal_exploration_rate * (1 - evaluations / self.budget):\n                    exploration_position = self.multi_modal_exploration(self.particles[i])\n                    exploration_fitness = func(exploration_position)\n                    evaluations += 1\n                    if exploration_fitness < fitness:\n                        self.particles[i] = exploration_position\n                        self.best_fitness[i] = exploration_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], exploration_fitness)\n                # Diversity-preserving mechanism\n                if np.random.rand() < self.diversity_preserving_rate * (1 - evaluations / self.budget):\n                    preserving_position = self.diversity_preserving(self.particles)\n                    preserving_fitness = func(preserving_position)\n                    evaluations += 1\n                    if preserving_fitness < fitness:\n                        self.particles[i] = preserving_position\n                        self.best_fitness[i] = preserving_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], preserving_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and introducing \"Multi-Modal Exploration\" and \"Diversity-Preserving\" strategies.", "configspace": "", "generation": 214, "fitness": 0.2352982797641633, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6881728187501271, 0.7038201661561085, 0.5814294189665208, 0.5647996603344447, 0.6532356240386265, 0.6772954140720764, 0.5667508640101862, 0.6003419961092717, 0.6045681715389768, 0.21665611581826083, 9.999999999998899e-05, 9.999999999998899e-05, 0.02631301011746623, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.11174394522542386, 0.08966016467211835, 0.10286226666255194, 0.09700327362857408, 0.1018615170921866, 0.11334142961688831, 0.12581725568035107, 0.14948703028832355, 0.11238292843949205, 0.09906458699835552, 0.09709325186544104, 0.09850586013505103, 0.09981841853982387, 0.06998867867734371, 0.1091276972620503, 0.11824032504578486, 0.08549554927373448, 0.07491410211628358, 0.8565393173551905, 0.9208317724009186, 0.8317006196351263, 0.8205686831118538, 0.8610991263649681, 0.7692198407693688, 0.8997733647026778, 0.8750017362233444, 0.8996156126148102, 0.24369485152212833, 0.22526140468015687, 0.2393788218836661, 0.23735056094518514, 0.2541591167863845, 0.3085796583546334, 0.24538480084918046, 0.22599093706792694, 0.24991631751453047, 0.35542821991700946, 0.3235299478839767, 0.6095720297158852, 0.3656390575214339, 0.3354380157086292, 0.2046465230367922, 0.26746351400726176, 0.21444616684860962, 0.2846465423238521, 0.21353719822838357, 0.11864811890739113, 0.15175603634495238, 0.0951721248564874, 0.12777156012256818, 0.14514276483345367, 0.14265859721357865, 0.18516805643791534, 0.1625426174993374, 0.1634172552317037, 0.1234631841372571, 0.17624800262525875, 0.12423194086019196, 0.15834326206324456, 0.13315906827445656, 0.19284503819443322, 0.13703037358849235, 0.15288443272487862, 9.999999999998899e-05, 0.02842950934549604, 9.999999999998899e-05, 0.04984323667997215, 0.002344642957751941, 0.020368845618649378, 9.999999999998899e-05, 9.999999999998899e-05, 0.06981074711719848, 0.11113011429844044, 0.04772447187128326, 0.09957913664081208, 0.06487818394338973, 0.12841008514061159, 0.028694259405079747, 0.206042011719056, 0.09733359758726234, 0.14888170491168762, 0.10279766585651373, 0.11634104988868199, 0.09575987074604564, 0.08228258658297205, 0.06582462188966398, 0.07890179320120772, 0.10525553660479559, 0.1045868799306261, 0.07227396687070609, 0.16788803233871985, 0.10510564487131557, 0.08965966643430623, 0.11463808211105575, 0.1552337650756812, 0.12644593046449681, 0.19727039324498896, 0.12783707640980735, 0.12057012398535238, 0.5474045340569855, 0.3968438947630648, 0.4129015277333804, 0.4639894501736985, 0.42324124361339543, 0.403543443931501, 0.4314565548709265, 0.44988154296808247, 0.4338333126344903, 0.11368192242367914, 0.11142334799357612, 0.10562656112526236, 0.09824132971247179, 0.07715766152732106, 0.1318016229494775, 0.10637109043068216, 0.11700776598965568, 0.13036470580292592, 0.25748479917072764, 0.207617200481499, 0.15962747962310553, 0.1882095461350447, 0.21512409504947638, 0.2166943574546103, 0.20863378524661125, 0.31248848753971314, 0.1680383872784128, 0.3484907595519777, 0.359161098676977, 0.27907798444548304, 0.27901736629226503, 0.24241740147519142, 0.2537543296458965, 0.2636471733765098, 0.3534670302448708, 0.2677567486521789, 0.21937598165502437, 0.23176769197512104, 0.23051456329465014, 0.26147220031997676, 0.23948121122819488, 0.24197166296356476, 0.21064130050313867, 0.2215426544557989, 0.2202460193311686, 0.23030429346745274, 0.25123058649616314, 0.19960828866027402, 0.2661092431160963, 0.22176080729967484, 0.21292008065878, 0.2090853991407855, 0.2006560882351941, 0.1920026132844922, 0.1688091283251293, 0.1855508769655314, 0.1980306612944993, 0.1821070116630985, 0.19575938502800594, 0.1849603904068442, 0.17677036369494958, 0.22270241373543564, 0.17386950038096005, 0.7049267014814404, 0.1739027402372687, 0.18536136658720048, 0.1719906146875414, 0.19804371430610024, 0.19670093223436536, 0.7260841350114308, 0.5953379285933877, 0.8049467747685316, 0.4934525368657223, 0.21072534318871716, 0.3775975248514777, 0.369604770537704, 0.16478556750791562, 0.35781370304876114, 0.1661416139832712, 0.16427543585031057, 0.4515017631414404, 0.2095774565201879, 0.18426668513314282, 0.1780249440274736, 0.18333530013398414, 0.19841237879124152, 0.1945605098892379, 0.18102081964132488, 0.1844012257092792, 0.19044687897332502, 0.09995297635318168, 0.08469165580829341, 0.08820309965056095, 0.08944421887728204, 0.09188394489826368, 0.10366414383458256, 0.09594889196941347, 0.0821678339905968, 0.08457137058922182]}, "mutation_prompt": null}
{"id": "0a88d633-136c-4ece-be07-1cf7305693d4", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective approach\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_objective_approach(self, position):\n        if np.random.rand() < self.multi_objective_rate:\n            return position + np.random.uniform(-1, 1, size=self.dim)\n        else:\n            return position\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Multi-objective approach\n                self.particles[i] = self.multi_objective_approach(self.particles[i])\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Multi-Objective\" approach to balance exploration and exploitation.", "configspace": "", "generation": 215, "fitness": 0.2312081192252055, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6409874805984468, 0.665740244559319, 0.6621686919030529, 0.6177895843048629, 0.5876815654446736, 0.6633392209974419, 0.6276060902304228, 0.6526193182514224, 0.6598904622432569, 0.011651204674342441, 0.010603174001015181, 0.0011563618128529463, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.04741878025460178, 9.999999999998899e-05, 0.10344961538962139, 0.07476348793272103, 0.10698305754178639, 0.11020110373656611, 0.09499302578681601, 0.1496027316049402, 0.1298652182890755, 0.12703196387421922, 0.10883605545502228, 0.13341511939298512, 0.0804165572285076, 0.09715976475124277, 0.10298661165182699, 0.07875388839050868, 0.09993207713373597, 0.14997898726166858, 0.07997679146957948, 0.0889719713189504, 0.8733598438926402, 0.8829247581101383, 0.8107330706494309, 0.8418236243637234, 0.826048943956618, 0.8763580715416123, 0.9217728619694531, 0.8927136208258287, 0.869403023962819, 0.25140527813160796, 0.2467587277487192, 0.26870185862858054, 0.28366271636312335, 0.23114576728644975, 0.25582077141830384, 0.2555034018735709, 0.21342555956703058, 0.24670188328717257, 0.22821418400769278, 0.3465783679549802, 0.22195558410990235, 0.3443793578857436, 0.37502113555895644, 0.20177794790268588, 0.23042586382550867, 0.22152995992848357, 0.24020029535848186, 0.10103285501279602, 0.10732974791680172, 0.11777054567507728, 0.12449462682364187, 0.29637022364856636, 0.1576304423248588, 0.204987868880819, 0.22550985418358982, 0.13376901046619982, 0.20078006519439828, 0.15483073881471066, 0.14675019337162887, 0.1580301660563055, 0.1621585253070813, 0.15164297447802022, 0.154326020698488, 0.13546253824491195, 0.2319091403968463, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.036008263538462426, 9.999999999998899e-05, 0.013182792050333236, 0.043146302900879396, 9.999999999998899e-05, 9.999999999998899e-05, 0.1806116247417101, 0.04478055658063518, 0.0940481830953579, 0.11431716588091334, 0.061049789755089345, 0.043796230341460074, 0.15970612186074717, 0.08651917900030892, 0.09443935050284669, 0.13347069570251546, 0.11500579868630989, 0.06289732516438018, 0.13579257058856242, 0.10717011734560589, 0.05567800507781917, 0.1349373558547854, 0.08418935218086021, 0.05618195208018806, 0.23686623216109493, 0.11672269306935035, 0.14116042112727534, 0.1910108637713802, 0.10428006230925513, 0.08257856368408889, 0.20466780026119502, 0.15221583154958573, 0.12119164834168183, 0.43191115382130085, 0.45001523991956616, 0.471094357427999, 0.39927251447151557, 0.4257720536808576, 0.48282286234812744, 0.43653658896924363, 0.4027339036834756, 0.4201563314962191, 0.10422727743864812, 0.11404235539658025, 0.11271198270505045, 0.14643559416542662, 0.11933950807470206, 0.11581743458578875, 0.1436727919470775, 0.1250738128707548, 0.1103749771319017, 0.28930681481136367, 0.23763752292975882, 0.19449709859722042, 0.2360538189840934, 0.31232349681646976, 0.2969244087793673, 0.297064085168931, 0.21857631210082196, 0.20779188270962778, 0.3053909578903583, 0.3350584845362251, 0.29280307968410635, 0.3666488259581687, 0.31702327379842565, 0.3286392645546179, 0.31413772986542077, 0.27523852343835487, 0.21664678388819636, 0.2403601823461483, 0.22192289997359527, 0.23364259880279326, 0.17808726652938822, 0.27173294990276486, 0.24993524292113367, 0.19160163881183379, 0.23962314152675723, 0.19161676234169922, 0.22117981833973543, 0.22810907608397712, 0.2578077627096508, 0.22552198954956415, 0.20633638004270116, 0.22961211289004535, 0.22037614750775614, 0.2061916058128298, 0.23877262382244824, 0.17187511133913336, 0.20408670973783027, 0.18091496284561104, 0.1826917144641339, 0.18858736945822052, 0.18767358197393802, 0.18865543521321004, 0.19182737290730134, 0.17343479968020925, 0.6588153428031345, 0.18617103570970317, 0.18707646475125794, 0.7700540064253435, 0.19840188432709205, 0.14586050198447376, 0.1414882362582348, 0.15538474064174024, 0.2204610142084117, 0.5320110331352523, 0.20872997180046393, 0.1675053608494005, 0.4100145088571071, 0.21325957693244169, 0.4033210131574101, 0.16627714554943795, 0.1694648518504378, 0.3069886904715988, 0.18773127518521837, 0.18670233431827632, 0.19913581431402982, 0.1870572743958805, 0.1843311921338452, 0.1935408433598783, 0.19633632451674143, 0.1877709620819198, 0.19754664360714091, 0.0938693262250263, 0.07690147340882703, 0.07088632812903228, 0.09583908349763093, 0.1004354963443227, 0.09592806611064952, 0.07972400803906399, 0.09667963076826258, 0.09547686002136269]}, "mutation_prompt": null}
{"id": "e7975328-e978-4584-bc3f-40aa9abd1e89", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < 0.2:  # Modified opposition-based learning with probability 0.2\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and modified opposition-based learning with probability 0.2.", "configspace": "", "generation": 216, "fitness": 0.23660467148715092, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6573652859826458, 0.6479138828760608, 0.6155682065720697, 0.6521170106926442, 0.5983228597862076, 0.6695112469035098, 0.655159355118514, 0.6340361737118273, 0.5335360902203734, 0.02862120514916755, 0.027687286794752852, 0.002488352515412573, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13751429562673168, 0.11298652833027589, 0.13393371339207494, 0.1033803474592796, 0.11186597949988697, 0.09600849460570227, 0.14968614667203983, 0.13668635228916537, 0.10199635415733521, 0.07573948703197053, 0.07911538518997063, 0.09874582552684186, 0.10823128410384375, 0.08727058463698434, 0.07907250805618882, 0.07334791608283231, 0.09242359438178827, 0.08653631220506774, 0.8855087489440115, 0.9367278963131287, 0.7831297877663888, 0.6559252233272745, 0.8936601822047983, 0.771208842535294, 0.9057781328935146, 0.9078726210689054, 0.8833744478283087, 0.27774713442665244, 0.25258326937195874, 0.23757060897399174, 0.26839964107128345, 0.24389764638560651, 0.29400478676352926, 0.2291886358685984, 0.23564225487010626, 0.23826919172320749, 0.4209474051087676, 0.3808353775463901, 0.3059787496911356, 0.2747402077519602, 0.3641374402794021, 0.20252523160104396, 0.5447172720445994, 0.21598422102277692, 0.24222691557031217, 0.09318248592369838, 0.10778567328787525, 0.12120504477918825, 0.16528962100780664, 0.12665191625783823, 0.13309748752278105, 0.1273033671839806, 0.22544301122064025, 0.15995600440049962, 0.16059431081527475, 0.23068220029941955, 0.1533374948245213, 0.1594596221187392, 0.15770567685010306, 0.2319041474758171, 0.17846900845351432, 0.18052303760182642, 0.1502728013281529, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.0018718426765200746, 0.018109148834418054, 9.999999999998899e-05, 0.008122655960657754, 9.999999999998899e-05, 0.07721704224432802, 0.12871399568260822, 0.05681794262740114, 0.1310837259147174, 0.10378656628405025, 0.08334335525823322, 0.02748895624423786, 0.11173380417543122, 0.09176979410798536, 0.08532241599543999, 0.09399818119126957, 0.10759365161680967, 0.11439500839507533, 0.07081961878789822, 0.11661237214845499, 0.07680688306118844, 0.09672267706416571, 0.081293040177155, 0.08020921573350259, 0.24464016021776036, 0.10357467030957723, 0.20350699695223262, 0.08774280816317437, 0.17904092558820506, 0.1368684571861697, 0.16095360665672653, 0.11660499949099179, 0.12300867014228933, 0.4474187730415501, 0.44061846620839806, 0.4435943538832272, 0.4508636481181727, 0.4444718343219095, 0.42997022854232403, 0.41110550181534655, 0.415887642122328, 0.4413523010777298, 0.11199888154872684, 0.11472186203546408, 0.10160292982165209, 0.21468801597218767, 0.10722805069120855, 0.1262516988740746, 0.10864781464822026, 0.10740834503225338, 0.09073384205580293, 0.315266063726826, 0.1685152579078636, 0.19251027759489814, 0.1999187477301687, 0.3448668559218271, 0.20139424904145842, 0.2514570397574083, 0.15127008709892764, 0.17681938417480958, 0.25307876349074987, 0.30912661216730464, 0.31600919395433547, 0.25562107048111316, 0.33870938020822716, 0.3211600501413435, 0.24685375939384757, 0.2849957681373395, 0.2545488698084404, 0.21623658278685887, 0.20244937974220711, 0.26236129877797154, 0.22850283808768967, 0.20402218793242932, 0.28078302003550637, 0.2021200599812153, 0.23145446912964918, 0.20843083709363175, 0.22617617049269523, 0.24708111013747336, 0.2386980483152522, 0.2339926258077678, 0.23070586362078438, 0.2145924866730774, 0.23226507261073137, 0.21064786243950206, 0.21215639095963368, 0.19830568782890745, 0.18595517902824155, 0.19225401215858928, 0.19909310616303666, 0.20480979608298766, 0.17499236825281328, 0.16779582520486258, 0.17840729409374567, 0.1751144578085745, 0.1801510410196897, 0.1864537953919888, 0.740048728117605, 0.6824370140252116, 0.1987023127131743, 0.1989107729423637, 0.6567642016065707, 0.1469523660319726, 0.6021068854851259, 0.6076830621774898, 0.2084385722242642, 0.5257681143940257, 0.41997032508787835, 0.45160661164571647, 0.16775793231363711, 0.16759653257671503, 0.30862711995063175, 0.3358808714352316, 0.19503171559728283, 0.18550065811844574, 0.17941663190178314, 0.23054214352609037, 0.1979753176370922, 0.18263091813891996, 0.18028370665327642, 0.18944880276062148, 0.19010795157822702, 0.0902171696532017, 0.09256532272161677, 0.09119153773237287, 0.09562714347035539, 0.08392409808660362, 0.08942066216413369, 0.09877595463021605, 0.08979214591029339, 0.0850252112470049]}, "mutation_prompt": null}
{"id": "f876df81-2006-4c76-8cd0-c6a0f2da8c01", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.swarm_intelligence_rate = 0.05  # Novel swarm intelligence mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_intelligence(self, particles):\n        centroid = np.mean(particles, axis=0)\n        return centroid + np.random.uniform(-1, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Swarm intelligence mechanism\n                if np.random.rand() < self.swarm_intelligence_rate * (1 - evaluations / self.budget):\n                    swarm_intelligence_position = self.swarm_intelligence(self.particles)\n                    swarm_intelligence_fitness = func(swarm_intelligence_position)\n                    evaluations += 1\n                    if swarm_intelligence_fitness < fitness:\n                        self.particles[i] = swarm_intelligence_position\n                        self.best_fitness[i] = swarm_intelligence_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], swarm_intelligence_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a novel \"Swarm Intelligence\" mechanism.", "configspace": "", "generation": 217, "fitness": 0.23190810768856873, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6078797813920398, 0.6650825224339811, 0.6036330003467802, 0.6959918078794731, 0.603550389229292, 0.5424749478311077, 0.5929182907945005, 0.6138161845687188, 0.5652754921967542, 0.015303388485889857, 0.022490425014536797, 0.0004806128952995481, 9.999999999998899e-05, 0.0004282396065996563, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10137853535564567, 0.16741532638279077, 0.10971046483081259, 0.08009927325883293, 0.1321087203405985, 0.09826484049822215, 0.13758183877360952, 0.0979121488173843, 0.11210015825785724, 0.08634711647823334, 0.07491596422671432, 0.10274520205454996, 0.09472914546457101, 0.07215526949507167, 0.08998755598641961, 0.08653515881737184, 0.10179907664985, 0.07570751230124428, 0.8897774913221711, 0.8748917084735571, 0.8722013410627688, 0.7846498348699489, 0.7914698573604682, 0.8702391272943064, 0.9066840350418823, 0.8852731116581839, 0.9037746588069585, 0.25510005375620337, 0.2644306491842906, 0.27726397624217913, 0.23323806201421737, 0.2554421167365122, 0.26667511561973634, 0.29522408845532, 0.2604850897661638, 0.24977828724225237, 0.2764560628145478, 0.2793457411902768, 0.22660934966859336, 0.23496349076431167, 0.3652738140559687, 0.27594479972402264, 0.31286502957826057, 0.17845538185731347, 0.31489506842611703, 0.1424221710094009, 0.12527686711276442, 0.12435897800949791, 0.13866967355908533, 0.19368155098445594, 0.1719408990154896, 0.13395346467894687, 0.1574034195702828, 0.15671898903005443, 0.1491364655225198, 0.15779057880601777, 0.1549766717344464, 0.13701386355117007, 0.17366859887474695, 0.1882951857013474, 0.1695273073404805, 0.13658309442336636, 0.14124722302903814, 0.024012922685835103, 9.999999999998899e-05, 0.02817365540888017, 0.04162173246910461, 0.007250572891482676, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.01827418315808027, 0.11349260745189238, 0.044121523033977206, 0.11540254405726769, 0.05578759625552665, 0.0772051406043851, 0.05287378426538181, 0.12062596928722102, 0.07072387317489104, 0.07790833610852754, 0.1279423292492332, 0.10450978513933895, 0.11626816130863094, 0.08225666075617077, 0.12585864425724325, 0.06177641177397286, 0.11270531241667558, 0.05658222503936927, 0.09796175396112161, 0.2111889476321256, 0.1415855711744729, 0.09164536954379421, 0.19397778718095593, 0.16043947658780922, 0.06521720844461887, 0.14629050710604552, 0.12432286727937358, 0.09417293082783307, 0.40447174484878246, 0.47875074193684686, 0.43082958576569697, 0.4284047968698371, 0.42491027473902565, 0.4003234940106978, 0.457433313236283, 0.46152083953648804, 0.4364852622504821, 0.12583957703943793, 0.1067021393517047, 0.07703329212289678, 0.12479732189905535, 0.11070183067499506, 0.13270121982714167, 0.14677942262681476, 0.1178744700936668, 0.0864058900303386, 0.17510551238290428, 0.20012423594227102, 0.16674659461365005, 0.1849231740988535, 0.23704491370562464, 0.20687017626789217, 0.20805068320836517, 0.19345483637700434, 0.2285751425792586, 0.33325133931794315, 0.3736917348291904, 0.3288643168695744, 0.34678667873424074, 0.3606300482416661, 0.3424502470779286, 0.23905779734793697, 0.27589859766139235, 0.2404123120932733, 0.24056259784750322, 0.237314911091411, 0.22436009793742173, 0.20132981903951064, 0.27046254428240046, 0.24353926220287492, 0.2012362302214814, 0.23254562335895035, 0.20975130213392734, 0.22977652909957524, 0.23147076592156657, 0.21716146339759979, 0.2353628948398241, 0.2327023755776223, 0.21191032059706927, 0.25914600849031977, 0.22079103130304012, 0.2874486591462093, 0.17519425921792986, 0.17671630005032768, 0.20827041686429115, 0.19939461801883285, 0.2281236499373317, 0.19458532362544034, 0.18931939692904098, 0.2137510931047908, 0.17242468138992972, 0.1860120947539643, 0.18672743725730023, 0.18697692365687357, 0.6199847233399343, 0.19901293525381558, 0.19640519700331038, 0.7079037122753482, 0.15213746681467377, 0.6595831160045139, 0.5405393709694227, 0.21052880031620613, 0.6789781006150726, 0.3752994739466802, 0.16462524207003337, 0.4738757691160759, 0.16700565836857872, 0.37489569746717377, 0.2831803147037243, 0.1842984001347514, 0.18926198498195257, 0.2001930259336776, 0.20732903799596147, 0.20265847989785035, 0.1893200816988636, 0.17682015264592288, 0.1942292153605808, 0.179393121248814, 0.08692931924368019, 0.08723092093874707, 0.09203091628538151, 0.09487124455983609, 0.09239267436448739, 0.08564346762353237, 0.08602411522795961, 0.08758672970788972, 0.08574347897722889]}, "mutation_prompt": null}
{"id": "bd913693-99d0-49b0-8add-3ce960f92827", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.differential_evolution_rate = 0.1  # Novel differential evolution mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def differential_evolution(self, position):\n        r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        while r1 == r2:\n            r1, r2 = np.random.randint(0, self.swarm_size, size=2)\n        mutation_vector = self.particles[r1] + 0.5 * (self.particles[r2] - position)\n        return mutation_vector\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Differential evolution for enhanced exploration\n                if np.random.rand() < self.differential_evolution_rate * (1 - evaluations / self.budget):\n                    de_position = self.differential_evolution(self.particles[i])\n                    de_fitness = func(de_position)\n                    evaluations += 1\n                    if de_fitness < fitness:\n                        self.particles[i] = de_position\n                        self.best_fitness[i] = de_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], de_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and \"Differential Evolution\" for enhanced exploration.", "configspace": "", "generation": 218, "fitness": 0.2320642684405668, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6109639902698869, 0.7092337146362642, 0.7495612606404467, 0.6131544782589498, 0.6271773823975313, 0.5952977879810517, 0.6130956172644317, 0.6543403517993039, 0.6313752757634512, 0.0026173299268990036, 9.999999999998899e-05, 0.0043236954843208775, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.003143112926795366, 9.999999999998899e-05, 0.12872914571899274, 0.10527851254151355, 0.14598486555659507, 0.09597088850941504, 0.09906346718078407, 0.10962291396847645, 0.13970958050087812, 0.12703206417957047, 0.09723004404507396, 0.07974940007138298, 0.0731026546112633, 0.07004367155691338, 0.07987178745504464, 0.07945327606250174, 0.09498054756807106, 0.11107397065637781, 0.07507965736878741, 0.09319878270077975, 0.8723382267689146, 0.9390843125931196, 0.8699688996786935, 0.8154071925619149, 0.7453259197801683, 0.7455447474727104, 0.9070610093394202, 0.9040720015687129, 0.9097151454503045, 0.25713739755320464, 0.23992537792501112, 0.24351245112616993, 0.2540665410202442, 0.2893350700291185, 0.2815953721604201, 0.26188466018509304, 0.27957468919873796, 0.2720574807468492, 0.2443638459048021, 0.3370659427421302, 0.2705652393723452, 0.8584416021297484, 0.2712448655694141, 0.219260312539304, 0.2692306071190117, 0.23181390339731156, 0.31233969513450865, 0.14875032251930786, 0.13529428054965542, 0.24377418051173694, 0.11132528218052817, 0.14504059163921834, 0.12161692583191142, 0.1302060342852286, 0.13606349961054642, 0.14516384370248903, 0.13655501463059516, 0.16768598202772156, 0.15953720141670524, 0.19149529568395052, 0.15227610985953655, 0.211998536930747, 0.20572367443565442, 0.1748605338056235, 0.1523040834025865, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.03306639236371245, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.009610141805437289, 0.09181329731562815, 0.0825381094149088, 0.08911868394997413, 0.13231557495442725, 0.07694604467608646, 0.04131776330349801, 0.09102110334734081, 0.08322732141621314, 0.10395978626619129, 0.15067475018080245, 0.06117818831119515, 0.0865829308832119, 0.11125497201375478, 0.09895790752653122, 0.07542798349919844, 0.08901939303310757, 0.1521630185906626, 0.0784687643206351, 0.1804937845250193, 0.1614108882041705, 0.09029385031733905, 0.09432407811277588, 0.10453599660021629, 0.11516137495809686, 0.1547345756053854, 0.16600726430371016, 0.08647005749885028, 0.42263030497109544, 0.4311496667314294, 0.4219046276845245, 0.4406558226593047, 0.46236601872082805, 0.42050000877291027, 0.4275070961013179, 0.4467902806256304, 0.4364320253972116, 0.11447777731413045, 0.09414313894850124, 0.0772354004537934, 0.12209631667988563, 0.13904633444896586, 0.14961134412494426, 0.10676068702198427, 0.11968310422674189, 0.09087120210212685, 0.14519983028099248, 0.29451061336530826, 0.26614408020248126, 0.23504937289403238, 0.30611998255350736, 0.21146160676805847, 0.20883257798322818, 0.20108414836658617, 0.16438406733346222, 0.2566904246375651, 0.30405829515344984, 0.30661232464312205, 0.24770424379774036, 0.33571645820547436, 0.2589928491259198, 0.27014481966100934, 0.3106818906097384, 0.2899742494616363, 0.21544994134733542, 0.19114692826096213, 0.2995245970292122, 0.2347477078340343, 0.2554387299132016, 0.2224524924443534, 0.1645530305491546, 0.20817834414967185, 0.22925807238558082, 0.22884963821731985, 0.2510813638049303, 0.22308278096325962, 0.24055751909220147, 0.23118173020166766, 0.258011365001505, 0.24990623947422375, 0.23666771125373753, 0.20482764550434385, 0.17257381046109255, 0.19831992925308017, 0.18870338497468098, 0.17572337637273194, 0.1995048888865083, 0.18113812551877284, 0.21569579881149514, 0.17314427790153708, 0.1779093651587862, 0.18548739858061158, 0.18610430174238812, 0.18511655532319327, 0.7535667494376205, 0.19971218702064497, 0.19576083310673442, 0.14050962057986416, 0.15188767551534343, 0.8096998577217773, 0.39629208080440825, 0.16770331397643, 0.3414773609668931, 0.2152018823317252, 0.48480837067757154, 0.1649224328890756, 0.27230779471171596, 0.4766166354229924, 0.3689311140716187, 0.18313873310548456, 0.19232950688949257, 0.20032921981609597, 0.18506494832592812, 0.20057181387670342, 0.19244516348003704, 0.18893370425138734, 0.19252106118361234, 0.18747270883417233, 0.08490918337109032, 0.10712745389615119, 0.098053765149962, 0.09376204433622459, 0.10226205155136048, 0.0916578879043407, 0.08959499194167708, 0.10180056842858454, 0.08849209815454306]}, "mutation_prompt": null}
{"id": "ad0132d8-d8b2-4817-9a9a-9a34eeb65a8d", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.self_adaptive_levy_flight_rate = 0.1  # New self-adaptive levy flight mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def self_adaptive_levy_flight(self, position):\n        levy_flight_step_size = np.random.uniform(0.1, 1.0)\n        return position + levy_flight_step_size * self.levy_flight(self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Self-adaptive levy flight mechanism\n                if np.random.rand() < self.self_adaptive_levy_flight_rate * (1 - evaluations / self.budget):\n                    levy_flight_position = self.self_adaptive_levy_flight(self.particles[i])\n                    levy_flight_fitness = func(levy_flight_position)\n                    evaluations += 1\n                    if levy_flight_fitness < fitness:\n                        self.particles[i] = levy_flight_position\n                        self.best_fitness[i] = levy_flight_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], levy_flight_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Self-Adaptive Levy Flight\" mechanism.", "configspace": "", "generation": 219, "fitness": 0.23704610400393358, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.21.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6062014230450958, 0.6216254795673962, 0.6284139073453661, 0.6367860987547982, 0.6883218679214772, 0.6350289949716896, 0.553644358554057, 0.650811287512819, 0.719860230671415, 0.004366945056094473, 0.03348216587394659, 0.029632587560428303, 9.999999999998899e-05, 0.04598967844871693, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10305770475441967, 0.08373351541919438, 0.11011803779904983, 0.09745490681548286, 0.079026820658603, 0.10196895208710555, 0.11259188400375553, 0.1124856753068656, 0.16000954250798727, 0.07477801468025369, 0.09311442734724629, 0.10217505150672679, 0.09741790261979677, 0.07051151204738249, 0.0879847276163156, 0.09076440823094056, 0.09358704765236725, 0.09522575353965657, 0.8602612222959732, 0.9164934428121712, 0.8828244945243049, 0.8057100716239322, 0.8590535158108314, 0.8829626043582663, 0.8899557157736718, 0.8966879254991372, 0.8265888413624555, 0.25457728417908965, 0.2714876537054237, 0.2817440868595007, 0.271341774734177, 0.25630515114755525, 0.2561258799742512, 0.23693542913169963, 0.26340522904238584, 0.2356505847527639, 0.2998082304307199, 0.3707455318896826, 0.3004860925389864, 0.20803992653088565, 0.8590993129395308, 0.24806558669836698, 0.3512712574766058, 0.2886201779973926, 0.2413499230716606, 0.187110362514473, 0.13454368634227742, 0.1178989567575569, 0.03644404636600318, 0.14804195291687772, 0.1469346715927572, 0.1461371006869595, 0.17475074663392842, 0.1363989684993745, 0.13630630527797571, 0.20570772603518495, 0.15446734428113906, 0.1525101249731693, 0.14565707851643384, 0.1644587850800554, 0.1618750557975963, 0.16846666479949712, 0.16158822688043561, 9.999999999998899e-05, 0.03148811468807633, 0.013711617640708385, 0.0406736167492856, 0.04730975938369886, 0.023753532042338654, 9.999999999998899e-05, 9.999999999998899e-05, 0.015348242130085454, 0.07617055420080576, 0.06750801303767162, 0.1318941296822762, 0.08378213885130759, 0.11813514612785603, 0.02515610658874734, 0.1749259288983288, 0.06489203324758241, 0.09009866805438338, 0.11064551839806991, 0.06357279617256406, 0.24143909751427706, 0.19890372835183356, 0.11833297758065398, 0.08133849342947741, 0.09744174883727574, 0.07847561817845994, 0.08132253414403645, 0.195269083491996, 0.15557054987122154, 0.1326173706552678, 0.0867538791658582, 0.0648883320331699, 0.15921318791647032, 0.14737766470867297, 0.09717785378287969, 0.10860264335957615, 0.4318535712601187, 0.42297964589764947, 0.43430239587740493, 0.4322652255197794, 0.40075710107726004, 0.46387723243046364, 0.42467240111000293, 0.40740575737219964, 0.45210237638116557, 0.10591318999093458, 0.10093128604486379, 0.08136877864090453, 0.10194320271727975, 0.06387452574562236, 0.17328680654142592, 0.12173304430798149, 0.11427595471020158, 0.10109059291761224, 0.26318849455123294, 0.19254557321427956, 0.16692582013139456, 0.21252515545956852, 0.3890062120757549, 0.294728689552744, 0.27097135361589275, 0.21132784946559824, 0.249701443101486, 0.3202053630456312, 0.31108731976716963, 0.34078588220463857, 0.27047518529926773, 0.3003876066502267, 0.25478877138232714, 0.23021694993575215, 0.2939591277089305, 0.2250868532856828, 0.23232466442005684, 0.2450986890393707, 0.28056585149470337, 0.31303990194946196, 0.21981247628608913, 0.2604352352576963, 0.17572868837047895, 0.22211024828594705, 0.2317903803563116, 0.23554883020497808, 0.21523911375560922, 0.26510284869519796, 0.23840008387162803, 0.22743443180025857, 0.23464170400092021, 0.2203886681731977, 0.2527049105964845, 0.23712180152298534, 0.19175849201347117, 0.21707804952552157, 0.18828488563452106, 0.1855327959688522, 0.18114905526594793, 0.21301441686491707, 0.17446048158625072, 0.1789078290588133, 0.19066739145362321, 0.13712645860975448, 0.18542882662176674, 0.18566087671421783, 0.1989122390179432, 0.1982516618240142, 0.7420662593720992, 0.14114698308877427, 0.6463882998965165, 0.6775143217813977, 0.5393951527125925, 0.21056335842165252, 0.3927773436779589, 0.345445125482298, 0.16494339923808365, 0.1676785602419919, 0.23592315223166305, 0.38916273630174314, 0.5721963539226932, 0.17659258890091456, 0.2041633411346203, 0.18799904311061533, 0.20209997277794856, 0.2064419355695698, 0.22844543031135522, 0.1906732445551823, 0.19392857971997424, 0.17602411708267596, 0.08195761183798989, 0.07165174633613591, 0.0873136765369763, 0.087185198021, 0.08742110285067106, 0.09074586985028965, 0.09772804523837164, 0.08483772703625436, 0.11562312047371903]}, "mutation_prompt": null}
{"id": "592be710-c731-456f-9c28-538f3fbb1394", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n        self.multi_objective_rate = 0.1  # New multi-objective strategy\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def multi_objective_strategy(self, position):\n        # New multi-objective strategy to balance exploration and exploitation\n        exploration_vector = np.random.uniform(-1, 1, size=self.dim)\n        exploitation_vector = 0.5 * (self.best_positions[np.argmin(self.best_fitness)] - position) + 0.5 * (self.global_best_position - position)\n        return position + exploration_vector * np.random.uniform(0, 1, size=self.dim) + exploitation_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Multi-objective strategy\n                if np.random.rand() < self.multi_objective_rate:\n                    self.particles[i] = self.multi_objective_strategy(self.particles[i])\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Multi-Objective\" strategy to balance exploration and exploitation.", "configspace": "", "generation": 220, "fitness": 0.23741785396408177, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6004354663239577, 0.6069297451915092, 0.6072212309727253, 0.6436666362597968, 0.6798393664121662, 0.6361473621891559, 0.5699179286575733, 0.6214115940556105, 0.6475764276724213, 9.999999999998899e-05, 0.034748521153377676, 0.07102412781709866, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10040463017311707, 0.06935947148608834, 0.1909237403323054, 0.09391228767576909, 0.09862878951214538, 0.13622663235842392, 0.12560020777496883, 0.11875564039820052, 0.12381244033763705, 0.0798902910365279, 0.09108253117636289, 0.08359457528243497, 0.08780417167325683, 0.07545581269312929, 0.08413698157430372, 0.1362340027981076, 0.07873074049761686, 0.07063329978576782, 0.8339877549872982, 0.9104022935273931, 0.8487873738367298, 0.7960611720966726, 0.8406701090014257, 0.835013552153985, 0.9032053816843655, 0.9071250254955499, 0.8781030667179273, 0.30037665563892113, 0.30698325114053404, 0.23924982762142677, 0.281114457485689, 0.2937511361565084, 0.2759679242228421, 0.22722191261574542, 0.237481876635807, 0.22454244046339544, 0.2855053801037727, 0.8592949381968475, 0.30600437919236734, 0.304349496162716, 0.36473266667165616, 0.20088049083258674, 0.21114967592870815, 0.21224738389912956, 0.21608585150175863, 0.2555122963983467, 0.12174663864320467, 0.11259353798116933, 0.10336785346836164, 0.1252072708422336, 0.1943405750270335, 0.15150426333638134, 0.11237959802054287, 0.16719005057673475, 0.1533644392083554, 0.19424373951812535, 0.1386395632704578, 0.15053846654238878, 0.12413548637211247, 0.19129504907042372, 0.14046440443899955, 0.18519337841672157, 0.20818093164765583, 0.004696493506613164, 9.999999999998899e-05, 9.999999999998899e-05, 0.06942836984964995, 0.05727873664907934, 0.007082898700086715, 0.04345370507403146, 0.0016624689543286442, 9.999999999998899e-05, 0.06499997721172968, 0.07491513855883836, 0.0753579383515971, 0.06918487547990626, 0.0539963357715878, 0.037336742074201124, 0.09999796714080278, 0.14164809830950276, 0.03619843725668592, 0.15879448221921866, 0.07858173682500658, 0.1036764755154943, 0.19160648003074543, 0.07536154052661381, 0.06383156564929737, 0.2201374849483313, 0.07399335611479241, 0.17076534487086215, 0.2017375194195935, 0.11131023508539639, 0.1662480747831473, 0.21457417230797993, 0.12746264404194985, 0.1434972163019922, 0.08987395569994372, 0.10718413508679547, 0.10612840400334023, 0.45904725143877934, 0.39978846072021157, 0.45819966983702587, 0.5084279925949148, 0.4452807733552048, 0.47696411086247437, 0.46840605342233277, 0.47271570901503823, 0.4022613587110093, 0.11835382991469268, 0.09514048562285038, 0.11694699565863953, 0.14728567628802225, 0.11879287863655885, 0.13139386026748945, 0.2617998749166731, 0.12657680785869818, 0.10839014289571391, 0.32852407140959383, 0.2224637650969823, 0.16702211693864844, 0.22288222378292344, 0.33059418262322837, 0.2049101489383367, 0.18244226617318016, 0.22106334418392448, 0.21685199669295074, 0.2897811499316264, 0.2506870105695881, 0.28633269588880517, 0.28614768383113676, 0.3621970766797662, 0.2775955070151198, 0.25878273680607766, 0.27495939399572566, 0.2717159049337917, 0.24129854353548497, 0.22601309799178038, 0.243626651261157, 0.23064668853679537, 0.23366300187254396, 0.22406592641715772, 0.20027748596738182, 0.23121524067616916, 0.21246028507357262, 0.23076305642106076, 0.20846965253492766, 0.24521294734862953, 0.2368110675922559, 0.25228843590997574, 0.22281335427955296, 0.2342739984024933, 0.22764314046750367, 0.21301269478454765, 0.19380367130431575, 0.17350063550476025, 0.20693217791377716, 0.20459908401757865, 0.1853167349770699, 0.20144042182605448, 0.1949506109405198, 0.17950362129501085, 0.17750861552644892, 0.15020328946393824, 0.18560427290448678, 0.18511054424619033, 0.5179313138784274, 0.19926348340762057, 0.19635825507358906, 0.14106028177898222, 0.7022392113790648, 0.557138835201396, 0.44431746853036036, 0.19459906787027836, 0.4198733339855907, 0.46707828071252344, 0.32883706678942204, 0.40205841398900477, 0.34271601922851724, 0.28194176333388643, 0.49591357749065157, 0.1924878806519651, 0.18775499011649677, 0.1959979890491148, 0.18229439821045412, 0.18570060592830073, 0.17716911276002467, 0.19687163029842847, 0.20714498483846167, 0.1949574917160487, 0.0839097438494657, 0.10990119560416112, 0.08995758614937455, 0.09104326914587746, 0.0789576457786596, 0.09119943119794793, 0.08628912127269128, 0.09215307925451999, 0.0860850949277765]}, "mutation_prompt": null}
{"id": "0cd61c1f-d4b4-4b5f-89f6-f8d0256c6434", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.memory = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.memory_size = 5\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def update_memory(self, position, fitness):\n        if len(self.memory) < self.memory_size:\n            self.memory.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.memory])\n            if fitness < self.memory[worst_index][1]:\n                self.memory[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    self.update_memory(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                        self.update_memory(self.particles[i], opposition_fitness)\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                        self.update_memory(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                        self.update_memory(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                        self.update_memory(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                        self.update_memory(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n                # Memory-based position update\n                if np.random.rand() < 0.05:\n                    memory_index = np.random.randint(len(self.memory))\n                    self.particles[i] = self.memory[memory_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                        self.update_memory(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and an additional \"Memory-Based\" strategy to improve convergence.", "configspace": "", "generation": 221, "fitness": 0.22831679312003855, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.23 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.579697711232884, 0.6107897462083813, 0.6781162326439376, 0.5692252725163419, 0.5641073444931711, 0.6455036384039639, 0.5932907447472706, 0.5990063356252108, 0.5971082521942095, 9.999999999998899e-05, 0.028818330890222787, 0.00018098128557431092, 0.0009723432508544905, 9.999999999998899e-05, 0.04229236295472161, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.10958187993753077, 0.11452577657395413, 0.10271619097377716, 0.076264831955696, 0.12311575251442697, 0.1358997406430832, 0.1408662205311837, 0.13216098780983887, 0.10351947895176528, 0.07462098670633155, 0.09082896314963251, 0.0879514676134282, 0.08404964697160833, 0.08530973293449229, 0.0819610838496807, 0.09475537278032531, 0.07586164615859725, 0.10027627839404174, 0.8274092357451754, 0.9144520510402934, 0.7646290253390798, 0.7720785450389216, 0.8363827675715467, 0.7907679002652908, 0.916521769213983, 0.9178784404976604, 0.8464835940534493, 0.23890614336724014, 0.2826406300961454, 0.2746730259567256, 0.26425341799709035, 0.2751863921805098, 0.21195721603325135, 0.21193065803268762, 0.24772437360733224, 0.2803076786476548, 0.307544046826427, 0.21437508531450444, 0.222441656347791, 0.27508161880664506, 0.25978909342881884, 0.20018320503291975, 0.31278960894800123, 0.2297562992388611, 0.21466340745352785, 0.16959757981774692, 0.12974633054596818, 0.1452938030047991, 0.13712036202780997, 0.14469419064183653, 0.17914458427444568, 0.15855872780643565, 0.290017194193107, 0.1685576512477448, 0.18683675618437445, 0.12854450328171296, 0.1392180319307028, 0.14173320071564144, 0.24291283760615556, 0.19799146594173866, 0.1533591536144404, 0.1656922334180415, 0.18598316571648088, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.007344706743035223, 9.999999999998899e-05, 0.006202578411350634, 0.005186069702644236, 0.003284378408784816, 0.018269159275386637, 0.13587218417677305, 0.05234718767986468, 0.12532076378954748, 0.0683349235050511, 0.09458973891407763, 0.03704456753628582, 0.14857293787398407, 0.07551587991753916, 0.07075590427362022, 0.07979636912462551, 0.06163179972135657, 0.08491872074565932, 0.05590481442350759, 0.06272055393304488, 0.07705413271760553, 0.10660419483194294, 0.11041206883905597, 0.05311723949590197, 0.1668860713774991, 0.08484082706541718, 0.09524528585937642, 0.13364727315606983, 0.128197689250509, 0.15730120285288962, 0.11347159240349358, 0.08420969465786743, 0.08981381722283988, 0.4202000329941846, 0.4145720053234734, 0.4361228128280742, 0.4045721978524254, 0.43355711951873, 0.47001755026646286, 0.4803365682587758, 0.4558479149167487, 0.43076284367183737, 0.11895219572410987, 0.09999587576353297, 0.11418320827809203, 0.09783031232229966, 0.09298002034488906, 0.1037693795989919, 0.09814293906373661, 0.12739252821939773, 0.1661539700585115, 0.21042075073139221, 0.2186028582775007, 0.16668775890526244, 0.18937735723210258, 0.2962830562666815, 0.1985155131375015, 0.23758325696974603, 0.17483686686408417, 0.16390430550353918, 0.24742531265101508, 0.3278870959598936, 0.3316381577815142, 0.30896602143178975, 0.2788883316518963, 0.2967504799450509, 0.25988422235259945, 0.24280038586180475, 0.23257125353197639, 0.20794158841903632, 0.24524919580853521, 0.23427675713765495, 0.2723865019388503, 0.2527766721779149, 0.25834729196599693, 0.2384545601100485, 0.21656482918491626, 0.2204393951010476, 0.2151910422910166, 0.21407735468920852, 0.21692960073105427, 0.21787282408101727, 0.24023187119316947, 0.22555242453095103, 0.24405213528521352, 0.2311774142428754, 0.2248461744392648, 0.17360561690864984, 0.1722829287681954, 0.1699912246502603, 0.17690564623172722, 0.18475224787903965, 0.1824729833590535, 0.1995599765395023, 0.1970817205998916, 0.18097780045679202, 0.1841045062345369, 0.18673701239479046, 0.18761322732086172, 0.5222623807177009, 0.19817519918929283, 0.2994403584651105, 0.141216919508389, 0.605519017017202, 0.7734409017049847, 0.4372746213017479, 0.212270708246438, 0.46841898898724044, 0.42217315282205914, 0.5329902165363611, 0.5877890988436014, 0.16617001691603583, 0.3529638495064781, 0.27902195546469555, 0.19273623546898344, 0.18552219326424335, 0.20093809486475078, 0.19624239539235555, 0.17941088997444965, 0.186238129253942, 0.20394389506245114, 0.18203041201405845, 0.17881391526111434, 0.09403190594044009, 0.08398061376262034, 0.08623228405005046, 0.08357856865244051, 0.08423038467929889, 0.0869881758084966, 0.08352506109333824, 0.09189784306886106, 0.10159562552494339]}, "mutation_prompt": null}
{"id": "27dc38c6-0c07-4bb1-a314-651aec3349ed", "solution": "import numpy as np\n\nclass HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11:\n    def __init__(self, budget, dim):\n        self.budget = budget\n        self.dim = dim\n        self.lower_bound = -5.0\n        self.upper_bound = 5.0\n        self.swarm_size = int(np.sqrt(budget))\n        self.particles = np.random.uniform(self.lower_bound, self.upper_bound, size=(self.swarm_size, self.dim))\n        self.velocities = np.zeros((self.swarm_size, self.dim))\n        self.best_positions = np.copy(self.particles)\n        self.best_fitness = np.inf * np.ones(self.swarm_size)\n        self.global_best_position = np.random.uniform(self.lower_bound, self.upper_bound, size=self.dim)\n        self.global_best_fitness = np.inf\n        self.archive = []\n        self.temperature = 1000.0\n        self.cooling_rate = 0.99\n        self.adaptive_cooling_rate = 0.4  # Refined adaptive cooling rate\n        self.levy_flight_alpha = 1.5\n        self.levy_flight_beta = 1.8\n        self.opposition_based_learning_rate = 0.2\n        self.dynamic_opposition_based_learning_rate = 0.15  # Refined dynamic opposition-based learning rate\n        self.dynamic_opposition_based_learning_rate_decay = 0.99  # New dynamic opposition-based learning rate decay\n        self.inertia_weight = 0.9\n        self.inertia_weight_damping_ratio = 0.99\n        self.mutation_rate = 0.1\n        self.adaptive_mutation_rate = 0.05  # Adaptive mutation rate\n        self.mutation_step_size = 0.1\n        self.velocity_clustering_rate = 0.1\n        self.particle_filtering_rate = 0.2\n        self.adaptive_particle_filtering_rate = 0.05  # New adaptive particle filtering rate\n        self.archive_size = 10\n        self.exploration_rate = 0.5\n        self.exploitation_rate = 0.5\n        self.hybrid_repulsion_rate = 0.1  # Novel hybrid-repulsion mechanism\n        self.swarm_restructuring_rate = 0.05  # New swarm restructuring mechanism\n        self.quantum_tunneling_rate = 0.1  # Novel quantum tunneling mechanism\n\n    def levy_flight(self, size):\n        r1 = np.random.uniform(size=size)\n        r2 = np.random.uniform(size=size)\n        return 0.01 * r1 / (r2 ** (1 / self.levy_flight_beta))\n\n    def cauchy_mutation(self, position):\n        mutation_mask = np.random.rand(self.dim) < self.mutation_rate\n        mutation_vector = np.random.standard_cauchy(size=self.dim)\n        return position + mutation_vector * mutation_mask\n\n    def gaussian_perturbation(self, position):\n        perturbation_vector = np.random.normal(loc=0, scale=0.1, size=self.dim)\n        return position + perturbation_vector\n\n    def opposition_based_learning(self, position):\n        return self.lower_bound + self.upper_bound - position\n\n    def velocity_clustering(self, velocities):\n        velocity_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        velocity_clusters = np.argmin(np.linalg.norm(velocities[:, np.newaxis] - velocity_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_velocities = velocities[velocity_clusters == i]\n            if len(cluster_velocities) > 0:\n                velocity_centroids[i] = np.mean(cluster_velocities, axis=0)\n        return velocity_centroids\n\n    def particle_filtering(self, particles):\n        particle_centroids = np.random.uniform(-1, 1, size=(3, self.dim))\n        particle_clusters = np.argmin(np.linalg.norm(particles[:, np.newaxis] - particle_centroids, axis=2), axis=1)\n        for i in range(3):\n            cluster_particles = particles[particle_clusters == i]\n            if len(cluster_particles) > 0:\n                particle_centroids[i] = np.mean(cluster_particles, axis=0)\n        return particle_centroids\n\n    def hybrid_repulsion(self, position):\n        repulsion_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + repulsion_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def swarm_restructuring(self, particles):\n        centroid = np.mean(particles, axis=0)\n        distances = np.linalg.norm(particles - centroid, axis=1)\n        farthest_index = np.argmax(distances)\n        return particles[farthest_index]\n\n    def quantum_tunneling(self, position):\n        tunneling_vector = np.random.uniform(-1, 1, size=self.dim)\n        return position + tunneling_vector * np.random.uniform(0, 1, size=self.dim)\n\n    def update_archive(self, position, fitness):\n        if len(self.archive) < self.archive_size:\n            self.archive.append((position, fitness))\n        else:\n            worst_index = np.argmax([f for _, f in self.archive])\n            if fitness < self.archive[worst_index][1]:\n                self.archive[worst_index] = (position, fitness)\n\n    def __call__(self, func):\n        evaluations = 0\n        while evaluations < self.budget:\n            for i in range(self.swarm_size):\n                fitness = func(self.particles[i])\n                evaluations += 1\n                if fitness < self.best_fitness[i]:\n                    self.best_fitness[i] = fitness\n                    self.best_positions[i] = np.copy(self.particles[i])\n                    self.update_archive(self.particles[i], fitness)\n                    if fitness < self.global_best_fitness:\n                        self.global_best_fitness = fitness\n                        self.global_best_position = np.copy(self.particles[i])\n                # Modified velocity update with adaptive acceleration coefficients\n                self.velocities[i] = self.inertia_weight * self.velocities[i] + 0.5 * np.random.uniform(-1, 1, size=self.dim) * (1 - evaluations / self.budget) + 0.5 * (self.best_positions[i] - self.particles[i]) * (1 + evaluations / self.budget) + 0.5 * (self.global_best_position - self.particles[i]) * (1 - evaluations / self.budget) + 0.1 * np.random.uniform(-1, 1, size=self.dim)\n                velocity_centroids = self.velocity_clustering(self.velocities)\n                if np.random.rand() < self.velocity_clustering_rate:\n                    self.velocities[i] = velocity_centroids[np.argmin(np.linalg.norm(self.velocities[i] - velocity_centroids, axis=1))]\n                self.particles[i] += self.velocities[i]\n                self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                self.velocities[i] = np.clip(self.velocities[i], -1, 1)\n                # Levy flight for enhanced global search\n                if np.random.rand() < 0.1:\n                    self.particles[i] += self.levy_flight(self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Dynamic opposition-based learning with adaptive rate\n                if np.random.rand() < self.opposition_based_learning_rate * (1 - evaluations / self.budget) * (1 + self.dynamic_opposition_based_learning_rate * (evaluations / self.budget)):\n                    opposition_position = self.opposition_based_learning(self.particles[i])\n                    opposition_fitness = func(opposition_position)\n                    evaluations += 1\n                    if opposition_fitness < fitness:\n                        self.particles[i] = opposition_position\n                        self.best_fitness[i] = opposition_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], opposition_fitness)\n                self.dynamic_opposition_based_learning_rate *= self.dynamic_opposition_based_learning_rate_decay\n                # Cauchy mutation and Gaussian perturbation\n                if np.random.rand() < self.mutation_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_mutation_rate * (evaluations / self.budget)):\n                    mutated_position = self.cauchy_mutation(self.particles[i])\n                    mutated_position = self.gaussian_perturbation(mutated_position)\n                    mutated_fitness = func(mutated_position)\n                    evaluations += 1\n                    if mutated_fitness < fitness:\n                        self.particles[i] = mutated_position\n                        self.best_fitness[i] = mutated_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], mutated_fitness)\n                # Particle filtering for enhanced exploration\n                if np.random.rand() < self.particle_filtering_rate * (1 - evaluations / self.budget) * (1 + self.adaptive_particle_filtering_rate * (evaluations / self.budget)):\n                    particle_centroids = self.particle_filtering(self.particles)\n                    self.particles[i] = particle_centroids[np.argmin(np.linalg.norm(self.particles[i] - particle_centroids, axis=1))]\n                # Hybrid-repulsion mechanism\n                if np.random.rand() < self.hybrid_repulsion_rate * (1 - evaluations / self.budget):\n                    repulsion_position = self.hybrid_repulsion(self.particles[i])\n                    repulsion_fitness = func(repulsion_position)\n                    evaluations += 1\n                    if repulsion_fitness < fitness:\n                        self.particles[i] = repulsion_position\n                        self.best_fitness[i] = repulsion_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], repulsion_fitness)\n                # Swarm restructuring mechanism\n                if np.random.rand() < self.swarm_restructuring_rate * (1 - evaluations / self.budget):\n                    restructuring_position = self.swarm_restructuring(self.particles)\n                    restructuring_fitness = func(restructuring_position)\n                    evaluations += 1\n                    if restructuring_fitness < fitness:\n                        self.particles[i] = restructuring_position\n                        self.best_fitness[i] = restructuring_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], restructuring_fitness)\n                # Quantum tunneling for enhanced local search\n                if np.random.rand() < self.quantum_tunneling_rate * (1 - evaluations / self.budget):\n                    tunneling_position = self.quantum_tunneling(self.particles[i])\n                    tunneling_fitness = func(tunneling_position)\n                    evaluations += 1\n                    if tunneling_fitness < fitness:\n                        self.particles[i] = tunneling_position\n                        self.best_fitness[i] = tunneling_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], tunneling_fitness)\n                # Exploration-exploitation balance mechanism\n                if np.random.rand() < self.exploration_rate:\n                    self.particles[i] += np.random.uniform(-1, 1, size=self.dim)\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                else:\n                    self.particles[i] += 0.5 * (self.best_positions[i] - self.particles[i]) + 0.5 * (self.global_best_position - self.particles[i])\n                    self.particles[i] = np.clip(self.particles[i], self.lower_bound, self.upper_bound)\n                # Archive-based position update\n                if np.random.rand() < 0.05:\n                    archive_index = np.random.randint(len(self.archive))\n                    self.particles[i] = self.archive[archive_index][0]\n            # Modified simulated annealing with adaptive cooling\n            if evaluations % (self.swarm_size // 2) == 0:\n                for i in range(self.swarm_size // 2):\n                    new_position = np.copy(self.particles[i])\n                    new_position += np.random.uniform(-1, 1, size=self.dim)\n                    new_position = np.clip(new_position, self.lower_bound, self.upper_bound)\n                    new_fitness = func(new_position)\n                    evaluations += 1\n                    if new_fitness < self.best_fitness[i] or np.random.rand() < np.exp((self.best_fitness[i] - new_fitness) / self.temperature):\n                        self.particles[i] = new_position\n                        self.best_fitness[i] = new_fitness\n                        self.best_positions[i] = np.copy(self.particles[i])\n                        self.update_archive(self.particles[i], new_fitness)\n                    self.temperature *= self.cooling_rate * (1 - self.adaptive_cooling_rate * (evaluations / self.budget))\n            # Dynamic inertia weight\n            self.inertia_weight *= self.inertia_weight_damping_ratio\n        return self.global_best_position\n\n# Example usage:\ndef example_func(x):\n    return np.sum(x**2)\n\noptimizer = HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11(budget=1000, dim=10)\nresult = optimizer(example_func)\nprint(result)", "name": "HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11", "description": "Novel Metaheuristic Algorithm, Hybrid Swarm Optimizer with Adaptive Cooling, Levy Flight, and Opposition-Based Learning with Dynamic Inertia Weight, Self-Adaptive Mutation, and Velocity Clustering, incorporating a new \"Particle Filtering\" strategy, enhanced \"Archive\" strategy, and \"Dynamic Opposition-Based Learning Rate\" to further enhance convergence speed and diversity of the swarm, with modified velocity update, simulated annealing, and dynamic inertia weight, and a new \"Exploration-Exploitation\" balance mechanism, with refined adaptive cooling rate, dynamic opposition-based learning rate, and adaptive particle filtering rate, and a novel \"Hybrid-Repulsion\" mechanism, and a new \"Swarm Restructuring\" mechanism, and incorporating \"Quantum Tunneling\" for enhanced local search, with adaptive mutation rate and dynamic opposition-based learning rate, and a new \"Dynamic Opposition-Based Learning Rate Decay\" mechanism.", "configspace": "", "generation": 222, "fitness": 0.23983816408646877, "feedback": "The algorithm HybridSwarmOptimizerACLOBLDIWSAMV2PFRefinedV11 got an average Area over the convergence curve (AOCC, 1.0 is the best) score of 0.24 with standard deviation 0.20.", "error": "", "parent_id": "73057caa-68af-45bb-8345-89f928846769", "metadata": {"aucs": [0.6402039298598112, 0.72514905958211, 0.6175065144633836, 0.6457634481167651, 0.6003919734686368, 0.6835287345313714, 0.6302155607802402, 0.5998404823096456, 0.5572099759187963, 9.999999999998899e-05, 0.048962070544597, 0.0018442533160542007, 0.0010341109936902182, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.13767740517193472, 0.10253507337339562, 0.13376595627551235, 0.10318770774878483, 0.1119674021477054, 0.09601153494439407, 0.15519597640780836, 0.13507693717976288, 0.09039996655175897, 0.07724433424894683, 0.08540926807759408, 0.11842643679877551, 0.10826389014503857, 0.09451061514488013, 0.07955609436740418, 0.07939861902602185, 0.09257545024914016, 0.10337862403341858, 0.8863739170558738, 0.9370801703511664, 0.7600776329529341, 0.7075000785610862, 0.8948201347233677, 0.77379010117394, 0.906273483257864, 0.9084806348959552, 0.8843628704913108, 0.25484369738603496, 0.2595800238782152, 0.2514246882806931, 0.24406568597974865, 0.28972816635403653, 0.2853769144577354, 0.28744983958732717, 0.22313713221851839, 0.21406947590710756, 0.33136688662067026, 0.3761479232722812, 0.3291992801803525, 0.27461707644166367, 0.6435577439481217, 0.19807524140502608, 0.6154283515678511, 0.22156514699966434, 0.21994060661931558, 0.09105778207304249, 0.10957067472248616, 0.12213230092250471, 0.16842412146505337, 0.12389621579555732, 0.14218028947571815, 0.12791120073335638, 0.23789159891596534, 0.16216086202807622, 0.1663124179002602, 0.23626766101821484, 0.1376216850715415, 0.17317398412152651, 0.15733121727635513, 0.23650527593224202, 0.17887450425757034, 0.1845928597293196, 0.15126922925859088, 9.999999999998899e-05, 0.0007384593532405725, 9.999999999998899e-05, 0.0068494924085438225, 0.02094030698520255, 9.999999999998899e-05, 9.999999999998899e-05, 9.999999999998899e-05, 0.024205773459217705, 0.13197435395279167, 0.05451327872387446, 0.14445460373587937, 0.10596418498615645, 0.09214960485962531, 0.03699056341726559, 0.16664579028938953, 0.11420653802225278, 0.07889437116164721, 0.0741392934565076, 0.11142290003414657, 0.11281611456815244, 0.07302187755646394, 0.1125883345908385, 0.07225310701404342, 0.11022902286043479, 0.08970660057687296, 0.07967165260154929, 0.22582398564697792, 0.13331345143780582, 0.20509193206993082, 0.08703106823206985, 0.1834964743223989, 0.1357591898540279, 0.15464575216450727, 0.1164627897293925, 0.12491537755663595, 0.449409168198344, 0.4327217421969367, 0.43473693132304136, 0.4372037616271558, 0.43382497897861416, 0.452183982782307, 0.4467733255500491, 0.4619107983076971, 0.49871728625845946, 0.11282374451284072, 0.11226560369921335, 0.12621581778603264, 0.23582099109168486, 0.10806913038171884, 0.1343504608251369, 0.10800781834829831, 0.10782421810404574, 0.09091710156793853, 0.30547410331514746, 0.179674598303311, 0.1676876834120813, 0.20018082388443503, 0.3641448810163602, 0.2144810732872403, 0.27011958163772176, 0.16149158591108737, 0.1884357931887093, 0.25827954001838793, 0.3300123963427153, 0.3595196913507337, 0.26100092842878264, 0.3165511304145461, 0.31539945900175215, 0.2653662753288927, 0.2816799621044661, 0.25249221349019757, 0.2354331058455026, 0.2622461858126156, 0.2648652033945137, 0.18077924583647587, 0.24449845241604173, 0.27513594416054943, 0.20449998091397947, 0.23523245074361587, 0.20333166222139842, 0.21033701052659548, 0.21049718343406576, 0.21558842710975967, 0.25901415218380897, 0.26366548375988663, 0.23157191728324467, 0.22377732221637403, 0.21029601593902758, 0.21674656511528634, 0.19941856776900713, 0.186561441919174, 0.18257576164934997, 0.19009199070326244, 0.19721379443562437, 0.17461604886608018, 0.16947856013622353, 0.1785961933849436, 0.17371458179443544, 0.18024267460559096, 0.18647061102562135, 0.6848693414616751, 0.5845240927619891, 0.1987440171366498, 0.1989316455957154, 0.7744709213907301, 0.14725521620627968, 0.6959590408669158, 0.557495759177767, 0.20861723229031837, 0.4215330148482671, 0.43597214056028244, 0.4612339020146885, 0.16776147790574814, 0.16759050234286244, 0.31868424947819796, 0.3109480193104398, 0.19741541321526945, 0.19809031423214796, 0.18443366990320376, 0.23036050321992585, 0.19000877663937255, 0.17493630223479484, 0.18008122854140418, 0.1896373338566868, 0.1823893080542882, 0.09074887243832841, 0.07187259311619454, 0.087880132788827, 0.08551039513880132, 0.0826288581206931, 0.08866780687757514, 0.09258158427673513, 0.0914062484032725, 0.08578397442260899]}, "mutation_prompt": null}
